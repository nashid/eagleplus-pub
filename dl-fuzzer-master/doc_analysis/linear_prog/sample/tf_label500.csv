API,Arg,Descp,Normalized_descp,dtype,tensor_t,structure,shape,ndim,range,enum
tf.keras.layers.LocallyConnected1D,implementation,"implementation mode, either `1`, `2`, or `3`.`1` loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops.`2` stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops.`3` stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply.How to choose:`1`: large, dense models,`2`: small models,`3`: large, sparse models,where ""large"" stands for large input/output activations (i.e. many `filters`, `input_filters`, large `input_size`,`output_size`), and ""sparse"" stands for few connections between inputs and outputs, i.e. small ratio`filters * input_filters * kernel_size / (input_size * strides)`, where inputs to and outputs of the layer are assumed to have shapes`(input_size, input_filters)`, `(output_size, filters)`respectively.It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM.Also, only `padding=""valid""` is supported by `implementation=1`.",50X potentially at the expense of RAM Also only PARAM QSTR is supported by implementation CONSTANT_NUM,,,,,,,
tf.range,limit,"A 0-D `Tensor` (scalar). Upper limit of sequence, exclusive. If None, defaults to the value of `start` while the first entry of the range defaults to 0.",A CONSTANT_NUM D D_STRUCTURE BSTR,,D_STRUCTURE,,,CONSTANT_NUM,,
tf.nn.conv1d_transpose,input,"A 3-D `Tensor` of type `float` and shape`[batch, in_width, in_channels]` for `NWC` data format or`[batch, in_channels, in_width]` for `NCW` data format.",A CONSTANT_NUM D D_STRUCTURE of type D_TYPE and shape BSTR for QSTR data format or BSTR for QSTR data format,D_TYPE,D_STRUCTURE,,BSTR,CONSTANT_NUM,,
tf.random.stateless_truncated_normal,stddev,"A 0-D Tensor or Python value of type `dtype`. The standard deviation of the normal distribution, before truncation.",A CONSTANT_NUM D D_STRUCTURE or Python value of type PARAM,PARAM,D_STRUCTURE,,,CONSTANT_NUM,,
tf.math.segment_min,segment_ids,"A `Tensor`. Must be one of the following types: `int32`, `int64`. A 1-D tensor whose size is equal to the size of `data`'s first dimension.  Values should be sorted and can be repeated.",A CONSTANT_NUM D D_STRUCTURE whose size is equal to the size of PARAMs first dimension,,D_STRUCTURE,,&PARAM,CONSTANT_NUM,,
tf.sparse.segment_sqrt_n,indices,A 1-D `Tensor` with indices into `data`. Has same rank as`segment_ids`.,A CONSTANT_NUM D D_STRUCTURE with indices into PARAM,,D_STRUCTURE,,,CONSTANT_NUM,,
tf.nn.atrous_conv2d_transpose,filters,"A 4-D `Tensor` with the same type as `value` and shape`[filter_height, filter_width, out_channels, in_channels]`. `filters`'`in_channels` dimension must match that of `value`. Atrous convolution is equivalent to standard convolution with upsampled filters with effective height `filter_height + (filter_height - 1) * (rate - 1)` and effective width `filter_width + (filter_width - 1) * (rate - 1)`, produced by inserting `rate - 1` zeros along consecutive elements across the`filters`' spatial dimensions.",A CONSTANT_NUM D D_STRUCTURE with the same type as PARAM and shape BSTR,&PARAM,D_STRUCTURE,,BSTR,CONSTANT_NUM,,
tf.image.non_max_suppression_overlaps,overlaps,"A 2-D float `Tensor` of shape `[num_boxes, num_boxes]`.",A CONSTANT_NUM D D_TYPE D_STRUCTURE of shape BSTR,,D_STRUCTURE,,BSTR,CONSTANT_NUM,,
tf.image.non_max_suppression_overlaps,scores,A 1-D float `Tensor` of shape `[num_boxes]` representing a single score corresponding to each box (each row of boxes).,A CONSTANT_NUM D D_TYPE D_STRUCTURE of shape BSTR representing a single score corresponding to each box BSTR,,D_STRUCTURE,,BSTR,CONSTANT_NUM,,
tf.nn.batch_norm_with_global_normalization,mean,"A 1D mean Tensor with size matching the last dimension of t. This is the first output from tf.nn.moments, or a saved moving average thereof.",A CONSTANT_NUM D mean D_STRUCTURE with size matching the last dimension of t This is the first output from tf nn moments or a saved moving average thereof,,D_STRUCTURE,,,CONSTANT_NUM,,
tf.zeros_like,input,A `Tensor`.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.expand_dims,input,A `Tensor`.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.math.l2_normalize,x,A `Tensor`.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.bitcast,input,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int64`, `int32`, `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `complex64`, `complex128`, `qint8`, `quint8`, `qint16`, `quint16`, `qint32`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.debugging.check_numerics,tensor,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.math.betainc,a,"A `Tensor`. Must be one of the following types: `float32`, `float64`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.nn.selu,features,"A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.linspace,num,"A `Tensor`. Must be one of the following types: `int32`, `int64`. 0-D tensor. Number of values to generate.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.space_to_batch_nd,paddings,"A `Tensor`. Must be one of the following types: `int32`, `int64`. 2-D with shape `[M, 2]`, all values must be >= 0.`paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension`i + 1`, which corresponds to spatial dimension `i`.  It is required that`block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.This operation is equivalent to the following steps: Zero-pad the start and end of dimensions `[1, ..., M]` of the input according to `paddings` to produce `padded` of shape `padded_shape`.Reshape `padded` to `reshaped_padded` of shape:[batch] + [padded_shape[1] / block_shape[0],  block_shape[0], ..., padded_shape[M] / block_shape[M-1], block_shape[M-1]] + remaining_shapePermute dimensions of `reshaped_padded` to produce`permuted_reshaped_padded` of shape:block_shape + [batch] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shapeReshape `permuted_reshaped_padded` to flatten `block_shape` into the batch dimension, producing an output tensor of shape:[batch * prod(block_shape)] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape Some examples:(1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and   `paddings = [[0, 0], [0, 0]]`:",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.math.segment_min,segment_ids,"A `Tensor`. Must be one of the following types: `int32`, `int64`. A 1-D tensor whose size is equal to the size of `data`'s first dimension.  Values should be sorted and can be repeated.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.image.sample_distorted_bounding_box,image_size,"A `Tensor`. Must be one of the following types: `uint8`, `int8`,`int16`, `int32`, `int64`. 1-D, containing `[height, width, channels]`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.math.polygamma,x,A `Tensor`. Must have the same type as `a`.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.linalg.cross,b,"A `Tensor`. Must have the same type as `a`. Another tensor, of same type and shape as `a`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.linalg.triangular_solve,rhs,"A `Tensor`. Must have the same type as `matrix`. Shape is `[..., M, K]`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.dtypes.complex,imag,A `Tensor`. Must have the same type as `real`.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.linspace,stop,A `Tensor`. Must have the same type as `start`. 0-D tensor. Last entry in the range.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.bitwise.right_shift,y,A `Tensor`. Must have the same type as `x`.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.math.greater,y,A `Tensor`. Must have the same type as `x`.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.space_to_batch,input,"A `Tensor`. N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`, where spatial_shape has `M` dimensions.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.tensor_scatter_nd_add,tensor,A `Tensor`. Tensor to copy/update.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.keras.backend.binary_crossentropy,output,A tensor.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.keras.backend.local_conv1d,kernel_size,"a tuple of a single integer, specifying the length of the 1D convolution window.",a D_STRUCTURE of a single D_TYPE specifying the length of the CONSTANT_NUM D convolution window,D_TYPE,,D_STRUCTURE,[1],1,"[0,inf)",
tf.gradients,stop_gradients,Optional. A `Tensor` or list of tensors not to differentiate through.,A D_STRUCTURE of D_STRUCTURE not to differentiate through,,D_STRUCTURE,D_STRUCTURE,,,,
tf.parallel_stack,values,A list of `Tensor` objects with the same shape and type.,A D_STRUCTURE of D_STRUCTURE objects with the same shape and type,,D_STRUCTURE,D_STRUCTURE,,,,
tf.io.decode_proto,field_names,"A list of `strings`. List of strings containing proto field names. An extension field can be decoded by using its full name, e.g. EXT_PACKAGE.EXT_FIELD_NAME.",A D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
tf.graph_util.import_graph_def,return_elements,A list of strings containing operation names in`graph_def` that will be returned as `Operation` objects; and/or tensor names in `graph_def` that will be returned as `Tensor` objects.,A D_STRUCTURE of D_TYPE containing operation names in PARAM that will be returned as QSTR objects and or D_STRUCTURE names in PARAM that will be returned as D_STRUCTURE objects,D_TYPE,,D_STRUCTURE,,,,
tf.nn.fractional_avg_pool,pooling_ratio,"A list of `floats` that has length >= 4.  Pooling ratio for each dimension of `value`, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling ratio on height and width dimensions respectively.",A D_STRUCTURE of D_TYPE that has length REXPR,D_TYPE,,D_STRUCTURE,[REXPR],1,,
tf.nn.erosion2d,dilations,"A list of `ints` that has length `>= 4`. 1-D of length 4. The input stride for atrous morphological dilation. Must be: `[1, rate_height, rate_width, 1]`.",A D_STRUCTURE of D_TYPE that has length REXPR,D_TYPE,,D_STRUCTURE,[REXPR],1,,
tf.extract_volume_patches,strides,"A list of `ints` that has length `>= 5`. 1-D of length 5. How far the centers of two consecutive patches are in`input`. Must be: `[1, stride_planes, stride_rows, stride_cols, 1]`.",A D_STRUCTURE of D_TYPE that has length REXPR,D_TYPE,,D_STRUCTURE,[REXPR],1,,
tf.keras.layers.average,inputs,A list of input tensors (at least 2).,A D_STRUCTURE of input D_STRUCTURE BSTR,,D_STRUCTURE,D_STRUCTURE,,,,
tf.control_dependencies,control_inputs,"A list of `Operation` or `Tensor` objects which must be executed or computed before running the operations defined in the context. Can also be `None` to clear the control dependencies. If eager execution is enabled, any callable object in the `control_inputs` list will be called.",A D_STRUCTURE of QSTR or D_STRUCTURE objects which must be executed or computed before running the operations defined in the context,,D_STRUCTURE,D_STRUCTURE,,,,
tf.nn.nce_loss,weights,"A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`objects whose concatenation along dimension 0 has shape [num_classes, dim].  The (possibly-partitioned) class embeddings.",A D_STRUCTURE of shape BSTR or a D_STRUCTURE of D_STRUCTUREobjects whose concatenation along dimension CONSTANT_NUM has shape BSTR,,D_STRUCTURE,D_STRUCTURE,BSTR,,,
tf.nn.sampled_softmax_loss,weights,"A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`objects whose concatenation along dimension 0 has shape [num_classes, dim].  The (possibly-sharded) class embeddings.",A D_STRUCTURE of shape BSTR or a D_STRUCTURE of D_STRUCTUREobjects whose concatenation along dimension CONSTANT_NUM has shape BSTR,,D_STRUCTURE,D_STRUCTURE,BSTR,,,
tf.quantization.fake_quant_with_min_max_vars_gradient,min,A `Tensor` of type `float32`.,A D_STRUCTURE of type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient,max,A `Tensor` of type `float32`.,A D_STRUCTURE of type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.image.draw_bounding_boxes,colors,A `Tensor` of type `float32`. 2-D. A list of RGBA colors to cycle through for the boxes.,A D_STRUCTURE of type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.math.in_top_k,predictions,A `Tensor` of type `float32`. A `batch_size` x `classes` tensor.,A D_STRUCTURE of type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.audio.encode_wav,sample_rate,A `Tensor` of type `int32`. Scalar containing the sample frequency.,A D_STRUCTURE of type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.io.decode_csv,records,A `Tensor` of type `string`. Each string is a record/row in the csv and all records should have the same format.,A D_STRUCTURE of type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.math.cumulative_logsumexp,axis,"A `Tensor` of type `int32` or `int64` (default: 0). Must be in the range `[-rank(x), rank(x))`.",A D_STRUCTURE of type D_TYPE default CONSTANT_NUM,,D_STRUCTURE,,,,,
tf.foldr,elems,"A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension.  The nested sequence of the resulting slices will be the first argument to `fn`.",A D_STRUCTURE or BSTR D_STRUCTURE of D_STRUCTURE each of which will be unpacked along their first dimension,,D_STRUCTURE,D_STRUCTURE,,,,
tf.ragged.stack_dynamic_partitions,data,A `Tensor` or `RaggedTensor` containing the values to stack.,A D_STRUCTURE or QSTR containing the values to stack,,D_STRUCTURE,,,,,
tf.math.scalar_mul,x,A `Tensor` or `IndexedSlices` to be scaled.,A D_STRUCTURE or QSTR to be scaled,,D_STRUCTURE,,,,,
tf.strings.ngrams,data,A Tensor or RaggedTensor containing the source data for the ngrams.,A D_STRUCTURE or RaggedTensor containing the source data for the ngrams,,D_STRUCTURE,,,,,
tf.math.equal,x,A `tf.Tensor` or `tf.SparseTensor` or `tf.IndexedSlices`.,A D_STRUCTURE or tf IndexedSlices,,D_STRUCTURE,,,,,
tf.keras.backend.var,x,A tensor or variable.,A D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.cumprod,x,A tensor or variable.,A D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.categorical_crossentropy,output,"A tensor resulting from a softmax (unless `from_logits` is True, in which case `output` is expected to be the logits).",A D_STRUCTURE resulting from a softmax unless PARAM is CONSTANT_BOOL in which case QSTR is expected to be the logits,,D_STRUCTURE,,,,,
tf.keras.backend.local_conv2d,output_shape,"a tuple with (output_row, output_col).",a D_STRUCTURE with BSTR,,,D_STRUCTURE,BSTR,,,
tf.math.unsorted_segment_sqrt_n,data,A `Tensor` with floating point or complex dtype.,A D_STRUCTURE with D_TYPE dtype,D_TYPE,D_STRUCTURE,,,,,
tf.keras.backend.binary_crossentropy,target,A tensor with the same shape as `output`.,A D_STRUCTURE with the same shape as PARAM,,D_STRUCTURE,,&PARAM,,,
tf.nn.sampled_softmax_loss,remove_accidental_hits,"A `bool`.  whether to remove ""accidental hits"" where a sampled class equals one of the target classes.  Default is True.",A D_TYPE,D_TYPE,,,,0,,
tf.strings.unicode_transcode,input_encoding,"A `string`. Text encoding of the input strings. This is any of the encodings supported by ICU ucnv algorithmic converters. Examples: `""UTF-16"", ""US ASCII"", ""UTF-8""`.",A D_TYPE,D_TYPE,,,,0,,
tf.nn.conv3d_transpose,data_format,A string. 'NDHWC' and 'NCDHW' are supported.,A D_TYPE,D_TYPE,,,,0,,
tf.nn.conv1d_transpose,data_format,A string. `'NWC'` and `'NCW'` are supported.,A D_TYPE,D_TYPE,,,,0,,
tf.nn.max_pool,data_format,"A string. Specifies the channel dimension. For N=1 it can be either ""NWC"" (default) or ""NCW"", for N=2 it can be either ""NHWC"" (default) or ""NCHW"" and for N=3 either ""NDHWC"" (default) or ""NCDHW"".",A D_TYPE,D_TYPE,,,,0,,
tf.einsum,equation,"a `str` describing the contraction, in the same format as`numpy.einsum`.",a D_TYPE describing the contraction in the same format as numpy einsum,D_TYPE,,,,0,,
tf.estimator.regressor_parse_example_spec,label_key,A string identifying the label. It means tf.Example stores labels with this key.,A D_TYPE identifying the label,D_TYPE,,,,0,,
tf.keras.backend.foldl,name,A string name for the foldl node in the graph,A D_TYPE name for the foldl node in the graph,D_TYPE,,,,0,,
tf.keras.backend.foldr,name,A string name for the foldr node in the graph,A D_TYPE name for the foldr node in the graph,D_TYPE,,,,0,,
tf.keras.layers.Conv3DTranspose,data_format,"A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs.`channels_last` corresponds to inputs with shape`(batch, depth, height, width, channels)` while `channels_first`corresponds to inputs with shape`(batch, channels, depth, height, width)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be ""channels_last"".",A D_TYPE one of QSTR BSTR or QSTR,D_TYPE,,,,0,,QSTR
tf.keras.layers.AveragePooling3D,data_format,"A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs.`channels_last` corresponds to inputs with shape`(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`while `channels_first` corresponds to inputs with shape`(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be ""channels_last"".",A D_TYPE one of QSTR BSTR or QSTR,D_TYPE,,,,0,,QSTR
tf.nn.dilation2d,data_format,"A `string`, only `""NHWC""` is currently supported.",A D_TYPE only QSTR is currently supported,D_TYPE,,,,0,,
tf.image.non_max_suppression_overlaps,overlap_threshold,A float representing the threshold for deciding whether boxes overlap too much with respect to the provided overlap values.,A D_TYPE representing the threshold for deciding whether boxes overlap too much with respect to the provided overlap values,D_TYPE,,,,0,,
tf.image.combined_non_max_suppression,iou_threshold,A float representing the threshold for deciding whether boxes overlap too much with respect to IOU.,A D_TYPE representing the threshold for deciding whether PARAM overlap too much with respect to IOU,D_TYPE,,,,0,,
tf.data.experimental.dense_to_ragged_batch,drop_remainder,"(Optional.) A `tf.bool` scalar `tf.Tensor`, representing whether the last batch should be dropped in the case it has fewer than`batch_size` elements; the default behavior is not to drop the smaller batch.",A D_TYPE scalar D_STRUCTURE representing whether the last batch should be dropped in the case it has fewer than PARAM elements the default behavior is not to drop the smaller batch,D_TYPE,D_STRUCTURE,,,0,,
tf.strings.format,template,A string template to format tensor values into.,A D_TYPE template to format D_STRUCTURE values into,D_TYPE,,,,0,,
tf.keras.backend.random_uniform,maxval,"A float, upper boundary of the uniform distribution to draw samples.",A D_TYPE upper boundary of the uniform distribution to draw samples,D_TYPE,,,,0,,
tf.feature_column.numeric_column,default_value,"A single value compatible with `dtype` or an iterable of values compatible with `dtype` which the column takes on during`tf.Example` parsing if data is missing. A default value of `None` will cause `tf.io.parse_example` to fail if an example does not contain this column. If a single value is provided, the same value will be applied as the default value for every item. If an iterable of values is provided, the shape of the `default_value` should be equal to the given `shape`.",A default value of QSTR will cause tf io parse_example to fail if an example does not contain this column,,,,,,,
tf.data.experimental.make_batched_features_dataset,reader,A function or class that can be called with a `filenames` tensor and (optional) `reader_args` and returns a `Dataset` of `Example` tensors. Defaults to `tf.data.TFRecordDataset`.,A function or class that can be called with a QSTR D_STRUCTURE and BSTR PARAM and returns a QSTR of QSTR D_STRUCTURE,,,,,,,
tf.estimator.add_metrics,metric_fn,"A function which should obey the following signature: Args: can only have following four arguments in any order:predictions: Predictions `Tensor` or dict of `Tensor` created by given`estimator`.features: Input `dict` of `Tensor` objects created by `input_fn` which is given to `estimator.evaluate` as an argument.labels:  Labels `Tensor` or dict of `Tensor` created by `input_fn`which is given to `estimator.evaluate` as an argument.config: config attribute of the `estimator`.Returns: Dict of metric results keyed by name. Final metrics are a union of this and `estimator's` existing metrics. If there is a name conflict between this and `estimator`s existing metrics, this will override the existing one. The values of the dict are the results of calling a metric function, namely a `(metric_tensor, update_op)` tuple. ",A function which should obey the following signature Args can only have following four arguments in any order predictions Predictions D_STRUCTURE of D_STRUCTURE created by given PARAM features Input D_STRUCTURE of D_STRUCTURE objects created by QSTR which is given to PARAM evaluate as an argument labels Labels D_STRUCTURE of D_STRUCTURE created by QSTR which is given to PARAM evaluate as an argument config config attribute of the PARAM Returns D_STRUCTURE of metric results keyed by name,,,,,,,
tf.data.experimental.make_csv_dataset,shuffle_buffer_size,"Buffer size to use for shuffling. A large buffer size ensures better shuffling, but increases memory usage and startup time.",A large buffer size ensures better shuffling but increases memory usage and startup time,,,,,,,
tf.nn.max_pool1d,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.math.reciprocal_no_nan,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.nn.selu,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.math.cosh,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.math.is_nan,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.identity_n,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.dynamic_stitch,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.bitwise.bitwise_or,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.linalg.cross,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.nn.relu6,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.unstack,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.math.unsorted_segment_sqrt_n,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.strings.regex_replace,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.rank,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.nn.sampled_softmax_loss,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.random.stateless_truncated_normal,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.math.less_equal,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.image.grayscale_to_rgb,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.math.unsorted_segment_mean,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.math.squared_difference,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.io.decode_png,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.truncatemod,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.math.unsorted_segment_prod,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.extract_volume_patches,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.math.segment_prod,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.debugging.assert_type,name,"A name for this operation. Defaults to ""assert_type""",A name for this operation,string,,,,0,,
tf.nn.separable_conv2d,name,A name for this operation (optional).,A name for this operation BSTR,string,,,,0,,
tf.image.adjust_jpeg_quality,name,A name for this operation (optional).,A name for this operation BSTR,string,,,,0,,
tf.debugging.assert_equal,name,"A name for this operation (optional).  Defaults to ""assert_equal"".",A name for this operation BSTR,string,,,,0,,
tf.debugging.assert_greater_equal,name,"A name for this operation (optional).  Defaults to ""assert_greater_equal"".",A name for this operation BSTR,string,,,,0,,
tf.debugging.assert_none_equal,name,"A name for this operation (optional).  Defaults to ""assert_none_equal"".",A name for this operation BSTR,string,,,,0,,
tf.debugging.assert_rank_at_least,name,"A name for this operation (optional).  Defaults to ""assert_rank_at_least"".",A name for this operation BSTR,string,,,,0,,
tf.debugging.assert_integer,name,"A name for this operation (optional). Defaults to ""assert_integer"".",A name for this operation BSTR,string,,,,0,,
tf.math.is_strictly_increasing,name,"A name for this operation (optional). Defaults to ""is_strictly_increasing""",A name for this operation BSTR,string,,,,0,,
tf.ragged.boolean_mask,name,A name prefix for the returned tensor (optional).,A name prefix for the returned D_STRUCTURE BSTR,string,,,,0,,
tf.data.experimental.make_csv_dataset,label_name,"A optional string corresponding to the label column. If provided, the data for this column is returned as a separate `Tensor` from the features dictionary, so that the dataset complies with the format expected by a `tf.Estimator.train` or `tf.Estimator.evaluate` input function.",A optional D_TYPE corresponding to the label column,D_TYPE,,,,CONSTANT_NUM,,
tf.keras.mixed_precision.experimental.set_policy,policy,"A Policy, or a string that will be converted to a Policy..",A Policy or a D_TYPE that will be converted to a Policy,D_TYPE,,,,0,,
tf.random.categorical,seed,A Python integer. Used to create a random seed for the distribution. See `tf.compat.v1.set_random_seed` for behavior.,A Python D_TYPE,D_TYPE,,,,0,,
tf.image.random_flip_left_right,seed,A Python integer. Used to create a random seed. See`tf.compat.v1.set_random_seed` for behavior.,A Python D_TYPE,D_TYPE,,,,0,,
tf.keras.initializers.he_uniform,seed,A Python integer. Used to seed the random generator.,A Python D_TYPE,D_TYPE,,,,0,,
tf.ragged.stack,axis,"A python integer, indicating the dimension along which to stack. (Note: Unlike `tf.stack`, the `axis` parameter must be statically known.) Negative values are supported only if the rank of at least one`values` value is statically known.",A python D_TYPE indicating the dimension along which to stack,D_TYPE,,,,0,,
tf.estimator.train_and_evaluate,train_spec,A `TrainSpec` instance to specify the training specification.,A QSTR instance to specify the training specification,,,,,,,
tf.graph_util.import_graph_def,graph_def,A `GraphDef` proto containing operations to be imported into the default graph.,A QSTR proto containing operations to be imported into the default graph,,,,,,,
tf.math.in_top_k,predictions,A `Tensor` of type `float32`. A `batch_size` x `classes` tensor.,A QSTR x QSTR D_STRUCTURE,,D_STRUCTURE,,"[QSTR,QSTR]",,,
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",A RNN cell instance or a D_STRUCTURE of RNN cell instances,,,,,,,
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",A RNN cell is a class that has A call BSTR method returning BSTR,,,,,,,
tf.image.adjust_brightness,delta,A scalar. Amount to add to the pixel values.,A scalar,,,,,0,,
tf.signal.hann_window,window_length,A scalar `Tensor` indicating the window length to generate.,A scalar D_STRUCTURE indicating the window length to generate,int,D_STRUCTURE,,,0,"[0,inf)",
tf.one_hot,off_value,A scalar defining the value to fill in output when `indices[j] != i`. (default: 0),A scalar defining the value to fill in output when PARAM BSTR i,,,,,0,,
tf.nn.embedding_lookup_sparse,params,"A single tensor representing the complete embedding tensor, or a list of P tensors all of same shape except for the first dimension, representing sharded embedding tensors.  Alternatively, a`PartitionedVariable`, created by partitioning along dimension 0. Each element must be appropriately sized for `""div""` `partition_strategy`.",A single D_STRUCTURE representing the complete embedding D_STRUCTURE of P D_STRUCTURE all of same shape except for the first dimension representing sharded embedding D_STRUCTURE,,D_STRUCTURE,,,,,
tf.feature_column.numeric_column,default_value,"A single value compatible with `dtype` or an iterable of values compatible with `dtype` which the column takes on during`tf.Example` parsing if data is missing. A default value of `None` will cause `tf.io.parse_example` to fail if an example does not contain this column. If a single value is provided, the same value will be applied as the default value for every item. If an iterable of values is provided, the shape of the `default_value` should be equal to the given `shape`.",A single value compatible with PARAM or an D_STRUCTURE of values compatible with PARAM which the column takes on during tf Example parsing if data is missing,dtype,,D_STRUCTURE,,,,
tf.tpu.experimental.initialize_tpu_system,cluster_resolver,"A tf.distribute.cluster_resolver.TPUClusterResolver, which provides information about the TPU cluster.",A tf distribute cluster_resolver TPUClusterResolver which provides information about the TPU cluster,,,,,,,
tf.feature_column.numeric_column,key,"A unique string identifying the input feature. It is used as the column name and the dictionary key for feature parsing configs, feature`Tensor` objects, and feature columns.",A unique D_TYPE identifying the input feature,D_TYPE,,,,0,,
tf.keras.preprocessing.sequence.skipgrams,sequence,"A word sequence (sentence), encoded as a list     of word indices (integers). If using a `sampling_table`,     word indices are expected to match the rank     of the words in a reference dataset (e.g. 10 would encode     the 10-th most frequently occurring token).     Note that index 0 is expected to be a non-word and will be skipped.",A word D_STRUCTURE BSTR,,,D_STRUCTURE,,,,
tf.keras.layers.Conv3D,activation,"Activation function to use. If you don't specify anything, no activation is applied (ie. ""linear"" activation: `a(x) = x`).",Activation function to use,,,,,,,
tf.required_space_to_batch_paddings,base_paddings,"Optional int32 Tensor of shape [N, 2].  Specifies the minimum amount of padding to use.  All elements must be >= 0.  If not specified, defaults to 0.",All elements must be REXPR,,,,,,"[0,inf)",
tf.estimator.classifier_parse_example_spec,feature_columns,An iterable containing all feature columns. All items should be instances of classes derived from `FeatureColumn`.,All items should be instances of classes derived from QSTR,,,,,,,
tf.keras.layers.DenseFeatures,feature_columns,"An iterable containing the FeatureColumns to use as inputs to your model. All items should be instances of classes derived from `DenseColumn` such as `numeric_column`, `embedding_column`,`bucketized_column`, `indicator_column`. If you have categorical features, you can wrap them with an `embedding_column` or`indicator_column`.",All items should be instances of classes derived from QSTR such as QSTR,,,,,,,
tf.nn.embedding_lookup_sparse,params,"A single tensor representing the complete embedding tensor, or a list of P tensors all of same shape except for the first dimension, representing sharded embedding tensors.  Alternatively, a`PartitionedVariable`, created by partitioning along dimension 0. Each element must be appropriately sized for `""div""` `partition_strategy`.",Alternatively a QSTR created by partitioning along dimension CONSTANT_NUM,,,,,,,
tf.image.adjust_brightness,delta,A scalar. Amount to add to the pixel values.,Amount to add to the pixel values,numeric,,,,0,"[0,inf)",
tf.estimator.classifier_parse_example_spec,feature_columns,An iterable containing all feature columns. All items should be instances of classes derived from `FeatureColumn`.,An D_STRUCTURE containing all feature columns,,,D_STRUCTURE,,,,
tf.keras.layers.DenseFeatures,feature_columns,"An iterable containing the FeatureColumns to use as inputs to your model. All items should be instances of classes derived from `DenseColumn` such as `numeric_column`, `embedding_column`,`bucketized_column`, `indicator_column`. If you have categorical features, you can wrap them with an `embedding_column` or`indicator_column`.",An D_STRUCTURE containing the FeatureColumns to use as inputs to your model,,,D_STRUCTURE,,,,
tf.random.fixed_unigram_candidate_sampler,seed,An `int`. An operation-specific seed. Default is 0.,An D_TYPE,D_TYPE,,,,0,,
tf.unstack,num,An `int`. The length of the dimension `axis`. Automatically inferred if`None` (the default).,An D_TYPE,D_TYPE,,,,0,,
tf.random.learned_unigram_candidate_sampler,range_max,An `int`. The number of possible classes.,An D_TYPE,D_TYPE,,,,0,,
tf.nn.sampled_softmax_loss,num_classes,An `int`. The number of possible classes.,An D_TYPE,D_TYPE,,,,0,,
tf.gather,batch_dims,An `integer`.  The number of batch dimensions.  Must be less than `rank(indices)`.,An D_TYPE,D_TYPE,,,,0,,
tf.slice,begin,An `int32` or `int64` `Tensor`.,An D_TYPE D_STRUCTURE,D_TYPE,D_STRUCTURE,,,,,
tf.strided_slice,new_axis_mask,An `int32` mask.,An D_TYPE mask,D_TYPE,,,,,,
tf.keras.backend.in_top_k,k,"An `int`, number of top elements to consider.",An D_TYPE number of top elements to consider,D_TYPE,,,,0,"[0,inf)",
tf.keras.layers.LocallyConnected1D,kernel_size,"An integer or tuple/list of a single integer, specifying the length of the 1D convolution window.",An D_TYPE or D_STRUCTURE of a single D_TYPE specifying the length of the CONSTANT_NUM D convolution window,D_TYPE,,D_STRUCTURE,[1],0;1,"[0,inf)",
tf.nn.conv1d,stride,An int or list of `ints` that has length `1` or `3`.  The number of entries by which the filter is moved right at each step.,An D_TYPE or D_STRUCTURE of D_TYPE that has length CONSTANT_NUM,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
tf.nn.conv2d_transpose,strides,"An int or list of `ints` that has length `1`, `2` or `4`.  The stride of the sliding window for each dimension of `input`. If a single value is given it is replicated in the `H` and `W` dimension. By default the `N` and `C` dimensions are set to 0. The dimension order is determined by the value of `data_format`, see below for details.",An D_TYPE or D_STRUCTURE of D_TYPE that has length CONSTANT_NUM,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
tf.nn.fractional_max_pool,pooling_ratio,"An int or list of `ints` that has length `1`, `2` or `4`. Pooling ratio for each dimension of `value`, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling ratio on height and width dimensions respectively.",An D_TYPE or D_STRUCTURE of D_TYPE that has length CONSTANT_NUM,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
tf.nn.conv1d_transpose,dilations,"An int or list of `ints` that has length `1` or `3` which defaults to 1. The dilation factor for each dimension of input. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. Dilations in the batch and depth dimensions must be 1.",An D_TYPE or D_STRUCTURE of D_TYPE that has length CONSTANT_NUM which defaults to CONSTANT_NUM,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
tf.signal.inverse_stft,frame_step,An integer scalar `Tensor`. The number of samples to step.,An D_TYPE scalar D_STRUCTURE,D_TYPE,D_STRUCTURE,,,0,,
tf.feature_column.embedding_column,dimension,"An integer specifying dimension of the embedding, must be > 0.",An D_TYPE specifying dimension of the embedding must be REXPR,D_TYPE,,,,0,,
tf.keras.backend.std,axis,"An integer, the axis to compute the standard deviation.",An D_TYPE the axis to compute the standard deviation,D_TYPE,,,,0,,
tf.io.decode_proto,field_names,"A list of `strings`. List of strings containing proto field names. An extension field can be decoded by using its full name, e.g. EXT_PACKAGE.EXT_FIELD_NAME.",An extension field can be decoded by using its full PARAM e g,,,,,,,
tf.nn.conv_transpose,input,"An N+2 dimensional `Tensor` of shape`[batch_size] + input_spatial_shape + [in_channels]` if data_format does not start with ""NC"" (default), or`[batch_size, in_channels] + input_spatial_shape` if data_format starts with ""NC"". It must be one of the following types:`half`, `bfloat16`, `float32`, `float64`.",An N CONSTANT_NUM dimensional D_STRUCTURE of shape BSTR input_spatial_shape BSTR if PARAM does not start with QSTR BSTR or BSTR input_spatial_shape QSTR NC,,D_STRUCTURE,,,>=CONSTANT_NUM,,
tf.random.fixed_unigram_candidate_sampler,seed,An `int`. An operation-specific seed. Default is 0.,An operation specific seed,,,,,,,
tf.image.random_hue,seed,An operation-specific seed. It will be used in conjunction with the graph-level seed to determine the real seeds that will be used in this operation. Please see the documentation of set_random_seed for its interaction with the graph-level random seed.,An operation specific seed,,,,,,,
tf.nn.depthwise_conv2d_backprop_input,dilations,"An optional list of `ints`. Defaults to `[1, 1, 1, 1]`. 1-D tensor of length 4.  The dilation factor for each dimension of`input`. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of`data_format`, see above for details. Dilations in the batch and depth dimensions must be 1.",An optional D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
tf.io.encode_base64,pad,An optional `bool`. Defaults to `False`. Bool whether padding is applied at the ends.,An optional D_TYPE,D_TYPE,,,,0,,
tf.linalg.triangular_solve,adjoint,An optional `bool`. Defaults to `False`. Boolean indicating whether to solve with `matrix` or its (block-wise)        adjoint.,An optional D_TYPE,D_TYPE,,,,0,,
tf.linalg.triangular_solve,lower,An optional `bool`. Defaults to `True`. Boolean indicating whether the innermost matrices in `matrix` are lower or upper triangular.,An optional D_TYPE,D_TYPE,,,,0,,
tf.nn.max_pool_with_argmax,include_batch_in_index,An optional `boolean`. Defaults to `False`. Whether to include batch dimension in flattened index of `argmax`.,An optional D_TYPE,D_TYPE,,,,0,,
tf.nn.fractional_avg_pool,seed,"An optional `int`.  Defaults to `0`.  If set to be non-zero, the random number generator is seeded by the given seed.  Otherwise it is seeded by a random seed.",An optional D_TYPE,D_TYPE,,,,0,,
tf.image.encode_png,compression,An optional `int`. Defaults to `-1`. Compression level.,An optional D_TYPE,D_TYPE,,,,0,,
tf.image.sample_distorted_bounding_box,seed,"An optional `int`. Defaults to `0`. If `seed` is set to non-zero, the random number generator is seeded by the given `seed`.  Otherwise, it is seeded by a random seed.",An optional D_TYPE,D_TYPE,,,,0,,
tf.io.decode_and_crop_jpeg,channels,An optional `int`. Defaults to `0`. Number of color channels for the decoded image.,An optional D_TYPE,D_TYPE,,,,0,,
tf.nn.local_response_normalization,depth_radius,An optional `int`. Defaults to `5`. 0-D.  Half-width of the 1-D normalization window.,An optional D_TYPE,D_TYPE,,,,0,,
tf.data.experimental.make_csv_dataset,use_quote_delim,"An optional bool. Defaults to `True`. If false, treats double quotation marks as regular characters inside of the string fields.",An optional D_TYPE,D_TYPE,,,,0,,
tf.math.argmin,output_type,"An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to`tf.int64`.",An optional D_TYPE from D_TYPE,D_TYPE,,,,0,,D_TYPE
tf.signal.dct,name,An optional name for the operation.,An optional name for the operation,string,,,,0,,
tf.signal.ifftshift,name,An optional name for the operation.,An optional name for the operation,string,,,,0,,
tf.feature_column.sequence_categorical_column_with_vocabulary_list,vocabulary_list,An ordered iterable defining the vocabulary. Each feature is mapped to the index of its value (if present) in `vocabulary_list`. Must be castable to `dtype`.,An ordered D_STRUCTURE defining the vocabulary,,,D_STRUCTURE,,,,
tf.strings.unicode_decode,input,An `N` dimensional potentially ragged `string` tensor with shape`[D1...DN]`.  `N` must be statically known.,An QSTR dimensional potentially ragged D_TYPE D_STRUCTURE with shape BSTR,D_TYPE,D_STRUCTURE,,BSTR,QSTR,,
tf.linalg.cross,b,"A `Tensor`. Must have the same type as `a`. Another tensor, of same type and shape as `a`.",Another D_STRUCTURE of same type and shape as QSTR,&QSTR,D_STRUCTURE,,&QSTR,,,
tf.debugging.enable_check_numerics,path_length_limit,Limit to the file path included in the printed stack trace. Applicable only to ops in `tf.function`s (graphs).,Applicable only to ops in tf function BSTR,,,,,,,
tf.keras.utils.get_file,archive_format,"Archive format to try for extracting the file. Options are 'auto', 'tar', 'zip', and None. 'tar' includes tar, tar.gz, and tar.bz files. The default 'auto' is ['tar', 'zip']. None or an empty list will return no matches found.",Archive format to try for extracting the file,,,,,,,
tf.keras.backend.rnn,step_function,"RNN step function. Args;     input; Tensor with shape `(samples, ...)` (no time dimension),         representing input for the batch of samples at a certain         time step.     states; List of tensors. Returns;     output; Tensor with shape `(samples, output_dim)`        (no time dimension).     new_states; List of tensors, same length and shapes         as 'states'. The first state in the list must be the         output tensor at the previous timestep.",Args input D_STRUCTURE with shape BSTR BSTR representing input for the batch of samples at a certain time step,,,,,,,
tf.nn.atrous_conv2d_transpose,filters,"A 4-D `Tensor` with the same type as `value` and shape`[filter_height, filter_width, out_channels, in_channels]`. `filters`'`in_channels` dimension must match that of `value`. Atrous convolution is equivalent to standard convolution with upsampled filters with effective height `filter_height + (filter_height - 1) * (rate - 1)` and effective width `filter_width + (filter_width - 1) * (rate - 1)`, produced by inserting `rate - 1` zeros along consecutive elements across the`filters`' spatial dimensions.",Atrous convolution is equivalent to standard convolution with upsampled filters with effective height QSTR filter_width BSTR produced by inserting PARAM CONSTANT_NUM zeros along consecutive elements across the QSTR spatial dimensions,,,,,,,
tf.unstack,num,An `int`. The length of the dimension `axis`. Automatically inferred if`None` (the default).,Automatically inferred if QSTR BSTR,,,,,,,
tf.keras.backend.reverse,axes,Integer or iterable of integers. Axes to reverse.,Axes to reverse,int,,,,,,
tf.tuple,name,(optional) A name to use as a `name_scope` for the operation.,BSTR A name to use as a QSTR for the operation,string,,,,0,,
tf.foldr,initializer,"(optional) A tensor or (possibly nested) sequence of tensors, as the initial value for the accumulator.",BSTR D_STRUCTURE of D_STRUCTURE as the initial value for the accumulator,,D_STRUCTURE,D_STRUCTURE,,,,
tf.config.set_logical_device_configuration,logical_devices,"(optional) List of `tf.config.LogicalDeviceConfiguration`objects to allocate for the specified `PhysicalDevice`. If None, the default configuration will be used.",BSTR D_STRUCTURE of tf config LogicalDeviceConfiguration QSTR PhysicalDevice,,,D_STRUCTURE,,,,
tf.foldl,name,(optional) Name prefix for the returned tensors.,BSTR Name prefix for the returned D_STRUCTURE,string,,,,0,,
tf.nn.ctc_loss,blank_index,"(optional) Set the class index to use for the blank label. Negative values will start from num_classes, ie, -1 will reproduce the ctc_loss behavior of using num_classes - 1 for the blank symbol. There is some memory/performance overhead to switching from the default of 0 as an additional shifted copy of the logits may be created.",BSTR Set the class index to use for the blank label,,,,,,,
tf.nn.RNNCellDropoutWrapper,dtype,"(optional) The `dtype` of the input, state, and output tensors. Required and used <strong>iff</strong> `variational_recurrent = True`.",BSTR The QSTR of the input state and output D_STRUCTURE,QSTR,,,,,,
tf.linalg.pinv,a,(Batch of) `float`-like matrix-shaped `Tensor`(s) which are to be pseudo-inverted.,BSTR which are to be pseudo inverted,,,,,,,
tf.data.experimental.make_csv_dataset,shuffle_buffer_size,"Buffer size to use for shuffling. A large buffer size ensures better shuffling, but increases memory usage and startup time.",Buffer size to use for shuffling,int,,,,,"[0,inf)",
tf.nn.conv2d_transpose,strides,"An int or list of `ints` that has length `1`, `2` or `4`.  The stride of the sliding window for each dimension of `input`. If a single value is given it is replicated in the `H` and `W` dimension. By default the `N` and `C` dimensions are set to 0. The dimension order is determined by the value of `data_format`, see below for details.",By default the QSTR dimensions are set to CONSTANT_NUM,,,,,,,
tf.control_dependencies,control_inputs,"A list of `Operation` or `Tensor` objects which must be executed or computed before running the operations defined in the context. Can also be `None` to clear the control dependencies. If eager execution is enabled, any callable object in the `control_inputs` list will be called.",Can also be QSTR to clear the control dependencies,,,,,,,
tf.image.encode_png,compression,An optional `int`. Defaults to `-1`. Compression level.,Compression level,,,,,,,
tf.nn.fractional_avg_pool,pooling_ratio,"A list of `floats` that has length >= 4.  Pooling ratio for each dimension of `value`, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling ratio on height and width dimensions respectively.",CONSTANT_FLOAT and CONSTANT_FLOAT are pooling ratio on height and width dimensions respectively,,,,,,,
tf.nn.fractional_max_pool,pooling_ratio,"An int or list of `ints` that has length `1`, `2` or `4`. Pooling ratio for each dimension of `value`, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling ratio on height and width dimensions respectively.",CONSTANT_FLOAT and CONSTANT_FLOAT are pooling ratio on height and width dimensions respectively,,,,,,,
tf.image.draw_bounding_boxes,colors,A `Tensor` of type `float32`. 2-D. A list of RGBA colors to cycle through for the boxes.,CONSTANT_NUM D A D_STRUCTURE of RGBA colors to cycle through for the PARAM,,D_STRUCTURE,,,CONSTANT_NUM,,
tf.image.sample_distorted_bounding_box,image_size,"A `Tensor`. Must be one of the following types: `uint8`, `int8`,`int16`, `int32`, `int64`. 1-D, containing `[height, width, channels]`.",CONSTANT_NUM D containing BSTR,,D_STRUCTURE,,BSTR,CONSTANT_NUM,,
tf.linspace,num,"A `Tensor`. Must be one of the following types: `int32`, `int64`. 0-D tensor. Number of values to generate.",CONSTANT_NUM D D_STRUCTURE,,D_STRUCTURE,,,CONSTANT_NUM,,
tf.linspace,stop,A `Tensor`. Must have the same type as `start`. 0-D tensor. Last entry in the range.,CONSTANT_NUM D D_STRUCTURE,,D_STRUCTURE,,,CONSTANT_NUM,,
tf.nn.weighted_moments,axes,1-d tensor of int32 values; these are the axes along which to compute mean and variance.,CONSTANT_NUM d D_STRUCTURE of D_TYPE values these are the axes along which to compute mean and variance,D_TYPE,D_STRUCTURE,,,CONSTANT_NUM,,
tf.nn.depthwise_conv2d_backprop_input,dilations,"An optional list of `ints`. Defaults to `[1, 1, 1, 1]`. 1-D tensor of length 4.  The dilation factor for each dimension of`input`. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of`data_format`, see above for details. Dilations in the batch and depth dimensions must be 1.",CONSTANT_NUM D D_STRUCTURE of length CONSTANT_NUM,,,D_STRUCTURE,[CONSTANT_NUM],1,,
tf.keras.backend.local_conv2d,inputs,"4D tensor with shape: (batch_size, filters, new_rows, new_cols) if data_format='channels_first' or 4D tensor with shape: (batch_size, new_rows, new_cols, filters) if data_format='channels_last'.",CONSTANT_NUM D D_STRUCTURE with shape BSTR if PARAM QSTR or CONSTANT_NUM D D_STRUCTURE with shape BSTR if PARAM QSTR,,D_STRUCTURE,,BSTR,CONSTANT_NUM,,
tf.nn.local_response_normalization,depth_radius,An optional `int`. Defaults to `5`. 0-D.  Half-width of the 1-D normalization window.,CONSTANT_NUM D D_TYPE width of the CONSTANT_NUM D normalization window,D_TYPE,,,,CONSTANT_NUM,,
tf.nn.erosion2d,dilations,"A list of `ints` that has length `>= 4`. 1-D of length 4. The input stride for atrous morphological dilation. Must be: `[1, rate_height, rate_width, 1]`.",CONSTANT_NUM D of length CONSTANT_NUM,,,,[CONSTANT_NUM],1,,
tf.extract_volume_patches,strides,"A list of `ints` that has length `>= 5`. 1-D of length 5. How far the centers of two consecutive patches are in`input`. Must be: `[1, stride_planes, stride_rows, stride_cols, 1]`.",CONSTANT_NUM D of length CONSTANT_NUM,,,,[CONSTANT_NUM],1,,
tf.space_to_batch_nd,paddings,"A `Tensor`. Must be one of the following types: `int32`, `int64`. 2-D with shape `[M, 2]`, all values must be >= 0.`paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension`i + 1`, which corresponds to spatial dimension `i`.  It is required that`block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.This operation is equivalent to the following steps: Zero-pad the start and end of dimensions `[1, ..., M]` of the input according to `paddings` to produce `padded` of shape `padded_shape`.Reshape `padded` to `reshaped_padded` of shape:[batch] + [padded_shape[1] / block_shape[0],  block_shape[0], ..., padded_shape[M] / block_shape[M-1], block_shape[M-1]] + remaining_shapePermute dimensions of `reshaped_padded` to produce`permuted_reshaped_padded` of shape:block_shape + [batch] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shapeReshape `permuted_reshaped_padded` to flatten `block_shape` into the batch dimension, producing an output tensor of shape:[batch * prod(block_shape)] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape Some examples:(1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and   `paddings = [[0, 0], [0, 0]]`:",CONSTANT_NUM D with shape BSTR all values must be REXPRpaddings BSTR BSTR specifies the padding for PARAM dimension i CONSTANT_NUM which corresponds to spatial dimension QSTR,,,,BSTR,CONSTANT_NUM,,
tf.keras.preprocessing.sequence.skipgrams,sequence,"A word sequence (sentence), encoded as a list     of word indices (integers). If using a `sampling_table`,     word indices are expected to match the rank     of the words in a reference dataset (e.g. 10 would encode     the 10-th most frequently occurring token).     Note that index 0 is expected to be a non-word and will be skipped.",CONSTANT_NUM would encode the CONSTANT_NUM th most frequently occurring token,,,,,,,
tf.keras.layers.DepthwiseConv2D,bias_constraint,Constraint function applied to the bias vector.,Constraint function applied to the bias D_STRUCTURE,,,,,,,
tf.keras.layers.Embedding,embeddings_constraint,Constraint function applied to the `embeddings` matrix.,Constraint function applied to the QSTR matrix,,,,,,,
tf.keras.layers.SimpleRNN,recurrent_constraint,Constraint function applied to the `recurrent_kernel`weights matrix.  Default: `None`.,Constraint function applied to the QSTR weights matrix,,,,,,,
tf.io.decode_image,expand_animations,"Controls the shape of the returned op's output. If`True`, the returned op will produce a 3-D tensor for PNG, JPEG, and BMP files; and a 4-D tensor for all GIFs, whether animated or not. If,`False`, the returned op will produce a 3-D tensor for all file types and will truncate animated GIFs to the first frame.",Controls the shape of the returned op output,,,,,,,
tf.keras.layers.LocallyConnected1D,implementation,"implementation mode, either `1`, `2`, or `3`.`1` loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops.`2` stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops.`3` stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply.How to choose:`1`: large, dense models,`2`: small models,`3`: large, sparse models,where ""large"" stands for large input/output activations (i.e. many `filters`, `input_filters`, large `input_size`,`output_size`), and ""sparse"" stands for few connections between inputs and outputs, i.e. small ratio`filters * input_filters * kernel_size / (input_size * strides)`, where inputs to and outputs of the layer are assumed to have shapes`(input_size, input_filters)`, `(output_size, filters)`respectively.It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM.Also, only `padding=""valid""` is supported by `implementation=1`.",Correct choice of implementation can lead to dramatic speed improvements e g,,,,,,,
tf.keras.preprocessing.text.text_to_word_sequence,filters,"list (or concatenation) of characters to filter out, such as     punctuation. Default: ``!""#$%&()*+,-./:;<=>?@[\]^_`{|}~\t\n``,     includes basic punctuation, tabs, and newlines.",D_STRUCTURE BSTR of characters to filter out such as punctuation,,,,,,,
tf.keras.backend.ctc_decode,y_pred,"tensor `(samples, time_steps, num_categories)`containing the prediction, or output of the softmax.",D_STRUCTURE BSTRcontaining the prediction or output of the softmax,,D_STRUCTURE,,,,,
tf.keras.layers.InputSpec,axes,Dictionary mapping integer axes to a specific dimension value.,D_STRUCTURE mapping D_TYPE axes to a specific dimension value,D_TYPE,,D_STRUCTURE,,,,
tf.math.truediv,x,`Tensor` numerator of numeric type.,D_STRUCTURE numerator of D_TYPE type,D_TYPE,D_STRUCTURE,,,,,
tf.keras.backend.conv2d_transpose,dilation_rate,Tuple of 2 integers.,D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
tf.keras.backend.pool2d,pool_size,tuple of 2 integers.,D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
tf.keras.backend.concatenate,tensors,list of tensors to concatenate.,D_STRUCTURE of D_STRUCTURE to concatenate,,D_STRUCTURE,D_STRUCTURE,,,,
tf.io.decode_proto,field_names,"A list of `strings`. List of strings containing proto field names. An extension field can be decoded by using its full name, e.g. EXT_PACKAGE.EXT_FIELD_NAME.",D_STRUCTURE of D_TYPE containing proto field names,D_TYPE,,D_STRUCTURE,,,,
tf.nn.pool,dilations,"Optional.  Dilation rate.  List of N ints >= 1. Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values of strides must be 1.",D_STRUCTURE of N D_TYPE REXPR,D_TYPE,,D_STRUCTURE,[N],1,REXPR,
tf.nn.ctc_loss,logits,"tensor of shape [frames, batch_size, num_labels], if logits_time_major == False, shape is [batch_size, frames, num_labels].",D_STRUCTURE of shape BSTR if PARAM CONSTANT_BOOL shape is BSTR,,D_STRUCTURE,,BSTR,,,
tf.sets.intersection,b,"`Tensor` or `SparseTensor` of the same type as `a`. If sparse, indices must be sorted in row-major order.",D_STRUCTURE of the same type as QSTR,&QSTR,D_STRUCTURE,,,,,
tf.sets.difference,b,"`Tensor` or `SparseTensor` of the same type as `a`. If sparse, indices must be sorted in row-major order.",D_STRUCTURE of the same type as QSTR,&QSTR,D_STRUCTURE,,,,,
tf.linalg.normalize,tensor,"`Tensor` of types `float32`, `float64`, `complex64`, `complex128`",D_STRUCTURE of types D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.keras.backend.argmax,x,Tensor or variable.,D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.sin,x,Tensor or variable.,D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.transpose,x,Tensor or variable.,D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.dtype,x,Tensor or variable.,D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.minimum,y,Tensor or variable.,D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.clip,x,Tensor or variable.,D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.int_shape,x,Tensor or variable.,D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.less_equal,x,Tensor or variable.,D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.sqrt,x,Tensor or variable.,D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.spatial_3d_padding,x,Tensor or variable.,D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.tensor_scatter_nd_add,tensor,A `Tensor`. Tensor to copy/update.,D_STRUCTURE to copy update,,D_STRUCTURE,,,,,
tf.keras.backend.print_tensor,x,Tensor to print.,D_STRUCTURE to print,,D_STRUCTURE,,,,,
tf.keras.backend.batch_normalization,beta,Tensor with which to center the input.,D_STRUCTURE with which to center the input,,D_STRUCTURE,,,,,
tf.keras.layers.SimpleRNN,go_backwards,"Boolean (default False). If True, process the input sequence backwards and return the reversed sequence.",D_TYPE BSTR,D_TYPE,,,,,,
tf.debugging.assert_non_negative,x,Numeric `Tensor`.,D_TYPE D_STRUCTURE,D_TYPE,D_STRUCTURE,,,,,
tf.signal.linear_to_mel_weight_matrix,dtype,DF: tf.dtypes.float32,ONE_WORD D_TYPE,dtype,,,,,,
tf.random.uniform,dtype,DF: tf.dtypes.float32,ONE_WORD D_TYPE,dtype,,,,,,
tf.math.argmin,output_type,DF: tf.dtypes.int64,ONE_WORD D_TYPE,dtype,,,,,,
tf.data.experimental.dense_to_ragged_batch,row_splits_dtype,DF: tf.dtypes.int64,ONE_WORD D_TYPE,dtype,,,,,,
tf.keras.layers.SimpleRNN,use_bias,"Boolean, (default `True`), whether the layer uses a bias vector.",D_TYPE default CONSTANT_BOOL whether the layer uses a bias D_STRUCTURE,bool,,,,0,,
tf.sparse.cross_hashed,hash_key,"Integer hash_key that will be used by the `FingerprintCat64`function. If not given, will use a default key.",D_TYPE hash_key that will be used by the QSTR function,D_TYPE,,,,,,
tf.linalg.triangular_solve,lower,An optional `bool`. Defaults to `True`. Boolean indicating whether the innermost matrices in `matrix` are lower or upper triangular.,D_TYPE indicating whether the innermost matrices in PARAM are lower or upper triangular,D_TYPE,,,,0,,
tf.linalg.triangular_solve,adjoint,An optional `bool`. Defaults to `False`. Boolean indicating whether to solve with `matrix` or its (block-wise)        adjoint.,D_TYPE indicating whether to solve with PARAM or its BSTR adjoint,D_TYPE,,,,0,,
tf.keras.regularizers.l1,l,Float; L1 regularization factor.,D_TYPE L1 regularization factor,D_TYPE,,,,,,
tf.keras.preprocessing.sequence.skipgrams,vocabulary_size,"Int, maximum possible word index + 1",D_TYPE maximum possible word index CONSTANT_NUM,D_TYPE,,,,,,
tf.image.random_brightness,max_delta,"float, must be non-negative.",D_TYPE must be non negative,D_TYPE,,,,,"[0,inf)",
tf.keras.experimental.terminate_keras_multiprocessing_pools,use_sigkill,Boolean of whether or not to perform a cleanup pass using SIGKILL.,D_TYPE of whether or not to perform a cleanup pass using SIGKILL,D_TYPE,,,,0,,
tf.linalg.lstsq,name,"string, optional name of the operation.",D_TYPE optional name of the operation,D_TYPE,,,,0,,
tf.keras.layers.UpSampling2D,size,"Int, or tuple of 2 integers. The upsampling factors for rows and columns.",D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
tf.keras.backend.reverse,axes,Integer or iterable of integers. Axes to reverse.,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,0;1,,
tf.signal.fftshift,axes,"`int` or shape `tuple`, optional Axes over which to shift.  Default is None, which shifts all axes.",D_TYPE or shape D_STRUCTURE optional Axes over which to shift,D_TYPE,,,,0;1,"[0,inf)",
tf.io.gfile.stat,path,"string, path to a file",D_TYPE path to a file,D_TYPE,,,,0,,
tf.keras.backend.pool2d,pool_mode,"string, `""max""` or `""avg""`.",D_TYPE QSTR,D_TYPE,,,,,,QSTR
tf.keras.backend.random_normal_variable,seed,"Integer, random seed.",D_TYPE random seed,D_TYPE,,,,,,
tf.keras.layers.ReLU,negative_slope,Float >= 0. Negative slope coefficient.,D_TYPE REXPR,D_TYPE,,,,,REXPR,
tf.keras.layers.Embedding,output_dim,int >= 0. Dimension of the dense embedding.,D_TYPE REXPR,D_TYPE,,,,,REXPR,
tf.keras.preprocessing.sequence.skipgrams,window_size,"Int, size of sampling windows (technically half-window).     The window of a word `w_i` will be     `[i - window_size, i + window_size+1]`.",D_TYPE size of sampling windows BSTR,D_TYPE,,,,,"[0,inf)",
tf.keras.layers.AveragePooling1D,pool_size,"Integer, size of the average pooling windows.",D_TYPE size of the average pooling windows,D_TYPE,,,,,"[0,inf)",
tf.keras.backend.categorical_crossentropy,axis,"Int specifying the channels axis. `axis=-1` corresponds to data format `channels_last', and`axis=1`corresponds to data format`channels_first`.",D_TYPE specifying the channels axis,D_TYPE,,,,,,
tf.io.gfile.walk,topdown,"bool, Traverse pre order if True, post order if False.",D_TYPE Traverse pre order if CONSTANT_BOOL post order if CONSTANT_BOOL,D_TYPE,,,,0,,
tf.io.encode_base64,pad,An optional `bool`. Defaults to `False`. Bool whether padding is applied at the ends.,D_TYPE whether padding is applied at the ends,D_TYPE,,,,0,,
tf.keras.layers.LocallyConnected2D,use_bias,"Boolean, whether the layer uses a bias vector.",D_TYPE whether the layer uses a bias D_STRUCTURE,D_TYPE,,,,0,,
tf.keras.layers.Dense,use_bias,"Boolean, whether the layer uses a bias vector.",D_TYPE whether the layer uses a bias D_STRUCTURE,D_TYPE,,,,0,,
tf.keras.layers.GRU,return_sequences,"Boolean. Whether to return the last output in the output sequence, or the full sequence. Default: `False`.",Default CONSTANT_BOOL,bool,,,,0,,
tf.keras.layers.SimpleRNN,go_backwards,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.io.encode_base64,pad,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.layers.GRU,return_sequences,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.math.reduce_min,keepdims,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.math.cumulative_logsumexp,exclusive,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.linalg.matvec,b_is_sparse,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.linalg.triangular_solve,adjoint,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.utils.plot_model,show_shapes,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.data.experimental.dense_to_ragged_batch,drop_remainder,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.utils.plot_model,expand_nested,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.sparse.reduce_max,output_is_sparse,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.nn.max_pool_with_argmax,include_batch_in_index,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.linalg.matrix_rank,validate_args,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.layers.Attention,use_scale,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.experimental.terminate_keras_multiprocessing_pools,use_sigkill,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.data.experimental.make_batched_features_dataset,sloppy_ordering,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.layers.RNN,go_backwards,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.backend.any,keepdims,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.layers.ConvLSTM2D,return_sequences,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.io.gfile.rename,overwrite,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.io.decode_jpeg,try_recover_truncated,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.linalg.matmul,adjoint_b,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.data.experimental.make_csv_dataset,use_quote_delim,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.preprocessing.sequence.skipgrams,shuffle,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.nn.sampled_softmax_loss,remove_accidental_hits,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.layers.LocallyConnected2D,use_bias,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.linalg.triangular_solve,lower,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.sets.union,validate_indices,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.io.decode_image,expand_animations,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.layers.SimpleRNN,use_bias,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.layers.ConvLSTM2D,unit_forget_bias,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.io.gfile.walk,topdown,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.layers.Dense,use_bias,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.xla.experimental.jit_scope,compile_ops,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.layers.experimental.preprocessing.TextVectorization,pad_to_max_tokens,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.layers.SeparableConv1D,use_bias,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.linalg.tridiagonal_solve,partial_pivoting,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.autograph.to_graph,recursive,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.utils.plot_model,show_layer_names,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.io.decode_jpeg,fancy_upscaling,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.preprocessing.text.text_to_word_sequence,lower,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
tf.keras.layers.SimpleRNN,recurrent_dropout,DF: 0.0,DEFAULT CONSTANT_FLOAT,float,,,,0,,
tf.random.normal,mean,DF: 0.0,DEFAULT CONSTANT_FLOAT,float,,,,0,,
tf.keras.layers.SimpleRNN,dropout,DF: 0.0,DEFAULT CONSTANT_FLOAT,float,,,,0,,
tf.keras.layers.GRUCell,recurrent_dropout,DF: 0.0,DEFAULT CONSTANT_FLOAT,float,,,,0,,
tf.keras.layers.LSTM,recurrent_dropout,DF: 0.0,DEFAULT CONSTANT_FLOAT,float,,,,0,,
tf.keras.backend.batch_normalization,epsilon,DF: 0.001,DEFAULT CONSTANT_FLOAT,float,,,,0,,
tf.image.ssim_multiscale,k1,DF: 0.01,DEFAULT CONSTANT_FLOAT,float,,,,0,,
tf.keras.regularizers.l1,l,DF: 0.01,DEFAULT CONSTANT_FLOAT,float,,,,0,,
tf.image.non_max_suppression_overlaps,overlap_threshold,DF: 0.5,DEFAULT CONSTANT_FLOAT,float,,,,0,,
tf.image.combined_non_max_suppression,iou_threshold,DF: 0.5,DEFAULT CONSTANT_FLOAT,float,,,,0,,
tf.keras.backend.random_uniform,maxval,DF: 1.0,DEFAULT CONSTANT_FLOAT,float,,,,0,,
tf.keras.backend.truncated_normal,stddev,DF: 1.0,DEFAULT CONSTANT_FLOAT,float,,,,0,,
tf.random.stateless_truncated_normal,stddev,DF: 1.0,DEFAULT CONSTANT_FLOAT,float,,,,0,,
tf.one_hot,off_value,A scalar defining the value to fill in output when `indices[j] != i`. (default: 0),default CONSTANT_NUM,int,,,,0,,
tf.linalg.diag,num_cols,DF: -1,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.backend.softmax,axis,DF: -1,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.image.encode_png,compression,DF: -1,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.signal.idct,axis,DF: -1,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.backend.categorical_crossentropy,axis,DF: -1,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.layers.Concatenate,axis,DF: -1,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.backend.batch_normalization,axis,DF: -1,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.strings.as_string,width,DF: -1,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.signal.frame,axis,DF: -1,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.layers.Conv3D,strides,"DF: (1, 1, 1)",DEFAULT CONSTANT_NUM,int,,,,1,,
tf.keras.backend.conv2d_transpose,dilation_rate,"DF: (1, 1)",DEFAULT CONSTANT_NUM,int,,,,1,,
tf.keras.backend.temporal_padding,padding,"DF: (1, 1)",DEFAULT CONSTANT_NUM,int,,,,1,,
tf.keras.layers.UpSampling2D,size,"DF: (2, 2)",DEFAULT CONSTANT_NUM,int,,,,1,,
tf.nn.depthwise_conv2d_backprop_input,dilations,"DF: [1, 1, 1, 1]",DEFAULT CONSTANT_NUM,int,,,,1,,
tf.io.decode_and_crop_jpeg,channels,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.layers.ReLU,negative_slope,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.math.cumulative_logsumexp,axis,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.nn.fractional_avg_pool,seed,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.ragged.stack,axis,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.preprocessing.image.apply_affine_transform,tx,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.strided_slice,new_axis_mask,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.gather,batch_dims,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.image.sample_distorted_bounding_box,seed,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.gather_nd,batch_dims,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.strided_slice,end_mask,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.backend.relu,threshold,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.datasets.reuters.load_data,skip_top,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.ragged.range,deltas,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.layers.LocallyConnected1D,implementation,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.layers.SeparableConv2D,depth_multiplier,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.backend.ctc_decode,beam_width,DF: 100,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.debugging.experimental.enable_dump_debug_info,circular_buffer_size,DF: 1000,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.data.experimental.make_csv_dataset,shuffle_buffer_size,DF: 10000,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.layers.AveragePooling1D,pool_size,DF: 2,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.datasets.imdb.load_data,oov_char,DF: 2,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.strings.format,summarize,DF: 3,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.preprocessing.sequence.skipgrams,window_size,DF: 4,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.nn.local_response_normalization,depth_radius,DF: 5,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.debugging.enable_check_numerics,path_length_limit,DF: 50,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.strings.unicode_transcode,replacement_char,DF: 65533,DEFAULT CONSTANT_NUM,int,,,,0,,
tf.keras.utils.get_file,archive_format,DF: auto,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.estimator.model_to_estimator,checkpoint_format,DF: checkpoint,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.norm,ord,DF: euclidean,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.LSTMCell,kernel_initializer,DF: glorot_uniform,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.LSTM,kernel_initializer,DF: glorot_uniform,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.Dense,kernel_initializer,DF: glorot_uniform,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.ConvLSTM2D,kernel_initializer,DF: glorot_uniform,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.ConvLSTM2D,recurrent_activation,DF: hard_sigmoid,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.searchsorted,side,DF: left,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.linalg.matrix_transpose,name,DF: matrix_transpose,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.backend.pool2d,pool_mode,DF: max,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.feature_column.embedding_column,combiner,DF: mean,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.nn.conv3d_transpose,data_format,DF: NDHWC,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.preprocessing.image.random_shift,fill_mode,DF: nearest,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.nn.avg_pool2d,data_format,DF: NHWC,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.nn.conv1d_transpose,data_format,DF: NWC,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.nn.max_pool1d,data_format,DF: NWC,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.SimpleRNN,recurrent_initializer,DF: orthogonal,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.nn.conv2d_transpose,padding,DF: SAME,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.nn.sampled_softmax_loss,name,DF: sampled_softmax_loss,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.experimental.preprocessing.TextVectorization,split,DF: SPLIT_ON_WHITESPACE,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.SimpleRNNCell,activation,DF: tanh,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.unstack,name,DF: unstack,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.MaxPool3D,padding,DF: valid,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.Conv2DTranspose,padding,DF: valid,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.SeparableConv1D,padding,DF: valid,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.Conv3D,bias_initializer,DF: zeros,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.LSTMCell,bias_initializer,DF: zeros,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.keras.layers.PReLU,alpha_initializer,DF: zeros,DEFAULT DF_STR,string,,,,0,,DF_STR
tf.nn.sampled_softmax_loss,remove_accidental_hits,"A `bool`.  whether to remove ""accidental hits"" where a sampled class equals one of the target classes.  Default is True.",Default is CONSTANT_BOOL,bool,,,,0,,
tf.random.fixed_unigram_candidate_sampler,seed,An `int`. An operation-specific seed. Default is 0.,Default is CONSTANT_NUM,int,,,,0,,
tf.debugging.assert_near,rtol,"`Tensor`.  Same `dtype` as, and broadcastable to, `x`. The relative tolerance.  Default is `10 * eps`.",Default is CONSTANT_NUM eps,int,,,,0,,
tf.signal.fftshift,axes,"`int` or shape `tuple`, optional Axes over which to shift.  Default is None, which shifts all axes.",Default is None which shifts all axes,,,,,,,
tf.summary.write,name,DF: None,DEFAULT None,,,,,,,
tf.nn.pool,name,DF: None,DEFAULT None,,,,,,,
tf.nn.separable_conv2d,name,DF: None,DEFAULT None,,,,,,,
tf.nn.max_pool1d,name,DF: None,DEFAULT None,,,,,,,
tf.debugging.assert_negative,summarize,DF: None,DEFAULT None,,,,,,,
tf.math.reciprocal_no_nan,name,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.experimental.preprocessing.PreprocessingLayer,data,DF: None,DEFAULT None,,,,,,,
tf.image.random_hue,seed,DF: None,DEFAULT None,,,,,,,
tf.linalg.lu_solve,name,DF: None,DEFAULT None,,,,,,,
tf.nn.selu,name,DF: None,DEFAULT None,,,,,,,
tf.math.cosh,name,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.Lambda,mask,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.SimpleRNN,recurrent_constraint,DF: None,DEFAULT None,,,,,,,
tf.signal.dct,name,DF: None,DEFAULT None,,,,,,,
tf.data.experimental.make_csv_dataset,label_name,DF: None,DEFAULT None,,,,,,,
tf.summary.flush,writer,DF: None,DEFAULT None,,,,,,,
tf.math.is_nan,name,DF: None,DEFAULT None,,,,,,,
tf.identity_n,name,DF: None,DEFAULT None,,,,,,,
tf.keras.initializers.he_uniform,seed,DF: None,DEFAULT None,,,,,,,
tf.tpu.experimental.initialize_tpu_system,cluster_resolver,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.InputSpec,axes,DF: None,DEFAULT None,,,,,,,
tf.tuple,name,DF: None,DEFAULT None,,,,,,,
tf.dynamic_stitch,name,DF: None,DEFAULT None,,,,,,,
tf.gradients,stop_gradients,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.DepthwiseConv2D,bias_constraint,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.ConvLSTM2D,activity_regularizer,DF: None,DEFAULT None,,,,,,,
tf.math.is_strictly_increasing,name,DF: None,DEFAULT None,,,,,,,
tf.signal.ifftshift,name,DF: None,DEFAULT None,,,,,,,
tf.nn.RNNCellDropoutWrapper,input_keep_prob,DF: None,DEFAULT None,,,,,,,
tf.linalg.lstsq,name,DF: None,DEFAULT None,,,,,,,
tf.bitwise.bitwise_or,name,DF: None,DEFAULT None,,,,,,,
tf.debugging.assert_near,summarize,DF: None,DEFAULT None,,,,,,,
tf.debugging.assert_near,rtol,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.AveragePooling3D,data_format,DF: None,DEFAULT None,,,,,,,
tf.foldr,initializer,DF: None,DEFAULT None,,,,,,,
tf.foldl,name,DF: None,DEFAULT None,,,,,,,
tf.linalg.cross,name,DF: None,DEFAULT None,,,,,,,
tf.image.random_flip_left_right,seed,DF: None,DEFAULT None,,,,,,,
tf.nn.ctc_loss,blank_index,DF: None,DEFAULT None,,,,,,,
tf.nn.pool,dilations,DF: None,DEFAULT None,,,,,,,
tf.nn.relu6,name,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.LocallyConnected1D,activity_regularizer,DF: None,DEFAULT None,,,,,,,
tf.random.fixed_unigram_candidate_sampler,seed,DF: None,DEFAULT None,,,,,,,
tf.image.adjust_jpeg_quality,name,DF: None,DEFAULT None,,,,,,,
tf.ragged.range,dtype,DF: None,DEFAULT None,,,,,,,
tf.math.unsorted_segment_sqrt_n,name,DF: None,DEFAULT None,,,,,,,
tf.keras.backend.random_normal_variable,seed,DF: None,DEFAULT None,,,,,,,
tf.strings.reduce_join,axis,DF: None,DEFAULT None,,,,,,,
tf.graph_util.import_graph_def,return_elements,DF: None,DEFAULT None,,,,,,,
tf.ragged.boolean_mask,name,DF: None,DEFAULT None,,,,,,,
tf.random.categorical,seed,DF: None,DEFAULT None,,,,,,,
tf.strings.regex_replace,name,DF: None,DEFAULT None,,,,,,,
tf.keras.Input,batch_size,DF: None,DEFAULT None,,,,,,,
tf.unstack,num,DF: None,DEFAULT None,,,,,,,
tf.rank,name,DF: None,DEFAULT None,,,,,,,
tf.math.top_k,name,DF: None,DEFAULT None,,,,,,,
tf.debugging.assert_type,name,DF: None,DEFAULT None,,,,,,,
tf.eye,num_columns,DF: None,DEFAULT None,,,,,,,
tf.keras.backend.foldr,name,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.Embedding,embeddings_constraint,DF: None,DEFAULT None,,,,,,,
tf.keras.backend.foldl,name,DF: None,DEFAULT None,,,,,,,
tf.summary.write,metadata,DF: None,DEFAULT None,,,,,,,
tf.debugging.assert_rank_at_least,name,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.Conv3D,bias_regularizer,DF: None,DEFAULT None,,,,,,,
tf.one_hot,off_value,DF: None,DEFAULT None,,,,,,,
tf.required_space_to_batch_paddings,base_paddings,DF: None,DEFAULT None,,,,,,,
tf.nn.max_pool,data_format,DF: None,DEFAULT None,,,,,,,
tf.random.stateless_truncated_normal,name,DF: None,DEFAULT None,,,,,,,
tf.nn.conv1d_transpose,dilations,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.PReLU,shared_axes,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.Conv3DTranspose,data_format,DF: None,DEFAULT None,,,,,,,
tf.math.less_equal,name,DF: None,DEFAULT None,,,,,,,
tf.image.grayscale_to_rgb,name,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.SimpleRNNCell,bias_regularizer,DF: None,DEFAULT None,,,,,,,
tf.norm,name,DF: None,DEFAULT None,,,,,,,
tf.debugging.assert_equal,name,DF: None,DEFAULT None,,,,,,,
tf.math.unsorted_segment_mean,name,DF: None,DEFAULT None,,,,,,,
tf.feature_column.numeric_column,default_value,DF: None,DEFAULT None,,,,,,,
tf.math.squared_difference,name,DF: None,DEFAULT None,,,,,,,
tf.io.decode_png,name,DF: None,DEFAULT None,,,,,,,
tf.debugging.assert_integer,name,DF: None,DEFAULT None,,,,,,,
tf.truncatemod,name,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.Conv3D,activation,DF: None,DEFAULT None,,,,,,,
tf.data.experimental.make_batched_features_dataset,shuffle_seed,DF: None,DEFAULT None,,,,,,,
tf.math.unsorted_segment_prod,name,DF: None,DEFAULT None,,,,,,,
tf.print,output_stream,DF: None,DEFAULT None,,,,,,,
tf.data.experimental.make_batched_features_dataset,reader,DF: None,DEFAULT None,,,,,,,
tf.signal.fftshift,axes,DF: None,DEFAULT None,,,,,,,
tf.debugging.assert_none_equal,name,DF: None,DEFAULT None,,,,,,,
tf.extract_volume_patches,name,DF: None,DEFAULT None,,,,,,,
tf.sparse.cross_hashed,hash_key,DF: None,DEFAULT None,,,,,,,
tf.keras.backend.std,axis,DF: None,DEFAULT None,,,,,,,
tf.debugging.assert_greater_equal,name,DF: None,DEFAULT None,,,,,,,
tf.nn.RNNCellDropoutWrapper,dtype,DF: None,DEFAULT None,,,,,,,
tf.feature_column.crossed_column,hash_key,DF: None,DEFAULT None,,,,,,,
tf.math.segment_prod,name,DF: None,DEFAULT None,,,,,,,
tf.math.reduce_euclidean_norm,axis,DF: None,DEFAULT None,,,,,,,
tf.math.not_equal,name,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.experimental.preprocessing.Normalization,reset_state,DF: None,DEFAULT None,,,,,,,
tf.sparse.eye,num_columns,DF: None,DEFAULT None,,,,,,,
tf.image.draw_bounding_boxes,name,DF: None,DEFAULT None,,,,,,,
tf.debugging.assert_greater,name,DF: None,DEFAULT None,,,,,,,
tf.nn.max_pool_with_argmax,name,DF: None,DEFAULT None,,,,,,,
tf.strings.split,name,DF: None,DEFAULT None,,,,,,,
tf.feature_column.sequence_categorical_column_with_identity,default_value,DF: None,DEFAULT None,,,,,,,
tf.math.cumprod,name,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.Cropping3D,data_format,DF: None,DEFAULT None,,,,,,,
tf.keras.backend.relu,max_value,DF: None,DEFAULT None,,,,,,,
tf.nn.atrous_conv2d_transpose,name,DF: None,DEFAULT None,,,,,,,
tf.keras.backend.random_binomial,dtype,DF: None,DEFAULT None,,,,,,,
tf.linalg.normalize,axis,DF: None,DEFAULT None,,,,,,,
tf.keras.backend.random_uniform,seed,DF: None,DEFAULT None,,,,,,,
tf.reduce_all,name,DF: None,DEFAULT None,,,,,,,
tf.io.decode_image,name,DF: None,DEFAULT None,,,,,,,
tf.nn.avg_pool3d,name,DF: None,DEFAULT None,,,,,,,
tf.summary.trace_export,profiler_outdir,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.BatchNormalization,gamma_constraint,DF: None,DEFAULT None,,,,,,,
tf.math.accumulate_n,shape,DF: None,DEFAULT None,,,,,,,
tf.math.segment_min,name,DF: None,DEFAULT None,,,,,,,
tf.linalg.tensor_diag,name,DF: None,DEFAULT None,,,,,,,
tf.keras.backend.in_test_phase,training,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.Conv1D,activity_regularizer,DF: None,DEFAULT None,,,,,,,
tf.math.confusion_matrix,weights,DF: None,DEFAULT None,,,,,,,
tf.keras.backend.local_conv1d,data_format,DF: None,DEFAULT None,,,,,,,
tf.data.experimental.make_csv_dataset,column_defaults,DF: None,DEFAULT None,,,,,,,
tf.histogram_fixed_width_bins,name,DF: None,DEFAULT None,,,,,,,
tf.math.reciprocal,name,DF: None,DEFAULT None,,,,,,,
tf.keras.experimental.SequenceFeatures,name,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.SeparableConv1D,trainable,DF: None,DEFAULT None,,,,,,,
tf.io.parse_single_sequence_example,example_name,DF: None,DEFAULT None,,,,,,,
tf.keras.backend.prod,axis,DF: None,DEFAULT None,,,,,,,
tf.feature_column.numeric_column,normalizer_fn,DF: None,DEFAULT None,,,,,,,
tf.linalg.solve,name,DF: None,DEFAULT None,,,,,,,
tf.scatter_nd,name,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.SeparableConv1D,activation,DF: None,DEFAULT None,,,,,,,
tf.math.is_non_decreasing,name,DF: None,DEFAULT None,,,,,,,
tf.keras.Input,name,DF: None,DEFAULT None,,,,,,,
tf.debugging.Assert,name,DF: None,DEFAULT None,,,,,,,
tf.math.reduce_mean,axis,DF: None,DEFAULT None,,,,,,,
tf.linalg.logm,name,DF: None,DEFAULT None,,,,,,,
tf.keras.utils.get_file,cache_dir,DF: None,DEFAULT None,,,,,,,
tf.math.reduce_logsumexp,axis,DF: None,DEFAULT None,,,,,,,
tf.keras.layers.SimpleRNN,recurrent_constraint,Constraint function applied to the `recurrent_kernel`weights matrix.  Default: `None`.,Default QSTR,string,,,,,,QSTR
tf.keras.layers.LSTMCell,kernel_initializer,"Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`.",Default QSTR,string,,,,,,QSTR
tf.keras.layers.LSTM,kernel_initializer,"Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`.",Default QSTR,string,,,,,,QSTR
tf.keras.layers.SimpleRNN,recurrent_initializer,"Initializer for the `recurrent_kernel`weights matrix, used for the linear transformation of the recurrent state. Default: `orthogonal`.",Default QSTR,string,,,,,,QSTR
tf.keras.layers.LSTMCell,bias_initializer,Initializer for the bias vector. Default: `zeros`.,Default QSTR,string,,,,,,QSTR
tf.keras.layers.SimpleRNNCell,bias_regularizer,Regularizer function applied to the bias vector. Default:`None`.,Default QSTR,,,,,,,
tf.linalg.matrix_rank,validate_args,"When `True`, additional assertions might be embedded in the graph. Default value: `False` (i.e., no graph assertions are added).",Default value CONSTANT_BOOL BSTR,bool,,,,0,,
tf.image.ssim_multiscale,k1,Default value 0.01,Default value CONSTANT_FLOAT,float,,,,0,,
tf.linalg.lu_solve,name,"Python `str` name given to ops managed by this object. Default value: `None` (i.e., 'lu_solve').",Default value QSTR i e QSTR,,,,,,,
tf.nn.depthwise_conv2d_backprop_input,dilations,"An optional list of `ints`. Defaults to `[1, 1, 1, 1]`. 1-D tensor of length 4.  The dilation factor for each dimension of`input`. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of`data_format`, see above for details. Dilations in the batch and depth dimensions must be 1.",Defaults to BSTR,,,,,1,,
tf.nn.pool,dilations,"Optional.  Dilation rate.  List of N ints >= 1. Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values of strides must be 1.",Defaults to BSTR N If any value of dilation_rate is REXPR then all values of PARAM must be CONSTANT_NUM,,,,,,,
tf.io.encode_base64,pad,An optional `bool`. Defaults to `False`. Bool whether padding is applied at the ends.,Defaults to CONSTANT_BOOL,bool,,,,0,,
tf.linalg.triangular_solve,adjoint,An optional `bool`. Defaults to `False`. Boolean indicating whether to solve with `matrix` or its (block-wise)        adjoint.,Defaults to CONSTANT_BOOL,bool,,,,0,,
tf.linalg.triangular_solve,lower,An optional `bool`. Defaults to `True`. Boolean indicating whether the innermost matrices in `matrix` are lower or upper triangular.,Defaults to CONSTANT_BOOL,bool,,,,0,,
tf.nn.max_pool_with_argmax,include_batch_in_index,An optional `boolean`. Defaults to `False`. Whether to include batch dimension in flattened index of `argmax`.,Defaults to CONSTANT_BOOL,bool,,,,0,,
tf.data.experimental.make_csv_dataset,use_quote_delim,"An optional bool. Defaults to `True`. If false, treats double quotation marks as regular characters inside of the string fields.",Defaults to CONSTANT_BOOL,bool,,,,0,,
tf.nn.fractional_avg_pool,seed,"An optional `int`.  Defaults to `0`.  If set to be non-zero, the random number generator is seeded by the given seed.  Otherwise it is seeded by a random seed.",Defaults to CONSTANT_NUM,int,,,,0,,
tf.image.encode_png,compression,An optional `int`. Defaults to `-1`. Compression level.,Defaults to CONSTANT_NUM,int,,,,0,,
tf.image.sample_distorted_bounding_box,seed,"An optional `int`. Defaults to `0`. If `seed` is set to non-zero, the random number generator is seeded by the given `seed`.  Otherwise, it is seeded by a random seed.",Defaults to CONSTANT_NUM,int,,,,0,,
tf.io.decode_and_crop_jpeg,channels,An optional `int`. Defaults to `0`. Number of color channels for the decoded image.,Defaults to CONSTANT_NUM,int,,,,0,,
tf.nn.local_response_normalization,depth_radius,An optional `int`. Defaults to `5`. 0-D.  Half-width of the 1-D normalization window.,Defaults to CONSTANT_NUM,int,,,,0,,
tf.ragged.range,deltas,Vector or scalar `Tensor`.  Specifies the increment for each range. Defaults to `1`.,Defaults to CONSTANT_NUM,int,,,,0,,
tf.eye,num_columns,Optional non-negative `int32` scalar `Tensor` giving the number of columns in each batch matrix.  Defaults to `num_rows`.,Defaults to PARAM,,,,,,,
tf.debugging.assert_equal,name,"A name for this operation (optional).  Defaults to ""assert_equal"".",Defaults to QSTR,,,,,,,
tf.debugging.assert_greater_equal,name,"A name for this operation (optional).  Defaults to ""assert_greater_equal"".",Defaults to QSTR,,,,,,,
tf.debugging.assert_none_equal,name,"A name for this operation (optional).  Defaults to ""assert_none_equal"".",Defaults to QSTR,,,,,,,
tf.debugging.assert_rank_at_least,name,"A name for this operation (optional).  Defaults to ""assert_rank_at_least"".",Defaults to QSTR,,,,,,,
tf.debugging.assert_integer,name,"A name for this operation (optional). Defaults to ""assert_integer"".",Defaults to QSTR,,,,,,,
tf.math.is_strictly_increasing,name,"A name for this operation (optional). Defaults to ""is_strictly_increasing""",Defaults to QSTR,,,,,,,
tf.debugging.assert_type,name,"A name for this operation. Defaults to ""assert_type""",Defaults to QSTR,,,,,,,
tf.print,output_stream,"The output stream, logging level, or file to print to. Defaults to sys.stderr, but sys.stdout, tf.compat.v1.logging.info, tf.compat.v1.logging.warning, tf.compat.v1.logging.error, absl.logging.info, absl.logging.warning and absl.loogging,error are also supported. To print to a file, pass a string started with ""file://"" followed by the file path, e.g., ""file:///tmp/foo.out"".",Defaults to sys stderr but sys stdout tf compat v1 logging info tf compat v1 logging warning tf compat v1 logging error absl logging info absl logging warning and absl loogging error are also supported,,,,,,,
tf.data.experimental.make_batched_features_dataset,reader,A function or class that can be called with a `filenames` tensor and (optional) `reader_args` and returns a `Dataset` of `Example` tensors. Defaults to `tf.data.TFRecordDataset`.,Defaults to tf data TFRecordDataset,,,,,,,
tf.math.argmin,output_type,"An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to`tf.int64`.",Defaults toD_TYPE,dtype,,,,0,,
tf.nn.pool,dilations,"Optional.  Dilation rate.  List of N ints >= 1. Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values of strides must be 1.",Dilation rate,numeric,,,,,"[0,1]",
tf.nn.conv1d_transpose,dilations,"An int or list of `ints` that has length `1` or `3` which defaults to 1. The dilation factor for each dimension of input. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. Dilations in the batch and depth dimensions must be 1.",Dilations in the batch and depth dimensions must be CONSTANT_NUM,,,,,,,
tf.nn.depthwise_conv2d_backprop_input,dilations,"An optional list of `ints`. Defaults to `[1, 1, 1, 1]`. 1-D tensor of length 4.  The dilation factor for each dimension of`input`. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of`data_format`, see above for details. Dilations in the batch and depth dimensions must be 1.",Dilations in the batch and depth dimensions must be CONSTANT_NUM,,,,,,,
tf.keras.layers.Embedding,output_dim,int >= 0. Dimension of the dense embedding.,Dimension of the dense embedding,int,,,,,,
tf.train.list_variables,ckpt_dir_or_file,Directory with checkpoints file or path to checkpoint.,Directory with checkpoints file or path to checkpoint,string,,,,0,,
tf.io.decode_csv,records,A `Tensor` of type `string`. Each string is a record/row in the csv and all records should have the same format.,Each D_TYPE is a record row in the csv and all records should have the same format,,,,,,,
tf.nn.embedding_lookup_sparse,params,"A single tensor representing the complete embedding tensor, or a list of P tensors all of same shape except for the first dimension, representing sharded embedding tensors.  Alternatively, a`PartitionedVariable`, created by partitioning along dimension 0. Each element must be appropriately sized for `""div""` `partition_strategy`.",Each element must be appropriately sized for QSTR,,,,,,,
tf.feature_column.sequence_categorical_column_with_vocabulary_list,vocabulary_list,An ordered iterable defining the vocabulary. Each feature is mapped to the index of its value (if present) in `vocabulary_list`. Must be castable to `dtype`.,Each feature is mapped to the index of its value BSTR in QSTR,,,,,,,
tf.xla.experimental.jit_scope,compile_ops,"Whether to enable or disable compilation in the scope. Either a Python bool, or a callable that accepts the parameter`node_def` and returns a python bool.",Either a Python D_TYPE or a callable that accepts the parameter QSTR and returns a python D_TYPE,D_TYPE,,,,0,,
tf.compat.dimension_value,dimension,"Either a `Dimension` instance, an integer, or None.",Either a QSTR instance an D_TYPE or None,D_TYPE,,,,,,
tf.keras.layers.Lambda,mask,"Either None (indicating no masking) or a callable with the same signature as the `compute_mask` layer method, or a tensor that will be returned as output mask regardless what the input is.",Either None BSTR or a callable with the same signature as the QSTR layer method or a D_STRUCTURE that will be returned as output mask regardless what the input is,,,,,,,
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",Either the QSTR or the pair of QSTR are provided QSTR is a scalar D_STRUCTURE that represents the batch size of the inputs,,,,,,,
tf.strings.unicode_transcode,input_encoding,"A `string`. Text encoding of the input strings. This is any of the encodings supported by ICU ucnv algorithmic converters. Examples: `""UTF-16"", ""US ASCII"", ""UTF-8""`.",Examples UTF CONSTANT_NUM QSTR,,,,,,,
tf.debugging.experimental.enable_dump_debug_info,circular_buffer_size,"Size of the circular buffers for execution events. These circular buffers are designed to reduce the overhead of debugging dumping. They hold the most recent debug events concerning eager execution of ops and `tf.function`s and traces of tensor values computed inside`tf.function`s. They are written to the file system only when the proper flushing method is called (see description of return values below). Expected to be an integer. If <= 0, the circular-buffer behavior will be disabled, i.e., the execution debug events will be written to the file writers in the same way as non-execution events such as op creations and source-file snapshots.",Expected to be an D_TYPE,D_TYPE,,,,0,,
tf.io.decode_proto,field_names,"A list of `strings`. List of strings containing proto field names. An extension field can be decoded by using its full name, e.g. EXT_PACKAGE.EXT_FIELD_NAME.",EXT_PACKAGE EXT_FIELD_NAME,,,,,,,
tf.estimator.add_metrics,metric_fn,"A function which should obey the following signature: Args: can only have following four arguments in any order:predictions: Predictions `Tensor` or dict of `Tensor` created by given`estimator`.features: Input `dict` of `Tensor` objects created by `input_fn` which is given to `estimator.evaluate` as an argument.labels:  Labels `Tensor` or dict of `Tensor` created by `input_fn`which is given to `estimator.evaluate` as an argument.config: config attribute of the `estimator`.Returns: Dict of metric results keyed by name. Final metrics are a union of this and `estimator's` existing metrics. If there is a name conflict between this and `estimator`s existing metrics, this will override the existing one. The values of the dict are the results of calling a metric function, namely a `(metric_tensor, update_op)` tuple. ",Final metrics are a union of this and PARAMs existing metrics,,,,,,,
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",For backward compatible reason if this attribute is not available for the cell the value will be inferred by the first element of the QSTR A get_initial_state inputs None batch_size None dtype None QSTR call as the initial state if the user didn t specify any initial state via other means,,,,,,,
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",For backward compatible reason if this method is not implemented by the cell the RNN layer will create a zero filled D_STRUCTURE with the size of BSTR,,,,,,,
tf.nn.fractional_avg_pool,pooling_ratio,"A list of `floats` that has length >= 4.  Pooling ratio for each dimension of `value`, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling ratio on height and width dimensions respectively.",For example a valid pooling ratio looks like BSTR,,,,,,,
tf.nn.fractional_max_pool,pooling_ratio,"An int or list of `ints` that has length `1`, `2` or `4`. Pooling ratio for each dimension of `value`, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling ratio on height and width dimensions respectively.",For example a valid pooling ratio looks like BSTR,,,,,,,
tf.keras.layers.PReLU,shared_axes,"The axes along which to share learnable parameters for the activation function. For example, if the incoming feature maps are from a 2D convolution with output shape `(batch, height, width, channels)`, and you wish to share parameters across space so that each filter only has one set of parameters, set `shared_axes=[1, 2]`.",For example if the incoming feature maps are from a CONSTANT_NUM D convolution with output shape BSTR and you wish to share parameters across space so that each filter only has one set of parameters set shared_axes BSTR,,,,,,,
tf.signal.idct,axis,For future expansion. The axis to compute the DCT along. Must be `-1`.,For future expansion,,,,,,,
tf.nn.max_pool,data_format,"A string. Specifies the channel dimension. For N=1 it can be either ""NWC"" (default) or ""NCW"", for N=2 it can be either ""NHWC"" (default) or ""NCHW"" and for N=3 either ""NDHWC"" (default) or ""NCDHW"".",For N CONSTANT_NUM it can be either QSTR BSTR or QSTR for N CONSTANT_NUM it can be either QSTR BSTR or QSTR and for N CONSTANT_NUM either QSTR BSTR or QSTR,,,,,,,QSTR
tf.nn.with_space_to_batch,op,"Function that maps (input, num_spatial_dims, padding) -> output",Function that maps BSTR REXPR,,,,,,,
tf.sparse.segment_sqrt_n,indices,A 1-D `Tensor` with indices into `data`. Has same rank as`segment_ids`.,Has same rank as PARAM,,,,,&PARAM,,
tf.image.crop_to_bounding_box,target_height,Height of the result.,Height of the result,numeric,,,,,"[0,inf)",
tf.keras.preprocessing.image.random_shift,hrg,"Height shift range, as a float fraction of the height.",Height shift range as a D_TYPE fraction of the height,D_TYPE,,,,,,
tf.image.crop_to_bounding_box,offset_width,Horizontal coordinate of the top-left corner of the result in the input.,Horizontal coordinate of the top left corner of the result in the input,,,,,,,
tf.extract_volume_patches,strides,"A list of `ints` that has length `>= 5`. 1-D of length 5. How far the centers of two consecutive patches are in`input`. Must be: `[1, stride_planes, stride_rows, stride_cols, 1]`.",How far the centers of two consecutive patches are in PARAM,,,,,,,
tf.nn.conv2d_transpose,strides,"An int or list of `ints` that has length `1`, `2` or `4`.  The stride of the sliding window for each dimension of `input`. If a single value is given it is replicated in the `H` and `W` dimension. By default the `N` and `C` dimensions are set to 0. The dimension order is determined by the value of `data_format`, see below for details.",If a single value is given it is replicated in the QSTR dimension,,,,,,,
tf.feature_column.numeric_column,default_value,"A single value compatible with `dtype` or an iterable of values compatible with `dtype` which the column takes on during`tf.Example` parsing if data is missing. A default value of `None` will cause `tf.io.parse_example` to fail if an example does not contain this column. If a single value is provided, the same value will be applied as the default value for every item. If an iterable of values is provided, the shape of the `default_value` should be equal to the given `shape`.",If a single value is provided the same value will be applied as the default value for every item,,,,,,,
tf.feature_column.numeric_column,default_value,"A single value compatible with `dtype` or an iterable of values compatible with `dtype` which the column takes on during`tf.Example` parsing if data is missing. A default value of `None` will cause `tf.io.parse_example` to fail if an example does not contain this column. If a single value is provided, the same value will be applied as the default value for every item. If an iterable of values is provided, the shape of the `default_value` should be equal to the given `shape`.",If an D_STRUCTURE of values is provided the PARAM of the QSTR should be equal to the given PARAM,,,,,,,
tf.keras.layers.ConvLSTM2D,unit_forget_bias,"Boolean. If True, add 1 to the bias of the forget gate at initialization. Use in combination with `bias_initializer=""zeros""`. This is recommended in Jozefowicz et al.",If CONSTANT_BOOL add CONSTANT_NUM to the bias of the forget gate at initialization,bool,,,,0,,
tf.math.cumulative_logsumexp,exclusive,"If `True`, perform exclusive cumulative log-sum-exp.",If CONSTANT_BOOL perform exclusive cumulative log sum exp,bool,,,,0,,
tf.keras.layers.SimpleRNN,go_backwards,"Boolean (default False). If True, process the input sequence backwards and return the reversed sequence.",If CONSTANT_BOOL process the input D_STRUCTURE backwards and return the reversed D_STRUCTURE,bool,,,,0,,
tf.linalg.matvec,b_is_sparse,"If `True`, `b` is treated as a sparse matrix.",If CONSTANT_BOOL QSTR is treated as a sparse matrix,bool,,,,0,,
tf.math.reduce_min,keepdims,"If true, retains reduced dimensions with length 1.",If CONSTANT_BOOL retains reduced dimensions with length CONSTANT_NUM,bool,,,,0,,
tf.sparse.reduce_max,output_is_sparse,"If true, returns a `SparseTensor` instead of a dense`Tensor` (the default).",If CONSTANT_BOOL returns a D_STRUCTURE instead of a denseD_STRUCTURE BSTR,bool,,,,0,,
tf.io.decode_image,expand_animations,"Controls the shape of the returned op's output. If`True`, the returned op will produce a 3-D tensor for PNG, JPEG, and BMP files; and a 4-D tensor for all GIFs, whether animated or not. If,`False`, the returned op will produce a 3-D tensor for all file types and will truncate animated GIFs to the first frame.",If CONSTANT_BOOL the returned op will produce a CONSTANT_NUM D D_STRUCTURE for all file types and will truncate animated GIFs to the first frame,bool,,,,0,,
tf.io.decode_image,expand_animations,"Controls the shape of the returned op's output. If`True`, the returned op will produce a 3-D tensor for PNG, JPEG, and BMP files; and a 4-D tensor for all GIFs, whether animated or not. If,`False`, the returned op will produce a 3-D tensor for all file types and will truncate animated GIFs to the first frame.",If CONSTANT_BOOL the returned op will produce a CONSTANT_NUM D D_STRUCTURE for PNG JPEG and BMP files and a CONSTANT_NUM D D_STRUCTURE for all GIFs whether animated or not,bool,,,,0,,
tf.data.experimental.make_csv_dataset,use_quote_delim,"An optional bool. Defaults to `True`. If false, treats double quotation marks as regular characters inside of the string fields.",If CONSTANT_BOOL treats D_TYPE quotation marks as regular characters inside of the D_TYPE fields,bool,,,,0,,
tf.keras.layers.Attention,use_scale,"If `True`, will create a scalar variable to scale the attention scores.",If CONSTANT_BOOL will create a scalar variable to scale the attention scores,bool,,,,0,,
tf.control_dependencies,control_inputs,"A list of `Operation` or `Tensor` objects which must be executed or computed before running the operations defined in the context. Can also be `None` to clear the control dependencies. If eager execution is enabled, any callable object in the `control_inputs` list will be called.",If eager execution is enabled any callable object in the QSTR D_STRUCTURE will be called,,,,,,,
tf.linalg.diag,num_cols,"The number of columns of the output matrix. If it is not provided, the op assumes the output matrix is a square matrix and infers the matrix size from `d_lower`, `d_upper`, and the innermost dimension of `diagonal`.",If it is not provided the op assumes the output matrix is a square matrix and infers the matrix size from QSTR and the innermost dimension of PARAM,,,,,,,
tf.range,limit,"A 0-D `Tensor` (scalar). Upper limit of sequence, exclusive. If None, defaults to the value of `start` while the first entry of the range defaults to 0.",If None defaults to the value of PARAM while the first entry of the range defaults to CONSTANT_NUM,,,,,,,
tf.config.set_logical_device_configuration,logical_devices,"(optional) List of `tf.config.LogicalDeviceConfiguration`objects to allocate for the specified `PhysicalDevice`. If None, the default configuration will be used.",If None the default configuration will be used,,,,,,,
tf.sparse.cross_hashed,hash_key,"Integer hash_key that will be used by the `FingerprintCat64`function. If not given, will use a default key.",If not given will use a default key,,,,,,,
tf.required_space_to_batch_paddings,base_paddings,"Optional int32 Tensor of shape [N, 2].  Specifies the minimum amount of padding to use.  All elements must be >= 0.  If not specified, defaults to 0.",If not specified defaults to CONSTANT_NUM,,,,,,,
tf.ragged.range,dtype,"The type of the elements of the resulting tensor.  If not specified, then a value is chosen based on the other args.",If not specified then a value is chosen based on the other args,,,,,,,
tf.keras.backend.ctc_decode,beam_width,if `greedy` is `false`: a beam search decoder will be used with a beam of this width.,if PARAM is CONSTANT_BOOL a beam search decoder will be used with a beam of this width,,,,,,,
tf.data.experimental.make_csv_dataset,label_name,"A optional string corresponding to the label column. If provided, the data for this column is returned as a separate `Tensor` from the features dictionary, so that the dataset complies with the format expected by a `tf.Estimator.train` or `tf.Estimator.evaluate` input function.",If provided the data for this column is returned as a separate D_STRUCTURE from the features D_STRUCTURE so that the dataset complies with the format expected by a tf Estimator train QSTR tf Estimator evaluate input function,,,,,,,
tf.math.reduce_euclidean_norm,axis,"The dimensions to reduce. If `None` (the default), reduces all dimensions. Must be in the range `[-rank(input_tensor), rank(input_tensor))`.",If QSTR BSTR reduces all dimensions,,,,,,,
tf.image.sample_distorted_bounding_box,seed,"An optional `int`. Defaults to `0`. If `seed` is set to non-zero, the random number generator is seeded by the given `seed`.  Otherwise, it is seeded by a random seed.",If QSTR is set to non zero the random number generator is seeded by the given QSTR,,,,,,,
tf.debugging.experimental.enable_dump_debug_info,circular_buffer_size,"Size of the circular buffers for execution events. These circular buffers are designed to reduce the overhead of debugging dumping. They hold the most recent debug events concerning eager execution of ops and `tf.function`s and traces of tensor values computed inside`tf.function`s. They are written to the file system only when the proper flushing method is called (see description of return values below). Expected to be an integer. If <= 0, the circular-buffer behavior will be disabled, i.e., the execution debug events will be written to the file writers in the same way as non-execution events such as op creations and source-file snapshots.",If REXPR the circular buffer behavior will be disabled i e the execution debug events will be written to the file writers in the same way as non execution events such as op creations and source file snapshots,,,,,,,
tf.nn.fractional_avg_pool,seed,"An optional `int`.  Defaults to `0`.  If set to be non-zero, the random number generator is seeded by the given seed.  Otherwise it is seeded by a random seed.",If set to be non zero the random number generator is seeded by the given seed,,,,,,,
tf.nn.conv1d_transpose,dilations,"An int or list of `ints` that has length `1` or `3` which defaults to 1. The dilation factor for each dimension of input. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. Dilations in the batch and depth dimensions must be 1.",If set to k REXPR there will be k CONSTANT_NUM skipped cells between each filter element on that dimension,,,,,,,
tf.nn.depthwise_conv2d_backprop_input,dilations,"An optional list of `ints`. Defaults to `[1, 1, 1, 1]`. 1-D tensor of length 4.  The dilation factor for each dimension of`input`. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of`data_format`, see above for details. Dilations in the batch and depth dimensions must be 1.",If set to k REXPR there will be k CONSTANT_NUM skipped cells between each PARAM element on that dimension,,,,,,,
tf.sets.intersection,b,"`Tensor` or `SparseTensor` of the same type as `a`. If sparse, indices must be sorted in row-major order.",If sparse indices must be sorted in row major order,,,,,,,
tf.sets.difference,b,"`Tensor` or `SparseTensor` of the same type as `a`. If sparse, indices must be sorted in row-major order.",If sparse indices must be sorted in row major order,,,,,,,
tf.estimator.add_metrics,metric_fn,"A function which should obey the following signature: Args: can only have following four arguments in any order:predictions: Predictions `Tensor` or dict of `Tensor` created by given`estimator`.features: Input `dict` of `Tensor` objects created by `input_fn` which is given to `estimator.evaluate` as an argument.labels:  Labels `Tensor` or dict of `Tensor` created by `input_fn`which is given to `estimator.evaluate` as an argument.config: config attribute of the `estimator`.Returns: Dict of metric results keyed by name. Final metrics are a union of this and `estimator's` existing metrics. If there is a name conflict between this and `estimator`s existing metrics, this will override the existing one. The values of the dict are the results of calling a metric function, namely a `(metric_tensor, update_op)` tuple. ",If there is a name conflict between this and PARAMs existing metrics this will override the existing one,,,,,,,
tf.keras.preprocessing.sequence.skipgrams,sequence,"A word sequence (sentence), encoded as a list     of word indices (integers). If using a `sampling_table`,     word indices are expected to match the rank     of the words in a reference dataset (e.g. 10 would encode     the 10-th most frequently occurring token).     Note that index 0 is expected to be a non-word and will be skipped.",If using a PARAM word indices are expected to match the rank of the words in a reference dataset e g,,,,,,,
tf.keras.layers.Conv3D,activation,"Activation function to use. If you don't specify anything, no activation is applied (ie. ""linear"" activation: `a(x) = x`).",If you don t specify anything no activation is applied ie,,,,,,,
tf.keras.layers.DenseFeatures,feature_columns,"An iterable containing the FeatureColumns to use as inputs to your model. All items should be instances of classes derived from `DenseColumn` such as `numeric_column`, `embedding_column`,`bucketized_column`, `indicator_column`. If you have categorical features, you can wrap them with an `embedding_column` or`indicator_column`.",If you have categorical features you can wrap them with an QSTR,,,,,,,
tf.keras.layers.Conv3DTranspose,data_format,"A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs.`channels_last` corresponds to inputs with shape`(batch, depth, height, width, channels)` while `channels_first`corresponds to inputs with shape`(batch, channels, depth, height, width)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be ""channels_last"".",If you never set it then it will be QSTR,,,,,,,
tf.keras.layers.AveragePooling3D,data_format,"A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs.`channels_last` corresponds to inputs with shape`(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`while `channels_first` corresponds to inputs with shape`(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be ""channels_last"".",If you never set it then it will be QSTR,,,,,,,
tf.keras.layers.LocallyConnected1D,implementation,"implementation mode, either `1`, `2`, or `3`.`1` loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops.`2` stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops.`3` stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply.How to choose:`1`: large, dense models,`2`: small models,`3`: large, sparse models,where ""large"" stands for large input/output activations (i.e. many `filters`, `input_filters`, large `input_size`,`output_size`), and ""sparse"" stands for few connections between inputs and outputs, i.e. small ratio`filters * input_filters * kernel_size / (input_size * strides)`, where inputs to and outputs of the layer are assumed to have shapes`(input_size, input_filters)`, `(output_size, filters)`respectively.It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM.Also, only `padding=""valid""` is supported by `implementation=1`.",implementation mode either CONSTANT_NUM CONSTANT_NUM loops over input spatial locations to perform the forward pass,,,,,,,CONSTANT_NUM
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",In the case that QSTR is a D_STRUCTURE of RNN cell instances the cells will be stacked on top of each other in the RNN resulting in an efficient stacked RNN,,,,,,,
tf.keras.layers.Conv3D,bias_initializer,Initializer for the bias vector.,Initializer for the bias D_STRUCTURE,,,,,,,
tf.keras.layers.LSTMCell,bias_initializer,Initializer for the bias vector. Default: `zeros`.,Initializer for the bias D_STRUCTURE,,,,,,,
tf.keras.layers.Dense,kernel_initializer,Initializer for the `kernel` weights matrix.,Initializer for the QSTR weights matrix,,,,,,,
tf.keras.layers.LSTMCell,kernel_initializer,"Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`.",Initializer for the QSTR weights matrix used for the linear transformation of the inputs,,,,,,,
tf.keras.layers.LSTM,kernel_initializer,"Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`.",Initializer for the QSTR weights matrix used for the linear transformation of the inputs,,,,,,,
tf.keras.layers.SimpleRNN,recurrent_initializer,"Initializer for the `recurrent_kernel`weights matrix, used for the linear transformation of the recurrent state. Default: `orthogonal`.",Initializer for the QSTR weights matrix used for the linear transformation of the recurrent state,,,,,,,
tf.keras.activations.tanh,x,Input tensor.,Input D_STRUCTURE,,D_STRUCTURE,,,,,
tf.keras.preprocessing.image.apply_channel_shift,x,Input tensor. Must be 3D.,Input D_STRUCTURE,,D_STRUCTURE,,,,,
tf.vectorized_map,fn,"The callable to be performed. It accepts one argument, which will have the same (possibly nested) structure as `elems`, and returns a possibly nested structure of Tensors and Operations, which may be different than the structure of `elems`.",It accepts one argument which will have the same BSTR structure as PARAM and returns a possibly nested structure of D_STRUCTURE and Operations which may be different than the structure of PARAM,,,,,,,
tf.scan,fn,"The callable to be performed.  It accepts two arguments.  The first will have the same structure as `initializer` if one is provided, otherwise it will have the same structure as `elems`.  The second will have the same (possibly nested) structure as `elems`.  Its output must have the same structure as `initializer` if one is provided, otherwise it must have the same structure as `elems`.",It accepts two arguments,,,,,,,
tf.keras.layers.experimental.preprocessing.PreprocessingLayer,data,"The data to train on. It can be passed either as a tf.data Dataset, or as a numpy array.",It can be passed either as a tf data Dataset or as a numpy D_STRUCTURE,,,,,,,
tf.keras.layers.Conv3DTranspose,data_format,"A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs.`channels_last` corresponds to inputs with shape`(batch, depth, height, width, channels)` while `channels_first`corresponds to inputs with shape`(batch, channels, depth, height, width)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be ""channels_last"".",It defaults to the QSTR value found in your Keras config file at keras keras json,,,,,,,
tf.keras.layers.AveragePooling3D,data_format,"A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs.`channels_last` corresponds to inputs with shape`(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`while `channels_first` corresponds to inputs with shape`(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be ""channels_last"".",It defaults to the QSTR value found in your Keras config file at keras keras json,,,,,,,
tf.keras.layers.LocallyConnected1D,implementation,"implementation mode, either `1`, `2`, or `3`.`1` loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops.`2` stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops.`3` stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply.How to choose:`1`: large, dense models,`2`: small models,`3`: large, sparse models,where ""large"" stands for large input/output activations (i.e. many `filters`, `input_filters`, large `input_size`,`output_size`), and ""sparse"" stands for few connections between inputs and outputs, i.e. small ratio`filters * input_filters * kernel_size / (input_size * strides)`, where inputs to and outputs of the layer are assumed to have shapes`(input_size, input_filters)`, `(output_size, filters)`respectively.It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM.Also, only `padding=""valid""` is supported by `implementation=1`.",It is memory efficient but performs a lot of BSTR ops CONSTANT_NUM stores layer weights in a dense but sparsely populated CONSTANT_NUM D matrix and implements the forward pass as a single matrix multiply,,,,,,,
tf.space_to_batch_nd,paddings,"A `Tensor`. Must be one of the following types: `int32`, `int64`. 2-D with shape `[M, 2]`, all values must be >= 0.`paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension`i + 1`, which corresponds to spatial dimension `i`.  It is required that`block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.This operation is equivalent to the following steps: Zero-pad the start and end of dimensions `[1, ..., M]` of the input according to `paddings` to produce `padded` of shape `padded_shape`.Reshape `padded` to `reshaped_padded` of shape:[batch] + [padded_shape[1] / block_shape[0],  block_shape[0], ..., padded_shape[M] / block_shape[M-1], block_shape[M-1]] + remaining_shapePermute dimensions of `reshaped_padded` to produce`permuted_reshaped_padded` of shape:block_shape + [batch] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shapeReshape `permuted_reshaped_padded` to flatten `block_shape` into the batch dimension, producing an output tensor of shape:[batch * prod(block_shape)] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape Some examples:(1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and   `paddings = [[0, 0], [0, 0]]`:",It is required that PARAM BSTR divides QSTR This operation is equivalent to the following steps Zero pad the start and end of dimensions BSTR of the PARAM according to QSTR to produce QSTR of shape QSTR Reshape QSTR to QSTR of shape BSTR padded_shape BSTR PARAM BSTR PARAM BSTR padded_shape BSTR PARAM BSTR PARAM BSTR remaining_shapePermute dimensions of QSTR to produce QSTR of shape PARAM BSTR padded_shape BSTR PARAM BSTR padded_shape BSTR PARAM BSTR remaining_shapeReshape QSTR to flatten PARAM into the batch dimension producing an output D_STRUCTURE of shape BSTR padded_shape BSTR PARAM BSTR padded_shape BSTR PARAM BSTR remaining_shape Some examples BSTR For the following PARAM of shape BSTR PARAM BSTR and paddings BSTR BSTR,,,,,,,
tf.feature_column.numeric_column,key,"A unique string identifying the input feature. It is used as the column name and the dictionary key for feature parsing configs, feature`Tensor` objects, and feature columns.",It is used as the column name and the D_STRUCTURE key for feature parsing configs featureD_STRUCTURE objects and feature columns,,,,,,,
tf.estimator.regressor_parse_example_spec,label_key,A string identifying the label. It means tf.Example stores labels with this key.,It means tf Example stores labels with this key,,,,,,,
tf.nn.conv_transpose,input,"An N+2 dimensional `Tensor` of shape`[batch_size] + input_spatial_shape + [in_channels]` if data_format does not start with ""NC"" (default), or`[batch_size, in_channels] + input_spatial_shape` if data_format starts with ""NC"". It must be one of the following types:`half`, `bfloat16`, `float32`, `float64`.",It must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.keras.layers.LocallyConnected1D,implementation,"implementation mode, either `1`, `2`, or `3`.`1` loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops.`2` stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops.`3` stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply.How to choose:`1`: large, dense models,`2`: small models,`3`: large, sparse models,where ""large"" stands for large input/output activations (i.e. many `filters`, `input_filters`, large `input_size`,`output_size`), and ""sparse"" stands for few connections between inputs and outputs, i.e. small ratio`filters * input_filters * kernel_size / (input_size * strides)`, where inputs to and outputs of the layer are assumed to have shapes`(input_size, input_filters)`, `(output_size, filters)`respectively.It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM.Also, only `padding=""valid""` is supported by `implementation=1`.",It uses a lot of RAM but performs few BSTR ops CONSTANT_NUM stores layer weights in a sparse D_STRUCTURE and implements the forward pass as a single sparse matrix multiply How to choose CONSTANT_NUM large dense models CONSTANT_NUM small models CONSTANT_NUM large sparse models where QSTR stands for large input output activations i e,,,,,,,
tf.image.random_hue,seed,An operation-specific seed. It will be used in conjunction with the graph-level seed to determine the real seeds that will be used in this operation. Please see the documentation of set_random_seed for its interaction with the graph-level random seed.,It will be used in conjunction with the graph level seed to determine the real seeds that will be used in this operation,,,,,,,
tf.scan,fn,"The callable to be performed.  It accepts two arguments.  The first will have the same structure as `initializer` if one is provided, otherwise it will have the same structure as `elems`.  The second will have the same (possibly nested) structure as `elems`.  Its output must have the same structure as `initializer` if one is provided, otherwise it must have the same structure as `elems`.",Its output must have the same structure as PARAM if one is provided otherwise it must have the same structure as PARAM,,,,,,,
tf.keras.backend.ones_like,x,Keras variable or tensor.,Keras variable or D_STRUCTURE,,D_STRUCTURE,,,,,
tf.linspace,stop,A `Tensor`. Must have the same type as `start`. 0-D tensor. Last entry in the range.,Last entry in the range,,,,,,,
tf.keras.backend.ctc_label_dense_to_sparse,label_lengths,length of the labels.,length of the PARAM,int,,,,,"[0,inf)",
tf.debugging.enable_check_numerics,path_length_limit,Limit to the file path included in the printed stack trace. Applicable only to ops in `tf.function`s (graphs).,Limit to the file path included in the printed stack trace,,,,,,,
tf.keras.layers.LocallyConnected1D,implementation,"implementation mode, either `1`, `2`, or `3`.`1` loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops.`2` stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops.`3` stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply.How to choose:`1`: large, dense models,`2`: small models,`3`: large, sparse models,where ""large"" stands for large input/output activations (i.e. many `filters`, `input_filters`, large `input_size`,`output_size`), and ""sparse"" stands for few connections between inputs and outputs, i.e. small ratio`filters * input_filters * kernel_size / (input_size * strides)`, where inputs to and outputs of the layer are assumed to have shapes`(input_size, input_filters)`, `(output_size, filters)`respectively.It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM.Also, only `padding=""valid""` is supported by `implementation=1`.",many PARAM QSTR large QSTR and QSTR stands for few connections between inputs and outputs i e,,,,,,,
tf.image.random_jpeg_quality,max_jpeg_quality,Maximum jpeg encoding quality to use.,Maximum jpeg encoding quality to use,,,,,,,
tf.image.resize_with_pad,method,Method to use for resizing image. See `image.resize()`,Method to use for resizing PARAM,,,,,,,
tf.keras.datasets.mnist.load_data,path,DF: mnist.npz,mnist npz,,,,,,,
tf.signal.linear_to_mel_weight_matrix,dtype,The `DType` of the result matrix. Must be a floating point type.,Must be a D_TYPE type,D_TYPE,,,,0,,
tf.nn.erosion2d,dilations,"A list of `ints` that has length `>= 4`. 1-D of length 4. The input stride for atrous morphological dilation. Must be: `[1, rate_height, rate_width, 1]`.",Must be BSTR,,,,BSTR,,,
tf.extract_volume_patches,strides,"A list of `ints` that has length `>= 5`. 1-D of length 5. How far the centers of two consecutive patches are in`input`. Must be: `[1, stride_planes, stride_rows, stride_cols, 1]`.",Must be BSTR,,,,BSTR,,,
tf.feature_column.sequence_categorical_column_with_vocabulary_list,vocabulary_list,An ordered iterable defining the vocabulary. Each feature is mapped to the index of its value (if present) in `vocabulary_list`. Must be castable to `dtype`.,Must be castable to PARAM,,,,,,,
tf.signal.idct,axis,For future expansion. The axis to compute the DCT along. Must be `-1`.,Must be CONSTANT_NUM,,,,,,,CONSTANT_NUM
tf.keras.preprocessing.image.apply_channel_shift,x,Input tensor. Must be 3D.,Must be CONSTANT_NUM D,,,,,CONSTANT_NUM,,
tf.gather,indices,"The index `Tensor`.  Must be one of the following types: `int32`,`int64`. Must be in range `[0, params.shape[axis])`.",Must be in range CONSTANT_NUM PARAM shape BSTR,,,,BSTR,,,
tf.math.cumulative_logsumexp,axis,"A `Tensor` of type `int32` or `int64` (default: 0). Must be in the range `[-rank(x), rank(x))`.",Must be in the range BSTR,,,,,,BSTR,
tf.math.reduce_euclidean_norm,axis,"The dimensions to reduce. If `None` (the default), reduces all dimensions. Must be in the range `[-rank(input_tensor), rank(input_tensor))`.",Must be in the range BSTR,,,,,,BSTR,
tf.gather,batch_dims,An `integer`.  The number of batch dimensions.  Must be less than `rank(indices)`.,Must be less than rank BSTR,,,,,,,
tf.bitcast,input,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int64`, `int32`, `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `complex64`, `complex128`, `qint8`, `quint8`, `qint16`, `quint16`, `qint32`.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.debugging.check_numerics,tensor,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.math.betainc,a,"A `Tensor`. Must be one of the following types: `float32`, `float64`.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.nn.selu,features,"A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.linspace,num,"A `Tensor`. Must be one of the following types: `int32`, `int64`. 0-D tensor. Number of values to generate.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.space_to_batch_nd,paddings,"A `Tensor`. Must be one of the following types: `int32`, `int64`. 2-D with shape `[M, 2]`, all values must be >= 0.`paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension`i + 1`, which corresponds to spatial dimension `i`.  It is required that`block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.This operation is equivalent to the following steps: Zero-pad the start and end of dimensions `[1, ..., M]` of the input according to `paddings` to produce `padded` of shape `padded_shape`.Reshape `padded` to `reshaped_padded` of shape:[batch] + [padded_shape[1] / block_shape[0],  block_shape[0], ..., padded_shape[M] / block_shape[M-1], block_shape[M-1]] + remaining_shapePermute dimensions of `reshaped_padded` to produce`permuted_reshaped_padded` of shape:block_shape + [batch] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shapeReshape `permuted_reshaped_padded` to flatten `block_shape` into the batch dimension, producing an output tensor of shape:[batch * prod(block_shape)] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape Some examples:(1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and   `paddings = [[0, 0], [0, 0]]`:",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.math.segment_min,segment_ids,"A `Tensor`. Must be one of the following types: `int32`, `int64`. A 1-D tensor whose size is equal to the size of `data`'s first dimension.  Values should be sorted and can be repeated.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.image.sample_distorted_bounding_box,image_size,"A `Tensor`. Must be one of the following types: `uint8`, `int8`,`int16`, `int32`, `int64`. 1-D, containing `[height, width, channels]`.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.gather,indices,"The index `Tensor`.  Must be one of the following types: `int32`,`int64`. Must be in range `[0, params.shape[axis])`.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.image.ssim_multiscale,img2,Second image batch. Must have the same rank as img1.,Must have the same rank as PARAM,,,,,&PARAM,,
tf.linalg.triangular_solve,rhs,"A `Tensor`. Must have the same type as `matrix`. Shape is `[..., M, K]`.",Must have the same type as PARAM,&PARAM,,,,,,
tf.dtypes.complex,imag,A `Tensor`. Must have the same type as `real`.,Must have the same type as PARAM,&PARAM,,,,,,
tf.linspace,stop,A `Tensor`. Must have the same type as `start`. 0-D tensor. Last entry in the range.,Must have the same type as PARAM,&PARAM,,,,,,
tf.math.polygamma,x,A `Tensor`. Must have the same type as `a`.,Must have the same type as QSTR,&PARAM,,,,,,
tf.linalg.cross,b,"A `Tensor`. Must have the same type as `a`. Another tensor, of same type and shape as `a`.",Must have the same type as QSTR,&PARAM,,,,,,
tf.bitwise.right_shift,y,A `Tensor`. Must have the same type as `x`.,Must have the same type as QSTR,&PARAM,,,,,,
tf.math.greater,y,A `Tensor`. Must have the same type as `x`.,Must have the same type as QSTR,&PARAM,,,,,,
tf.boolean_mask,tensor,N-D tensor.,N D D_STRUCTURE,,D_STRUCTURE,,,,,
tf.space_to_batch,input,"A `Tensor`. N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`, where spatial_shape has `M` dimensions.",N D with shape input_shape BSTR spatial_shape remaining_shape where spatial_shape has QSTR dimensions,,,,,,,
tf.nn.pool,name,Optional. Name of the op.,Name of the op,string,,,,0,,
tf.ragged.stack,axis,"A python integer, indicating the dimension along which to stack. (Note: Unlike `tf.stack`, the `axis` parameter must be statically known.) Negative values are supported only if the rank of at least one`values` value is statically known.",Negative PARAM are supported only if the rank of at least one PARAM value is statically known,,,,,,,
tf.keras.layers.ReLU,negative_slope,Float >= 0. Negative slope coefficient.,Negative slope coefficient,,,,,,"(-inf,0]",
tf.nn.ctc_loss,blank_index,"(optional) Set the class index to use for the blank label. Negative values will start from num_classes, ie, -1 will reproduce the ctc_loss behavior of using num_classes - 1 for the blank symbol. There is some memory/performance overhead to switching from the default of 0 as an additional shifted copy of the logits may be created.",Negative values will start from num_classes ie CONSTANT_NUM will reproduce the ctc_loss behavior of using num_classes CONSTANT_NUM for the blank symbol,,,,,,,
tf.keras.backend.rnn,step_function,"RNN step function. Args;     input; Tensor with shape `(samples, ...)` (no time dimension),         representing input for the batch of samples at a certain         time step.     states; List of tensors. Returns;     output; Tensor with shape `(samples, output_dim)`        (no time dimension).     new_states; List of tensors, same length and shapes         as 'states'. The first state in the list must be the         output tensor at the previous timestep.",new_states D_STRUCTURE of D_STRUCTURE same length and shapes as QSTR,,,,,,,
tf.keras.utils.get_file,archive_format,"Archive format to try for extracting the file. Options are 'auto', 'tar', 'zip', and None. 'tar' includes tar, tar.gz, and tar.bz files. The default 'auto' is ['tar', 'zip']. None or an empty list will return no matches found.",None or an empty D_STRUCTURE will return no matches found,,,,,,,
tf.keras.preprocessing.sequence.skipgrams,sequence,"A word sequence (sentence), encoded as a list     of word indices (integers). If using a `sampling_table`,     word indices are expected to match the rank     of the words in a reference dataset (e.g. 10 would encode     the 10-th most frequently occurring token).     Note that index 0 is expected to be a non-word and will be skipped.",Note that index CONSTANT_NUM is expected to be a non word and will be skipped,,,,,,,
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",Note that the shape BSTR might be QSTR during the graph construction,,,,,,,
tf.ragged.stack,axis,"A python integer, indicating the dimension along which to stack. (Note: Unlike `tf.stack`, the `axis` parameter must be statically known.) Negative values are supported only if the rank of at least one`values` value is statically known.",Note Unlike tf stack the QSTR parameter must be statically known,,,,,,,
tf.io.decode_and_crop_jpeg,channels,An optional `int`. Defaults to `0`. Number of color channels for the decoded image.,Number of color channels for the decoded image,int,,,,0,"[0,inf)",
tf.linspace,num,"A `Tensor`. Must be one of the following types: `int32`, `int64`. 0-D tensor. Number of values to generate.",Number of values to generate,int,,,,0,"[0,inf)",
tf.keras.layers.MaxPool3D,padding,"One of `""valid""` or `""same""` (case-insensitive).",One of QSTR BSTR,,,,,,,QSTR
tf.keras.layers.Conv2DTranspose,padding,"one of `""valid""` or `""same""` (case-insensitive).",one of QSTR BSTR,,,,,,,QSTR
tf.data.experimental.dense_to_ragged_batch,drop_remainder,"(Optional.) A `tf.bool` scalar `tf.Tensor`, representing whether the last batch should be dropped in the case it has fewer than`batch_size` elements; the default behavior is not to drop the smaller batch.",ONE_WORD BSTR,,,,,,,
tf.debugging.assert_rank_at_least,x,`Tensor`.,ONE_WORD D_STRUCTURE,,D_STRUCTURE,,,,,
tf.debugging.assert_near,rtol,"`Tensor`.  Same `dtype` as, and broadcastable to, `x`. The relative tolerance.  Default is `10 * eps`.",ONE_WORD D_STRUCTURE,,D_STRUCTURE,,,,,
tf.keras.backend.foldl,elems,tensor,ONE_WORD D_STRUCTURE,,D_STRUCTURE,,,,,
tf.keras.layers.ConvLSTM2D,unit_forget_bias,"Boolean. If True, add 1 to the bias of the forget gate at initialization. Use in combination with `bias_initializer=""zeros""`. This is recommended in Jozefowicz et al.",ONE_WORD D_TYPE,D_TYPE,,,,,,
tf.keras.layers.GRU,return_sequences,"Boolean. Whether to return the last output in the output sequence, or the full sequence. Default: `False`.",ONE_WORD D_TYPE,D_TYPE,,,,,,
tf.keras.preprocessing.text.text_to_word_sequence,filters,"list (or concatenation) of characters to filter out, such as     punctuation. Default: ``!""#$%&()*+,-./:;<=>?@[\]^_`{|}~\t\n``,     includes basic punctuation, tabs, and newlines.",ONE_WORD Default,,,,,,,
tf.nn.pool,dilations,"Optional.  Dilation rate.  List of N ints >= 1. Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values of strides must be 1.",ONE_WORD Optional,,,,,,,
tf.gradients,stop_gradients,Optional. A `Tensor` or list of tensors not to differentiate through.,ONE_WORD Optional,,,,,,,
tf.nn.pool,name,Optional. Name of the op.,ONE_WORD Optional,,,,,,,
tf.required_space_to_batch_paddings,base_paddings,"Optional int32 Tensor of shape [N, 2].  Specifies the minimum amount of padding to use.  All elements must be >= 0.  If not specified, defaults to 0.",Optional D_TYPE D_STRUCTURE of shape BSTR,D_TYPE,D_STRUCTURE,,BSTR,,,
tf.summary.write,name,Optional string name for this op.,Optional D_TYPE name for this op,D_TYPE,,,,0,,
tf.math.top_k,name,Optional name for the operation.,Optional name for the operation,string,,,,0,,
tf.eye,num_columns,Optional non-negative `int32` scalar `Tensor` giving the number of columns in each batch matrix.  Defaults to `num_rows`.,Optional non negative D_TYPE scalar D_STRUCTURE giving the number of columns in each batch matrix,D_TYPE,D_STRUCTURE,,,0,"[0,inf)",
tf.keras.Input,batch_size,optional static batch size (integer).,optional static batch size BSTR,int,,,,,"[0,inf)",
tf.summary.write,metadata,"Optional SummaryMetadata, as a proto or serialized bytes",Optional SummaryMetadata as a proto or serialized bytes,,,,,,,
tf.keras.utils.get_file,archive_format,"Archive format to try for extracting the file. Options are 'auto', 'tar', 'zip', and None. 'tar' includes tar, tar.gz, and tar.bz files. The default 'auto' is ['tar', 'zip']. None or an empty list will return no matches found.",Options are QSTR and None,,,,,,,QSTR
tf.summary.flush,writer,The `tf.summary.SummaryWriter` resource to flush. The thread default will be used if this parameter is None. Otherwise a `tf.no_op` is returned.,Otherwise a tf no_op is returned,,,,,,,
tf.nn.fractional_avg_pool,seed,"An optional `int`.  Defaults to `0`.  If set to be non-zero, the random number generator is seeded by the given seed.  Otherwise it is seeded by a random seed.",Otherwise it is seeded by a random seed,,,,,,,
tf.image.sample_distorted_bounding_box,seed,"An optional `int`. Defaults to `0`. If `seed` is set to non-zero, the random number generator is seeded by the given `seed`.  Otherwise, it is seeded by a random seed.",Otherwise it is seeded by a random seed,,,,,,,
tf.keras.layers.ConvLSTM2D,recurrent_activation,Activation function to use for the recurrent step.,PARAM function to use for the recurrent step,,,,,,,
tf.histogram_fixed_width,value_range,"Shape [2] `Tensor` of same `dtype` as `values`. values <= value_range[0] will be mapped to hist[0], values >= value_range[1] will be mapped to hist[-1].",PARAM REXPR BSTR will be mapped to hist BSTR PARAM REXPR BSTR will be mapped to hist BSTR,,,,,,,
tf.keras.datasets.mnist.load_data,path,path where to cache the dataset locally (relative to ~/.keras/datasets).,path where to cache the dataset locally relative to keras datasets,string,,,,0,,
tf.nn.compute_average_loss,per_example_loss,Per-example loss.,Per example loss,,,,,,,
tf.image.random_hue,seed,An operation-specific seed. It will be used in conjunction with the graph-level seed to determine the real seeds that will be used in this operation. Please see the documentation of set_random_seed for its interaction with the graph-level random seed.,Please see the documentation of set_random_seed for its interaction with the graph level random seed,,,,,,,
tf.nn.fractional_avg_pool,pooling_ratio,"A list of `floats` that has length >= 4.  Pooling ratio for each dimension of `value`, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling ratio on height and width dimensions respectively.",Pooling ratio for each dimension of PARAM currently only supports row and col dimension and should be REXPR,numeric,,,,,,
tf.nn.fractional_max_pool,pooling_ratio,"An int or list of `ints` that has length `1`, `2` or `4`. Pooling ratio for each dimension of `value`, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling ratio on height and width dimensions respectively.",Pooling ratio for each dimension of PARAM currently only supports row and col dimension and should be REXPR,numeric,,,,,,
tf.keras.backend.resize_images,height_factor,Positive integer.,Positive D_TYPE,D_TYPE,,,,,"(0,inf)",
tf.debugging.assert_negative,summarize,Print this many entries of each tensor.,Print this many entries of each D_STRUCTURE,int,,,,0,"[0,inf)",
tf.debugging.assert_near,summarize,Print this many entries of each tensor.,Print this many entries of each D_STRUCTURE,int,,,,0,"[0,inf)",
tf.linalg.lu_solve,name,"Python `str` name given to ops managed by this object. Default value: `None` (i.e., 'lu_solve').",Python D_TYPE name given to ops managed by this object,D_TYPE,,,,,,
tf.keras.layers.Conv3D,activation,"Activation function to use. If you don't specify anything, no activation is applied (ie. ""linear"" activation: `a(x) = x`).",QSTR activation a BSTR x,,,,,,,
tf.nn.conv3d_transpose,data_format,A string. 'NDHWC' and 'NCDHW' are supported.,QSTR are supported,,,,,,,QSTR
tf.nn.conv1d_transpose,data_format,A string. `'NWC'` and `'NCW'` are supported.,QSTR are supported,,,,,,,QSTR
tf.keras.backend.categorical_crossentropy,axis,"Int specifying the channels axis. `axis=-1` corresponds to data format `channels_last', and`axis=1`corresponds to data format`channels_first`.",QSTR channels_last and QSTR channels_first,,,,,,,
tf.nn.atrous_conv2d_transpose,filters,"A 4-D `Tensor` with the same type as `value` and shape`[filter_height, filter_width, out_channels, in_channels]`. `filters`'`in_channels` dimension must match that of `value`. Atrous convolution is equivalent to standard convolution with upsampled filters with effective height `filter_height + (filter_height - 1) * (rate - 1)` and effective width `filter_width + (filter_width - 1) * (rate - 1)`, produced by inserting `rate - 1` zeros along consecutive elements across the`filters`' spatial dimensions.",QSTR in_channels dimension must match that of PARAM,,,,,,,
tf.keras.utils.get_file,archive_format,"Archive format to try for extracting the file. Options are 'auto', 'tar', 'zip', and None. 'tar' includes tar, tar.gz, and tar.bz files. The default 'auto' is ['tar', 'zip']. None or an empty list will return no matches found.",QSTR includes tar tar gz and tar bz files,,,,,,,
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",QSTR is D_TYPE that represents the dtype of the inputs,,,,,,,
tf.strings.unicode_decode,input,An `N` dimensional potentially ragged `string` tensor with shape`[D1...DN]`.  `N` must be statically known.,QSTR must be statically known,,,,,,,
tf.searchsorted,side,left' or 'right'; 'left' corresponds to lower_bound and 'right' to upper_bound.,QSTR QSTR corresponds to lower_bound and QSTR to upper_bound,,,,,,,QSTR
tf.data.experimental.make_batched_features_dataset,shuffle_seed,Randomization seed to use for shuffling.,Randomization seed to use for shuffling,,,,,,,
tf.keras.layers.ConvLSTM2D,activity_regularizer,Regularizer function applied to.,Regularizer function applied to,,,,,,,
tf.keras.layers.Conv3D,bias_regularizer,Regularizer function applied to the bias vector.,Regularizer function applied to the bias D_STRUCTURE,,,,,,,
tf.keras.layers.SimpleRNNCell,bias_regularizer,Regularizer function applied to the bias vector. Default:`None`.,Regularizer function applied to the bias D_STRUCTURE,,,,,,,
tf.keras.layers.LocallyConnected1D,activity_regularizer,"Regularizer function applied to the output of the layer (its ""activation"")..",Regularizer function applied to the output of the layer BSTR,,,,,,,
tf.nn.RNNCellDropoutWrapper,dtype,"(optional) The `dtype` of the input, state, and output tensors. Required and used <strong>iff</strong> `variational_recurrent = True`.",Required and used REXPR REXPR strong REXPR CONSTANT_BOOL,,,,,,,
tf.image.resize_with_pad,method,DF: ResizeMethod.BILINEAR,ResizeMethod BILINEAR,,,,,,,
tf.keras.backend.rnn,step_function,"RNN step function. Args;     input; Tensor with shape `(samples, ...)` (no time dimension),         representing input for the batch of samples at a certain         time step.     states; List of tensors. Returns;     output; Tensor with shape `(samples, output_dim)`        (no time dimension).     new_states; List of tensors, same length and shapes         as 'states'. The first state in the list must be the         output tensor at the previous timestep.",Returns output D_STRUCTURE with shape BSTR BSTR,,,,,,,
tf.keras.datasets.reuters.get_word_index,path,DF: reuters_word_index.json,reuters_word_index json,,,,,,,
tf.image.adjust_gamma,image,RGB image or images to adjust.,RGB image or images to adjust,numeric,,,,,,
tf.keras.backend.rnn,step_function,"RNN step function. Args;     input; Tensor with shape `(samples, ...)` (no time dimension),         representing input for the batch of samples at a certain         time step.     states; List of tensors. Returns;     output; Tensor with shape `(samples, output_dim)`        (no time dimension).     new_states; List of tensors, same length and shapes         as 'states'. The first state in the list must be the         output tensor at the previous timestep.",RNN step function,,,,,,,
tf.debugging.assert_near,rtol,"`Tensor`.  Same `dtype` as, and broadcastable to, `x`. The relative tolerance.  Default is `10 * eps`.",Same QSTR as and broadcastable to QSTR,,,,,,,
tf.audio.encode_wav,sample_rate,A `Tensor` of type `int32`. Scalar containing the sample frequency.,Scalar containing the sample frequency,,D_STRUCTURE,,,0,,
tf.debugging.assert_rank,rank,Scalar integer `Tensor`.,Scalar D_TYPE D_STRUCTURE,D_TYPE,D_STRUCTURE,,,0,,
tf.image.ssim_multiscale,img2,Second image batch. Must have the same rank as img1.,Second image batch,numeric,,,,,,
tf.image.resize_with_pad,method,Method to use for resizing image. See `image.resize()`,See PARAM resize,,,,,,,
tf.random.categorical,seed,A Python integer. Used to create a random seed for the distribution. See `tf.compat.v1.set_random_seed` for behavior.,See tf compat v1 set_random_seed for behavior,,,,,,,
tf.image.random_flip_left_right,seed,A Python integer. Used to create a random seed. See`tf.compat.v1.set_random_seed` for behavior.,See tf compat v1 set_random_seed for behavior,,,,,,,
tf.histogram_fixed_width,value_range,"Shape [2] `Tensor` of same `dtype` as `values`. values <= value_range[0] will be mapped to hist[0], values >= value_range[1] will be mapped to hist[-1].",Shape BSTR D_STRUCTURE of same PARAM as PARAM,,D_STRUCTURE,,&PARAM,CONSTANT_NUM,,
tf.linalg.triangular_solve,rhs,"A `Tensor`. Must have the same type as `matrix`. Shape is `[..., M, K]`.",Shape is BSTR,,,,BSTR,,,
tf.math.reduce_variance,input_tensor,The tensor to reduce. Should have numeric type.,Should have D_TYPE type,D_TYPE,,,,,,
tf.debugging.experimental.enable_dump_debug_info,circular_buffer_size,"Size of the circular buffers for execution events. These circular buffers are designed to reduce the overhead of debugging dumping. They hold the most recent debug events concerning eager execution of ops and `tf.function`s and traces of tensor values computed inside`tf.function`s. They are written to the file system only when the proper flushing method is called (see description of return values below). Expected to be an integer. If <= 0, the circular-buffer behavior will be disabled, i.e., the execution debug events will be written to the file writers in the same way as non-execution events such as op creations and source-file snapshots.",Size of the circular buffers for execution events,int,,,,,"[0,inf)",
tf.keras.layers.LocallyConnected1D,implementation,"implementation mode, either `1`, `2`, or `3`.`1` loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops.`2` stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops.`3` stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply.How to choose:`1`: large, dense models,`2`: small models,`3`: large, sparse models,where ""large"" stands for large input/output activations (i.e. many `filters`, `input_filters`, large `input_size`,`output_size`), and ""sparse"" stands for few connections between inputs and outputs, i.e. small ratio`filters * input_filters * kernel_size / (input_size * strides)`, where inputs to and outputs of the layer are assumed to have shapes`(input_size, input_filters)`, `(output_size, filters)`respectively.It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM.Also, only `padding=""valid""` is supported by `implementation=1`.",small ratio PARAM input_filters PARAM BSTR where inputs to and outputs of the layer are assumed to have shapes BSTR BSTRrespectively It is recommended to benchmark each in the setting of interest to pick the most efficient one BSTR,,,,,,,
tf.nn.max_pool,data_format,"A string. Specifies the channel dimension. For N=1 it can be either ""NWC"" (default) or ""NCW"", for N=2 it can be either ""NHWC"" (default) or ""NCHW"" and for N=3 either ""NDHWC"" (default) or ""NCDHW"".",Specifies the channel dimension,,,,,,,
tf.ragged.range,deltas,Vector or scalar `Tensor`.  Specifies the increment for each range. Defaults to `1`.,Specifies the increment for each range,,,,,,,
tf.required_space_to_batch_paddings,base_paddings,"Optional int32 Tensor of shape [N, 2].  Specifies the minimum amount of padding to use.  All elements must be >= 0.  If not specified, defaults to 0.",Specifies the minimum amount of padding to use,numeric,,,,,"[0,inf)",
tf.feature_column.crossed_column,hash_key,Specify the hash_key that will be used by the `FingerprintCat64`function to combine the crosses fingerprints on SparseCrossOp (optional).,Specify the hash_key that will be used by the QSTR function to combine the crosses fingerprints on SparseCrossOp BSTR,,,,,,,
tf.keras.backend.truncated_normal,stddev,Standard deviation of the values.,Standard deviation of the values,numeric,,,,,,
tf.keras.layers.multiply,**kwargs,Standard layer keyword arguments.,Standard layer keyword arguments,,,,,,,
tf.keras.backend.rnn,step_function,"RNN step function. Args;     input; Tensor with shape `(samples, ...)` (no time dimension),         representing input for the batch of samples at a certain         time step.     states; List of tensors. Returns;     output; Tensor with shape `(samples, output_dim)`        (no time dimension).     new_states; List of tensors, same length and shapes         as 'states'. The first state in the list must be the         output tensor at the previous timestep.",states D_STRUCTURE of D_STRUCTURE,,,,,,,
tf.keras.preprocessing.text.text_to_word_sequence,filters,"DF: !""#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n",t n,,,,,,,
tf.keras.preprocessing.text.text_to_word_sequence,filters,"list (or concatenation) of characters to filter out, such as     punctuation. Default: ``!""#$%&()*+,-./:;<=>?@[\]^_`{|}~\t\n``,     includes basic punctuation, tabs, and newlines.",t n includes basic punctuation tabs and newlines,,,,,,,
tf.strings.unicode_transcode,input_encoding,"A `string`. Text encoding of the input strings. This is any of the encodings supported by ICU ucnv algorithmic converters. Examples: `""UTF-16"", ""US ASCII"", ""UTF-8""`.",Text encoding of the PARAM D_TYPE,,,,,,,
tf.signal.inverse_stft,window_fn,DF: tf.signal.hann_window,tf signal hann_window,,,,,,,
tf.keras.layers.PReLU,shared_axes,"The axes along which to share learnable parameters for the activation function. For example, if the incoming feature maps are from a 2D convolution with output shape `(batch, height, width, channels)`, and you wish to share parameters across space so that each filter only has one set of parameters, set `shared_axes=[1, 2]`.",The axes along which to share learnable parameters for the activation function,int,,,,,,
tf.signal.idct,axis,For future expansion. The axis to compute the DCT along. Must be `-1`.,The axis to compute the DCT along,int,,,,,,
tf.nn.nce_loss,weights,"A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`objects whose concatenation along dimension 0 has shape [num_classes, dim].  The (possibly-partitioned) class embeddings.",The BSTR class embeddings,,,,,,,
tf.nn.sampled_softmax_loss,weights,"A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`objects whose concatenation along dimension 0 has shape [num_classes, dim].  The (possibly-sharded) class embeddings.",The BSTR class embeddings,,,,,,,
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",The call method of the cell can also take the optional argument QSTR see section QSTR below A QSTR attribute,,,,,,,
tf.scan,fn,"The callable to be performed.  It accepts two arguments.  The first will have the same structure as `initializer` if one is provided, otherwise it will have the same structure as `elems`.  The second will have the same (possibly nested) structure as `elems`.  Its output must have the same structure as `initializer` if one is provided, otherwise it must have the same structure as `elems`.",The callable to be performed,,,,,,,
tf.vectorized_map,fn,"The callable to be performed. It accepts one argument, which will have the same (possibly nested) structure as `elems`, and returns a possibly nested structure of Tensors and Operations, which may be different than the structure of `elems`.",The callable to be performed,,,,,,,
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",The cell might choose to create a D_STRUCTURE full of zeros or full of other values based on the cell implementation QSTR is the input D_STRUCTURE to the RNN layer which should contain the batch size as its shape BSTR and also dtype,,,,,,,
tf.debugging.Assert,data,The tensors to print out when condition is false.,The D_STRUCTURE to print out when PARAM is CONSTANT_BOOL,,D_STRUCTURE,,,,,
tf.math.reduce_variance,input_tensor,The tensor to reduce. Should have numeric type.,The D_STRUCTURE to reduce,,D_STRUCTURE,,,,,
tf.sparse.slice,sp_input,The `SparseTensor` to split.,The D_STRUCTURE to split,,D_STRUCTURE,,,,,
tf.keras.layers.experimental.preprocessing.PreprocessingLayer,data,"The data to train on. It can be passed either as a tf.data Dataset, or as a numpy array.",The data to train on,,,,,,,
tf.strings.reduce_join,axis,"Which axis to join along. The default behavior is to join all elements, producing a scalar.",The default behavior is to join all elements producing a scalar,,,,,,,
tf.keras.backend.softmax,axis,The dimension softmax would be performed on. The default is -1 which indicates the last dimension.,The default is CONSTANT_NUM which indicates the last dimension,int,,,,0,,
tf.keras.utils.get_file,archive_format,"Archive format to try for extracting the file. Options are 'auto', 'tar', 'zip', and None. 'tar' includes tar, tar.gz, and tar.bz files. The default 'auto' is ['tar', 'zip']. None or an empty list will return no matches found.",The default QSTR is QSTR,,,,,,,
tf.nn.conv1d_transpose,dilations,"An int or list of `ints` that has length `1` or `3` which defaults to 1. The dilation factor for each dimension of input. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. Dilations in the batch and depth dimensions must be 1.",The dilation factor for each dimension of PARAM,,,,,,,
tf.nn.depthwise_conv2d_backprop_input,dilations,"An optional list of `ints`. Defaults to `[1, 1, 1, 1]`. 1-D tensor of length 4.  The dilation factor for each dimension of`input`. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of`data_format`, see above for details. Dilations in the batch and depth dimensions must be 1.",The dilation factor for each dimension of QSTR,,,,,,,
tf.nn.depthwise_conv2d_backprop_input,dilations,"An optional list of `ints`. Defaults to `[1, 1, 1, 1]`. 1-D tensor of length 4.  The dilation factor for each dimension of`input`. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of`data_format`, see above for details. Dilations in the batch and depth dimensions must be 1.",The dimension order is determined by the value of PARAM see above for details,,,,,,,
tf.nn.conv2d_transpose,strides,"An int or list of `ints` that has length `1`, `2` or `4`.  The stride of the sliding window for each dimension of `input`. If a single value is given it is replicated in the `H` and `W` dimension. By default the `N` and `C` dimensions are set to 0. The dimension order is determined by the value of `data_format`, see below for details.",The dimension order is determined by the value of PARAM see below for details,,,,,,,
tf.keras.backend.softmax,axis,The dimension softmax would be performed on. The default is -1 which indicates the last dimension.,The dimension softmax would be performed on,int,,,,,,
tf.math.reduce_euclidean_norm,axis,"The dimensions to reduce. If `None` (the default), reduces all dimensions. Must be in the range `[-rank(input_tensor), rank(input_tensor))`.",The dimensions to reduce,int,,,,,,
tf.nn.fractional_avg_pool,pooling_ratio,"A list of `floats` that has length >= 4.  Pooling ratio for each dimension of `value`, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling ratio on height and width dimensions respectively.",The first and last elements must be CONSTANT_FLOAT because we don t allow pooling on batch and channels dimensions,,,,,,,
tf.nn.fractional_max_pool,pooling_ratio,"An int or list of `ints` that has length `1`, `2` or `4`. Pooling ratio for each dimension of `value`, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling ratio on height and width dimensions respectively.",The first and last elements must be CONSTANT_FLOAT because we don t allow pooling on batch and channels dimensions,,,,,,,
tf.keras.backend.rnn,step_function,"RNN step function. Args;     input; Tensor with shape `(samples, ...)` (no time dimension),         representing input for the batch of samples at a certain         time step.     states; List of tensors. Returns;     output; Tensor with shape `(samples, output_dim)`        (no time dimension).     new_states; List of tensors, same length and shapes         as 'states'. The first state in the list must be the         output tensor at the previous timestep.",The first state in the D_STRUCTURE must be the output D_STRUCTURE at the previous timestep,,,,,,,
tf.scan,fn,"The callable to be performed.  It accepts two arguments.  The first will have the same structure as `initializer` if one is provided, otherwise it will have the same structure as `elems`.  The second will have the same (possibly nested) structure as `elems`.  Its output must have the same structure as `initializer` if one is provided, otherwise it must have the same structure as `elems`.",The first will have the same structure as PARAM if one is provided otherwise it will have the same structure as PARAM,,,,,,,
tf.gather,indices,"The index `Tensor`.  Must be one of the following types: `int32`,`int64`. Must be in range `[0, params.shape[axis])`.",The index D_STRUCTURE,,D_STRUCTURE,,,,,
tf.nn.erosion2d,dilations,"A list of `ints` that has length `>= 4`. 1-D of length 4. The input stride for atrous morphological dilation. Must be: `[1, rate_height, rate_width, 1]`.",The input stride for atrous morphological dilation,int,,,,,"[0,inf)",
tf.unstack,num,An `int`. The length of the dimension `axis`. Automatically inferred if`None` (the default).,The length of the dimension PARAM,int,,,,,"[0,inf)",
tf.norm,name,The name of the op.,The name of the op,string,,,,0,,
tf.foldr,elems,"A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension.  The nested sequence of the resulting slices will be the first argument to `fn`.",The nested D_STRUCTURE of the resulting slices will be the first argument to PARAM,,D_STRUCTURE,,,,,
tf.gather,batch_dims,An `integer`.  The number of batch dimensions.  Must be less than `rank(indices)`.,The number of batch dimensions,int,,,,0,"[0,inf)",
tf.linalg.diag,num_cols,"The number of columns of the output matrix. If it is not provided, the op assumes the output matrix is a square matrix and infers the matrix size from `d_lower`, `d_upper`, and the innermost dimension of `diagonal`.",The number of columns of the output matrix,int,,,,0,"[0,inf)",
tf.nn.conv1d,stride,An int or list of `ints` that has length `1` or `3`.  The number of entries by which the filter is moved right at each step.,The number of entries by which the filter is moved right at each step,int,,,,0,"[0,inf)",
tf.random.learned_unigram_candidate_sampler,range_max,An `int`. The number of possible classes.,The number of possible classes,int,,,,0,"[0,inf)",
tf.nn.sampled_softmax_loss,num_classes,An `int`. The number of possible classes.,The number of possible classes,int,,,,0,"[0,inf)",
tf.signal.inverse_stft,frame_step,An integer scalar `Tensor`. The number of samples to step.,The number of samples to step,int,,,,0,"[0,inf)",
tf.keras.layers.Conv3DTranspose,data_format,"A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs.`channels_last` corresponds to inputs with shape`(batch, depth, height, width, channels)` while `channels_first`corresponds to inputs with shape`(batch, channels, depth, height, width)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be ""channels_last"".",The ordering of the dimensions in the inputs QSTR corresponds to inputs with shape BSTR while QSTR corresponds to inputs with shape BSTR,,,,,,,QSTR
tf.keras.layers.AveragePooling3D,data_format,"A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs.`channels_last` corresponds to inputs with shape`(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`while `channels_first` corresponds to inputs with shape`(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be ""channels_last"".",The ordering of the dimensions in the inputs QSTR corresponds to inputs with shape BSTRwhile QSTR corresponds to inputs with shape BSTR,,,,,,,QSTR
tf.print,output_stream,"The output stream, logging level, or file to print to. Defaults to sys.stderr, but sys.stdout, tf.compat.v1.logging.info, tf.compat.v1.logging.warning, tf.compat.v1.logging.error, absl.logging.info, absl.logging.warning and absl.loogging,error are also supported. To print to a file, pass a string started with ""file://"" followed by the file path, e.g., ""file:///tmp/foo.out"".",The output stream logging level or file to print to,,,,,,,
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",The QSTR can also be TensorShape or D_STRUCTURE of TensorShape to represent high dimension state A QSTR attribute,,,,,,,
tf.signal.linear_to_mel_weight_matrix,dtype,The `DType` of the result matrix. Must be a floating point type.,The QSTR of the result matrix,,,,,,,
tf.debugging.assert_near,rtol,"`Tensor`.  Same `dtype` as, and broadcastable to, `x`. The relative tolerance.  Default is `10 * eps`.",The relative tolerance,,,,,,,
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",The returned initial state should have a shape of BSTR,,,,,,,
tf.scan,fn,"The callable to be performed.  It accepts two arguments.  The first will have the same structure as `initializer` if one is provided, otherwise it will have the same structure as `elems`.  The second will have the same (possibly nested) structure as `elems`.  Its output must have the same structure as `initializer` if one is provided, otherwise it must have the same structure as `elems`.",The second will have the same BSTR structure as PARAM,,,,,,,
tf.random.stateless_truncated_normal,stddev,"A 0-D Tensor or Python value of type `dtype`. The standard deviation of the normal distribution, before truncation.",The standard deviation of the normal distribution before truncation,numeric,,,,,,
tf.nn.conv2d_transpose,strides,"An int or list of `ints` that has length `1`, `2` or `4`.  The stride of the sliding window for each dimension of `input`. If a single value is given it is replicated in the `H` and `W` dimension. By default the `N` and `C` dimensions are set to 0. The dimension order is determined by the value of `data_format`, see below for details.",The stride of the sliding window for each dimension of PARAM,int,,,,,"[0,inf)",
tf.summary.flush,writer,The `tf.summary.SummaryWriter` resource to flush. The thread default will be used if this parameter is None. Otherwise a `tf.no_op` is returned.,The tf summary SummaryWriter resource to flush,,,,,,,
tf.summary.flush,writer,The `tf.summary.SummaryWriter` resource to flush. The thread default will be used if this parameter is None. Otherwise a `tf.no_op` is returned.,The thread default will be used if this parameter is None,,,,,,,
tf.ragged.range,dtype,"The type of the elements of the resulting tensor.  If not specified, then a value is chosen based on the other args.",The type of the elements of the resulting D_STRUCTURE,dtype,,,,,,
tf.random.uniform,dtype,"The type of the output: `float16`, `float32`, `float64`, `int32`, or `int64`.",The type of the output D_TYPE,dtype,,,,,,
tf.keras.layers.UpSampling2D,size,"Int, or tuple of 2 integers. The upsampling factors for rows and columns.",The upsampling factors for rows and columns,,,,,,,
tf.estimator.add_metrics,metric_fn,"A function which should obey the following signature: Args: can only have following four arguments in any order:predictions: Predictions `Tensor` or dict of `Tensor` created by given`estimator`.features: Input `dict` of `Tensor` objects created by `input_fn` which is given to `estimator.evaluate` as an argument.labels:  Labels `Tensor` or dict of `Tensor` created by `input_fn`which is given to `estimator.evaluate` as an argument.config: config attribute of the `estimator`.Returns: Dict of metric results keyed by name. Final metrics are a union of this and `estimator's` existing metrics. If there is a name conflict between this and `estimator`s existing metrics, this will override the existing one. The values of the dict are the results of calling a metric function, namely a `(metric_tensor, update_op)` tuple. ",The values of the D_STRUCTURE are the results of calling a metric function namely a BSTR D_STRUCTURE,,,,,,,
tf.keras.preprocessing.sequence.skipgrams,window_size,"Int, size of sampling windows (technically half-window).     The window of a word `w_i` will be     `[i - window_size, i + window_size+1]`.",The window of a word QSTR will be BSTR,,,,,,,
tf.nn.ctc_loss,blank_index,"(optional) Set the class index to use for the blank label. Negative values will start from num_classes, ie, -1 will reproduce the ctc_loss behavior of using num_classes - 1 for the blank symbol. There is some memory/performance overhead to switching from the default of 0 as an additional shifted copy of the logits may be created.",There is some memory performance overhead to switching from the default of CONSTANT_NUM as an additional shifted copy of the PARAM may be created,,,,,,,
tf.debugging.experimental.enable_dump_debug_info,circular_buffer_size,"Size of the circular buffers for execution events. These circular buffers are designed to reduce the overhead of debugging dumping. They hold the most recent debug events concerning eager execution of ops and `tf.function`s and traces of tensor values computed inside`tf.function`s. They are written to the file system only when the proper flushing method is called (see description of return values below). Expected to be an integer. If <= 0, the circular-buffer behavior will be disabled, i.e., the execution debug events will be written to the file writers in the same way as non-execution events such as op creations and source-file snapshots.",These circular buffers are designed to reduce the overhead of debugging dumping,,,,,,,
tf.debugging.experimental.enable_dump_debug_info,circular_buffer_size,"Size of the circular buffers for execution events. These circular buffers are designed to reduce the overhead of debugging dumping. They hold the most recent debug events concerning eager execution of ops and `tf.function`s and traces of tensor values computed inside`tf.function`s. They are written to the file system only when the proper flushing method is called (see description of return values below). Expected to be an integer. If <= 0, the circular-buffer behavior will be disabled, i.e., the execution debug events will be written to the file writers in the same way as non-execution events such as op creations and source-file snapshots.",They are written to the file system only when the proper flushing method is called BSTR,,,,,,,
tf.debugging.experimental.enable_dump_debug_info,circular_buffer_size,"Size of the circular buffers for execution events. These circular buffers are designed to reduce the overhead of debugging dumping. They hold the most recent debug events concerning eager execution of ops and `tf.function`s and traces of tensor values computed inside`tf.function`s. They are written to the file system only when the proper flushing method is called (see description of return values below). Expected to be an integer. If <= 0, the circular-buffer behavior will be disabled, i.e., the execution debug events will be written to the file writers in the same way as non-execution events such as op creations and source-file snapshots.",They hold the most recent debug events concerning eager execution of ops and tf function QSTR tf function s,,,,,,,
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",This can also be a D_STRUCTURE of D_TYPE BSTR,,D_STRUCTURE,D_STRUCTURE,BSTR,,,
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",This can be a single D_TYPE BSTR in which case it is the size of the recurrent state,D_TYPE,,,,0,"[0,inf)",
tf.keras.layers.RNN,cell,"A RNN cell instance or a list of RNN cell instances. A RNN cell is a class that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section ""Note on passing external constants"" below.A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state.A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the`state_size`.A `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation.`inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided.`batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatible reason, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size]. In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN. ",This can be a single D_TYPE or a TensorShape which represent the shape of the output,D_TYPE,,,,0;1,"[0,inf)",
tf.strings.unicode_transcode,input_encoding,"A `string`. Text encoding of the input strings. This is any of the encodings supported by ICU ucnv algorithmic converters. Examples: `""UTF-16"", ""US ASCII"", ""UTF-8""`.",This is any of the encodings supported by ICU ucnv algorithmic converters,,,,,,,
tf.keras.layers.ConvLSTM2D,unit_forget_bias,"Boolean. If True, add 1 to the bias of the forget gate at initialization. Use in combination with `bias_initializer=""zeros""`. This is recommended in Jozefowicz et al.",This is recommended in Jozefowicz et al,,,,,,,
tf.print,output_stream,"The output stream, logging level, or file to print to. Defaults to sys.stderr, but sys.stdout, tf.compat.v1.logging.info, tf.compat.v1.logging.warning, tf.compat.v1.logging.error, absl.logging.info, absl.logging.warning and absl.loogging,error are also supported. To print to a file, pass a string started with ""file://"" followed by the file path, e.g., ""file:///tmp/foo.out"".",To print to a file pass a D_TYPE started with file followed by the file path e g file tmp foo out,,,,,,,
tf.nn.RNNCellDropoutWrapper,input_keep_prob,"unit Tensor or float between 0 and 1, input keep probability; if it is constant and 1, no input dropout will be added.",unit D_STRUCTURE or D_TYPE between CONSTANT_NUM input keep probability if it is constant and CONSTANT_NUM no input dropout will be added,D_TYPE,D_STRUCTURE,,,,"[0,1]",
tf.range,limit,"A 0-D `Tensor` (scalar). Upper limit of sequence, exclusive. If None, defaults to the value of `start` while the first entry of the range defaults to 0.",Upper limit of D_STRUCTURE exclusive,,,,,,,
tf.keras.layers.ConvLSTM2D,unit_forget_bias,"Boolean. If True, add 1 to the bias of the forget gate at initialization. Use in combination with `bias_initializer=""zeros""`. This is recommended in Jozefowicz et al.",Use in combination with PARAM QSTR,,,,,,,
tf.keras.datasets.reuters.load_data,**kwargs,Used for backwards compatibility.,Used for backwards compatibility,,,,,,,
tf.image.random_flip_left_right,seed,A Python integer. Used to create a random seed. See`tf.compat.v1.set_random_seed` for behavior.,Used to create a random seed,,,,,,,
tf.random.categorical,seed,A Python integer. Used to create a random seed for the distribution. See `tf.compat.v1.set_random_seed` for behavior.,Used to create a random seed for the distribution,,,,,,,
tf.keras.initializers.he_uniform,seed,A Python integer. Used to seed the random generator.,Used to seed the random generator,,,,,,,
tf.math.segment_min,segment_ids,"A `Tensor`. Must be one of the following types: `int32`, `int64`. A 1-D tensor whose size is equal to the size of `data`'s first dimension.  Values should be sorted and can be repeated.",Values should be sorted and can be repeated,,,,,,,
tf.ragged.range,deltas,Vector or scalar `Tensor`.  Specifies the increment for each range. Defaults to `1`.,D_STRUCTURE or scalar D_STRUCTURE,,,D_STRUCTURE,,0;1,,
tf.image.crop_to_bounding_box,offset_height,Vertical coordinate of the top-left corner of the result in the input.,Vertical coordinate of the top left corner of the result in the input,,,,,,,
tf.keras.backend.in_train_phase,x,What to return in train phase (tensor or callable that returns a tensor).,What to return in train phase BSTR,,,,,,,
tf.linalg.matrix_rank,validate_args,"When `True`, additional assertions might be embedded in the graph. Default value: `False` (i.e., no graph assertions are added).",When CONSTANT_BOOL additional assertions might be embedded in the graph,bool,,,,0,,
tf.keras.datasets.reuters.get_word_index,path,where to cache the data (relative to `~/.keras/dataset`).,where to cache the data relative to keras dataset,,,,,,,
tf.keras.utils.plot_model,show_shapes,whether to display shape information.,whether to display shape information,bool,,,,0,,
tf.xla.experimental.jit_scope,compile_ops,"Whether to enable or disable compilation in the scope. Either a Python bool, or a callable that accepts the parameter`node_def` and returns a python bool.",Whether to enable or disable compilation in the scope,bool,,,,0,,
tf.config.set_soft_device_placement,enabled,Whether to enable soft placement.,Whether to enable soft placement,bool,,,,0,,
tf.keras.utils.plot_model,expand_nested,Whether to expand nested models into clusters.,Whether to expand nested models into clusters,bool,,,,0,,
tf.nn.max_pool_with_argmax,include_batch_in_index,An optional `boolean`. Defaults to `False`. Whether to include batch dimension in flattened index of `argmax`.,Whether to include batch dimension in flattened index of QSTR,bool,,,,0,,
tf.nn.sampled_softmax_loss,remove_accidental_hits,"A `bool`.  whether to remove ""accidental hits"" where a sampled class equals one of the target classes.  Default is True.",whether to remove QSTR where a sampled class equals one of the target classes,bool,,,,0,,
tf.keras.layers.GRU,return_sequences,"Boolean. Whether to return the last output in the output sequence, or the full sequence. Default: `False`.",Whether to return the last output in the output D_STRUCTURE or the full D_STRUCTURE,bool,,,,0,,
tf.keras.preprocessing.sequence.skipgrams,shuffle,Whether to shuffle the word couples before returning them.,Whether to shuffle the word couples before returning them,bool,,,,0,,
tf.sets.union,validate_indices,Whether to validate the order and range of sparse indices in `a` and `b`.,Whether to validate the order and range of sparse indices in QSTR,bool,,,,0,,
tf.strings.reduce_join,axis,"Which axis to join along. The default behavior is to join all elements, producing a scalar.",Which axis to join along,int,,,,,,
tf.keras.preprocessing.image.apply_affine_transform,tx,Width shift.,Width shift,,,,,,,
tf.keras.backend.function,**kwargs,Passed to `tf.Session.run`.,Passed to tf Session run,,,,,,,
tf.nn.RNNCellDropoutWrapper,**kwargs,dict of keyword arguments for base layer.,D_STRUCTURE of keyword arguments for base layer,,,D_STRUCTURE,,,,
tf.sets.intersection,a,"`Tensor` or `SparseTensor` of the same type as `b`. If sparse, indices must be sorted in row-major order.",D_STRUCTURE of the same type as QSTR,&QSTR,D_STRUCTURE,,,,,
tf.sets.intersection,a,"`Tensor` or `SparseTensor` of the same type as `b`. If sparse, indices must be sorted in row-major order.",If sparse indices must be sorted in row major order,,,,,,,
tf.keras.layers.SeparableConv1D,activation,Activation function. Set it to None to maintain a linear activation.,Set it to None to maintain a linear activation,,,,,,,
tf.keras.layers.SeparableConv1D,activation,Activation function. Set it to None to maintain a linear activation.,activation function,,,,,,,
tf.keras.layers.SimpleRNNCell,activation,"Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation is applied (ie. ""linear"" activation: `a(x) = x`).",Default hyperbolic tangent QSTR,,,,,,,
tf.keras.layers.SimpleRNNCell,activation,"Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation is applied (ie. ""linear"" activation: `a(x) = x`).",If you pass QSTR no activation is applied ie,,,,,,,
tf.keras.layers.SimpleRNNCell,activation,"Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation is applied (ie. ""linear"" activation: `a(x) = x`).",QSTR activation a BSTR x,,,,,,,
tf.keras.layers.SimpleRNNCell,activation,"Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation is applied (ie. ""linear"" activation: `a(x) = x`).",activation function to use,,,,,,,
tf.keras.layers.Conv1D,activity_regularizer,"Regularizer function applied to the output of the layer (its ""activation"")..",Regularizer function applied to the output of the layer BSTR,,,,,,,
tf.linalg.matmul,adjoint_b,"If `True`, `b` is conjugated and transposed before multiplication.",If CONSTANT_BOOL QSTR is conjugated and transposed before multiplication,bool,,,,0,,
tf.keras.layers.PReLU,alpha_initializer,Initializer function for the weights.,Initializer function for the weights,,,,,,,
tf.keras.backend.batch_normalization,axis,"Integer, the axis that should be normalized. (typically the features axis).",BSTR,,,,,,,
tf.keras.backend.batch_normalization,axis,"Integer, the axis that should be normalized. (typically the features axis).",D_TYPE the axis that should be normalized,D_TYPE,,,,,,
tf.keras.backend.prod,axis,"An integer, the axis to compute the product.",An D_TYPE the axis to compute the product,D_TYPE,,,,0,,
tf.keras.layers.Concatenate,axis,Axis along which to concatenate.,axis along which to concatenate,int,,,,,,
tf.linalg.normalize,axis,"If `axis` is `None` (the default), the input is considered a vector and a single vector norm is computed over the entire set of values in the tensor, i.e. `norm(tensor, ord=ord)` is equivalent to`norm(reshape(tensor, [-1]), ord=ord)`. If `axis` is a Python integer, the input is considered a batch of vectors, and `axis` determines the axis in`tensor` over which to compute vector norms. If `axis` is a 2-tuple of Python integers it is considered a batch of matrices and `axis` determines the axes in `tensor` over which to compute a matrix norm. Negative indices are supported. Example: If you are passing a tensor that can be either a matrix or a batch of matrices at runtime, pass`axis=[-2,-1]` instead of `axis=None` to make sure that matrix norms are computed.",Example If you are passing a D_STRUCTURE that can be either a matrix or a batch of matrices at runtime pass axis BSTR instead of axis None to make sure that matrix norms are computed,,,,,,,
tf.linalg.normalize,axis,"If `axis` is `None` (the default), the input is considered a vector and a single vector norm is computed over the entire set of values in the tensor, i.e. `norm(tensor, ord=ord)` is equivalent to`norm(reshape(tensor, [-1]), ord=ord)`. If `axis` is a Python integer, the input is considered a batch of vectors, and `axis` determines the axis in`tensor` over which to compute vector norms. If `axis` is a 2-tuple of Python integers it is considered a batch of matrices and `axis` determines the axes in `tensor` over which to compute a matrix norm. Negative indices are supported. Example: If you are passing a tensor that can be either a matrix or a batch of matrices at runtime, pass`axis=[-2,-1]` instead of `axis=None` to make sure that matrix norms are computed.",If axis is a CONSTANT_NUM D_STRUCTURE of Python D_TYPE it is considered a batch of matrices and axis determines the axes in D_STRUCTURE over which to compute a matrix norm,int,,D_STRUCTURE,,,,
tf.linalg.normalize,axis,"If `axis` is `None` (the default), the input is considered a vector and a single vector norm is computed over the entire set of values in the tensor, i.e. `norm(tensor, ord=ord)` is equivalent to`norm(reshape(tensor, [-1]), ord=ord)`. If `axis` is a Python integer, the input is considered a batch of vectors, and `axis` determines the axis in`tensor` over which to compute vector norms. If `axis` is a 2-tuple of Python integers it is considered a batch of matrices and `axis` determines the axes in `tensor` over which to compute a matrix norm. Negative indices are supported. Example: If you are passing a tensor that can be either a matrix or a batch of matrices at runtime, pass`axis=[-2,-1]` instead of `axis=None` to make sure that matrix norms are computed.",If axis is a Python D_TYPE the input is considered a batch of D_STRUCTURE and axis determines the axis inD_STRUCTURE over which to compute D_STRUCTURE norms,D_TYPE,,,,0,,
tf.linalg.normalize,axis,"If `axis` is `None` (the default), the input is considered a vector and a single vector norm is computed over the entire set of values in the tensor, i.e. `norm(tensor, ord=ord)` is equivalent to`norm(reshape(tensor, [-1]), ord=ord)`. If `axis` is a Python integer, the input is considered a batch of vectors, and `axis` determines the axis in`tensor` over which to compute vector norms. If `axis` is a 2-tuple of Python integers it is considered a batch of matrices and `axis` determines the axes in `tensor` over which to compute a matrix norm. Negative indices are supported. Example: If you are passing a tensor that can be either a matrix or a batch of matrices at runtime, pass`axis=[-2,-1]` instead of `axis=None` to make sure that matrix norms are computed.",If axis is QSTR BSTR the input is considered a D_STRUCTURE and a single D_STRUCTURE norm is computed over the entire set of values in the D_STRUCTURE i e,int,,D_STRUCTURE,,,,
tf.linalg.normalize,axis,"If `axis` is `None` (the default), the input is considered a vector and a single vector norm is computed over the entire set of values in the tensor, i.e. `norm(tensor, ord=ord)` is equivalent to`norm(reshape(tensor, [-1]), ord=ord)`. If `axis` is a Python integer, the input is considered a batch of vectors, and `axis` determines the axis in`tensor` over which to compute vector norms. If `axis` is a 2-tuple of Python integers it is considered a batch of matrices and `axis` determines the axes in `tensor` over which to compute a matrix norm. Negative indices are supported. Example: If you are passing a tensor that can be either a matrix or a batch of matrices at runtime, pass`axis=[-2,-1]` instead of `axis=None` to make sure that matrix norms are computed.",Negative indices are supported,,,,,,,
tf.linalg.normalize,axis,"If `axis` is `None` (the default), the input is considered a vector and a single vector norm is computed over the entire set of values in the tensor, i.e. `norm(tensor, ord=ord)` is equivalent to`norm(reshape(tensor, [-1]), ord=ord)`. If `axis` is a Python integer, the input is considered a batch of vectors, and `axis` determines the axis in`tensor` over which to compute vector norms. If `axis` is a 2-tuple of Python integers it is considered a batch of matrices and `axis` determines the axes in `tensor` over which to compute a matrix norm. Negative indices are supported. Example: If you are passing a tensor that can be either a matrix or a batch of matrices at runtime, pass`axis=[-2,-1]` instead of `axis=None` to make sure that matrix norms are computed.",norm D_STRUCTURE PARAM PARAM QSTR norm reshape D_STRUCTURE BSTR PARAM PARAM,D_TYPE,,D_STRUCTURE,,CONSTANT_NUM,,
tf.math.reduce_logsumexp,axis,"The dimensions to reduce. If `None` (the default), reduces all dimensions. Must be in the range `[-rank(input_tensor), rank(input_tensor))`.",If QSTR BSTR reduces all dimensions,,,,,,,
tf.math.reduce_logsumexp,axis,"The dimensions to reduce. If `None` (the default), reduces all dimensions. Must be in the range `[-rank(input_tensor), rank(input_tensor))`.",Must be in the range BSTR,,,,,,BSTR,
tf.math.reduce_logsumexp,axis,"The dimensions to reduce. If `None` (the default), reduces all dimensions. Must be in the range `[-rank(input_tensor), rank(input_tensor))`.",The dimensions to reduce,int,,,,,,
tf.math.reduce_mean,axis,"The dimensions to reduce. If `None` (the default), reduces all dimensions. Must be in the range `[-rank(input_tensor), rank(input_tensor))`.",If QSTR BSTR reduces all dimensions,,,,,,,
tf.math.reduce_mean,axis,"The dimensions to reduce. If `None` (the default), reduces all dimensions. Must be in the range `[-rank(input_tensor), rank(input_tensor))`.",Must be in the range BSTR,,,,,,BSTR,
tf.math.reduce_mean,axis,"The dimensions to reduce. If `None` (the default), reduces all dimensions. Must be in the range `[-rank(input_tensor), rank(input_tensor))`.",The dimensions to reduce,int,,,,,,
tf.signal.frame,axis,A scalar integer `Tensor` indicating the axis to frame. Defaults to the last axis. Supports negative values for indexing from the end.,A scalar D_TYPE D_STRUCTURE indicating the axis to frame,D_TYPE,D_STRUCTURE,,,0,,
tf.signal.frame,axis,A scalar integer `Tensor` indicating the axis to frame. Defaults to the last axis. Supports negative values for indexing from the end.,Defaults to the last axis,,,,,,,
tf.signal.frame,axis,A scalar integer `Tensor` indicating the axis to frame. Defaults to the last axis. Supports negative values for indexing from the end.,Supports negative values for indexing from the end,,,,,,,
tf.gather_nd,batch_dims,An integer or a scalar 'Tensor'. The number of batch dimensions.,An D_TYPE or a scalar QSTR,D_TYPE,D_STRUCTURE,,,0,,
tf.gather_nd,batch_dims,An integer or a scalar 'Tensor'. The number of batch dimensions.,The number of batch dimensions,int,,,,0,"[0,inf)",
tf.keras.backend.normalize_batch_in_training,beta,Tensor with which to center the input.,D_STRUCTURE with which to center the input,,D_STRUCTURE,,,,,
tf.compat.as_text,bytes_or_text,"A `bytes`, `str`, or `unicode` object.",A QSTR D_TYPE or QSTR object,D_TYPE,,,,0,,
tf.keras.utils.get_file,cache_dir,"Location to store cached files, when None it defaults to the Keras   Directory.",Location to store cached files when None it defaults to the Keras Directory,,,,,,,
tf.keras.estimator.model_to_estimator,checkpoint_format,"Sets the format of the checkpoint saved by the estimator when training. May be `saver` or `checkpoint`, depending on whether to save checkpoints from `tf.compat.v1.train.Saver` or `tf.train.Checkpoint`. The default is `checkpoint`. Estimators use name-based `tf.train.Saver`checkpoints, while Keras models use object-based checkpoints from`tf.train.Checkpoint`. Currently, saving object-based checkpoints from`model_to_estimator` is only supported by Functional and Sequential models.",Currently saving object based checkpoints from QSTR is only supported by Functional and Sequential models,,,,,,,
tf.keras.estimator.model_to_estimator,checkpoint_format,"Sets the format of the checkpoint saved by the estimator when training. May be `saver` or `checkpoint`, depending on whether to save checkpoints from `tf.compat.v1.train.Saver` or `tf.train.Checkpoint`. The default is `checkpoint`. Estimators use name-based `tf.train.Saver`checkpoints, while Keras models use object-based checkpoints from`tf.train.Checkpoint`. Currently, saving object-based checkpoints from`model_to_estimator` is only supported by Functional and Sequential models.",Estimators use name based tf train Saver checkpoints while Keras models use object based checkpoints from tf train Checkpoint,,,,,,,
tf.keras.estimator.model_to_estimator,checkpoint_format,"Sets the format of the checkpoint saved by the estimator when training. May be `saver` or `checkpoint`, depending on whether to save checkpoints from `tf.compat.v1.train.Saver` or `tf.train.Checkpoint`. The default is `checkpoint`. Estimators use name-based `tf.train.Saver`checkpoints, while Keras models use object-based checkpoints from`tf.train.Checkpoint`. Currently, saving object-based checkpoints from`model_to_estimator` is only supported by Functional and Sequential models.",May be QSTR depending on whether to save checkpoints from tf compat v1 train Saver QSTR tf train Checkpoint,,,,,,,
tf.keras.estimator.model_to_estimator,checkpoint_format,"Sets the format of the checkpoint saved by the estimator when training. May be `saver` or `checkpoint`, depending on whether to save checkpoints from `tf.compat.v1.train.Saver` or `tf.train.Checkpoint`. The default is `checkpoint`. Estimators use name-based `tf.train.Saver`checkpoints, while Keras models use object-based checkpoints from`tf.train.Checkpoint`. Currently, saving object-based checkpoints from`model_to_estimator` is only supported by Functional and Sequential models.",Sets the format of the checkpoint saved by the estimator when training,,,,,,,
tf.keras.estimator.model_to_estimator,checkpoint_format,"Sets the format of the checkpoint saved by the estimator when training. May be `saver` or `checkpoint`, depending on whether to save checkpoints from `tf.compat.v1.train.Saver` or `tf.train.Checkpoint`. The default is `checkpoint`. Estimators use name-based `tf.train.Saver`checkpoints, while Keras models use object-based checkpoints from`tf.train.Checkpoint`. Currently, saving object-based checkpoints from`model_to_estimator` is only supported by Functional and Sequential models.",The default is QSTR,,,,,,,
tf.data.experimental.make_csv_dataset,column_defaults,"A optional list of default values for the CSV fields. One item per selected column of the input record. Each item in the list is either a valid CSV dtype (float32, float64, int32, int64, or string), or a`Tensor` with one of the aforementioned types. The tensor can either be a scalar default value (if the column is optional), or an empty tensor (if the column is required). If a dtype is provided instead of a tensor, the column is also treated as required. If this list is not provided, tries to infer types based on reading the first num_rows_for_inference rows of files specified, and assumes all columns are optional, defaulting to `0`for numeric values and `""""` for string values. If both this and`select_columns` are specified, these must have the same lengths, and`column_defaults` is assumed to be sorted in order of increasing column index.",A optional D_STRUCTURE of default values for the CSV fields,,,D_STRUCTURE,,,,
tf.data.experimental.make_csv_dataset,column_defaults,"A optional list of default values for the CSV fields. One item per selected column of the input record. Each item in the list is either a valid CSV dtype (float32, float64, int32, int64, or string), or a`Tensor` with one of the aforementioned types. The tensor can either be a scalar default value (if the column is optional), or an empty tensor (if the column is required). If a dtype is provided instead of a tensor, the column is also treated as required. If this list is not provided, tries to infer types based on reading the first num_rows_for_inference rows of files specified, and assumes all columns are optional, defaulting to `0`for numeric values and `""""` for string values. If both this and`select_columns` are specified, these must have the same lengths, and`column_defaults` is assumed to be sorted in order of increasing column index.",Each item in the D_STRUCTURE is either a valid CSV dtype BSTR or aD_STRUCTURE with one of the aforementioned types,,,,,,,
tf.data.experimental.make_csv_dataset,column_defaults,"A optional list of default values for the CSV fields. One item per selected column of the input record. Each item in the list is either a valid CSV dtype (float32, float64, int32, int64, or string), or a`Tensor` with one of the aforementioned types. The tensor can either be a scalar default value (if the column is optional), or an empty tensor (if the column is required). If a dtype is provided instead of a tensor, the column is also treated as required. If this list is not provided, tries to infer types based on reading the first num_rows_for_inference rows of files specified, and assumes all columns are optional, defaulting to `0`for numeric values and `""""` for string values. If both this and`select_columns` are specified, these must have the same lengths, and`column_defaults` is assumed to be sorted in order of increasing column index.",If a dtype is provided instead of a D_STRUCTURE the column is also treated as required,,,,,,,
tf.data.experimental.make_csv_dataset,column_defaults,"A optional list of default values for the CSV fields. One item per selected column of the input record. Each item in the list is either a valid CSV dtype (float32, float64, int32, int64, or string), or a`Tensor` with one of the aforementioned types. The tensor can either be a scalar default value (if the column is optional), or an empty tensor (if the column is required). If a dtype is provided instead of a tensor, the column is also treated as required. If this list is not provided, tries to infer types based on reading the first num_rows_for_inference rows of files specified, and assumes all columns are optional, defaulting to `0`for numeric values and `""""` for string values. If both this and`select_columns` are specified, these must have the same lengths, and`column_defaults` is assumed to be sorted in order of increasing column index.",If both this and PARAM are specified these must have the same lengths and column_defaults is assumed to be sorted in order of increasing column index,,,,,,,
tf.data.experimental.make_csv_dataset,column_defaults,"A optional list of default values for the CSV fields. One item per selected column of the input record. Each item in the list is either a valid CSV dtype (float32, float64, int32, int64, or string), or a`Tensor` with one of the aforementioned types. The tensor can either be a scalar default value (if the column is optional), or an empty tensor (if the column is required). If a dtype is provided instead of a tensor, the column is also treated as required. If this list is not provided, tries to infer types based on reading the first num_rows_for_inference rows of files specified, and assumes all columns are optional, defaulting to `0`for numeric values and `""""` for string values. If both this and`select_columns` are specified, these must have the same lengths, and`column_defaults` is assumed to be sorted in order of increasing column index.",If this D_STRUCTURE is not provided tries to infer types based on reading the first PARAM rows of files specified and assumes all columns are optional defaulting to CONSTANT_NUMfor D_TYPE values and for D_TYPE values,,,,,,,
tf.data.experimental.make_csv_dataset,column_defaults,"A optional list of default values for the CSV fields. One item per selected column of the input record. Each item in the list is either a valid CSV dtype (float32, float64, int32, int64, or string), or a`Tensor` with one of the aforementioned types. The tensor can either be a scalar default value (if the column is optional), or an empty tensor (if the column is required). If a dtype is provided instead of a tensor, the column is also treated as required. If this list is not provided, tries to infer types based on reading the first num_rows_for_inference rows of files specified, and assumes all columns are optional, defaulting to `0`for numeric values and `""""` for string values. If both this and`select_columns` are specified, these must have the same lengths, and`column_defaults` is assumed to be sorted in order of increasing column index.",One item per selected column of the input record,,,,,,,
tf.data.experimental.make_csv_dataset,column_defaults,"A optional list of default values for the CSV fields. One item per selected column of the input record. Each item in the list is either a valid CSV dtype (float32, float64, int32, int64, or string), or a`Tensor` with one of the aforementioned types. The tensor can either be a scalar default value (if the column is optional), or an empty tensor (if the column is required). If a dtype is provided instead of a tensor, the column is also treated as required. If this list is not provided, tries to infer types based on reading the first num_rows_for_inference rows of files specified, and assumes all columns are optional, defaulting to `0`for numeric values and `""""` for string values. If both this and`select_columns` are specified, these must have the same lengths, and`column_defaults` is assumed to be sorted in order of increasing column index.",The D_STRUCTURE can either be a scalar default value BSTR,,,,,,,
tf.feature_column.embedding_column,combiner,"A string specifying how to reduce if there are multiple entries in a single row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default. 'sqrtn' often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see`tf.embedding_lookup_sparse`.",A D_TYPE specifying how to reduce if there are multiple entries in a single row,D_TYPE,,,,0,,
tf.feature_column.embedding_column,combiner,"A string specifying how to reduce if there are multiple entries in a single row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default. 'sqrtn' often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see`tf.embedding_lookup_sparse`.",Currently QSTR are supported with QSTR the default,,,,,,,QSTR
tf.feature_column.embedding_column,combiner,"A string specifying how to reduce if there are multiple entries in a single row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default. 'sqrtn' often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see`tf.embedding_lookup_sparse`.",Each of this can be thought as example level normalizations on the column,,,,,,,
tf.feature_column.embedding_column,combiner,"A string specifying how to reduce if there are multiple entries in a single row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default. 'sqrtn' often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see`tf.embedding_lookup_sparse`.",For more information see tf embedding_lookup_sparse,,,,,,,
tf.feature_column.embedding_column,combiner,"A string specifying how to reduce if there are multiple entries in a single row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default. 'sqrtn' often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see`tf.embedding_lookup_sparse`.",QSTR often achieves good accuracy in particular with bag of words columns,,,,,,,
tf.summary.audio,data,"A `Tensor` representing audio data with shape `[k, t, c]`, where `k` is the number of audio clips, `t` is the number of frames, and `c` is the number of channels. Elements should be floating-point values in `[-1.0, 1.0]`. Any of the dimensions may be statically unknown (i.e., `None`).",A D_STRUCTURE representing audio data with shape BSTR where QSTR is the number of audio clips QSTR is the number of frames and QSTR is the number of channels,int,D_STRUCTURE,,BSTR,,"[-1.0,1.0]",
tf.summary.audio,data,"A `Tensor` representing audio data with shape `[k, t, c]`, where `k` is the number of audio clips, `t` is the number of frames, and `c` is the number of channels. Elements should be floating-point values in `[-1.0, 1.0]`. Any of the dimensions may be statically unknown (i.e., `None`).",Any of the dimensions may be statically unknown i e QSTR,,,,,,,
tf.summary.audio,data,"A `Tensor` representing audio data with shape `[k, t, c]`, where `k` is the number of audio clips, `t` is the number of frames, and `c` is the number of channels. Elements should be floating-point values in `[-1.0, 1.0]`. Any of the dimensions may be statically unknown (i.e., `None`).",Elements should be D_TYPE values in BSTR,D_TYPE,,,,,BSTR,
tf.keras.backend.local_conv1d,data_format,"the data format, channels_first or channels_last.",the data format channels_first or channels_last,,,,,,,channels_first;channels_last
tf.keras.layers.Cropping3D,data_format,"A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs.`channels_last` corresponds to inputs with shape`(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`while `channels_first` corresponds to inputs with shape`(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be ""channels_last"".",A D_TYPE one of QSTR BSTR or QSTR,D_TYPE,,,,0,,QSTR
tf.keras.layers.Cropping3D,data_format,"A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs.`channels_last` corresponds to inputs with shape`(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`while `channels_first` corresponds to inputs with shape`(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be ""channels_last"".",If you never set it then it will be QSTR,,,,,,,
tf.keras.layers.Cropping3D,data_format,"A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs.`channels_last` corresponds to inputs with shape`(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`while `channels_first` corresponds to inputs with shape`(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be ""channels_last"".",It defaults to the QSTR value found in your Keras config file at keras keras json,,,,,,,
tf.keras.layers.Cropping3D,data_format,"A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs.`channels_last` corresponds to inputs with shape`(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`while `channels_first` corresponds to inputs with shape`(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be ""channels_last"".",The ordering of the dimensions in the inputs QSTR corresponds to inputs with shape BSTRwhile QSTR corresponds to inputs with shape BSTR,,,,,,,
tf.nn.avg_pool2d,data_format,A string. 'NHWC' and 'NCHW' are supported.,A D_TYPE,D_TYPE,,,,0,,
tf.nn.avg_pool2d,data_format,A string. 'NHWC' and 'NCHW' are supported.,QSTR are supported,,,,,,,QSTR
tf.nn.max_pool1d,data_format,"An optional string from: ""NWC"", ""NCW"". Defaults to ""NWC"".",An optional D_TYPE from QSTR,D_TYPE,,,,0,,QSTR
tf.nn.max_pool1d,data_format,"An optional string from: ""NWC"", ""NCW"". Defaults to ""NWC"".",Defaults to QSTR,,,,,,,
tf.feature_column.sequence_categorical_column_with_identity,default_value,"If `None`, this column's graph operations will fail for out-of-range inputs. Otherwise, this value must be in the range`[0, num_buckets)`, and will replace out-of-range inputs.",If QSTR this column graph operations will fail for out of range inputs,,,,,,,
tf.feature_column.sequence_categorical_column_with_identity,default_value,"If `None`, this column's graph operations will fail for out-of-range inputs. Otherwise, this value must be in the range`[0, num_buckets)`, and will replace out-of-range inputs.",Otherwise this value must be in the range BSTR and will replace out of range inputs,,,,,,,
tf.keras.layers.SeparableConv2D,depth_multiplier,The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to `filters_in * depth_multiplier`.,The number of depthwise convolution output channels for each input channel,int,,,,0,"[0,inf)",
tf.keras.layers.SeparableConv2D,depth_multiplier,The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to `filters_in * depth_multiplier`.,The total number of depthwise convolution output channels will be equal to filters_in depth_multiplier,,,,,,,
tf.nn.dilation2d,dilations,"A list of `ints` that has length `>= 4`. The input stride for atrous morphological dilation. Must be:`[1, rate_height, rate_width, 1]`.",A D_STRUCTURE of D_TYPE that has length REXPR,D_TYPE,,D_STRUCTURE,[REXPR],,,
tf.nn.dilation2d,dilations,"A list of `ints` that has length `>= 4`. The input stride for atrous morphological dilation. Must be:`[1, rate_height, rate_width, 1]`.",Must be BSTR,D_TYPE,,,BSTR,,,
tf.nn.dilation2d,dilations,"A list of `ints` that has length `>= 4`. The input stride for atrous morphological dilation. Must be:`[1, rate_height, rate_width, 1]`.",The PARAM stride for atrous morphological dilation,int,,,,,"[0,inf)",
tf.keras.layers.SimpleRNN,dropout,Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0.,D_TYPE between CONSTANT_NUM,D_TYPE,,,,,CONSTANT_NUM,
tf.keras.layers.SimpleRNN,dropout,Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0.,Default CONSTANT_NUM,,,,,,,
tf.keras.layers.SimpleRNN,dropout,Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0.,Fraction of the PARAM to drop for the linear transformation of the inputs,,,,,,"[0,1]",
tf.keras.backend.random_binomial,dtype,"String, dtype of returned tensor.",D_TYPE dtype of returned D_STRUCTURE,D_TYPE;dtype,,,,0,,
tf.keras.backend.map_fn,elems,tensor,D_STRUCTURE,,D_STRUCTURE,,,,,
tf.strided_slice,end_mask,An `int32` mask.,An D_TYPE mask,D_TYPE,,,,,,
tf.autograph.to_graph,entity,Python callable or class to convert.,Python callable or class to convert,,,,,,,
tf.keras.backend.batch_normalization,epsilon,Fuzz factor.,Fuzz factor,,,,,,,
tf.io.parse_single_sequence_example,example_name,"A scalar (0-D Tensor) of strings (optional), the name of the serialized proto.",A scalar BSTR the PARAM of the PARAM proto,string,tensor,,,0,,
tf.grad_pass_through,f,function `f(*x)` that returns a `Tensor` or nested structure of `Tensor`outputs.,function f BSTR that returns a D_STRUCTURE or nested structure of D_STRUCTUREoutputs,,,,,,,
tf.io.decode_jpeg,fancy_upscaling,An optional `bool`. Defaults to `True`. If true use a slower but nicer upscaling of the chroma planes (yuv420/422 only).,An optional D_TYPE,D_TYPE,,,,0,,
tf.io.decode_jpeg,fancy_upscaling,An optional `bool`. Defaults to `True`. If true use a slower but nicer upscaling of the chroma planes (yuv420/422 only).,Defaults to CONSTANT_BOOL,,,,,,,
tf.io.decode_jpeg,fancy_upscaling,An optional `bool`. Defaults to `True`. If true use a slower but nicer upscaling of the chroma planes (yuv420/422 only).,If CONSTANT_BOOL use a slower but nicer upscaling of the chroma planes BSTR,bool,,,,0,,
tf.data.experimental.make_csv_dataset,file_pattern,List of files or patterns of file paths containing CSV records. See `tf.io.gfile.glob` for pattern rules.,D_STRUCTURE of files or patterns of file paths containing CSV records,,,D_STRUCTURE,,,,
tf.data.experimental.make_csv_dataset,file_pattern,List of files or patterns of file paths containing CSV records. See `tf.io.gfile.glob` for pattern rules.,See tf io gfile glob for pattern rules,,,,,,,
tf.keras.preprocessing.image.random_shift,fill_mode,"Points outside the boundaries of the input     are filled according to the given mode     (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).",Points outside the boundaries of the input are filled according to the given mode one of QSTR,,,,,,,QSTR
tf.keras.layers.LocallyConnected1D,filters,"Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).",D_TYPE the dimensionality of the output space i e,D_TYPE,,,,,,
tf.keras.layers.LocallyConnected1D,filters,"Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).",the number of output filters in the convolution,int,,,,0,"[0,inf)",
tf.nn.convolution,filters,Alias of filter.,Alias of filter,,,,,,,
tf.signal.inverse_stft_window_fn,frame_step,An integer scalar `Tensor`. The number of samples to step.,An D_TYPE scalar D_STRUCTURE,D_TYPE,D_STRUCTURE,,,0,,
tf.signal.inverse_stft_window_fn,frame_step,An integer scalar `Tensor`. The number of samples to step.,The number of samples to step,int,,,,0,"[0,inf)",
tf.py_function,func,"A Python function which accepts a list of `Tensor` objects having element types that match the corresponding `tf.Tensor` objects in `inp`and returns a list of `Tensor` objects (or a single `Tensor`, or `None`) having element types that match the corresponding values in `Tout`.",A Python function which accepts a D_STRUCTURE of D_STRUCTURE objects having element types that match the corresponding D_STRUCTURE objects in PARAMand returns a D_STRUCTURE of D_STRUCTURE objects or a single D_STRUCTURE or QSTR having element types that match the corresponding values in PARAM,,,,,,,
tf.keras.layers.BatchNormalization,gamma_constraint,Optional constraint for the gamma weight.,Optional constraint for the gamma weight,,,,,,,
tf.keras.layers.RNN,go_backwards,"Boolean (default `False`). If True, process the input sequence backwards and return the reversed sequence.",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,0,,
tf.keras.layers.RNN,go_backwards,"Boolean (default `False`). If True, process the input sequence backwards and return the reversed sequence.",If CONSTANT_BOOL process the input D_STRUCTURE backwards and return the reversed D_STRUCTURE,bool,,,,0,,
tf.edit_distance,hypothesis,A `SparseTensor` containing hypothesis sequences.,A D_STRUCTURE containing hypothesis sequences,,D_STRUCTURE,,,,,
tf.image.ssim,img1,First image batch.,First image batch,numeric,,,,,,
tf.py_function,inp,A list of `Tensor` objects.,A D_STRUCTURE of D_STRUCTURE objects,,D_STRUCTURE,D_STRUCTURE,,,,
tf.linalg.inv,input,"A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`. Shape is `[..., M, M]`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.linalg.inv,input,"A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`. Shape is `[..., M, M]`.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.linalg.inv,input,"A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`. Shape is `[..., M, M]`.",Shape is BSTR,,,,BSTR,,,
tf.math.argmax,input,"A `Tensor`. Must be one of the following types: `float32`, `float64`,`int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`,`quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`,`uint64`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.math.argmax,input,"A `Tensor`. Must be one of the following types: `float32`, `float64`,`int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`,`quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`,`uint64`.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.signal.fft2d,input,"A `Tensor`. Must be one of the following types: `complex64`, `complex128`. A complex tensor.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.signal.fft2d,input,"A `Tensor`. Must be one of the following types: `complex64`, `complex128`. A complex tensor.",A D_TYPE D_STRUCTURE,D_TYPE,D_STRUCTURE,,,,,
tf.signal.fft2d,input,"A `Tensor`. Must be one of the following types: `complex64`, `complex128`. A complex tensor.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.strings.lower,input,A `Tensor` of type `string`.,A D_STRUCTURE of type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.strings.to_number,input,A `Tensor` of type `string`.,A D_STRUCTURE of type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.keras.backend.ctc_batch_cost,input_length,"tensor `(samples, 1)` containing the sequence length for each batch item in `y_pred`.",D_STRUCTURE BSTR containing the D_STRUCTURE length for each batch item in PARAM,,D_STRUCTURE,,,,,
tf.quantization.quantized_concat,input_maxes,A list with the same length as `values` of `Tensor` objects with type `float32`. The maximum scalar values for each of the input tensors.,A D_STRUCTURE with the same length as PARAM of D_STRUCTURE objects with type D_TYPE,D_TYPE,,D_STRUCTURE,&PARAM,,,
tf.quantization.quantized_concat,input_maxes,A list with the same length as `values` of `Tensor` objects with type `float32`. The maximum scalar values for each of the input tensors.,The maximum scalar PARAM for each of the input D_STRUCTURE,numeric,,,,0,,
tf.math.reduce_sum,input_tensor,The tensor to reduce. Should have numeric type.,Should have D_TYPE type,D_TYPE,,,,,,
tf.math.reduce_sum,input_tensor,The tensor to reduce. Should have numeric type.,The D_STRUCTURE to reduce,,D_STRUCTURE,,,,,
tf.strings.unsorted_segment_join,inputs,A `Tensor` of type `string`. The input to be joined.,A D_STRUCTURE of type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.strings.unsorted_segment_join,inputs,A `Tensor` of type `string`. The input to be joined.,The input to be joined,,,,,,,
tf.keras.preprocessing.image.apply_channel_shift,intensity,Transformation intensity.,Transformation intensity,,,,,,,
tf.keras.preprocessing.image.random_channel_shift,intensity_range,Transformation intensity.,Transformation intensity,,,,,,,
tf.keras.backend.any,keepdims,whether the drop or broadcast the reduction axes.,whether the drop or broadcast the reduction axes,bool,,,,0,,
tf.keras.backend.conv2d_transpose,kernel,kernel tensor.,kernel D_STRUCTURE,,D_STRUCTURE,,,,,
tf.keras.layers.ConvLSTM2D,kernel_initializer,"Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs.",Initializer for the QSTR weights matrix used for the linear transformation of the inputs,,,,,,,
tf.keras.backend.local_conv2d,kernel_size,"a tuple of 2 integers, specifying the width and height of the 2D convolution window.",a D_STRUCTURE of CONSTANT_NUM D_TYPE specifying the width and height of the CONSTANT_NUM D convolution window,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],,"[0,inf)",
tf.keras.layers.Conv2DTranspose,kernel_size,"An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.",An D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE specifying the height and width of the CONSTANT_NUM D convolution window,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],,"[0,inf)",
tf.keras.layers.Conv2DTranspose,kernel_size,"An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.",Can be a single D_TYPE to specify the same value for all spatial dimensions,D_TYPE,,,,0,,
tf.nn.avg_pool3d,ksize,"An int or list of `ints` that has length `1`, `3` or `5`. The size of the window for each dimension of the input tensor.",An D_TYPE or D_STRUCTURE of D_TYPE that has length CONSTANT_NUM,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],0;1,,
tf.nn.avg_pool3d,ksize,"An int or list of `ints` that has length `1`, `3` or `5`. The size of the window for each dimension of the input tensor.",The size of the window for each dimension of the PARAM D_STRUCTURE,int,,,,,"[0,inf)",
tf.nn.softmax_cross_entropy_with_logits,labels,"Each vector along the class dimension should hold a valid probability distribution e.g. for the case in which labels are of shape`[batch_size, num_classes]`, each row of `labels[i]` must be a valid probability distribution.",Each D_STRUCTURE along the class dimension should hold a valid probability distribution e g,,,,,,,
tf.nn.softmax_cross_entropy_with_logits,labels,"Each vector along the class dimension should hold a valid probability distribution e.g. for the case in which labels are of shape`[batch_size, num_classes]`, each row of `labels[i]` must be a valid probability distribution.",for the case in which labels are of shape BSTR each row of labels BSTR must be a valid probability distribution,,,,,,,
tf.random.poisson,lam,A Tensor or Python value or N-D array of type `dtype`.`lam` provides the rate parameter(s) describing the poisson distribution(s) to sample.,A D_STRUCTURE or Python value or N D D_STRUCTURE of type PARAM lam provides the rate parameter BSTR to sample,PARAM,D_STRUCTURE,,,,,
tf.sequence_mask,lengths,"integer tensor, all its values <= maxlen.",D_TYPE D_STRUCTURE all its values REXPR,D_TYPE,D_STRUCTURE,,,,REXPR,
tf.estimator.experimental.call_logit_fn,logit_fn,A logit_fn as defined above.,A logit_fn as defined above,,,,,,,
tf.keras.preprocessing.text.text_to_word_sequence,lower,boolean. Whether to convert the input to lowercase.,D_TYPE,D_TYPE,,,,,,
tf.keras.preprocessing.text.text_to_word_sequence,lower,boolean. Whether to convert the input to lowercase.,Whether to convert the input to lowercase,bool,,,,0,,
tf.estimator.experimental.stop_if_no_decrease_hook,max_steps_without_decrease,"`int`, maximum number of training steps with no decrease in the given metric.",D_TYPE maximum number of training steps with no decrease in the given metric,D_TYPE,,,,0,"[0,inf)",
tf.keras.backend.clip,max_value,"Python float, integer, or tensor.",Python D_TYPE or D_STRUCTURE,D_TYPE,D_STRUCTURE,,,,,
tf.keras.backend.relu,max_value,float. Saturation threshold.,D_TYPE,D_TYPE,,,,,,
tf.keras.backend.relu,max_value,float. Saturation threshold.,Saturation PARAM,,,,,,,
tf.random.normal,mean,"A Tensor or Python value of type `dtype`, broadcastable with `stddev`. The mean of the normal distribution.",A D_STRUCTURE or Python value of type PARAM broadcastable with PARAM,PARAM,D_STRUCTURE,,,,,
tf.random.normal,mean,"A Tensor or Python value of type `dtype`, broadcastable with `stddev`. The mean of the normal distribution.",The mean of the normal distribution,numeric,,,,,,
tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient,min,A `Tensor` of type `float32`.,A D_STRUCTURE of type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.debugging.Assert,name,A name for this operation (optional).,A name for this operation BSTR,string,,,,0,,
tf.debugging.assert_greater,name,"A name for this operation (optional).  Defaults to ""assert_greater"".",A name for this operation BSTR,string,,,,0,,
tf.debugging.assert_greater,name,"A name for this operation (optional).  Defaults to ""assert_greater"".",Defaults to QSTR,,,,,,,
tf.histogram_fixed_width_bins,name,A name for this operation (defaults to 'histogram_fixed_width').,A name for this operation defaults to QSTR,string,,,,0,,
tf.image.draw_bounding_boxes,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.io.decode_image,name,A name for the operation (optional),A name for the operation BSTR,string,,,,0,,
tf.keras.experimental.SequenceFeatures,name,Name to give to the SequenceFeatures.,name to give to the SequenceFeatures,string,,,,0,,
tf.keras.Input,name,An optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn't provided.,An optional name D_TYPE for the layer,D_TYPE,,,,0,,
tf.keras.Input,name,An optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn't provided.,It will be autogenerated if it isn t provided,,,,,,,
tf.keras.Input,name,An optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn't provided.,Should be unique in a model BSTR,,,,,,,
tf.linalg.logm,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.linalg.matrix_transpose,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.linalg.solve,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.linalg.tensor_diag,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.math.cumprod,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.math.is_non_decreasing,name,"A name for this operation (optional).  Defaults to ""is_non_decreasing""",A name for this operation BSTR,string,,,,0,,
tf.math.is_non_decreasing,name,"A name for this operation (optional).  Defaults to ""is_non_decreasing""",Defaults to QSTR,,,,,,,
tf.math.not_equal,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.math.reciprocal,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.math.segment_min,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.nn.atrous_conv2d_transpose,name,Optional name for the returned tensor.,Optional name for the returned D_STRUCTURE,string,,,,0,,
tf.nn.avg_pool3d,name,Optional name for the operation.,Optional name for the operation,string,,,,0,,
tf.nn.max_pool_with_argmax,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.reduce_all,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.scatter_nd,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.strings.split,name,A name for the operation (optional).,A name for the operation BSTR,string,,,,0,,
tf.feature_column.numeric_column,normalizer_fn,"If not `None`, a function that can be used to normalize the value of the tensor after `default_value` is applied for parsing. Normalizer function takes the input `Tensor` as its argument, and returns the output `Tensor`. (e.g. lambda x: (x - 3.0) / 4.2). Please note that even though the most common use case of this function is normalization, it can be used for any kind of Tensorflow transformations.",e g,,,,,,,
tf.feature_column.numeric_column,normalizer_fn,"If not `None`, a function that can be used to normalize the value of the tensor after `default_value` is applied for parsing. Normalizer function takes the input `Tensor` as its argument, and returns the output `Tensor`. (e.g. lambda x: (x - 3.0) / 4.2). Please note that even though the most common use case of this function is normalization, it can be used for any kind of Tensorflow transformations.",If not QSTR a function that can be used to normalize the value of the D_STRUCTURE after PARAM is applied for parsing,,,,,,,
tf.feature_column.numeric_column,normalizer_fn,"If not `None`, a function that can be used to normalize the value of the tensor after `default_value` is applied for parsing. Normalizer function takes the input `Tensor` as its argument, and returns the output `Tensor`. (e.g. lambda x: (x - 3.0) / 4.2). Please note that even though the most common use case of this function is normalization, it can be used for any kind of Tensorflow transformations.",lambda x BSTR,,,,,,,
tf.feature_column.numeric_column,normalizer_fn,"If not `None`, a function that can be used to normalize the value of the tensor after `default_value` is applied for parsing. Normalizer function takes the input `Tensor` as its argument, and returns the output `Tensor`. (e.g. lambda x: (x - 3.0) / 4.2). Please note that even though the most common use case of this function is normalization, it can be used for any kind of Tensorflow transformations.",Normalizer function takes the input D_STRUCTURE as its argument and returns the output D_STRUCTURE,,,,,,,
tf.feature_column.numeric_column,normalizer_fn,"If not `None`, a function that can be used to normalize the value of the tensor after `default_value` is applied for parsing. Normalizer function takes the input `Tensor` as its argument, and returns the output `Tensor`. (e.g. lambda x: (x - 3.0) / 4.2). Please note that even though the most common use case of this function is normalization, it can be used for any kind of Tensorflow transformations.",Please note that even though the most common use case of this function is normalization it can be used for any kind of Tensorflow transformations,,,,,,,
tf.sparse.eye,num_columns,Optional non-negative integer or `int32` scalar `tensor` giving the number of columns in the resulting matrix. Defaults to `num_rows`.,Defaults to PARAM,,,,,,,
tf.sparse.eye,num_columns,Optional non-negative integer or `int32` scalar `tensor` giving the number of columns in the resulting matrix. Defaults to `num_rows`.,Optional non negative D_TYPE scalar D_STRUCTURE giving the number of columns in the resulting matrix,D_TYPE,D_STRUCTURE,,,0,"[0,inf)",
tf.random.fixed_unigram_candidate_sampler,num_sampled,An `int`.  The number of classes to randomly sample.,An D_TYPE,D_TYPE,,,,0,,
tf.random.fixed_unigram_candidate_sampler,num_sampled,An `int`.  The number of classes to randomly sample.,The number of classes to randomly sample,int,,,,0,"[0,inf)",
tf.test.create_local_cluster,num_workers,Number of worker servers to start.,Number of worker servers to start,int,,,,0,"[0,inf)",
tf.keras.datasets.imdb.load_data,oov_char,words that were cut out because of the `num_words`or `skip_top` limit will be replaced with this character.,words that were cut out because of the PARAMor PARAM limit will be replaced with this character,,,,,,,
tf.norm,ord,"Order of the norm. Supported values are `'fro'`, `'euclidean'`,`1`, `2`, `np.inf` and any positive real number yielding the corresponding p-norm. Default is `'euclidean'` which is equivalent to Frobenius norm if`tensor` is a matrix and equivalent to 2-norm for vectors. Some restrictions apply: a) The Frobenius norm `'fro'` is not defined for vectors, b) If axis is a 2-tuple (matrix norm), only `'euclidean'`, '`fro'`, `1`,    `2`, `np.inf` are supported. See the description of `axis` on how to compute norms for a batch of vectors or matrices stored in a tensor.",Default is QSTR which is equivalent to Frobenius norm ifD_STRUCTURE is a matrix and equivalent to CONSTANT_NUM norm for D_STRUCTURE,,,,,,,
tf.norm,ord,"Order of the norm. Supported values are `'fro'`, `'euclidean'`,`1`, `2`, `np.inf` and any positive real number yielding the corresponding p-norm. Default is `'euclidean'` which is equivalent to Frobenius norm if`tensor` is a matrix and equivalent to 2-norm for vectors. Some restrictions apply: a) The Frobenius norm `'fro'` is not defined for vectors, b) If axis is a 2-tuple (matrix norm), only `'euclidean'`, '`fro'`, `1`,    `2`, `np.inf` are supported. See the description of `axis` on how to compute norms for a batch of vectors or matrices stored in a tensor.",Order of the norm,,,,,,,
tf.norm,ord,"Order of the norm. Supported values are `'fro'`, `'euclidean'`,`1`, `2`, `np.inf` and any positive real number yielding the corresponding p-norm. Default is `'euclidean'` which is equivalent to Frobenius norm if`tensor` is a matrix and equivalent to 2-norm for vectors. Some restrictions apply: a) The Frobenius norm `'fro'` is not defined for vectors, b) If axis is a 2-tuple (matrix norm), only `'euclidean'`, '`fro'`, `1`,    `2`, `np.inf` are supported. See the description of `axis` on how to compute norms for a batch of vectors or matrices stored in a tensor.",See the description of PARAM on how to compute norms for a batch of D_STRUCTURE or matrices stored in a D_STRUCTURE,,,,,,,
tf.norm,ord,"Order of the norm. Supported values are `'fro'`, `'euclidean'`,`1`, `2`, `np.inf` and any positive real number yielding the corresponding p-norm. Default is `'euclidean'` which is equivalent to Frobenius norm if`tensor` is a matrix and equivalent to 2-norm for vectors. Some restrictions apply: a) The Frobenius norm `'fro'` is not defined for vectors, b) If axis is a 2-tuple (matrix norm), only `'euclidean'`, '`fro'`, `1`,    `2`, `np.inf` are supported. See the description of `axis` on how to compute norms for a batch of vectors or matrices stored in a tensor.",Some restrictions apply a The Frobenius norm QSTR is not defined for D_STRUCTURE b If PARAM is a CONSTANT_NUM D_STRUCTURE BSTR only QSTR CONSTANT_NUM np inf are supported,,,,,,,
tf.norm,ord,"Order of the norm. Supported values are `'fro'`, `'euclidean'`,`1`, `2`, `np.inf` and any positive real number yielding the corresponding p-norm. Default is `'euclidean'` which is equivalent to Frobenius norm if`tensor` is a matrix and equivalent to 2-norm for vectors. Some restrictions apply: a) The Frobenius norm `'fro'` is not defined for vectors, b) If axis is a 2-tuple (matrix norm), only `'euclidean'`, '`fro'`, `1`,    `2`, `np.inf` are supported. See the description of `axis` on how to compute norms for a batch of vectors or matrices stored in a tensor.",Supported values are QSTR CONSTANT_NUM np inf and any positive real number yielding the corresponding p norm,,,,,,,QSTR;CONSTANT_NUM
tf.io.gfile.rename,overwrite,"boolean, if false it's an error for `dst` to be occupied by an existing file.",D_TYPE if CONSTANT_BOOL it an error for PARAM to be occupied by an existing file,D_TYPE,,,,0,,
tf.keras.layers.experimental.preprocessing.TextVectorization,pad_to_max_tokens,"Only valid in  ""binary"", ""count"", and ""tf-idf"" modes. If True, the output will have its feature axis padded to `max_tokens` even if the number of unique tokens in the vocabulary is less than max_tokens, resulting in a tensor of shape [batch_size, max_tokens] regardless of vocabulary size. Defaults to True.",Defaults to CONSTANT_BOOL,,,,,,,
tf.keras.layers.experimental.preprocessing.TextVectorization,pad_to_max_tokens,"Only valid in  ""binary"", ""count"", and ""tf-idf"" modes. If True, the output will have its feature axis padded to `max_tokens` even if the number of unique tokens in the vocabulary is less than max_tokens, resulting in a tensor of shape [batch_size, max_tokens] regardless of vocabulary size. Defaults to True.",If CONSTANT_BOOL the output will have its feature axis padded to PARAM even if the number of unique tokens in the vocabulary is less than PARAM resulting in a D_STRUCTURE of shape BSTR regardless of vocabulary size,bool,,,,0,,
tf.keras.layers.experimental.preprocessing.TextVectorization,pad_to_max_tokens,"Only valid in  ""binary"", ""count"", and ""tf-idf"" modes. If True, the output will have its feature axis padded to `max_tokens` even if the number of unique tokens in the vocabulary is less than max_tokens, resulting in a tensor of shape [batch_size, max_tokens] regardless of vocabulary size. Defaults to True.",Only valid in QSTR modes,,,,,,,
tf.keras.backend.temporal_padding,padding,"Tuple of 2 integers, how many zeros to add at the start and end of dim 1.",D_STRUCTURE of CONSTANT_NUM D_TYPE how many zeros to add at the start and end of dim CONSTANT_NUM,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],,"[0,inf)",
tf.keras.layers.SeparableConv1D,padding,"One of `""valid""`, `""same""`, or `""causal""` (case-insensitive).",One of QSTR BSTR,,,,,,,QSTR
tf.nn.conv2d_transpose,padding,"A string, either `'VALID'` or `'SAME'`. The padding algorithm. See the ""returns"" section of `tf.nn.convolution` for details.",A D_TYPE either QSTR,D_TYPE,,,,0,,QSTR
tf.nn.conv2d_transpose,padding,"A string, either `'VALID'` or `'SAME'`. The padding algorithm. See the ""returns"" section of `tf.nn.convolution` for details.",See the QSTR section of tf nn convolution for details,,,,,,,
tf.nn.conv2d_transpose,padding,"A string, either `'VALID'` or `'SAME'`. The padding algorithm. See the ""returns"" section of `tf.nn.convolution` for details.",The padding algorithm,,,,,,,
tf.nn.dilation2d,padding,"A `string` from: `""SAME"", ""VALID""`. The type of padding algorithm to use.",A D_TYPE from QSTR,D_TYPE,,,,0,,QSTR
tf.nn.dilation2d,padding,"A `string` from: `""SAME"", ""VALID""`. The type of padding algorithm to use.",The type of padding algorithm to use,,,,,,,
tf.linalg.tridiagonal_solve,partial_pivoting,"whether to perform partial pivoting. `True` by default. Partial pivoting makes the procedure more stable, but slower. Partial pivoting is unnecessary in some cases, including diagonally dominant and symmetric positive definite matrices (see e.g. theorem 9.12 in [1]).",CONSTANT_BOOL by default,bool,,,,0,,
tf.linalg.tridiagonal_solve,partial_pivoting,"whether to perform partial pivoting. `True` by default. Partial pivoting makes the procedure more stable, but slower. Partial pivoting is unnecessary in some cases, including diagonally dominant and symmetric positive definite matrices (see e.g. theorem 9.12 in [1]).",Partial pivoting is unnecessary in some cases including diagonally dominant and symmetric positive definite matrices see e g,,,,,,,
tf.linalg.tridiagonal_solve,partial_pivoting,"whether to perform partial pivoting. `True` by default. Partial pivoting makes the procedure more stable, but slower. Partial pivoting is unnecessary in some cases, including diagonally dominant and symmetric positive definite matrices (see e.g. theorem 9.12 in [1]).",Partial pivoting makes the procedure more stable but slower,,,,,,,
tf.linalg.tridiagonal_solve,partial_pivoting,"whether to perform partial pivoting. `True` by default. Partial pivoting makes the procedure more stable, but slower. Partial pivoting is unnecessary in some cases, including diagonally dominant and symmetric positive definite matrices (see e.g. theorem 9.12 in [1]).",theorem CONSTANT_NUM in BSTR,,,,,,,
tf.linalg.tridiagonal_solve,partial_pivoting,"whether to perform partial pivoting. `True` by default. Partial pivoting makes the procedure more stable, but slower. Partial pivoting is unnecessary in some cases, including diagonally dominant and symmetric positive definite matrices (see e.g. theorem 9.12 in [1]).",whether to perform partial pivoting,bool,,,,0,,
tf.io.gfile.mkdir,path,"string, name of the directory to be created",D_TYPE name of the directory to be created,D_TYPE,,,,0,,
tf.io.gfile.remove,path,"string, a path",D_TYPE a path,D_TYPE,,,,,,
tf.summary.trace_export,profiler_outdir,"Output directory for profiler. It is required when profiler is enabled when trace was started. Otherwise, it is ignored.",It is required when profiler is enabled when trace was started,,,,,,,
tf.summary.trace_export,profiler_outdir,"Output directory for profiler. It is required when profiler is enabled when trace was started. Otherwise, it is ignored.",Otherwise it is ignored,,,,,,,
tf.summary.trace_export,profiler_outdir,"Output directory for profiler. It is required when profiler is enabled when trace was started. Otherwise, it is ignored.",Output directory for profiler,,,,,,,
tf.keras.layers.GRUCell,recurrent_dropout,Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.,D_TYPE between CONSTANT_NUM,D_TYPE,,,,,CONSTANT_NUM,
tf.keras.layers.GRUCell,recurrent_dropout,Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.,Default CONSTANT_NUM,,,,,,,
tf.keras.layers.GRUCell,recurrent_dropout,Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.,Fraction of the PARAM to drop for the linear transformation of the recurrent state,,,,,,"[0,1]",
tf.keras.layers.LSTM,recurrent_dropout,Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.,D_TYPE between CONSTANT_NUM,D_TYPE,,,,,CONSTANT_NUM,
tf.keras.layers.LSTM,recurrent_dropout,Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.,Default CONSTANT_NUM,,,,,,,
tf.keras.layers.LSTM,recurrent_dropout,Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.,Fraction of the PARAM to drop for the linear transformation of the recurrent state,,,,,,"[0,1]",
tf.keras.layers.SimpleRNN,recurrent_dropout,Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.,D_TYPE between CONSTANT_NUM,D_TYPE,,,,,CONSTANT_NUM,
tf.keras.layers.SimpleRNN,recurrent_dropout,Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.,Default CONSTANT_NUM,,,,,,,
tf.keras.layers.SimpleRNN,recurrent_dropout,Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.,Fraction of the PARAM to drop for the linear transformation of the recurrent state,,,,,,"[0,1]",
tf.autograph.to_graph,recursive,Whether to recursively convert any functions that the converted function may call.,Whether to recursively convert any functions that the converted function may call,bool,,,,0,,
tf.strings.unicode_transcode,replacement_char,"An optional `int`. Defaults to `65533`. The replacement character codepoint to be used in place of any invalid formatting in the input when `errors='replace'`. Any valid unicode codepoint may be used. The default value is the default unicode replacement character is 0xFFFD or U+65533.)Note that for UTF-8, passing a replacement character expressible in 1 byte, such as ' ', will preserve string alignment to the source since invalid bytes will be replaced with a 1-byte replacement. For UTF-16-BE and UTF-16-LE, any 1 or 2 byte replacement character will preserve byte alignment to the source.",An optional D_TYPE,D_TYPE,,,,0,,
tf.strings.unicode_transcode,replacement_char,"An optional `int`. Defaults to `65533`. The replacement character codepoint to be used in place of any invalid formatting in the input when `errors='replace'`. Any valid unicode codepoint may be used. The default value is the default unicode replacement character is 0xFFFD or U+65533.)Note that for UTF-8, passing a replacement character expressible in 1 byte, such as ' ', will preserve string alignment to the source since invalid bytes will be replaced with a 1-byte replacement. For UTF-16-BE and UTF-16-LE, any 1 or 2 byte replacement character will preserve byte alignment to the source.",Any valid unicode codepoint may be used,,,,,,,
tf.strings.unicode_transcode,replacement_char,"An optional `int`. Defaults to `65533`. The replacement character codepoint to be used in place of any invalid formatting in the input when `errors='replace'`. Any valid unicode codepoint may be used. The default value is the default unicode replacement character is 0xFFFD or U+65533.)Note that for UTF-8, passing a replacement character expressible in 1 byte, such as ' ', will preserve string alignment to the source since invalid bytes will be replaced with a 1-byte replacement. For UTF-16-BE and UTF-16-LE, any 1 or 2 byte replacement character will preserve byte alignment to the source.",Defaults to CONSTANT_NUM,,,,,,,
tf.strings.unicode_transcode,replacement_char,"An optional `int`. Defaults to `65533`. The replacement character codepoint to be used in place of any invalid formatting in the input when `errors='replace'`. Any valid unicode codepoint may be used. The default value is the default unicode replacement character is 0xFFFD or U+65533.)Note that for UTF-8, passing a replacement character expressible in 1 byte, such as ' ', will preserve string alignment to the source since invalid bytes will be replaced with a 1-byte replacement. For UTF-16-BE and UTF-16-LE, any 1 or 2 byte replacement character will preserve byte alignment to the source.",For UTF CONSTANT_NUM BE and UTF CONSTANT_NUM LE any CONSTANT_NUM byte replacement character will preserve byte alignment to the source,,,,,,,
tf.strings.unicode_transcode,replacement_char,"An optional `int`. Defaults to `65533`. The replacement character codepoint to be used in place of any invalid formatting in the input when `errors='replace'`. Any valid unicode codepoint may be used. The default value is the default unicode replacement character is 0xFFFD or U+65533.)Note that for UTF-8, passing a replacement character expressible in 1 byte, such as ' ', will preserve string alignment to the source since invalid bytes will be replaced with a 1-byte replacement. For UTF-16-BE and UTF-16-LE, any 1 or 2 byte replacement character will preserve byte alignment to the source.",Note that for UTF CONSTANT_NUM passing a replacement character expressible in CONSTANT_NUM byte such as QSTR will preserve D_TYPE alignment to the source since invalid bytes will be replaced with a CONSTANT_NUM byte replacement,,,,,,,
tf.strings.unicode_transcode,replacement_char,"An optional `int`. Defaults to `65533`. The replacement character codepoint to be used in place of any invalid formatting in the input when `errors='replace'`. Any valid unicode codepoint may be used. The default value is the default unicode replacement character is 0xFFFD or U+65533.)Note that for UTF-8, passing a replacement character expressible in 1 byte, such as ' ', will preserve string alignment to the source since invalid bytes will be replaced with a 1-byte replacement. For UTF-16-BE and UTF-16-LE, any 1 or 2 byte replacement character will preserve byte alignment to the source.",The default value is the default unicode replacement character is 0xFFFD or U CONSTANT_NUM,,,,,,,
tf.strings.unicode_transcode,replacement_char,"An optional `int`. Defaults to `65533`. The replacement character codepoint to be used in place of any invalid formatting in the input when `errors='replace'`. Any valid unicode codepoint may be used. The default value is the default unicode replacement character is 0xFFFD or U+65533.)Note that for UTF-8, passing a replacement character expressible in 1 byte, such as ' ', will preserve string alignment to the source since invalid bytes will be replaced with a 1-byte replacement. For UTF-16-BE and UTF-16-LE, any 1 or 2 byte replacement character will preserve byte alignment to the source.",The replacement character codepoint to be used in place of any invalid formatting in the PARAM when PARAM QSTR,,,,,,,
tf.keras.layers.experimental.preprocessing.Normalization,reset_state,"Optional argument specifying whether to clear the state of the layer at the start of the call to `adapt`, or whether to start from the existing state. Subclasses may choose to throw if reset_state is set to 'False'.",Optional argument specifying whether to clear the state of the layer at the start of the call to QSTR or whether to start from the existing state,bool,,,,0,,
tf.keras.layers.experimental.preprocessing.Normalization,reset_state,"Optional argument specifying whether to clear the state of the layer at the start of the call to `adapt`, or whether to start from the existing state. Subclasses may choose to throw if reset_state is set to 'False'.",Subclasses may choose to throw if reset_state is set to QSTR,,,,,,,
tf.keras.layers.ConvLSTM2D,return_sequences,"Boolean. Whether to return the last output in the output sequence, or the full sequence.",D_TYPE,D_TYPE,,,,,,
tf.keras.layers.ConvLSTM2D,return_sequences,"Boolean. Whether to return the last output in the output sequence, or the full sequence.",Whether to return the last output in the output D_STRUCTURE or the full D_STRUCTURE,bool,,,,0,,
tf.linalg.lu_solve,rhs,"Matrix-shaped float `Tensor` representing targets for which to solve;`A X = RHS`. To handle vector cases, use: `lu_solve(..., rhs[..., tf.newaxis])[..., 0]`.",Matrix shaped D_TYPE D_STRUCTURE representing targets for which to solve A X rhs,D_TYPE,D_STRUCTURE,,,,,
tf.linalg.lu_solve,rhs,"Matrix-shaped float `Tensor` representing targets for which to solve;`A X = RHS`. To handle vector cases, use: `lu_solve(..., rhs[..., tf.newaxis])[..., 0]`.",To handle D_STRUCTURE cases use lu_solve rhs BSTR BSTR,,,,,,,
tf.linalg.solve,rhs,"A `Tensor`. Must have the same type as `matrix`. Shape is `[..., M, K]`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.linalg.solve,rhs,"A `Tensor`. Must have the same type as `matrix`. Shape is `[..., M, K]`.",Must have the same type as PARAM,&PARAM,,,,,,
tf.linalg.solve,rhs,"A `Tensor`. Must have the same type as `matrix`. Shape is `[..., M, K]`.",Shape is BSTR,,,,BSTR,,,
tf.data.experimental.dense_to_ragged_batch,row_splits_dtype,The dtype that should be used for the `row_splits` of any new ragged tensors.  Existing `tf.RaggedTensor` elements do not have their row_splits dtype changed.,Existing tf RaggedTensor elements do not have their row_splits dtype changed,,,,,,,
tf.data.experimental.dense_to_ragged_batch,row_splits_dtype,The dtype that should be used for the `row_splits` of any new ragged tensors.  Existing `tf.RaggedTensor` elements do not have their row_splits dtype changed.,The dtype that should be used for the QSTR of any new ragged D_STRUCTURE,dtype,,,,,,
tf.nn.batch_norm_with_global_normalization,scale_after_normalization,A bool indicating whether the resulted tensor needs to be multiplied with gamma.,A D_TYPE indicating whether the resulted D_STRUCTURE needs to be multiplied with PARAM,D_TYPE,,,,0,,
tf.keras.backend.random_uniform,seed,"Integer, random seed.",D_TYPE random seed,D_TYPE,,,,,,
tf.io.parse_tensor,serialized,A `Tensor` of type `string`. A scalar string containing a serialized TensorProto proto.,A D_STRUCTURE of type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.io.parse_tensor,serialized,A `Tensor` of type `string`. A scalar string containing a serialized TensorProto proto.,A scalar D_TYPE containing a serialized TensorProto proto,D_TYPE,,,,0,,
tf.ensure_shape,shape,"A `TensorShape` representing the shape of this tensor, a`TensorShapeProto`, a list, a tuple, or None.",A QSTR representing the shape of this D_STRUCTURE a QSTR a D_STRUCTURE or None,int,,,,1,"[0,inf)",
tf.keras.backend.reshape,shape,Target shape tuple.,Target shape D_STRUCTURE,int,,D_STRUCTURE,,1,"[0,inf)",
tf.math.accumulate_n,shape,"Expected shape of elements of `inputs` (optional). Also controls the output shape of this op, which may affect type inference in other ops. A value of `None` means ""infer the input shape from the shapes in `inputs`"".",A value of QSTR means infer the input shape from the shapes in PARAM,,,,,,,
tf.math.accumulate_n,shape,"Expected shape of elements of `inputs` (optional). Also controls the output shape of this op, which may affect type inference in other ops. A value of `None` means ""infer the input shape from the shapes in `inputs`"".",Also controls the output shape of this op which may affect type inference in other ops,int,,,,1,"[0,inf)",
tf.math.accumulate_n,shape,"Expected shape of elements of `inputs` (optional). Also controls the output shape of this op, which may affect type inference in other ops. A value of `None` means ""infer the input shape from the shapes in `inputs`"".",Expected shape of elements of PARAM BSTR,int,,,,1,"[0,inf)",
tf.keras.utils.plot_model,show_layer_names,whether to display layer names.,whether to display layer names,bool,,,,0,,
tf.keras.datasets.reuters.load_data,skip_top,skip the top N most frequently occurring words (which may not be informative).,skip the top N most frequently occurring words BSTR,,,,,,,
tf.data.experimental.make_batched_features_dataset,sloppy_ordering,"If `True`, reading performance will be improved at the cost of non-deterministic ordering. If `False`, the order of elements produced is deterministic prior to shuffling (elements are still randomized if `shuffle=True`. Note that if the seed is set, then order of elements after shuffling is deterministic). Defaults to `False`.",Defaults to CONSTANT_BOOL,,,,,,,
tf.data.experimental.make_batched_features_dataset,sloppy_ordering,"If `True`, reading performance will be improved at the cost of non-deterministic ordering. If `False`, the order of elements produced is deterministic prior to shuffling (elements are still randomized if `shuffle=True`. Note that if the seed is set, then order of elements after shuffling is deterministic). Defaults to `False`.",If CONSTANT_BOOL reading performance will be improved at the cost of non deterministic ordering,bool,,,,0,,
tf.data.experimental.make_batched_features_dataset,sloppy_ordering,"If `True`, reading performance will be improved at the cost of non-deterministic ordering. If `False`, the order of elements produced is deterministic prior to shuffling (elements are still randomized if `shuffle=True`. Note that if the seed is set, then order of elements after shuffling is deterministic). Defaults to `False`.",If CONSTANT_BOOL the order of elements produced is deterministic prior to shuffling elements are still randomized if PARAM CONSTANT_BOOL,bool,,,,0,,
tf.data.experimental.make_batched_features_dataset,sloppy_ordering,"If `True`, reading performance will be improved at the cost of non-deterministic ordering. If `False`, the order of elements produced is deterministic prior to shuffling (elements are still randomized if `shuffle=True`. Note that if the seed is set, then order of elements after shuffling is deterministic). Defaults to `False`.",Note that if the seed is set then order of elements after shuffling is deterministic,,,,,,,
tf.sparse.retain,sp_input,The input `SparseTensor` with `N` non-empty elements.,The input D_STRUCTURE with QSTR non empty elements,,D_STRUCTURE,,,,,
tf.keras.layers.experimental.preprocessing.TextVectorization,split,"Optional specification for splitting the input text. Values can be None (no splitting), 'whitespace' (split on ASCII whitespace), or a Callable. The default is 'whitespace'.",Optional specification for splitting the input text,,,,,,,
tf.keras.layers.experimental.preprocessing.TextVectorization,split,"Optional specification for splitting the input text. Values can be None (no splitting), 'whitespace' (split on ASCII whitespace), or a Callable. The default is 'whitespace'.",The default is QSTR,,,,,,,
tf.keras.layers.experimental.preprocessing.TextVectorization,split,"Optional specification for splitting the input text. Values can be None (no splitting), 'whitespace' (split on ASCII whitespace), or a Callable. The default is 'whitespace'.",Values can be None BSTR QSTR BSTR or a Callable,,,,,,,QSTR
tf.keras.layers.Conv3D,strides,"An integer or tuple/list of 3 integers, specifying the strides of the convolution along each spatial dimension. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1.",An D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE specifying the strides of the convolution along each spatial dimension,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],0;1,"[0,inf)",
tf.keras.layers.Conv3D,strides,"An integer or tuple/list of 3 integers, specifying the strides of the convolution along each spatial dimension. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1.",Can be a single D_TYPE to specify the same value for all spatial dimensions,D_TYPE,,,,0,,
tf.keras.layers.Conv3D,strides,"An integer or tuple/list of 3 integers, specifying the strides of the convolution along each spatial dimension. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1.",Specifying any stride value CONSTANT_NUM is incompatible with specifying any PARAM value CONSTANT_NUM,,,,,,,
tf.strings.format,summarize,"An optional `int`. Defaults to `3`. When formatting the tensors, show the first and last `summarize`entries of each tensor dimension (recursively). If set to -1, all elements of the tensor will be shown.",An optional D_TYPE,D_TYPE,,,,0,,
tf.strings.format,summarize,"An optional `int`. Defaults to `3`. When formatting the tensors, show the first and last `summarize`entries of each tensor dimension (recursively). If set to -1, all elements of the tensor will be shown.",Defaults to CONSTANT_NUM,,,,,,,
tf.strings.format,summarize,"An optional `int`. Defaults to `3`. When formatting the tensors, show the first and last `summarize`entries of each tensor dimension (recursively). If set to -1, all elements of the tensor will be shown.",If set to CONSTANT_NUM all elements of the D_STRUCTURE will be shown,,,,,,,
tf.strings.format,summarize,"An optional `int`. Defaults to `3`. When formatting the tensors, show the first and last `summarize`entries of each tensor dimension (recursively). If set to -1, all elements of the tensor will be shown.",When formatting the D_STRUCTURE show the first and last summarizeentries of each D_STRUCTURE dimension BSTR,,,,,,,
tf.io.serialize_tensor,tensor,A `Tensor`. A Tensor of type `T`.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.io.serialize_tensor,tensor,A `Tensor`. A Tensor of type `T`.,A D_STRUCTURE of type QSTR,QSTR,D_STRUCTURE,,,,,
tf.linalg.svd,tensor,"`Tensor` of shape `[..., M, N]`. Let `P` be the minimum of `M` and`N`.",D_STRUCTURE of shape BSTR,,D_STRUCTURE,,BSTR,,,
tf.linalg.svd,tensor,"`Tensor` of shape `[..., M, N]`. Let `P` be the minimum of `M` and`N`.",Let QSTR be the minimum of QSTR,,,,,,,
tf.sparse.from_dense,tensor,A dense `Tensor` to be converted to a `SparseTensor`.,A dense D_STRUCTURE to be converted to a D_STRUCTURE,,D_STRUCTURE,,,,,
tf.tensor_scatter_nd_sub,tensor,A `Tensor`. Tensor to copy/update.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.tensor_scatter_nd_sub,tensor,A `Tensor`. Tensor to copy/update.,D_STRUCTURE to copy update,,D_STRUCTURE,,,,,
tf.keras.backend.relu,threshold,float. Threshold value for thresholded activation.,D_TYPE,D_TYPE,,,,,,
tf.keras.backend.relu,threshold,float. Threshold value for thresholded activation.,threshold value for thresholded activation,,,,,,,
tf.keras.layers.SeparableConv1D,trainable,"Boolean, if `True` the weights of this layer will be marked as trainable (and listed in `layer.trainable_weights`).",D_TYPE if CONSTANT_BOOL the weights of this layer will be marked as trainable and listed in layer trainable_weights,D_TYPE,,,,0,,
tf.keras.backend.in_test_phase,training,"Optional scalar tensor (or Python boolean, or Python integer) specifying the learning phase.",Optional scalar D_STRUCTURE BSTR specifying the learning phase,bool;int,D_STRUCTURE,,,0,,
tf.random.all_candidate_sampler,true_classes,"A `Tensor` of type `int64` and shape `[batch_size, num_true]`. The target classes.",A D_STRUCTURE of type D_TYPE and shape BSTR,D_TYPE,D_STRUCTURE,,BSTR,,,
tf.random.all_candidate_sampler,true_classes,"A `Tensor` of type `int64` and shape `[batch_size, num_true]`. The target classes.",The target classes,,,,,,,
tf.io.decode_jpeg,try_recover_truncated,An optional `bool`. Defaults to `False`. If true try to recover an image from truncated input.,An optional D_TYPE,D_TYPE,,,,0,,
tf.io.decode_jpeg,try_recover_truncated,An optional `bool`. Defaults to `False`. If true try to recover an image from truncated input.,Defaults to CONSTANT_BOOL,,,,,,,
tf.io.decode_jpeg,try_recover_truncated,An optional `bool`. Defaults to `False`. If true try to recover an image from truncated input.,If CONSTANT_BOOL try to recover an image from truncated input,bool,,,,0,,
tf.keras.layers.SimpleRNNCell,units,"Positive integer, dimensionality of the output space.",Positive D_TYPE dimensionality of the output space,D_TYPE,,,,,"(0,inf)",
tf.tensor_scatter_nd_sub,updates,A `Tensor`. Must have the same type as `tensor`. Updates to scatter into output.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.tensor_scatter_nd_sub,updates,A `Tensor`. Must have the same type as `tensor`. Updates to scatter into output.,Must have the same type as D_STRUCTURE,&D_STRUCTURE,,,,,,
tf.tensor_scatter_nd_sub,updates,A `Tensor`. Must have the same type as `tensor`. Updates to scatter into output.,updates to scatter into output,,,,,,,
tf.keras.layers.SeparableConv1D,use_bias,"Boolean, whether the layer uses a bias.",D_TYPE whether the layer uses a bias,D_TYPE,,,,0,,
tf.variable_creator_scope,variable_creator,the passed creator,the passed creator,,,,,,,
tf.math.confusion_matrix,weights,An optional `Tensor` whose shape matches `predictions`.,An optional D_STRUCTURE whose shape matches PARAM,,D_STRUCTURE,,&PARAM,,,
tf.strings.as_string,width,An optional `int`. Defaults to `-1`. Pad pre-decimal numbers to this width. Applies to both floating point and integer numbers. Only used if width > -1.,An optional D_TYPE,D_TYPE,,,,0,,
tf.strings.as_string,width,An optional `int`. Defaults to `-1`. Pad pre-decimal numbers to this width. Applies to both floating point and integer numbers. Only used if width > -1.,Applies to both D_TYPE and D_TYPE numbers,D_TYPE,,,,,,
tf.strings.as_string,width,An optional `int`. Defaults to `-1`. Pad pre-decimal numbers to this width. Applies to both floating point and integer numbers. Only used if width > -1.,Defaults to CONSTANT_NUM,,,,,,,
tf.strings.as_string,width,An optional `int`. Defaults to `-1`. Pad pre-decimal numbers to this width. Applies to both floating point and integer numbers. Only used if width > -1.,Only used if width CONSTANT_NUM,,,,,,,
tf.strings.as_string,width,An optional `int`. Defaults to `-1`. Pad pre-decimal numbers to this width. Applies to both floating point and integer numbers. Only used if width > -1.,Pad pre decimal numbers to this width,,,,,,,
tf.signal.inverse_stft,window_fn,"A callable that takes a window length and a `dtype` keyword argument and returns a `[window_length]` `Tensor` of samples in the provided datatype. If set to `None`, no windowing is used.",A callable that takes a window length and a QSTR keyword argument and returns a BSTR D_STRUCTURE of samples in the provided datatype,,,,,,,
tf.signal.inverse_stft,window_fn,"A callable that takes a window length and a `dtype` keyword argument and returns a `[window_length]` `Tensor` of samples in the provided datatype. If set to `None`, no windowing is used.",If set to QSTR no windowing is used,,,,,,,
tf.debugging.assert_non_positive,x,Numeric `Tensor`.,D_TYPE D_STRUCTURE,D_TYPE,D_STRUCTURE,,,,,
tf.debugging.assert_positive,x,Numeric `Tensor`.,D_TYPE D_STRUCTURE,D_TYPE,D_STRUCTURE,,,,,
tf.ensure_shape,x,A `Tensor`.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.keras.backend.all,x,Tensor or variable.,D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.argmin,x,Tensor or variable.,D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.batch_normalization,x,Input tensor or variable.,Input D_STRUCTURE or variable,,D_STRUCTURE,,,,,
tf.keras.backend.count_params,x,Variable or tensor.,Variable or D_STRUCTURE,,D_STRUCTURE,,,,,
tf.math.erfinv,x,`Tensor` with type `float` or `double`.,D_STRUCTURE with type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.math.lbeta,x,"A rank `n + 1` `Tensor`, `n >= 0` with type `float`, or `double`.",A rank n CONSTANT_NUM D_STRUCTURE n REXPR with type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.math.logical_and,x,A `Tensor` of type `bool`.,A D_STRUCTURE of type D_TYPE,D_TYPE,D_STRUCTURE,,,,,
tf.math.minimum,x,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.math.minimum,x,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.math.sign,x,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.math.sign,x,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.math.tanh,x,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.math.tanh,x,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.math.zeta,x,"A `Tensor`. Must be one of the following types: `float32`, `float64`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.math.zeta,x,"A `Tensor`. Must be one of the following types: `float32`, `float64`.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.nn.dropout,x,A floating point tensor.,A D_TYPE D_STRUCTURE,D_TYPE,D_STRUCTURE,,,,,
tf.math.atan2,y,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.",A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.math.atan2,y,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.",Must be one of the following types D_TYPE,D_TYPE,,,,,,
tf.math.equal,y,A `tf.Tensor` or `tf.SparseTensor` or `tf.IndexedSlices`.,A D_STRUCTURE or tf IndexedSlices,,D_STRUCTURE,,,,,
tf.math.squared_difference,y,A `Tensor`. Must have the same type as `x`.,A D_STRUCTURE,,D_STRUCTURE,,,,,
tf.math.squared_difference,y,A `Tensor`. Must have the same type as `x`.,Must have the same type as QSTR,&PARAM,,,,,,
tf.compat.forward_compatible,year,"A year (e.g., 2018). Must be an `int`.",A year BSTR,,,,,,,
tf.compat.forward_compatible,year,"A year (e.g., 2018). Must be an `int`.",Must be an D_TYPE,D_TYPE,,,,0,,
