aliases:
- tf.compat.v1.keras.layers.SimpleRNN
constraints:
  '**kwargs':
    descp: ''
  activation:
    default: tanh
    descp: 'Activation function to use. Default: hyperbolic tangent (tanh). If you
      pass None, no activation is applied (ie. "linear" activation: a(x) = x).'
  activity_regularizer:
    default: None
    descp: 'Regularizer function applied to the output of the layer (its "activation").
      Default: None.'
  bias_constraint:
    default: None
    descp: 'Constraint function applied to the bias vector. Default: None.'
  bias_initializer:
    default: zeros
    descp: 'Initializer for the bias vector. Default: zeros.'
  bias_regularizer:
    default: None
    descp: 'Regularizer function applied to the bias vector. Default: None.'
  dropout:
    default: '0.0'
    descp: 'Float between 0 and 1. Fraction of the units to drop for the linear transformation
      of the inputs. Default: 0.'
  go_backwards:
    default: 'False'
    descp: Boolean (default False). If True, process the input sequence backwards
      and return the reversed sequence.
  kernel_constraint:
    default: None
    descp: 'Constraint function applied to the kernel weights matrix. Default: None.'
  kernel_initializer:
    default: glorot_uniform
    descp: 'Initializer for the kernel weights matrix, used for the linear transformation
      of the inputs. Default: glorot_uniform.'
  kernel_regularizer:
    default: None
    descp: 'Regularizer function applied to the kernel weights matrix. Default: None.'
  recurrent_constraint:
    default: None
    descp: 'Constraint function applied to the recurrent_kernel weights matrix. Default:
      None.'
  recurrent_dropout:
    default: '0.0'
    descp: 'Float between 0 and 1. Fraction of the units to drop for the linear transformation
      of the recurrent state. Default: 0.'
  recurrent_initializer:
    default: orthogonal
    descp: 'Initializer for the recurrent_kernel weights matrix, used for the linear
      transformation of the recurrent state. Default: orthogonal.'
  recurrent_regularizer:
    default: None
    descp: 'Regularizer function applied to the recurrent_kernel weights matrix. Default:
      None.'
  return_sequences:
    default: 'False'
    descp: 'Boolean. Whether to return the last output in the output sequence, or
      the full sequence. Default: False.'
  return_state:
    default: 'False'
    descp: 'Boolean. Whether to return the last state in addition to the output. Default:
      False'
  stateful:
    default: 'False'
    descp: Boolean (default False). If True, the last state for each sample at index
      i in a batch will be used as initial state for the sample of index i in the
      following batch.
  units:
    descp: Positive integer, dimensionality of the output space.
  unroll:
    default: 'False'
    descp: Boolean (default False). If True, the network will be unrolled, else a
      symbolic loop will be used. Unrolling can speed-up a RNN, although it tends
      to be more memory-intensive. Unrolling is only suitable for short sequences.
  use_bias:
    default: 'True'
    descp: Boolean, (default True), whether the layer uses a bias vector.
exceptions:
- AttributeError: When the RNN layer is not stateful.
- ValueError: When the batch size of the RNN layer is unknown.
- ValueError: When the input numpy array is not compatible with the RNN layer state,
    either size wise or dtype wise.
inputs:
  optional:
  - activation
  - use_bias
  - kernel_initializer
  - recurrent_initializer
  - bias_initializer
  - kernel_regularizer
  - recurrent_regularizer
  - bias_regularizer
  - activity_regularizer
  - kernel_constraint
  - recurrent_constraint
  - bias_constraint
  - dropout
  - recurrent_dropout
  - return_sequences
  - return_state
  - go_backwards
  - stateful
  - unroll
  required:
  - units
  - '**kwargs'
link: https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/keras/layers/SimpleRNN
package: tensorflow
target: SimpleRNN
title: tf.keras.layers.SimpleRNN
version: 2.3.0
