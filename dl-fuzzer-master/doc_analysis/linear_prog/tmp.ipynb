{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "#from gensim.models import Doc2Vec\n",
    "from util import *\n",
    "from mining_util import *\n",
    "from scipy import spatial\n",
    "import pickle\n",
    "\n",
    "\n",
    "# import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model.wv.get_vector(\"D\")\n",
    "\n",
    "# descp = \"A CONSTANT_NUM D BSTR D_STRUCTURE with the same shape as QSTR\"\n",
    "# label = ['dtype', 'structure', 'shape', 'ndim', 'enum']\n",
    "# descp_list = descp.split( )\n",
    "# print(descp_list)\n",
    "# sen_vec = [0] * 100\n",
    "# for i in descp_list:\n",
    "#     sen_vec += model.wv.get_vector(i)\n",
    "\n",
    "# for i in label:\n",
    "#     w_vec = model.wv.get_vector(i)\n",
    "#     sim = 1 - spatial.distance.cosine(sen_vec, w_vec)\n",
    "#     print(str(i) + \":\" + str(sim))\n",
    "\n",
    "\n",
    "constr_cols = ['dtype', 'structure', 'shape', 'ndim', 'enum', 'range']\n",
    "\n",
    "\n",
    "\n",
    "def get_vec(model, str_list):\n",
    "    # input: a list of strings(words) or a sentence (string)\n",
    "    if isinstance(str_list, str):\n",
    "        str_list = str_list.split()\n",
    "    assert isinstance(str_list, list)\n",
    "    sen_vec = [0] * 100\n",
    "\n",
    "    for w in str_list:\n",
    "        sen_vec += model.wv.get_vector(w)\n",
    "    return sen_vec\n",
    "    \n",
    "\n",
    "\n",
    "def cal_dist(vec1, vec2):\n",
    "    # TODO: check other dist, e.g., Word Mover's Distance\n",
    "    dist = 1 - spatial.distance.cosine(vec1, vec2)\n",
    "    return dist\n",
    "    \n",
    "def normalize_ir(ir):\n",
    "    ir = re.sub('[\\[\\(]0,inf[\\)\\]]', 'positive', ir)\n",
    "    ir = re.sub('[\\[\\(]inf,0[\\)\\]]', 'negative', ir)\n",
    "    ir = re.sub('tf.dtype', 'dtype', ir)\n",
    "    ir = re.sub('numpy.dtype', 'dtype', ir)\n",
    "    ir = re.sub('torch.dtype', 'dtype', ir)\n",
    "    # ir = re.sub('[^0-9a-zA-Z_]+', '', ir)\n",
    "    ir = re.sub('&', '', ir)\n",
    "    ir = re.sub('[\\[\\]\\(\\)]', '', ir)       #shape [constant_num] -> constant_num\n",
    "    return ir \n",
    "\n",
    "def test_on_csv(csv_path, model_path, save_path):\n",
    "    df = pd.read_csv(csv_path)     \n",
    "    model = Word2Vec.load(model_path)\n",
    "    dist_list = []  \n",
    "    errors = []\n",
    "    for index, row in df.iterrows(): \n",
    "        if row.isnull()['Normalized_descp']:\n",
    "            continue\n",
    "        # get all constr\n",
    "        try:\n",
    "            all_ir = parse_ir(row, constr_cols) \n",
    "            if constr_empty(all_ir):   # if this row has no IRs\n",
    "                continue\n",
    "            sen_vec = get_vec(model, row['Normalized_descp'])\n",
    "            for cat in all_ir:  \n",
    "                for ir in all_ir[cat]:  # skip if empty\n",
    "                    \n",
    "                    ir_vec = get_vec(model, [cat, normalize_ir(ir)])\n",
    "\n",
    "                    dist_list.append(cal_dist(sen_vec, ir_vec))\n",
    "        except Exception as e: \n",
    "            # print(row)\n",
    "            # print(row['Normalized_descp'])\n",
    "            # print([cat, normalize_ir(ir)])\n",
    "            print(e)\n",
    "            errors.append(e)\n",
    "            # print()\n",
    "            # break\n",
    "    dump_pickle(save_path, dist_list)\n",
    "    # save_yaml(os.path.join(save_path, file_name), errors)\n",
    "    # file = open(save_path, 'wb')\n",
    "    # pickle.dump(dist_list, file)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "# test_on_csv('sample/tf30_merged.csv', 'w2v_data/w2v.model', 'w2v_data/tf_label_sim')\n",
    "# test_on_csv('sample/pt30_merged.csv', 'w2v_data/w2v.model', 'w2v_data/pt_label_sim')\n",
    "# test_on_csv('sample/mx30_merged.csv', 'w2v_data/w2v.model', 'w2v_data/mx_label_sim')\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('w2v_data/w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_vec1 = get_vec(model, ['while', 'CONSTANT_BOOL'])\n",
    "sen_vec2 = get_vec(model, ['to','compute'])\n",
    "ir_vec = get_vec(model, ['dtype', 'bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4678542371936587"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_dist(sen_vec1, ir_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0044736519191688195"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_dist(sen_vec2, ir_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docterfuzz",
   "language": "python",
   "name": "docterfuzz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
