API,Param,ratio,doc2.1_parsed_rmv1,tfdoc2.2
tf.keras.datasets.reuters.load_data.yaml,num_words,0.14043583535108958,max number of words to include. Words are ranked by how often they occur (in the training set) and only the most frequent words are kept,"integer or None. Words are ranked by how often they occur (in the training set) and only the num_words most frequent words are kept. Any less frequent word will appear as oov_char value in the sequence data. If None, all words are kept. Defaults to None, so all words are kept."
tf.keras.datasets.reuters.load_data.yaml,skip_top,0.6141732283464567,skip the top N most frequently occurring words (which may not be informative).,"skip the top N most frequently occurring words (which may not be informative). These words will appear as oov_char value in the dataset. Defaults to 0, so no words are skipped."
tf.keras.datasets.reuters.load_data.yaml,maxlen,0.25316455696202533,truncate sequences after this length.,"int or None. Maximum sequence length. Any longer sequence will be truncated. Defaults to None, which means no truncation."
tf.keras.datasets.reuters.load_data.yaml,test_split,0.518918918918919,Fraction of the dataset to be used as test data.,"Float between 0 and 1. Fraction of the dataset to be used as test data. Defaults to 0.2, meaning 20% of the dataset is used as test data."
tf.keras.datasets.reuters.load_data.yaml,seed,0.6666666666666666,random seed for sample shuffling.,int. Seed for reproducible data shuffling.
tf.keras.datasets.reuters.load_data.yaml,oov_char,0.8373983739837398,words that were cut out because of the `num_words`or `skip_top` limit will be replaced with this character.,int. The out-of-vocabulary character. Words that were cut out because of the num_words or skip_top limits will be replaced with this character.
tf.keras.estimator.model_to_estimator.yaml,keras_model,0.6617100371747212,A compiled Keras model object. This argument is mutually exclusive with `keras_model_path`.,A compiled Keras model object. This argument is mutually exclusive with keras_model_path. Estimator's model_fn uses the structure of the model to clone the model. Defaults to None.
tf.keras.estimator.model_to_estimator.yaml,custom_objects,0.176056338028169,Dictionary for custom objects.,"Dictionary for cloning customized objects. This is used with classes that is not part of this pip package. For example, if user maintains a relu6 class that inherits from tf.keras.layers.Layer, then pass custom_objects={'relu6': relu6}. Defaults to None."
tf.keras.estimator.model_to_estimator.yaml,model_dir,0.7489361702127659,"Directory to save `Estimator` model parameters, graph, summary files for TensorBoard, etc.","Directory to save Estimator model parameters, graph, summary files for TensorBoard, etc. If unset a directory will be created with tempfile.mkdtemp"
tf.keras.estimator.model_to_estimator.yaml,config,0.2054794520547945,`RunConfig` to config `Estimator`.,"RunConfig to config Estimator. Allows setting up things in model_fn based on configuration such as num_ps_replicas, or model_dir. Defaults to None. If both config.model_dir and the model_dir argument (above) are specified the model_dir argument takes precedence."
tf.debugging.experimental.enable_dump_debug_info.yaml,op_regex,0.857685009487666,"Dump data from only the tensors from op types that matches to the regular expression (through Python's `re.match()`). ""Op type"" refers to the names of the TensorFlow operations (e.g., ""MatMul"", ""LogSoftmax""), which may repeat in a TensorFlow function. It does not refer to the names of nodes (e.g., ""dense/MatMul"", ""dense_1/MatMul_1"") which are unique within a function.<ul><li>Example 1: Dump tensor data from only MatMul and Relu ops`op_regex=""^(MatMul|Relu)$""`.","Dump data from only the tensors from op types that matches to the regular expression (through Python's re.match()). ""Op type"" refers to the names of the TensorFlow operations (e.g., ""MatMul"", ""LogSoftmax""), which may repeat in a TensorFlow function. It does not refer to the names of nodes (e.g., ""dense/MatMul"", ""dense_1/MatMul_1"") which are unique within a function. Example 1: Dump tensor data from only MatMul and Relu ops op_regex=""^(MatMul|Relu)$"". Example 2: Dump tensors from all ops except Relu: op_regex=""(?!^Relu$)"". This filter operates in a logical AND relation with tensor_dtypes."
tf.debugging.experimental.enable_dump_debug_info.yaml,tensor_dtypes,0.5328798185941043,Dump data from only the tensors of which the specified dtypes. This optional argument can be in any of the following format:<ul><li>a list or tuple of `DType` objects or strings that can be converted to `DType` objects via `tf.as_dtype()`. Examples:,"Dump data from only the tensors of which the specified dtypes. This optional argument can be in any of the following format: a list or tuple of DType objects or strings that can be converted to DType objects via tf.as_dtype(). Examples: tensor_dtype=[tf.float32, tf.float64], tensor_dtype=[""float32"", ""float64""], tensor_dtypes=(tf.int32, tf.bool), tensor_dtypes=(""int32"", ""bool"") a callable that takes a single DType argument and returns a Python boolean indicating whether the dtype is to be included in the data dumping. Examples: tensor_dtype=lambda dtype: dtype.is_integer. This filter operates in a logical AND relation with op_regex."
tf.keras.backend.set_image_data_format.yaml,data_format,0.3371647509578544,string. `'channels_first'` or `'channels_last'`. Example: `python from keras import backend as K K.image_data_format() >>> 'channels_first' K.set_image_data_format('channels_last') K.image_data_format() >>> 'channels_last'`,string. 'channels_first' or 'channels_last'.
tf.keras.backend.set_value.yaml,x,0.8,Tensor to set to a new value.,Variable to set to a new value.
tf.extract_volume_patches.yaml,padding,0.658753709198813,"A `string` from: `""SAME"", ""VALID""`. The type of padding algorithm to use.We specify the size-related attributes as:","A string from: ""SAME"", ""VALID"". The type of padding algorithm to use. We specify the size-related attributes as: ksizes = [1, ksize_planes, ksize_rows, ksize_cols, 1] strides = [1, stride_planes, strides_rows, strides_cols, 1]"
tf.keras.layers.add2.yaml,inputs,0.7872340425531915,A list of input tensors (at least 2).,A list of input tensors (at least 2) with the same shape.
tf.image.central_crop.yaml,central_fraction,0.37438423645320196,"float (0, 1], fraction of size to crop Usage Example: `python >> import tensorflow as tf >> x = tf.random.normal(shape=(256, 256, 3)) >> tf.image.central_crop(x, 0.5)`","float (0, 1], fraction of size to crop"
tf.keras.losses.logcosh2.yaml,y_true,0.2631578947368421,tensor of true targets.,"Ground truth values. shape = [batch_size, d0, .. dN]."
tf.keras.losses.logcosh2.yaml,y_pred,0.4146341463414634,tensor of predicted targets.,"The predicted values. shape = [batch_size, d0, .. dN]."
tf.summary.trace_export.yaml,profiler_outdir,0.32432432432432434,"Output directory for profiler. It is required when profiler is enabled when trace was started. Otherwise, it is ignored.","Output directory for profiler. This is only used when the profiler was enabled when the trace was started. In that case, if there is a logdir-based default SummaryWriter, this defaults to the same directory, but otherwise the argument must be passed."
tf.data.experimental.scan.yaml,scan_func,0.8632075471698113,"A function that maps `(old_state, input_element)` to`(new_state, output_element). It must take two arguments and return a pair of nested structures of tensors. The`new_state`must match the structure of`initial_state`.","A function that maps (old_state, input_element) to (new_state, output_element). It must take two arguments and return a pair of nested structures of tensors. The new_state must match the structure of initial_state."
tf.random.stateless_uniform.yaml,minval,0.8740740740740741,A 0-D Tensor or Python value of type `dtype`. The lower bound on the range of random values to generate.  Defaults to 0.,A 0-D Tensor or Python value of type dtype. The lower bound on the range of random values to generate. Pass None for full-range integers. Defaults to 0.
tf.random.stateless_uniform.yaml,maxval,0.8888888888888888,A 0-D Tensor or Python value of type `dtype`. The upper bound on the range of random values to generate.  Defaults to 1 if `dtype` is floating point.,A 0-D Tensor or Python value of type dtype. The upper bound on the range of random values to generate. Defaults to 1 if dtype is floating point. Pass None for full-range integers.
tf.random.stateless_uniform.yaml,dtype,0.6027397260273972,"The type of the output: `float16`, `float32`, `float64`, `int32`, or`int64`.","The type of the output: float16, float32, float64, int32, or int64. For unbounded uniform ints (minval, maxval both None), uint32 and uint64 may be used."
tf.nn.conv3d.yaml,dilations,0.8846153846153846,"An optional list of `ints`. Defaults to `[1, 1, 1, 1, 1]`. 1-D tensor of length 5.  The dilation factor for each dimension of`input`. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of `data_format`, see above for details. Dilations in the batch and depth dimensions must be 1.","An optional list of ints. Defaults to [1, 1, 1, 1, 1]. 1-D tensor of length 5. The dilation factor for each dimension of input. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of data_format, see above for details. Dilations in the batch and depth dimensions must be 1."
tf.strings.substr.yaml,unit,0.8643356643356643,"An optional `string` from: `""BYTE"", ""UTF8_CHAR""`. Defaults to `""BYTE""`. The unit that is used to create the substring.  One of: `""BYTE""` (for defining position and length by bytes) or `""UTF8_CHAR""` (for the UTF-8 encoded Unicode code points).  The default is `""BYTE""`. Results are undefined if`unit=UTF8_CHAR` and the `input` strings do not contain structurally valid UTF-8.","An optional string from: ""BYTE"", ""UTF8_CHAR"". Defaults to ""BYTE"". The unit that is used to create the substring. One of: ""BYTE"" (for defining position and length by bytes) or ""UTF8_CHAR"" (for the UTF-8 encoded Unicode code points). The default is ""BYTE"". Results are undefined if unit=UTF8_CHAR and the input strings do not contain structurally valid UTF-8."
tf.ragged.constant.yaml,ragged_rank,0.42902208201892744,"An integer specifying the ragged rank of the returned`RaggedTensor`.  Must be nonnegative and less than `K`. Defaults to`max(0, K - 1)` if `inner_shape` is not specified.  Defaults to `max(0, K 1 - len(inner_shape))`if`inner_shape` is specified. ","An integer specifying the ragged rank of the returned RaggedTensor. Must be nonnegative and less than K. Defaults to max(0, K - 1) if inner_shape is not specified. Defaults to `max(0, K 1 - len(inner_shape))ifinner_shapeis specified. </td> </tr><tr> <td>inner_shape</td> <td> A tuple of integers specifying the shape for individual inner values in the returnedRaggedTensor. Defaults to()ifragged_rankis not specified. Ifragged_rankis specified, then a default is chosen based on the contents ofpylist. </td> </tr><tr> <td>name</td> <td> A name prefix for the returned tensor (optional). </td> </tr><tr> <td>row_splits_dtype</td> <td> data type for the constructedRaggedTensor`'s row_splits. One of tf.int32 or tf.int64."
tf.ragged.constant.yaml,inner_shape,0.0,"A tuple of integers specifying the shape for individual inner values in the returned `RaggedTensor`.  Defaults to `()` if `ragged_rank`is not specified.  If `ragged_rank` is specified, then a default is chosen based on the contents of `pylist`.",
tf.ragged.constant.yaml,name,0.0,A name prefix for the returned tensor (optional).,
tf.ragged.constant.yaml,row_splits_dtype,0.0,data type for the constructed `RaggedTensor`'s row_splits. One of `tf.int32` or `tf.int64`.,
tf.clip_by_value.yaml,clip_value_min,0.30601092896174864,"A 0-D (scalar) `Tensor`, or a `Tensor` with the same shape as `t`. The minimum value to clip by.",The minimum value to clip to. A scalar Tensor or one that is broadcastable to the shape of t.
tf.clip_by_value.yaml,clip_value_max,0.28415300546448086,"A 0-D (scalar) `Tensor`, or a `Tensor` with the same shape as `t`. The maximum value to clip by.",The minimum value to clip to. A scalar Tensor or one that is broadcastable to the shape of t.
tf.nest.flatten.yaml,structure,0.7619047619047619,"an arbitrarily nested structure or a scalar object. Note, numpy arrays are considered scalars.","an arbitrarily nested structure. Note, numpy arrays are considered atoms and are not flattened."
tf.image.random_crop.yaml,seed,0.8837209302325582,Python integer. Used to create a random seed. See`tf.compat.v1.set_random_seed`for behavior.,Python integer. Used to create a random seed. See tf.random.set_seed for behavior.
tf.image.resize.yaml,method,0.6862745098039216,ResizeMethod.  Defaults to `bilinear`.,"An image.ResizeMethod, or string equivalent. Defaults to bilinear."
tf.foldl.yaml,back_prop,0.6163522012578616,(optional) True enables support for back propagation.,(optional) Deprecated. False disables support for back propagation. Prefer using tf.stop_gradient instead.
tf.math.argmax.yaml,axis,0.3053435114503817,"A `Tensor`. Must be one of the following types: `int32`, `int64`. int32 or int64, must be in the range `-rank(input), rank(input))`. Describes which axis of the input Tensor to reduce across. For vectors, use axis = 0.","An integer, the axis to reduce across. Default to 0."
tf.math.argmax.yaml,output_type,0.8467153284671532,"An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to`tf.int64`.",An optional output dtype (tf.int32 or tf.int64). Defaults to tf.int64.
tf.math.argmax.yaml,name,0.704225352112676,A name for the operation (optional).,An optional name for the operation.
tf.math.argmax.yaml,input,0.09523809523809523,"A `Tensor`. Must be one of the following types: `float32`, `float64`,`int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`,`quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`,`uint64`.",A Tensor.
tf.keras.losses.hinge2.yaml,y_true,0.8945686900958466,The ground truth values. `y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are provided they will be converted to -1 or 1.,"The ground truth values. y_true values are expected to be -1 or 1. If binary (0 or 1) labels are provided they will be converted to -1 or 1. shape = [batch_size, d0, .. dN]."
tf.keras.losses.hinge2.yaml,y_pred,0.56,The predicted values.,"The predicted values. shape = [batch_size, d0, .. dN]."
tf.keras.losses.poisson2.yaml,y_true,0.2631578947368421,Tensor of true targets.,"Ground truth values. shape = [batch_size, d0, .. dN]."
tf.keras.losses.poisson2.yaml,y_pred,0.4146341463414634,Tensor of predicted targets.,"The predicted values. shape = [batch_size, d0, .. dN]."
tf.sparse.sparse_dense_matmul.yaml,sp_a,0.7428571428571429,"SparseTensor A, of rank 2.","SparseTensor (or dense Matrix) A, of rank 2."
tf.sparse.sparse_dense_matmul.yaml,b,0.780952380952381,A dense Matrix with the same dtype as sp_a.,"dense Matrix (or SparseTensor) B, with the same dtype as sp_a."
tf.while_loop.yaml,back_prop,0.2597402597402597,Whether backprop is enabled for this while loop.,(optional) Deprecated. False disables support for back propagation. Prefer using tf.stop_gradient instead.
tf.math.sqrt.yaml,x,0.8135593220338984,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.","A tf.Tensor of type bfloat16, half, float32, float64, complex64, complex128"
tf.keras.datasets.imdb.load_data.yaml,num_words,0.14043583535108958,max number of words to include. Words are ranked by how often they occur (in the training set) and only the most frequent words are kept,"integer or None. Words are ranked by how often they occur (in the training set) and only the num_words most frequent words are kept. Any less frequent word will appear as oov_char value in the sequence data. If None, all words are kept. Defaults to None, so all words are kept."
tf.keras.datasets.imdb.load_data.yaml,skip_top,0.6141732283464567,skip the top N most frequently occurring words (which may not be informative).,"skip the top N most frequently occurring words (which may not be informative). These words will appear as oov_char value in the dataset. Defaults to 0, so no words are skipped."
tf.keras.datasets.imdb.load_data.yaml,maxlen,0.3905325443786982,sequences longer than this will be filtered out.,"int or None. Maximum sequence length. Any longer sequence will be truncated. Defaults to None, which means no truncation."
tf.keras.datasets.imdb.load_data.yaml,seed,0.6666666666666666,random seed for sample shuffling.,int. Seed for reproducible data shuffling.
tf.keras.datasets.imdb.load_data.yaml,oov_char,0.8373983739837398,words that were cut out because of the `num_words`or `skip_top` limit will be replaced with this character.,int. The out-of-vocabulary character. Words that were cut out because of the num_words or skip_top limits will be replaced with this character.
tf.keras.backend.random_normal.yaml,mean,0.8142857142857143,"A float, mean of the normal distribution to draw samples.","A float, the mean value of the normal distribution to draw samples. Default to 0.0."
tf.keras.backend.random_normal.yaml,stddev,0.8765432098765432,"A float, standard deviation of the normal distribution to draw samples.","A float, the standard deviation of the normal distribution to draw samples. Default to 1.0."
tf.keras.backend.random_normal.yaml,dtype,0.453125,"String, dtype of returned tensor.","tf.dtypes.DType, dtype of returned tensor. Default to use Keras backend dtype which is float32."
tf.keras.backend.random_normal.yaml,seed,0.44680851063829785,"Integer, random seed.","Integer, random seed. Will use a random numpy integer when not specified."
tf.strings.join.yaml,separator,0.47058823529411764,"An optional `string`. Defaults to `""""`. string, an optional join separator.",A string added between each string being joined.
tf.strings.join.yaml,inputs,0.3321554770318021,"A list of at least 1 `Tensor` objects with type `string`. A list of string tensors.  The tensors must all have the same shape, or be scalars.  Scalars may be mixed in; these will be broadcast to the shape of non-scalar inputs.",A list of tf.Tensor objects of same size and tf.string dtype.
tf.scan.yaml,back_prop,0.6163522012578616,(optional) True enables support for back propagation.,(optional) Deprecated. False disables support for back propagation. Prefer using tf.stop_gradient instead.
tf.keras.backend.rnn.yaml,step_function,0.8331388564760793,"RNN step function. Args;     input; Tensor with shape `(samples, ...)` (no time dimension),         representing input for the batch of samples at a certain         time step.     states; List of tensors. Returns;     output; Tensor with shape `(samples, output_dim)`        (no time dimension).     new_states; List of tensors, same length and shapes         as 'states'. The first state in the list must be the         output tensor at the previous timestep.","RNN step function. Args; input; Tensor with shape (samples, ...) (no time dimension), representing input for the batch of samples at a certain time step. states; List of tensors. Returns; output; Tensor with shape (samples, output_dim) (no time dimension). new_states; List of tensors, same length and shapes as 'states'. The first state in the list must be the output tensor at the previous timestep."
tf.function.yaml,experimental_implements,0.5025510204081632,"If provided, contains a name of a ""known"" function this implements. For example ""mycompany.my_recurrent_cell"". This is stored as an attribute in inference function, which can then be detected when processing serialized function. Seehttps://github.com/tensorflow/community/blob/master/rfcs/20190610-standardizing-composite_ops.mdfor details.  For an example of utilizing this attribute see:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/transforms/prepare_composite_functions_tf.ccThe code above automatically detects and substitutes function that implements ""embedded_matmul"" and allows TFLite to substitute its own implementations. For instance, a tensorflow user can use this attribute to mark that their function also implements`embedded_matmul``` (perhaps more efficiently!) by specifying it using this flag.","If provided, contains a name of a ""known"" function this implements. For example ""mycompany.my_recurrent_cell"". This is stored as an attribute in inference function, which can then be detected when processing serialized function. See standardizing composite ops for details. For an example of utilizing this attribute see this example The code above automatically detects and substitutes function that implements ""embedded_matmul"" and allows TFLite to substitute its own implementations. For instance, a tensorflow user can use this attribute to mark that their function also implements embedded_matmul (perhaps more efficiently!) by specifying it using this parameter: @tf.function(experimental_implements=""embedded_matmul"")"
tf.data.experimental.get_next_as_optional.yaml,iterator,0.3614457831325301,A `tf.compat.v1.data.Iterator` object.,An iterator for an instance of tf.data.Dataset.
tf.image.extract_patches.yaml,name,0.0,A name for the operation (optional).,
tf.image.extract_patches.yaml,images,0.12240437158469945,"A 4-D Tensor with shape `[batch, in_rows, in_cols, depth]","A 4-D Tensor with shape [batch, in_rows, in_cols, depth] </td> </tr><tr> <td>sizes</td> <td> The size of the extracted patches. Must be [1, size_rows, size_cols, 1]. </td> </tr><tr> <td>strides</td> <td> A 1-D Tensor of length 4. How far the centers of two consecutive patches are in the images. Must be:[1, stride_rows, stride_cols, 1]. </td> </tr><tr> <td>rates</td> <td> A 1-D Tensor of length 4. Must be:[1, rate_rows, rate_cols, 1]. This is the input stride, specifying how far two consecutive patch samples are in the input. Equivalent to extracting patches withpatch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1), followed by subsampling them spatially by a factor ofrates. This is equivalent toratein dilated (a.k.a. Atrous) convolutions. </td> </tr><tr> <td>padding</td> <td> The type of padding algorithm to use. </td> </tr><tr> <td>name`"
tf.image.extract_patches.yaml,sizes,0.0,"The size of the extracted patches. Must be [1, size_rows, size_cols, 1].",
tf.image.extract_patches.yaml,strides,0.0,"A 1-D Tensor of length 4. How far the centers of two consecutive patches are in the images. Must be: `[1, stride_rows, stride_cols, 1]`.",
tf.image.extract_patches.yaml,rates,0.0,"A 1-D Tensor of length 4. Must be: `[1, rate_rows, rate_cols, 1]`. This is the input stride, specifying how far two consecutive patch samples are in the input. Equivalent to extracting patches with `patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1)`, followed by subsampling them spatially by a factor of `rates`. This is equivalent to `rate` in dilated (a.k.a. Atrous) convolutions.",
tf.image.extract_patches.yaml,padding,0.0,The type of padding algorithm to use.,
tf.math.logical_and.yaml,x,0.8636363636363636,A `Tensor` of type `bool`.,A tf.Tensor type bool.
tf.math.logical_xor.yaml,name,0.0,,A name for the operation (optional).
tf.space_to_batch_nd.yaml,paddings,0.6527594401901241,"A `Tensor`. Must be one of the following types: `int32`, `int64`. 2-D with shape `[M, 2]`, all values must be >= 0.`paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension`i + 1`, which corresponds to spatial dimension `i`.  It is required that`block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.This operation is equivalent to the following steps: Zero-pad the start and end of dimensions `[1, ..., M]` of the input according to `paddings` to produce `padded` of shape `padded_shape`.Reshape `padded` to `reshaped_padded` of shape:[batch] + [padded_shape[1] / block_shape[0],  block_shape[0], ..., padded_shape[M] / block_shape[M-1], block_shape[M-1]] + remaining_shapePermute dimensions of `reshaped_padded` to produce`permuted_reshaped_padded` of shape:block_shape + [batch] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shapeReshape `permuted_reshaped_padded` to flatten `block_shape` into the batch dimension, producing an output tensor of shape:[batch * prod(block_shape)] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape Some examples:(1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and   `paddings = [[0, 0], [0, 0]]`:","A Tensor. Must be one of the following types: int32, int64. 2-D with shape [M, 2], all values must be >= 0. paddings[i] = [pad_start, pad_end] specifies the padding for input dimension i + 1, which corresponds to spatial dimension i. It is required that block_shape[i] divides input_shape[i + 1] + pad_start + pad_end. This operation is equivalent to the following steps: Zero-pad the start and end of dimensions [1, ..., M] of the input according to paddings to produce padded of shape padded_shape. Reshape padded to reshaped_padded of shape: [batch] + [padded_shape[1] / block_shape[0], block_shape[0], ..., padded_shape[M] / block_shape[M-1], block_shape[M-1]] + remaining_shape Permute dimensions of reshaped_padded to produce permuted_reshaped_padded of shape: block_shape + [batch] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape Reshape permuted_reshaped_padded to flatten block_shape into the batch dimension, producing an output tensor of shape: [batch * prod(block_shape)] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape Some examples: (1) For the following input of shape [1, 2, 2, 1], block_shape = [2, 2], and paddings = [[0, 0], [0, 0]]: x = [[[[1], [2]], [[3], [4]]]] The output tensor has shape [4, 1, 1, 1] and value: [[[[1]]], [[[2]]], [[[3]]], [[[4]]]] (2) For the following input of shape [1, 2, 2, 3], block_shape = [2, 2], and paddings = [[0, 0], [0, 0]]: x = [[[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]] The output tensor has shape [4, 1, 1, 3] and value: [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]] (3) For the following input of shape [1, 4, 4, 1], block_shape = [2, 2], and paddings = [[0, 0], [0, 0]]: x = [[[[1], [2], [3], [4]], [[5], [6], [7], [8]], [[9], [10], [11], [12]], [[13], [14], [15], [16]]]] The output tensor has shape [4, 2, 2, 1] and value: x = [[[[1], [3]], [[9], [11]]], [[[2], [4]], [[10], [12]]], [[[5], [7]], [[13], [15]]], [[[6], [8]], [[14], [16]]]] (4) For the following input of shape [2, 2, 4, 1], block_shape = [2, 2], and paddings = [[0, 0], [2, 0]]: x = [[[[1], [2], [3], [4]], [[5], [6], [7], [8]]], [[[9], [10], [11], [12]], [[13], [14], [15], [16]]]] The output tensor has shape [8, 1, 3, 1] and value: x = [[[[0], [1], [3]]], [[[0], [9], [11]]], [[[0], [2], [4]]], [[[0], [10], [12]]], [[[0], [5], [7]]], [[[0], [13], [15]]], [[[0], [6], [8]]], [[[0], [14], [16]]]] Among others, this operation is useful for reducing atrous convolution into regular convolution."
tf.zeros_like.yaml,input,0.46153846153846156,A `Tensor`.,A Tensor or array-like object.
tf.keras.preprocessing.image.array_to_img.yaml,data_format,0.11971830985915492,"Image data format. either ""channels_first"" or ""channels_last"".","Image data format, can be either ""channels_first"" or ""channels_last"". Defaults to None, in which case the global setting tf.keras.backend.image_data_format() is used (unless you changed it, it defaults to ""channels_last"")."
tf.keras.preprocessing.image.array_to_img.yaml,scale,0.8571428571428571,"Whether to rescale image values to be within `[0, 255]`.","Whether to rescale image values to be within [0, 255]. Defaults to True."
tf.keras.preprocessing.image.array_to_img.yaml,dtype,0.1625,Dtype to use.,"Dtype to use. Default to None, in which case the global setting tf.keras.backend.floatx() is used (unless you changed it, it defaults to ""float32"")"
tf.keras.losses.categorical_crossentropy.yaml,y_true,0.8518518518518519,tensor of true targets.,Tensor of one-hot true targets.
tf.keras.models.model_from_yaml.yaml,yaml_string,0.8686868686868687,YAML string encoding a model configuration.,YAML string or open file encoding a model configuration.
tf.keras.backend.set_epsilon.yaml,value,0.3333333333333333,float. New value of epsilon. Example: `python from keras import backend as K K.epsilon() >>> 1e-07 K.set_epsilon(1e-05) K.epsilon() >>> 1e-05`,float. New value of epsilon.
tf.nn.fractional_max_pool.yaml,pseudo_random,0.8146551724137931,"An optional `bool`.  Defaults to `False`. When set to `True`, generates the pooling sequence in a pseudorandom fashion, otherwise, in a random fashion. Check paper Benjamin Graham, Fractional Max-Pooling for difference between pseudorandom and random.","An optional bool. Defaults to False. When set to True, generates the pooling sequence in a pseudorandom fashion, otherwise, in a random fashion. Check paper (Graham, 2015) for difference between pseudorandom and random."
tf.where.yaml,x,0.8691099476439791,"A Tensor which is of the same type as `y`, and may be broadcastable with`condition` and `y`.","If provided, a Tensor which is of the same type as y, and has a shape broadcastable with condition and y."
tf.where.yaml,y,0.8586387434554974,"A Tensor which is of the same type as `x`, and may be broadcastable with`condition` and `x`.","If provided, a Tensor which is of the same type as y, and has a shape broadcastable with condition and x."
tf.keras.preprocessing.image.img_to_array.yaml,data_format,0.13380281690140844,"Image data format, either ""channels_first"" or ""channels_last"".","Image data format, can be either ""channels_first"" or ""channels_last"". Defaults to None, in which case the global setting tf.keras.backend.image_data_format() is used (unless you changed it, it defaults to ""channels_last"")."
tf.keras.preprocessing.image.img_to_array.yaml,dtype,0.30601092896174864,Dtype to use for the returned array.,"Dtype to use. Default to None, in which case the global setting tf.keras.backend.floatx() is used (unless you changed it, it defaults to ""float32"")"
tf.keras.preprocessing.image.img_to_array.yaml,img,0.8636363636363636,PIL Image instance.,Input PIL Image instance.
tf.keras.backend.set_floatx.yaml,value,0.41545893719806765,"String; 'float16', 'float32', or 'float64'. Example: `python from keras import backend as K K.floatx() >>> 'float32' K.set_floatx('float16') K.floatx() >>> 'float16'`","String; 'float16', 'float32', or 'float64'."
tf.math.rsqrt.yaml,x,0.8421052631578947,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.","A tf.Tensor. Must be one of the following types: bfloat16, half, float32, float64. int32"
tf.math.logical_not.yaml,x,0.6567164179104478,A `Tensor` of type `bool`.,A Tensor of type bool. A Tensor of type bool.
tf.map_fn.yaml,back_prop,0.6163522012578616,(optional) True enables support for back propagation.,(optional) Deprecated. False disables support for back propagation. Prefer using tf.stop_gradient instead.
tf.transpose.yaml,perm,0.7474747474747475,A permutation of the dimensions of `a`.,A permutation of the dimensions of a. This should be a vector.
tf.foldr.yaml,back_prop,0.6163522012578616,(optional) True enables support for back propagation.,(optional) Deprecated. False disables support for back propagation. Prefer using tf.stop_gradient instead.
tf.keras.losses.squared_hinge.yaml,y_true,0.8932038834951457,The ground truth values. `y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are provided we will convert them to -1 or 1.,"The ground truth values. y_true values are expected to be -1 or 1. If binary (0 or 1) labels are provided we will convert them to -1 or 1. shape = [batch_size, d0, .. dN]."
tf.keras.losses.squared_hinge.yaml,y_pred,0.56,The predicted values.,"The predicted values. shape = [batch_size, d0, .. dN]."
tf.keras.datasets.cifar100.load_data.yaml,label_mode,0.25806451612903225,"one of ""fine"", ""coarse"".","one of ""fine"", ""coarse"". If it is ""fine"" the category labels are the fine-grained labels, if it is ""coarse"" the output labels are the coarse-grained superclasses."
tf.nn.depthwise_conv2d_backprop_input.yaml,dilations,0.8821081830790569,"An optional list of `ints`. Defaults to `[1, 1, 1, 1]`. 1-D tensor of length 4.  The dilation factor for each dimension of`input`. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of`data_format`, see above for details. Dilations in the batch and depth dimensions must be 1.","An optional list of ints. Defaults to [1, 1, 1, 1]. 1-D tensor of length 4. The dilation factor for each dimension of input. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of data_format, see above for details. Dilations in the batch and depth dimensions must be 1."
tf.batch_to_space.yaml,name,0.0,A name for the operation (optional).,
tf.batch_to_space.yaml,crops,0.5902260386412426,"A `Tensor`. Must be one of the following types: `int32`, `int64`. 2-D with shape `[M, 2]`, all values must be >= 0. `crops[i] = [crop_start, crop_end]` specifies the amount to crop from input dimension `i + 1`, which corresponds to spatial dimension `i`.  It is required that`crop_start[i] + crop_end[i] <= block_shape[i] * input_shape[i + 1]`. This operation is equivalent to the following steps: Reshape `input` to `reshaped` of shape: [block_shape[0], ..., block_shape[M-1], batch / prod(block_shape), input_shape[1], ..., input_shape[N-1]]  Permute dimensions of `reshaped` to produce `permuted` of shape  [batch / prod(block_shape),  input_shape[1], block_shape[0], ...,  input_shape[M], block_shape[M-1], input_shape[M+1], ..., input_shape[N-1]]  Reshape `permuted` to produce `reshaped_permuted` of shape  [batch / prod(block_shape), input_shape[1] * block_shape[0], ...,  input_shape[M] * block_shape[M-1], input_shape[M+1], ...,  input_shape[N-1]]  Crop the start and end of dimensions `[1, ..., M]` of `reshaped_permuted` according to `crops` to produce the output  of shape:  [batch / prod(block_shape),  input_shape[1] * block_shape[0] - crops[0,0] - crops[0,1], ..., input_shape[M] * block_shape[M-1] - crops[M-1,0] - crops[M-1,1],  input_shape[M+1], ..., input_shape[N-1]] Some examples:  (1) For the following input of shape `[4, 1, 1, 1]`,`block_shape = [2, 2]`, and `crops = [[0, 0], [0, 0]]`:  `[[[[1]]], [[[2]]], [[[3]]], [[[4]]]]`The output tensor has shape `[1, 2, 2, 1]` and value:  `x = [[[[1], [2]], [[3], [4]]]]`  (2) For the following input of shape `[4, 1, 1, 3]`,`block_shape = [2, 2]`, and `crops = [[0, 0], [0, 0]]`:  `[[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]`The output tensor has shape `[1, 2, 2, 3]` and value:  `x = [[[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]]`  (3) For the following input of shape `[4, 2, 2, 1]`,`block_shape = [2, 2]`, and `crops = [[0, 0], [0, 0]]`:  `x = [[[[1], [3]], [[9], [11]]], [[[2], [4]], [[10], [12]]], [[[5], [7]], [[13], [15]]], [[[6], [8]], [[14], [16]]]]`The output tensor has shape `[1, 4, 4, 1]` and value:  `x = [[[1], [2], [3],  [4]], [[5],   [6],  [7],  [8]], [[9],  [10], [11],  [12]], [[13], [14], [15],  [16]]]`  (4) For the following input of shape `[8, 1, 3, 1]`,`block_shape = [2, 2]`, and `crops = [[0, 0], [2, 0]]`:  `x = [[[[0], [1], [3]]], [[[0], [9], [11]]], [[[0], [2], [4]]], [[[0], [10], [12]]], [[[0], [5], [7]]], [[[0], [13], [15]]], [[[0], [6], [8]]], [[[0], [14], [16]]]]`The output tensor has shape `[2, 2, 4, 1]` and value:  `x = [[[[1], [2],  [3],  [4]], [[5],   [6],  [7],  [8]]], [[[9],  [10], [11],  [12]], [[13], [14], [15],  [16]]]]` ","A 2-D Tensor with shape [M, 2]. Must be one of the following types: int32, int64. All values must be >= 0. crops[i] = [crop_start, crop_end] specifies the amount to crop from input dimension i + 1, which corresponds to spatial dimension i. It is required that crop_start[i] + crop_end[i] <= block_shape[i] * input_shape[i + 1]. This operation is equivalent to the following steps: Reshape input to reshaped of shape: [block_shape[0], ..., block_shape[M-1], batch / prod(block_shape), input_shape[1], ..., input_shape[N-1]] Permute dimensions of reshaped to produce permuted of shape [batch / prod(block_shape), input_shape[1], block_shape[0], ..., input_shape[M], block_shape[M-1], input_shape[M+1], ..., input_shape[N-1]] Reshape permuted to produce reshaped_permuted of shape [batch / prod(block_shape), input_shape[1] * block_shape[0], ..., input_shape[M] * block_shape[M-1], input_shape[M+1], ..., input_shape[N-1]] Crop the start and end of dimensions [1, ..., M] of reshaped_permuted according to crops to produce the output of shape: [batch / prod(block_shape), input_shape[1] * block_shape[0] - crops[0,0] - crops[0,1], ..., input_shape[M] * block_shape[M-1] - crops[M-1,0] - crops[M-1,1], input_shape[M+1], ..., input_shape[N-1]] Some Examples: (1) For the following input of shape [4, 1, 1, 1], block_shape = [2, 2], and crops = [[0, 0], [0, 0]]: [[[[1]]], [[[2]]], [[[3]]], [[[4]]]] The output tensor has shape [1, 2, 2, 1] and value: [[3], [4]]]] ``` (2) For the following input of shape `[4, 1, 1, 3]`, `block_shape = [2, 2]`, and `crops = [[0, 0], [0, 0]]`: ```python [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]] The output tensor has shape [1, 2, 2, 3] and value: x = [[[[1, 2, 3], [4, 5, 6 ]], [[7, 8, 9], [10, 11, 12]]]] (3) For the following input of shape [4, 2, 2, 1], block_shape = [2, 2], and crops = [[0, 0], [0, 0]]: x = [[[[1], [3]], [[ 9], [11]]], [[[2], [4]], [[10], [12]]], [[[5], [7]], [[13], [15]]], [[[6], [8]], [[14], [16]]]] The output tensor has shape [1, 4, 4, 1] and value: x = [[[1], [2], [ 3], [ 4]], [[5], [6], [ 7], [ 8]], [[9], [10], [11], [12]], [[13], [14], [15], [16]]] (4) For the following input of shape [8, 1, 3, 1], block_shape = [2, 2], and crops = [[0, 0], [2, 0]]: x = [[[[0], [ 1], [ 3]]], [[[0], [ 9], [11]]], [[[0], [ 2], [ 4]]], [[[0], [10], [12]]], [[[0], [ 5], [ 7]]], [[[0], [13], [15]]], [[[0], [ 6], [ 8]]], [[[0], [14], [16]]]] The output tensor has shape [2, 2, 4, 1] and value: x = [[[[ 1], [ 2], [ 3], [ 4]], [[ 5], [ 6], [ 7], [ 8]]], [[[ 9], [10], [11], [12]], [[13], [14], [15], [16]]]] ``` </td> </tr><tr> <td> `name` </td> <td> A name for the operation (optional). </td> </tr> </table> <!-- Tabular view -->  <table class=""responsive fixed orange""> <colgroup><col width=""214px""><col></colgroup> <tr><th colspan=""2""><h2 class=""add-link"">Returns</h2></th></tr> <tr class=""alt""> <td colspan=""2""> A `Tensor`. Has the same type as `input`. </td> </tr> </table>  Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.  Last updated 2020-10-01 UTC.  Stay connected  Blog  GitHub  Twitter  YouTube  Support  Issue tracker  Release notes  Stack Overflow  Brand guidelines  Cite TensorFlow  Terms  Privacy  Sign up for the TensorFlow monthly newsletter  Subscribe  Language  English  中文 – 简体  [{""gaid"": ""UA-69864048-1"", ""dimensions"": {""dimension4"": ""TensorFlow Core v2.2.0"", ""dimension3"": false, ""dimension12"": false, ""dimension1"": ""Signed out"", ""dimension5"": ""en"", ""dimension6"": ""en"", ""dimension8"": null}, ""metrics"": {""ratings_value"": ""metric1"", ""ratings_count"": ""metric2""}}] {""parameters"": {""freeTrialEligibleUser"": ""False"", ""internalUser"": ""False"", ""language"": {""machineTranslated"": ""False"", ""requested"": ""en"", ""served"": ""en""}, ""pageType"": ""reference"", ""projectName"": ""TensorFlow Core v2.2.0"", ""scriptsafe"": null, ""signedIn"": ""False"", ""tenant"": ""tensorflow""}}  (function(d,e,v,s,i,t,E){d['GoogleDevelopersObject']=i;  t=e.createElement(v);t.async=1;t.src=s;E=e.getElementsByTagName(v)[0];  E.parentNode.insertBefore(t,E);})(window, document, 'script',  'https://www.gstatic.com/devrel-devsite/prod/vf7e3a995d426e05d42b78fc7d21a14329a91016dc065dc22c480cc8f443ef33e/tensorflow/js/app_loader.js', '[15,""en"",null,""/js/devsite_app_module.js"",""https://www.gstatic.com/devrel-devsite/prod/vf7e3a995d426e05d42b78fc7d21a14329a91016dc065dc22c480cc8f443ef33e"",""https://www.gstatic.com/devrel-devsite/prod/vf7e3a995d426e05d42b78fc7d21a14329a91016dc065dc22c480cc8f443ef33e/tensorflow"",""https://tensorflow-dot-devsite-v2-prod-3p.appspot.com"",null,null,[""/_pwa/tensorflow/manifest.json"",""/_static/images/video-placeholder.svg"",""https://www.gstatic.com/devrel-devsite/prod/vf7e3a995d426e05d42b78fc7d21a14329a91016dc065dc22c480cc8f443ef33e/tensorflow/images/favicon.png"",""https://www.gstatic.com/devrel-devsite/prod/vf7e3a995d426e05d42b78fc7d21a14329a91016dc065dc22c480cc8f443ef33e/tensorflow/images/lockup.svg"",""https://fonts.googleapis.com/css?family=Google+Sans:400,500|Roboto:400,400italic,500,500italic,700,700italic|Roboto+Mono:400,500,700|Material+Icons""],1,null,[1,6,8,12,14,17,21,25,40,50,63,70,75,76,80,87,88,91,92,93,97,98,100,101,102,103,105,107,111,115]]')"
tf.keras.preprocessing.sequence.pad_sequences.yaml,maxlen,0.4228571428571429,"Int, maximum length of all sequences.","Optional Int, maximum length of all sequences. If not provided, sequences will be padded to the length of the longest individual sequence."
tf.keras.preprocessing.sequence.pad_sequences.yaml,dtype,0.8458149779735683,"Type of the output sequences.     To pad sequences with variable length strings, you can use `object`.","(Optional, defaults to int32). Type of the output sequences. To pad sequences with variable length strings, you can use object."
tf.keras.preprocessing.sequence.pad_sequences.yaml,padding,0.7951807228915663,"String, 'pre' or 'post':     pad either before or after each sequence.","String, 'pre' or 'post' (optional, defaults to 'pre'): pad either before or after each sequence."
tf.keras.preprocessing.sequence.pad_sequences.yaml,truncating,0.8716216216216216,"String, 'pre' or 'post':     remove values from sequences larger than     `maxlen`, either at the beginning or at the end of the sequences.","String, 'pre' or 'post' (optional, defaults to 'pre'): remove values from sequences larger than maxlen, either at the beginning or at the end of the sequences."
tf.keras.preprocessing.sequence.pad_sequences.yaml,value,0.6966292134831461,"Float or String, padding value.`","Float or String, padding value. (Optional, defaults to 0.)"
tf.keras.preprocessing.sequence.pad_sequences.yaml,sequences,0.3269230769230769,"List of lists, where each element is a sequence.",List of sequences (each sequence is a list of integers).
tf.space_to_batch.yaml,paddings,0.6527594401901241,"A `Tensor`. Must be one of the following types: `int32`, `int64`. 2-D with shape `[M, 2]`, all values must be >= 0.`paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension`i + 1`, which corresponds to spatial dimension `i`.  It is required that`block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.This operation is equivalent to the following steps: Zero-pad the start and end of dimensions `[1, ..., M]` of the input according to `paddings` to produce `padded` of shape `padded_shape`.Reshape `padded` to `reshaped_padded` of shape:[batch] + [padded_shape[1] / block_shape[0],  block_shape[0], ..., padded_shape[M] / block_shape[M-1], block_shape[M-1]] + remaining_shapePermute dimensions of `reshaped_padded` to produce`permuted_reshaped_padded` of shape:block_shape + [batch] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shapeReshape `permuted_reshaped_padded` to flatten `block_shape` into the batch dimension, producing an output tensor of shape:[batch * prod(block_shape)] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape Some examples:(1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and   `paddings = [[0, 0], [0, 0]]`:","A Tensor. Must be one of the following types: int32, int64. 2-D with shape [M, 2], all values must be >= 0. paddings[i] = [pad_start, pad_end] specifies the padding for input dimension i + 1, which corresponds to spatial dimension i. It is required that block_shape[i] divides input_shape[i + 1] + pad_start + pad_end. This operation is equivalent to the following steps: Zero-pad the start and end of dimensions [1, ..., M] of the input according to paddings to produce padded of shape padded_shape. Reshape padded to reshaped_padded of shape: [batch] + [padded_shape[1] / block_shape[0], block_shape[0], ..., padded_shape[M] / block_shape[M-1], block_shape[M-1]] + remaining_shape Permute dimensions of reshaped_padded to produce permuted_reshaped_padded of shape: block_shape + [batch] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape Reshape permuted_reshaped_padded to flatten block_shape into the batch dimension, producing an output tensor of shape: [batch * prod(block_shape)] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape Some examples: (1) For the following input of shape [1, 2, 2, 1], block_shape = [2, 2], and paddings = [[0, 0], [0, 0]]: x = [[[[1], [2]], [[3], [4]]]] The output tensor has shape [4, 1, 1, 1] and value: [[[[1]]], [[[2]]], [[[3]]], [[[4]]]] (2) For the following input of shape [1, 2, 2, 3], block_shape = [2, 2], and paddings = [[0, 0], [0, 0]]: x = [[[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]] The output tensor has shape [4, 1, 1, 3] and value: [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]] (3) For the following input of shape [1, 4, 4, 1], block_shape = [2, 2], and paddings = [[0, 0], [0, 0]]: x = [[[[1], [2], [3], [4]], [[5], [6], [7], [8]], [[9], [10], [11], [12]], [[13], [14], [15], [16]]]] The output tensor has shape [4, 2, 2, 1] and value: x = [[[[1], [3]], [[9], [11]]], [[[2], [4]], [[10], [12]]], [[[5], [7]], [[13], [15]]], [[[6], [8]], [[14], [16]]]] (4) For the following input of shape [2, 2, 4, 1], block_shape = [2, 2], and paddings = [[0, 0], [2, 0]]: x = [[[[1], [2], [3], [4]], [[5], [6], [7], [8]]], [[[9], [10], [11], [12]], [[13], [14], [15], [16]]]] The output tensor has shape [8, 1, 3, 1] and value: x = [[[[0], [1], [3]]], [[[0], [9], [11]]], [[[0], [2], [4]]], [[[0], [10], [12]]], [[[0], [5], [7]]], [[[0], [13], [15]]], [[[0], [6], [8]]], [[[0], [14], [16]]]] Among others, this operation is useful for reducing atrous convolution into regular convolution."
tf.linalg.matmul.yaml,a_is_sparse,0.2827586206896552,"If `True`, `a` is treated as a sparse matrix.","If True, a is treated as a sparse matrix. Notice, this does not support tf.sparse.SparseTensor, it just makes optimizations that assume most values in a are zero. See tf.sparse.sparse_dense_matmul for some support for tf.SparseTensor multiplication."
tf.linalg.matmul.yaml,b_is_sparse,0.2827586206896552,"If `True`, `b` is treated as a sparse matrix.","If True, b is treated as a sparse matrix. Notice, this does not support tf.sparse.SparseTensor, it just makes optimizations that assume most values in a are zero. See tf.sparse.sparse_dense_matmul for some support for tf.SparseTensor multiplication."
tf.math.add_n.yaml,inputs,0.6556016597510373,"A list of `tf.Tensor` or `tf.IndexedSlices` objects, each with same shape and type.","A list of tf.Tensor or tf.IndexedSlices objects, each with the same shape and type. tf.IndexedSlices objects will be converted into dense tensors prior to adding."
tf.nn.depthwise_conv2d_backprop_filter.yaml,dilations,0.8821081830790569,"An optional list of `ints`. Defaults to `[1, 1, 1, 1]`. 1-D tensor of length 4.  The dilation factor for each dimension of`input`. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of`data_format`, see above for details. Dilations in the batch and depth dimensions must be 1.","An optional list of ints. Defaults to [1, 1, 1, 1]. 1-D tensor of length 4. The dilation factor for each dimension of input. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension. The dimension order is determined by the value of data_format, see above for details. Dilations in the batch and depth dimensions must be 1."
tf.keras.models.load_model.yaml,filepath,0.8868778280542986,"One of the following: String, path to the saved model`h5py.File` object from which to load the model ","One of the following: String or pathlib.Path object, path to the saved model h5py.File object from which to load the model"
tf.numpy_function.yaml,Tout,0.46210720887245843,"A list or tuple of tensorflow data types or a single tensorflow data type if there is only one, indicating what `func` returns. stateful (bool): If True, the function should be considered stateful. If a function is stateless, when given the same input it will return the same output and have no observable side effects. Optimizations such as common subexpression elimination are only performed on stateless operations.","A list or tuple of tensorflow data types or a single tensorflow data type if there is only one, indicating what func returns."
tf.keras.models.save_model.yaml,filepath,0.8868778280542986,"One of the following: String, path where to save the model`h5py.File` object where to save the model ","One of the following: String or pathlib.Path object, path where to save the model h5py.File object where to save the model"
tf.fill.yaml,name,0.20930232558139536,A name for the operation (optional).,Optional string. The name of the output tf.Tensor.
tf.fill.yaml,dims,0.5064377682403434,"A `Tensor`. Must be one of the following types: `int32`, `int64`. 1-D. Represents the shape of the output tensor.","A 1-D sequence of non-negative numbers. Represents the shape of the output tf.Tensor. Entries should be of type: int32, int64."
tf.fill.yaml,value,0.45,A `Tensor`. 0-D (scalar). Value to fill the returned tensor. @compatibility(numpy) Equivalent to np.full @end_compatibility,A value to fill the returned tf.Tensor.
tf.nn.fractional_avg_pool.yaml,pseudo_random,0.8146551724137931,"An optional `bool`.  Defaults to `False`. When set to `True`, generates the pooling sequence in a pseudorandom fashion, otherwise, in a random fashion. Check paper Benjamin Graham, Fractional Max-Pooling for difference between pseudorandom and random.","An optional bool. Defaults to False. When set to True, generates the pooling sequence in a pseudorandom fashion, otherwise, in a random fashion. Check paper (Graham, 2015) for difference between pseudorandom and random."
tf.keras.backend.std.yaml,axis,0.5527638190954773,"An integer, the axis to compute the standard deviation.","An integer, the axis to compute the standard deviation. If None (the default), reduces all dimensions. Must be in the range [-rank(x), rank(x))."
tf.keras.backend.std.yaml,x,0.34146341463414637,A tensor or variable.,A tensor or variable. It should have numerical dtypes. Boolean type inputs will be converted to float.
