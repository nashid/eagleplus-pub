- - torch.linspace.yaml
  - steps
  - torch.linspace
- - torch.nn.functional.adaptive_avg_pool1d.yaml
  - output_size
  - torch.nn.functional.adaptive_avg_pool1d
- - torch.nn.tripletmarginloss.yaml
  - reduction
  - torch.nn.TripletMarginLoss
- - torch.clamp.yaml
  - input
  - torch.clamp
- - torch.addcdiv.yaml
  - input
  - torch.addcdiv
- - torch.logical_and.yaml
  - out
  - torch.logical_and
- - torch.jit.save.yaml
  - _extra_files
  - torch.jit.save
- - torch.sum2.yaml
  - dim
  - torch.sum
- - torch.numel.yaml
  - input
  - torch.numel
- - torch.is_tensor.yaml
  - obj
  - torch.is_tensor
- - torch.nn.utils.spectral_norm.yaml
  - name
  - torch.nn.utils.spectral_norm
- - torch.lobpcg.yaml
  - method
  - torch.lobpcg
- - torch.round.yaml
  - out
  - torch.round
- - torch.nn.ctcloss.yaml
  - zero_infinity
  - torch.nn.CTCLoss
- - torch.nn.utils.prune.random_unstructured.yaml
  - amount
  - torch.nn.utils.prune.random_unstructured
- - torch.rand.yaml
  - layout
  - torch.rand
- - torch.nn.functional.nll_loss.yaml
  - ignore_index
  - torch.nn.functional.nll_loss
- - torch.addr.yaml
  - beta
  - torch.addr
- - torch.nn.functional.avg_pool1d.yaml
  - input
  - torch.nn.functional.avg_pool1d
- - torch.multinomial.yaml
  - generator
  - torch.multinomial
- - torch.distributed.send.yaml
  - dst
  - torch.distributed.send
- - torch.nn.rrelu.yaml
  - inplace
  - torch.nn.RReLU
- - torch.masked_select.yaml
  - input
  - torch.masked_select
- - torch.nn.instancenorm1d.yaml
  - momentum
  - torch.nn.InstanceNorm1d
- - torch.cuda.set_rng_state.yaml
  - new_state
  - torch.cuda.set_rng_state
- - torch.symeig.yaml
  - out
  - torch.symeig
- - torch.floor_divide.yaml
  - other
  - torch.floor_divide
- - torch.addmm.yaml
  - mat1
  - torch.addmm
- - torch.eye.yaml
  - requires_grad
  - torch.eye
- - torch.nn.functional.conv_transpose2d.yaml
  - input
  - torch.nn.functional.conv_transpose2d
- - torch.nn.maxunpool2d.yaml
  - padding
  - torch.nn.MaxUnpool2d
- - torch.autograd.functional.jacobian.yaml
  - strict
  - torch.autograd.functional.jacobian
- - torch.triu.yaml
  - diagonal
  - torch.triu
- - torch.nn.multilabelmarginloss.yaml
  - reduce
  - torch.nn.MultiLabelMarginLoss
- - torch.sigmoid.yaml
  - input
  - torch.sigmoid
- - torch.nn.convtranspose2d.yaml
  - groups
  - torch.nn.ConvTranspose2d
- - torch.triu_indices.yaml
  - row
  - torch.triu_indices
- - torch.distributed.get_world_size.yaml
  - group
  - torch.distributed.get_world_size
- - torch.nn.crossentropyloss.yaml
  - reduction
  - torch.nn.CrossEntropyLoss
- - torch.nn.utils.prune.remove.yaml
  - name
  - torch.nn.utils.prune.remove
- - torch.pca_lowrank.yaml
  - niter
  - torch.pca_lowrank
- - torch.nn.kldivloss.yaml
  - reduction
  - torch.nn.KLDivLoss
- - torch.empty_like.yaml
  - device
  - torch.empty_like
- - torch.distributions.kl.kl_divergence.yaml
  - p
  - torch.distributions.kl.kl_divergence
- - torch.nn.bceloss.yaml
  - reduce
  - torch.nn.BCELoss
- - torch.utils.cpp_extension.load.yaml
  - extra_cflags
  - torch.utils.cpp_extension.load
- - torch.narrow.yaml
  - start
  - torch.narrow
- - torch.nn.batchnorm3d.yaml
  - momentum
  - torch.nn.BatchNorm3d
- - torch.logical_and.yaml
  - input
  - torch.logical_and
- - torch.nn.maxunpool1d.yaml
  - stride
  - torch.nn.MaxUnpool1d
- - torch.hub.download_url_to_file.yaml
  - url
  - torch.hub.download_url_to_file
- - torch.distributed.all_gather.yaml
  - async_op
  - torch.distributed.all_gather
- - torch.nn.adaptivelogsoftmaxwithloss.yaml
  - div_value
  - torch.nn.AdaptiveLogSoftmaxWithLoss
- - torch.mode.yaml
  - out
  - torch.mode
- - torch.mm.yaml
  - input
  - torch.mm
- - torch.ne.yaml
  - other
  - torch.ne
- - torch.nn.constantpad3d.yaml
  - padding
  - torch.nn.ConstantPad3d
- - torch.lu.yaml
  - get_infos
  - torch.lu
- - torch.nn.functional.embedding.yaml
  - padding_idx
  - torch.nn.functional.embedding
- - torch.gt.yaml
  - out
  - torch.gt
- - torch.nn.utils.rnn.pack_padded_sequence.yaml
  - batch_first
  - torch.nn.utils.rnn.pack_padded_sequence
- - torch.nn.conv1d.yaml
  - kernel_size
  - torch.nn.Conv1d
- - torch.cuda.manual_seed.yaml
  - seed
  - torch.cuda.manual_seed
- - torch.nn.tripletmarginloss.yaml
  - reduce
  - torch.nn.TripletMarginLoss
- - torch.nn.lstm.yaml
  - input_size
  - torch.nn.LSTM
- - torch.rand_like.yaml
  - dtype
  - torch.rand_like
- - torch.hub.load_state_dict_from_url.yaml
  - progress
  - torch.hub.load_state_dict_from_url
- - torch.as_strided.yaml
  - storage_offset
  - torch.as_strided
- - torch.nn.avgpool1d.yaml
  - kernel_size
  - torch.nn.AvgPool1d
- - torch.nn.batchnorm3d.yaml
  - affine
  - torch.nn.BatchNorm3d
- - torch.utils.cpp_extension.load.yaml
  - sources
  - torch.utils.cpp_extension.load
- - torch.hamming_window.yaml
  - periodic
  - torch.hamming_window
- - torch.histc.yaml
  - min
  - torch.histc
- - torch.abs.yaml
  - input
  - torch.abs
- - torch.nn.utils.weight_norm.yaml
  - name
  - torch.nn.utils.weight_norm
- - torch.autograd.functional.vjp.yaml
  - create_graph
  - torch.autograd.functional.vjp
- - torch.ones.yaml
  - device
  - torch.ones
- - torch.remainder.yaml
  - input
  - torch.remainder
- - torch.square.yaml
  - input
  - torch.square
- - torch.sum2.yaml
  - keepdim
  - torch.sum
- - torch.nn.maxpool2d.yaml
  - return_indices
  - torch.nn.MaxPool2d
- - torch.logsumexp.yaml
  - out
  - torch.logsumexp
- - torch.einsum.yaml
  - '*operands'
  - torch.einsum
- - torch.norm.yaml
  - input
  - torch.norm
- - torch.addcdiv.yaml
  - value
  - torch.addcdiv
- - torch.normal222.yaml
  - size
  - torch.normal
- - torch.tensordot.yaml
  - a
  - torch.tensordot
- - torch.quantization.propagate_qconfig_.yaml
  - qconfig_dict
  - torch.quantization.propagate_qconfig_
- - torch.nn.utils.prune.global_unstructured.yaml
  - pruning_method
  - torch.nn.utils.prune.global_unstructured
- - torch.nn.init.uniform_.yaml
  - a
  - torch.nn.init.uniform_
- - torch.neg.yaml
  - input
  - torch.neg
- - torch.div.yaml
  - input
  - torch.div
- - torch.ifft.yaml
  - input
  - torch.ifft
- - torch.nn.functional.conv_transpose2d.yaml
  - dilation
  - torch.nn.functional.conv_transpose2d
- - torch.argsort.yaml
  - descending
  - torch.argsort
- - torch.nn.maxpool2d.yaml
  - stride
  - torch.nn.MaxPool2d
- - torch.sparse_coo_tensor.yaml
  - requires_grad
  - torch.sparse_coo_tensor
- - torch.log1p.yaml
  - out
  - torch.log1p
- - torch.autograd.functional.vhp.yaml
  - strict
  - torch.autograd.functional.vhp
- - torch.nn.functional.conv_transpose1d.yaml
  - weight
  - torch.nn.functional.conv_transpose1d
- - torch.tensordot.yaml
  - b
  - torch.tensordot
- - torch.rand_like.yaml
  - input
  - torch.rand_like
- - torch.kthvalue.yaml
  - keepdim
  - torch.kthvalue
- - torch.can_cast.yaml
  - to
  - torch.can_cast
- - torch.repeat_interleave.yaml
  - input
  - torch.repeat_interleave
- - torch.nn.functional.interpolate.yaml
  - align_corners
  - torch.nn.functional.interpolate
- - torch.min2.yaml
  - keepdim
  - torch.min
- - torch.nn.functional.adaptive_max_pool3d.yaml
  - return_indices
  - torch.nn.functional.adaptive_max_pool3d
- - torch.nn.nllloss.yaml
  - reduction
  - torch.nn.NLLLoss
- - torch.utils.cpp_extension.load.yaml
  - is_python_module
  - torch.utils.cpp_extension.load
- - torch.distributed.broadcast.yaml
  - src
  - torch.distributed.broadcast
- - torch.linspace.yaml
  - layout
  - torch.linspace
- - torch.unsqueeze.yaml
  - dim
  - torch.unsqueeze
- - torch.clamp.yaml
  - out
  - torch.clamp
- - torch.nn.quantized.functional.conv3d.yaml
  - scale
  - torch.nn.quantized.functional.conv3d
- - torch.nn.localresponsenorm.yaml
  - alpha
  - torch.nn.LocalResponseNorm
- - torch.nn.functional.avg_pool1d.yaml
  - ceil_mode
  - torch.nn.functional.avg_pool1d
- - torch.nn.rnn.yaml
  - input_size
  - torch.nn.RNN
- - torch.nn.functional.dropout3d.yaml
  - inplace
  - torch.nn.functional.dropout3d
- - torch.nn.functional.poisson_nll_loss.yaml
  - full
  - torch.nn.functional.poisson_nll_loss
- - torch.empty_like.yaml
  - layout
  - torch.empty_like
- - torch.narrow.yaml
  - input
  - torch.narrow
- - torch.nn.functional.kl_div.yaml
  - target
  - torch.nn.functional.kl_div
- - torch.autograd.functional.hessian.yaml
  - strict
  - torch.autograd.functional.hessian
- - torch.utils.dlpack.from_dlpack.yaml
  - dlpack
  - torch.utils.dlpack.from_dlpack
- - torch.nn.functional.gumbel_softmax.yaml
  - dim
  - torch.nn.functional.gumbel_softmax
- - torch.quantize_per_channel.yaml
  - axis
  - torch.quantize_per_channel
- - torch.eye.yaml
  - dtype
  - torch.eye
- - torch.eq.yaml
  - other
  - torch.eq
- - torch.nn.functional.embedding.yaml
  - norm_type
  - torch.nn.functional.embedding
- - torch.nn.batchnorm1d.yaml
  - affine
  - torch.nn.BatchNorm1d
- - torch.logical_not.yaml
  - out
  - torch.logical_not
- - torch.nn.softshrink.yaml
  - lambd
  - torch.nn.Softshrink
- - torch.chunk.yaml
  - chunks
  - torch.chunk
- - torch.cuda.stream.yaml
  - stream
  - torch.cuda.stream
- - torch.nn.unfold.yaml
  - stride
  - torch.nn.Unfold
- - torch.nn.functional.binary_cross_entropy_with_logits.yaml
  - weight
  - torch.nn.functional.binary_cross_entropy_with_logits
- - torch.nn.functional.binary_cross_entropy_with_logits.yaml
  - pos_weight
  - torch.nn.functional.binary_cross_entropy_with_logits
- - torch.utils.checkpoint.checkpoint_sequential.yaml
  - functions
  - torch.utils.checkpoint.checkpoint_sequential
- - torch.nn.init.ones_.yaml
  - tensor
  - torch.nn.init.ones_
- - torch.quantization.swap_module.yaml
  - mapping
  - torch.quantization.swap_module
- - torch.nonzero.yaml
  - input
  - torch.nonzero
- - torch.logical_and.yaml
  - other
  - torch.logical_and
- - torch.cdist.yaml
  - x1
  - torch.cdist
- - torch.distributed.reduce.yaml
  - group
  - torch.distributed.reduce
- - torch.sin.yaml
  - out
  - torch.sin
- - torch.nn.cosinesimilarity.yaml
  - dim
  - torch.nn.CosineSimilarity
- - torch.le.yaml
  - input
  - torch.le
- - torch.rfft.yaml
  - signal_ndim
  - torch.rfft
- - torch.nn.functional.avg_pool1d.yaml
  - padding
  - torch.nn.functional.avg_pool1d
- - torch.autograd.functional.hvp.yaml
  - strict
  - torch.autograd.functional.hvp
- - torch.distributed.all_gather.yaml
  - tensor
  - torch.distributed.all_gather
- - torch.autograd.gradgradcheck.yaml
  - grad_outputs
  - torch.autograd.gradgradcheck
- - torch.cat.yaml
  - tensors
  - torch.cat
- - torch.autograd.gradcheck.yaml
  - rtol
  - torch.autograd.gradcheck
- - torch.logspace.yaml
  - start
  - torch.logspace
- - torch.nn.l1loss.yaml
  - size_average
  - torch.nn.L1Loss
- - torch.nn.transformer.yaml
  - activation
  - torch.nn.Transformer
- - torch.nn.utils.clip_grad_norm_.yaml
  - max_norm
  - torch.nn.utils.clip_grad_norm_
- - torch.jit.save.yaml
  - m
  - torch.jit.save
- - torch.logical_or.yaml
  - out
  - torch.logical_or
- - torch.addcmul.yaml
  - input
  - torch.addcmul
- - torch.sparse.addmm.yaml
  - mat
  - torch.sparse.addmm
- - torch.bartlett_window.yaml
  - dtype
  - torch.bartlett_window
- - torch.pinverse.yaml
  - input
  - torch.pinverse
- - torch.nn.convtranspose3d.yaml
  - bias
  - torch.nn.ConvTranspose3d
- - torch.log.yaml
  - out
  - torch.log
- - torch.nn.quantized.functional.conv2d.yaml
  - bias
  - torch.nn.quantized.functional.conv2d
- - torch.onnx.export.yaml
  - verbose
  - torch.onnx.export
- - torch.nn.instancenorm3d.yaml
  - eps
  - torch.nn.InstanceNorm3d
- - torch.autograd.grad.yaml
  - outputs
  - torch.autograd.grad
- - torch.nn.celu.yaml
  - inplace
  - torch.nn.CELU
- - torch.sparse_coo_tensor.yaml
  - values
  - torch.sparse_coo_tensor
- - torch.nn.functional.affine_grid.yaml
  - theta
  - torch.nn.functional.affine_grid
- - torch.autograd.functional.hessian.yaml
  - create_graph
  - torch.autograd.functional.hessian
- - torch.nn.quantized.functional.avg_pool2d.yaml
  - stride
  - torch.nn.quantized.functional.avg_pool2d
- - torch.autograd.gradcheck.yaml
  - inputs
  - torch.autograd.gradcheck
- - torch.nn.functional.avg_pool3d.yaml
  - ceil_mode
  - torch.nn.functional.avg_pool3d
- - torch.where.yaml
  - x
  - torch.where
- - torch.unique.yaml
  - return_inverse
  - torch.unique
- - torch.index_select.yaml
  - index
  - torch.index_select
- - torch.autograd.functional.hessian.yaml
  - inputs
  - torch.autograd.functional.hessian
- - torch.hub.load.yaml
  - '**kwargs'
  - torch.hub.load
- - torch.std.yaml
  - unbiased
  - torch.std
- - torch.nn.localresponsenorm.yaml
  - beta
  - torch.nn.LocalResponseNorm
- - torch.renorm.yaml
  - dim
  - torch.renorm
- - torch.distributed.barrier.yaml
  - group
  - torch.distributed.barrier
- - torch.hamming_window.yaml
  - device
  - torch.hamming_window
- - torch.autograd.grad.yaml
  - inputs
  - torch.autograd.grad
- - torch.quantization.quantize_qat.yaml
  - run_args
  - torch.quantization.quantize_qat
- - torch.nn.init.zeros_.yaml
  - tensor
  - torch.nn.init.zeros_
- - torch.nn.upsamplingbilinear2d.yaml
  - size
  - torch.nn.UpsamplingBilinear2d
- - torch.jit.load.yaml
  - _extra_files
  - torch.jit.load
- - torch.nn.rnncell.yaml
  - bias
  - torch.nn.RNNCell
- - torch.addmv.yaml
  - out
  - torch.addmv
- - torch.bernoulli.yaml
  - out
  - torch.bernoulli
- - torch.cuda.comm.gather.yaml
  - destination
  - torch.cuda.comm.gather
- - torch.add.yaml
  - input
  - torch.add
- - torch.atan2.yaml
  - out
  - torch.atan2
- - torch.normal2.yaml
  - out
  - torch.normal
- - torch.distributed.get_rank.yaml
  - group
  - torch.distributed.get_rank
- - torch.var2.yaml
  - dim
  - torch.var
- - torch.nn.utils.prune.random_unstructured.yaml
  - module
  - torch.nn.utils.prune.random_unstructured
- - torch.hann_window.yaml
  - periodic
  - torch.hann_window
- - torch.lu.yaml
  - out
  - torch.lu
- - torch.nn.transformerencoderlayer.yaml
  - dropout
  - torch.nn.TransformerEncoderLayer
- - torch.nn.functional.binary_cross_entropy_with_logits.yaml
  - target
  - torch.nn.functional.binary_cross_entropy_with_logits
- - torch.quantization.quantize_qat.yaml
  - run_fn
  - torch.quantization.quantize_qat
- - torch.nn.transformerdecoderlayer.yaml
  - nhead
  - torch.nn.TransformerDecoderLayer
- - torch.min2.yaml
  - out
  - torch.min
- - torch.nn.multilabelmarginloss.yaml
  - size_average
  - torch.nn.MultiLabelMarginLoss
- - torch.nn.utils.prune.custom_from_mask.yaml
  - mask
  - torch.nn.utils.prune.custom_from_mask
- - torch.bitwise_not.yaml
  - input
  - torch.bitwise_not
- - torch.eye.yaml
  - out
  - torch.eye
- - torch.svd.yaml
  - out
  - torch.svd
- - torch.lu_unpack.yaml
  - LU_pivots
  - torch.lu_unpack
- - torch.sparse.mm.yaml
  - mat1
  - torch.sparse.mm
- - torch.where.yaml
  - y
  - torch.where
- - torch.tensordot.yaml
  - dims
  - torch.tensordot
- - torch.cuda.set_rng_state.yaml
  - device
  - torch.cuda.set_rng_state
- - torch.digamma.yaml
  - input
  - torch.digamma
- - torch.nn.fold.yaml
  - dilation
  - torch.nn.Fold
- - torch.nn.functional.pad.yaml
  - value
  - torch.nn.functional.pad
- - torch.kthvalue.yaml
  - dim
  - torch.kthvalue
- - torch.ge.yaml
  - input
  - torch.ge
- - torch.bincount.yaml
  - weights
  - torch.bincount
- - torch.nn.transformerdecoder.yaml
  - num_layers
  - torch.nn.TransformerDecoder
- - torch.nn.poissonnllloss.yaml
  - eps
  - torch.nn.PoissonNLLLoss
- - torch.nn.transformerencoderlayer.yaml
  - d_model
  - torch.nn.TransformerEncoderLayer
- - torch.nn.maxunpool2d.yaml
  - stride
  - torch.nn.MaxUnpool2d
- - torch.nn.adaptivelogsoftmaxwithloss.yaml
  - in_features
  - torch.nn.AdaptiveLogSoftmaxWithLoss
- - torch.logspace.yaml
  - steps
  - torch.logspace
- - torch.nn.functional.avg_pool2d.yaml
  - count_include_pad
  - torch.nn.functional.avg_pool2d
- - torch.mm.yaml
  - out
  - torch.mm
- - torch.nn.relu.yaml
  - inplace
  - torch.nn.ReLU
- - torch.reshape.yaml
  - input
  - torch.reshape
- - torch.nn.convtranspose1d.yaml
  - out_channels
  - torch.nn.ConvTranspose1d
- - torch.distributed.send.yaml
  - tag
  - torch.distributed.send
- - torch.nn.init.constant_.yaml
  - val
  - torch.nn.init.constant_
- - torch.nn.functional.avg_pool1d.yaml
  - stride
  - torch.nn.functional.avg_pool1d
- - torch.sparse_coo_tensor.yaml
  - device
  - torch.sparse_coo_tensor
- - torch.allclose.yaml
  - equal_nan
  - torch.allclose
- - torch.std_mean.yaml
  - input
  - torch.std_mean
- - torch.lt.yaml
  - other
  - torch.lt
- - torch.randperm.yaml
  - device
  - torch.randperm
- - torch.clamp.yaml
  - max
  - torch.clamp
- - torch.zeros.yaml
  - '*size'
  - torch.zeros
- - torch.nn.quantized.functional.avg_pool2d.yaml
  - kernel_size
  - torch.nn.quantized.functional.avg_pool2d
- - torch.nn.quantized.functional.conv2d.yaml
  - dilation
  - torch.nn.quantized.functional.conv2d
- - torch.distributed.broadcast_multigpu.yaml
  - group
  - torch.distributed.broadcast_multigpu
- - torch.nn.bilinear.yaml
  - in2_features
  - torch.nn.Bilinear
- - torch.atan2.yaml
  - other
  - torch.atan2
- - torch.ones.yaml
  - out
  - torch.ones
- - torch.remainder.yaml
  - out
  - torch.remainder
- - torch.unique.yaml
  - input
  - torch.unique
- - torch.matrix_rank.yaml
  - input
  - torch.matrix_rank
- - torch.nn.functional.conv_transpose3d.yaml
  - output_padding
  - torch.nn.functional.conv_transpose3d
- - torch.lobpcg.yaml
  - n
  - torch.lobpcg
- - torch.nn.softmax.yaml
  - dim
  - torch.nn.Softmax
- - torch.var.yaml
  - unbiased
  - torch.var
- - torch.distributed.recv.yaml
  - tensor
  - torch.distributed.recv
- - torch.nn.convtranspose2d.yaml
  - output_padding
  - torch.nn.ConvTranspose2d
- - torch.nn.functional.ctc_loss.yaml
  - target_lengths
  - torch.nn.functional.ctc_loss
- - torch.nn.convtranspose2d.yaml
  - out_channels
  - torch.nn.ConvTranspose2d
- - torch.cumprod.yaml
  - dtype
  - torch.cumprod
- - torch.cuda.memory_stats.yaml
  - device
  - torch.cuda.memory_stats
- - torch.std2.yaml
  - dim
  - torch.std
- - torch.renorm.yaml
  - p
  - torch.renorm
- - torch.rot90.yaml
  - dims
  - torch.rot90
- - torch.nn.lppool1d.yaml
  - kernel_size
  - torch.nn.LPPool1d
- - torch.nn.conv2d.yaml
  - padding_mode
  - torch.nn.Conv2d
- - torch.ormqr.yaml
  - input3
  - torch.ormqr
- - torch.nn.functional.cosine_similarity.yaml
  - x1
  - torch.nn.functional.cosine_similarity
- - torch.addmm.yaml
  - alpha
  - torch.addmm
- - torch.max2.yaml
  - out
  - torch.max
- - torch.nn.syncbatchnorm.yaml
  - track_running_stats
  - torch.nn.SyncBatchNorm
- - torch.cuda.comm.broadcast_coalesced.yaml
  - tensors
  - torch.cuda.comm.broadcast_coalesced
- - torch.autograd.grad.yaml
  - retain_graph
  - torch.autograd.grad
- - torch.nn.functional.log_softmax.yaml
  - input
  - torch.nn.functional.log_softmax
- - torch.nn.maxpool3d.yaml
  - return_indices
  - torch.nn.MaxPool3d
- - torch.utils.checkpoint.checkpoint.yaml
  - '*args'
  - torch.utils.checkpoint.checkpoint
- - torch.empty_like.yaml
  - dtype
  - torch.empty_like
- - torch.logical_or.yaml
  - other
  - torch.logical_or
- - torch.nn.replicationpad3d.yaml
  - padding
  - torch.nn.ReplicationPad3d
- - torch.nn.relu6.yaml
  - inplace
  - torch.nn.ReLU6
- - torch.nn.quantized.functional.conv3d.yaml
  - input
  - torch.nn.quantized.functional.conv3d
- - torch.mean2.yaml
  - input
  - torch.mean
- - torch.nn.linear.yaml
  - in_features
  - torch.nn.Linear
- - torch.dist.yaml
  - input
  - torch.dist
- - torch.nn.functional.affine_grid.yaml
  - size
  - torch.nn.functional.affine_grid
- - torch.nn.init.eye_.yaml
  - tensor
  - torch.nn.init.eye_
- - torch.nn.utils.rnn.pad_sequence.yaml
  - padding_value
  - torch.nn.utils.rnn.pad_sequence
- - torch.nn.maxpool2d.yaml
  - kernel_size
  - torch.nn.MaxPool2d
- - torch.rand.yaml
  - '*size'
  - torch.rand
- - torch.nn.quantized.functional.avg_pool2d.yaml
  - ceil_mode
  - torch.nn.quantized.functional.avg_pool2d
- - torch.gather.yaml
  - input
  - torch.gather
- - torch.remainder.yaml
  - other
  - torch.remainder
- - torch.normal2.yaml
  - std
  - torch.normal2
- - torch.nn.init.orthogonal_.yaml
  - gain
  - torch.nn.init.orthogonal_
- - torch.chain_matmul.yaml
  - '*matrices'
  - torch.chain_matmul
- - torch.distributed.send.yaml
  - group
  - torch.distributed.send
- - torch.nn.layernorm.yaml
  - eps
  - torch.nn.LayerNorm
- - torch.nn.dataparallel.yaml
  - output_device
  - torch.nn.DataParallel
- - torch.div2.yaml
  - out
  - torch.div
- - torch.autograd.functional.hvp.yaml
  - func
  - torch.autograd.functional.hvp
- - torch.arange.yaml
  - start
  - torch.arange
- - torch.unique.yaml
  - sorted
  - torch.unique
- - torch.nn.utils.spectral_norm.yaml
  - dim
  - torch.nn.utils.spectral_norm
- - torch.std_mean2.yaml
  - unbiased
  - torch.std_mean
- - torch.cummax.yaml
  - out
  - torch.cummax
- - torch.nn.rrelu.yaml
  - lower
  - torch.nn.RReLU
- - torch.solve.yaml
  - A
  - torch.solve
- - torch.nn.reflectionpad2d.yaml
  - padding
  - torch.nn.ReflectionPad2d
- - torch.distributed.gather.yaml
  - dst
  - torch.distributed.gather
- - torch.jit.load.yaml
  - map_location
  - torch.jit.load
- - torch.var_mean2.yaml
  - keepdim
  - torch.var_mean
- - torch.distributed.broadcast_multigpu.yaml
  - src
  - torch.distributed.broadcast_multigpu
- - torch.nn.adaptivemaxpool1d.yaml
  - output_size
  - torch.nn.AdaptiveMaxPool1d
- - torch.nn.batchnorm2d.yaml
  - track_running_stats
  - torch.nn.BatchNorm2d
- - torch.nn.convtranspose3d.yaml
  - groups
  - torch.nn.ConvTranspose3d
- - torch.nn.smoothl1loss.yaml
  - reduction
  - torch.nn.SmoothL1Loss
- - torch.nn.functional.avg_pool2d.yaml
  - input
  - torch.nn.functional.avg_pool2d
- - torch.addmm.yaml
  - out
  - torch.addmm
- - torch.nn.functional.conv_transpose1d.yaml
  - padding
  - torch.nn.functional.conv_transpose1d
- - torch.ne.yaml
  - input
  - torch.ne
- - torch.var2.yaml
  - out
  - torch.var
- - torch.nn.quantized.functional.conv3d.yaml
  - bias
  - torch.nn.quantized.functional.conv3d
- - torch.nn.fold.yaml
  - kernel_size
  - torch.nn.Fold
- - torch.histc.yaml
  - out
  - torch.histc
- - torch.nn.upsample.yaml
  - scale_factor
  - torch.nn.Upsample
- - torch.distributed.all_reduce.yaml
  - tensor
  - torch.distributed.all_reduce
- - torch.nn.utils.remove_spectral_norm.yaml
  - name
  - torch.nn.utils.remove_spectral_norm
- - torch.is_complex.yaml
  - input
  - torch.is_complex
- - torch.sinh.yaml
  - input
  - torch.sinh
- - torch.load.yaml
  - map_location
  - torch.load
- - torch.addmv.yaml
  - vec
  - torch.addmv
- - torch.onnx.export.yaml
  - f
  - torch.onnx.export
- - torch.normal.yaml
  - std
  - torch.normal
- - torch.nn.gru.yaml
  - bias
  - torch.nn.GRU
- - torch.distributed.new_group.yaml
  - ranks
  - torch.distributed.new_group
- - torch.eig.yaml
  - out
  - torch.eig
- - torch.jit.save.yaml
  - f
  - torch.jit.save
- - torch.clamp.yaml
  - min
  - torch.clamp
- - torch.nn.functional.poisson_nll_loss.yaml
  - eps
  - torch.nn.functional.poisson_nll_loss
- - torch.linspace.yaml
  - dtype
  - torch.linspace
- - torch.autograd.grad.yaml
  - allow_unused
  - torch.autograd.grad
- - torch.distributed.send.yaml
  - tensor
  - torch.distributed.send
- - torch.empty_strided.yaml
  - device
  - torch.empty_strided
- - torch.nn.maxpool1d.yaml
  - kernel_size
  - torch.nn.MaxPool1d
- - torch.norm.yaml
  - dim
  - torch.norm
- - torch.hub.load.yaml
  - '*args'
  - torch.hub.load
- - torch.addbmm.yaml
  - beta
  - torch.addbmm
- - torch.nn.utils.prune.random_structured.yaml
  - amount
  - torch.nn.utils.prune.random_structured
- - torch.nn.upsample.yaml
  - size
  - torch.nn.Upsample
- - torch.mode.yaml
  - input
  - torch.mode
- - torch.nn.transformerdecoderlayer.yaml
  - dropout
  - torch.nn.TransformerDecoderLayer
- - torch.sparse.addmm.yaml
  - mat1
  - torch.sparse.addmm
- - torch.nn.functional.dropout.yaml
  - inplace
  - torch.nn.functional.dropout
- - torch.ifft.yaml
  - normalized
  - torch.ifft
- - torch.jit.trace.yaml
  - check_trace
  - torch.jit.trace
- - torch.ger.yaml
  - vec2
  - torch.ger
- - torch.svd.yaml
  - some
  - torch.svd
- - torch.distributed.all_gather.yaml
  - group
  - torch.distributed.all_gather
- - torch.std2.yaml
  - unbiased
  - torch.std2
- - torch.nn.poissonnllloss.yaml
  - size_average
  - torch.nn.PoissonNLLLoss
- - torch.nn.maxpool3d.yaml
  - ceil_mode
  - torch.nn.MaxPool3d
- - torch.ones.yaml
  - dtype
  - torch.ones
- - torch.triu_indices.yaml
  - dtype
  - torch.triu_indices
- - torch.multinomial.yaml
  - out
  - torch.multinomial
- - torch.nn.functional.embedding.yaml
  - sparse
  - torch.nn.functional.embedding
- - torch.nn.syncbatchnorm.yaml
  - process_group
  - torch.nn.SyncBatchNorm
- - torch.nn.fold.yaml
  - padding
  - torch.nn.Fold
- - torch.nn.multilabelsoftmarginloss.yaml
  - reduction
  - torch.nn.MultiLabelSoftMarginLoss
- - torch.sparse.sum.yaml
  - dtype
  - torch.sparse.sum
- - torch.nn.replicationpad1d.yaml
  - padding
  - torch.nn.ReplicationPad1d
- - torch.load.yaml
  - '**pickle_load_args'
  - torch.load
- - torch.nn.transformer.yaml
  - num_decoder_layers
  - torch.nn.Transformer
- - torch.utils.checkpoint.checkpoint.yaml
  - preserve_rng_state
  - torch.utils.checkpoint.checkpoint
- - torch.nn.utils.rnn.pack_sequence.yaml
  - enforce_sorted
  - torch.nn.utils.rnn.pack_sequence
- - torch.randperm.yaml
  - out
  - torch.randperm
- - torch.neg.yaml
  - out
  - torch.neg
- - torch.rot90.yaml
  - input
  - torch.rot90
- - torch.nn.embedding.yaml
  - norm_type
  - torch.nn.Embedding
- - torch.matmul.yaml
  - out
  - torch.matmul
- - torch.nn.utils.rnn.pack_padded_sequence.yaml
  - enforce_sorted
  - torch.nn.utils.rnn.pack_padded_sequence
- - torch.combinations.yaml
  - with_replacement
  - torch.combinations
- - torch.nn.functional.binary_cross_entropy_with_logits.yaml
  - reduction
  - torch.nn.functional.binary_cross_entropy_with_logits
- - torch.nn.maxpool1d.yaml
  - ceil_mode
  - torch.nn.MaxPool1d
- - torch.nn.transformerdecoder.yaml
  - norm
  - torch.nn.TransformerDecoder
- - torch.nn.embeddingbag.yaml
  - norm_type
  - torch.nn.EmbeddingBag
- - torch.roll.yaml
  - shifts
  - torch.roll
- - torch.autograd.functional.vjp.yaml
  - func
  - torch.autograd.functional.vjp
- - torch.matrix_rank.yaml
  - symmetric
  - torch.matrix_rank
- - torch.gather.yaml
  - index
  - torch.gather
- - torch.round.yaml
  - input
  - torch.round
- - torch.poisson.yaml
  - generator
  - torch.poisson
- - torch.log1p.yaml
  - input
  - torch.log1p
- - torch.nn.rnn.yaml
  - hidden_size
  - torch.nn.RNN
- - torch.nn.functional.nll_loss.yaml
  - input
  - torch.nn.functional.nll_loss
- - torch.renorm.yaml
  - input
  - torch.renorm
- - torch.autograd.functional.vjp.yaml
  - strict
  - torch.autograd.functional.vjp
- - torch.can_cast.yaml
  - from
  - torch.can_cast
- - torch.cartesian_prod.yaml
  - '*tensors'
  - torch.cartesian_prod
- - torch.utils.data.random_split.yaml
  - dataset
  - torch.utils.data.random_split
- - torch.nn.bcewithlogitsloss.yaml
  - pos_weight
  - torch.nn.BCEWithLogitsLoss
- - torch.nn.nllloss.yaml
  - size_average
  - torch.nn.NLLLoss
- - torch.gt.yaml
  - input
  - torch.gt
- - torch.acos.yaml
  - input
  - torch.acos
- - torch.baddbmm.yaml
  - beta
  - torch.baddbmm
- - torch.trapz.yaml
  - dim
  - torch.trapz
- - torch.nn.convtranspose3d.yaml
  - padding
  - torch.nn.ConvTranspose3d
- - torch.nn.parallel.data_parallel.yaml
  - device_ids
  - torch.nn.parallel.data_parallel
- - torch.quantization.quantize.yaml
  - mapping
  - torch.quantization.quantize
- - torch.onnx.export.yaml
  - output_names
  - torch.onnx.export
- - torch.distributed.isend.yaml
  - tensor
  - torch.distributed.isend
- - torch.nn.grucell.yaml
  - hidden_size
  - torch.nn.GRUCell
- - torch.var2.yaml
  - keepdim
  - torch.var
- - torch.nn.functional.normalize.yaml
  - out
  - torch.nn.functional.normalize
- - torch.nn.upsamplingnearest2d.yaml
  - size
  - torch.nn.UpsamplingNearest2d
- - torch.utils.cpp_extension.check_compiler_abi_compatibility.yaml
  - compiler
  - torch.utils.cpp_extension.check_compiler_abi_compatibility
- - torch.nn.utils.prune.ln_structured.yaml
  - name
  - torch.nn.utils.prune.ln_structured
- - torch.nn.functional.cross_entropy.yaml
  - target
  - torch.nn.functional.cross_entropy
- - torch.mv.yaml
  - out
  - torch.mv
- - torch.nn.embedding.yaml
  - sparse
  - torch.nn.Embedding
- - torch.nn.mseloss.yaml
  - reduction
  - torch.nn.MSELoss
- - torch.nn.maxpool1d.yaml
  - dilation
  - torch.nn.MaxPool1d
- - torch.nn.quantized.functional.conv2d.yaml
  - input
  - torch.nn.quantized.functional.conv2d
- - torch.log10.yaml
  - input
  - torch.log10
- - torch.rfft.yaml
  - input
  - torch.rfft
- - torch.nn.gru.yaml
  - dropout
  - torch.nn.GRU
- - torch.arange.yaml
  - end
  - torch.arange
- - torch.cummin.yaml
  - input
  - torch.cummin
- - torch.nn.quantized.functional.conv3d.yaml
  - stride
  - torch.nn.quantized.functional.conv3d
- - torch.nn.functional.avg_pool2d.yaml
  - divisor_override
  - torch.nn.functional.avg_pool2d
- - torch.nn.functional.conv_transpose2d.yaml
  - output_padding
  - torch.nn.functional.conv_transpose2d
- - torch.diag.yaml
  - out
  - torch.diag
- - torch.quantization.fuse_modules.yaml
  - fuser_func
  - torch.quantization.fuse_modules
- - torch.quantization.convert.yaml
  - mapping
  - torch.quantization.convert
- - torch.nn.hardtanh.yaml
  - inplace
  - torch.nn.Hardtanh
- - torch.onnx.export.yaml
  - aten
  - torch.onnx.export
- - torch.nn.functional.conv1d.yaml
  - stride
  - torch.nn.functional.conv1d
- - torch.quantization.quantize.yaml
  - inplace
  - torch.quantization.quantize
- - torch.fmod.yaml
  - input
  - torch.fmod
- - torch.transpose.yaml
  - dim1
  - torch.transpose
- - torch.nn.maxpool3d.yaml
  - stride
  - torch.nn.MaxPool3d
- - torch.randperm.yaml
  - dtype
  - torch.randperm
- - torch.nn.maxunpool3d.yaml
  - padding
  - torch.nn.MaxUnpool3d
- - torch.prod2.yaml
  - keepdim
  - torch.prod
- - torch.quantization.convert.yaml
  - inplace
  - torch.quantization.convert
- - torch.addr.yaml
  - vec1
  - torch.addr
- - torch.nn.functional.avg_pool3d.yaml
  - divisor_override
  - torch.nn.functional.avg_pool3d
- - torch.poisson.yaml
  - input*
  - torch.poisson
- - torch.matrix_power.yaml
  - n
  - torch.matrix_power
- - torch.nn.softmarginloss.yaml
  - reduce
  - torch.nn.SoftMarginLoss
- - torch.nn.conv3d.yaml
  - stride
  - torch.nn.Conv3d
- - torch.ormqr.yaml
  - input2
  - torch.ormqr
- - torch.randn_like.yaml
  - input
  - torch.randn_like
- - torch.nn.hingeembeddingloss.yaml
  - size_average
  - torch.nn.HingeEmbeddingLoss
- - torch.pow.yaml
  - out
  - torch.pow
- - torch.median.yaml
  - input
  - torch.median
- - torch.random.fork_rng2.yaml
  - devices
  - torch.random.fork_rng
- - torch.nn.avgpool2d.yaml
  - ceil_mode
  - torch.nn.AvgPool2d
- - torch.stft.yaml
  - n_fft
  - torch.stft
- - torch.nn.quantized.functional.interpolate.yaml
  - align_corners
  - torch.nn.quantized.functional.interpolate
- - torch.nn.parallel.data_parallel.yaml
  - module
  - torch.nn.parallel.data_parallel
- - torch.nn.upsample.yaml
  - mode
  - torch.nn.Upsample
- - torch.set_printoptions.yaml
  - sci_mode
  - torch.set_printoptions
- - torch.norm.yaml
  - keepdim
  - torch.norm
- - torch.diagflat.yaml
  - input
  - torch.diagflat
- - torch.distributed.recv.yaml
  - src
  - torch.distributed.recv
- - torch.nn.mseloss.yaml
  - reduce
  - torch.nn.MSELoss
- - torch.nn.softmarginloss.yaml
  - size_average
  - torch.nn.SoftMarginLoss
- - torch.cummax.yaml
  - input
  - torch.cummax
- - torch.nn.multimarginloss.yaml
  - weight
  - torch.nn.MultiMarginLoss
- - torch.nn.fractionalmaxpool2d.yaml
  - kernel_size
  - torch.nn.FractionalMaxPool2d
- - torch.imag.yaml
  - input
  - torch.imag
- - torch.load.yaml
  - f
  - torch.load
- - torch.bmm.yaml
  - input
  - torch.bmm
- - torch.hub.load_state_dict_from_url.yaml
  - url
  - torch.hub.load_state_dict_from_url
- - torch.reciprocal.yaml
  - out
  - torch.reciprocal
- - torch.nn.functional.nll_loss.yaml
  - reduce
  - torch.nn.functional.nll_loss
- - torch.nn.avgpool3d.yaml
  - count_include_pad
  - torch.nn.AvgPool3d
- - torch.pinverse.yaml
  - rcond
  - torch.pinverse
- - torch.lobpcg.yaml
  - niter
  - torch.lobpcg
- - torch.nn.quantized.functional.conv3d.yaml
  - groups
  - torch.nn.quantized.functional.conv3d
- - torch.distributed.scatter.yaml
  - tensor
  - torch.distributed.scatter
- - torch.nn.adaptivemaxpool2d.yaml
  - return_indices
  - torch.nn.AdaptiveMaxPool2d
- - torch.nn.upsample.yaml
  - align_corners
  - torch.nn.Upsample
- - torch.topk.yaml
  - dim
  - torch.topk
- - torch.zeros_like.yaml
  - dtype
  - torch.zeros_like
- - torch.nn.batchnorm2d.yaml
  - num_features
  - torch.nn.BatchNorm2d
- - torch.eye.yaml
  - m
  - torch.eye
- - torch.nn.init.dirac_.yaml
  - groups
  - torch.nn.init.dirac_
- - torch.utils.data.random_split.yaml
  - lengths
  - torch.utils.data.random_split
- - torch.quantization.quantize.yaml
  - run_args
  - torch.quantization.quantize
- - torch.hub.list.yaml
  - force_reload
  - torch.hub.list
- - torch.nn.functional.avg_pool3d.yaml
  - input
  - torch.nn.functional.avg_pool3d
- - torch.nn.functional.conv_transpose2d.yaml
  - weight
  - torch.nn.functional.conv_transpose2d
- - torch.set_default_tensor_type.yaml
  - t
  - torch.set_default_tensor_type
- - torch.nn.functional.grid_sample.yaml
  - input
  - torch.nn.functional.grid_sample
- - torch.autograd.functional.vhp.yaml
  - create_graph
  - torch.autograd.functional.vhp
- - torch.empty_like.yaml
  - input
  - torch.empty_like
- - torch.cuda.comm.reduce_add.yaml
  - inputs
  - torch.cuda.comm.reduce_add
- - torch.conj.yaml
  - out
  - torch.conj
- - torch.erf.yaml
  - out
  - torch.erf
- - torch.chunk.yaml
  - dim
  - torch.chunk
- - torch.sum2.yaml
  - input
  - torch.sum
- - torch.set_rng_state.yaml
  - new_state
  - torch.set_rng_state
- - torch.nn.upsamplingnearest2d.yaml
  - scale_factor
  - torch.nn.UpsamplingNearest2d
- - torch.full.yaml
  - layout
  - torch.full
- - torch.cumsum.yaml
  - dim
  - torch.cumsum
- - torch.cat.yaml
  - dim
  - torch.cat
- - torch.nn.maxunpool3d.yaml
  - stride
  - torch.nn.MaxUnpool3d
- - torch.multinomial.yaml
  - replacement
  - torch.multinomial
- - torch.nn.conv1d.yaml
  - dilation
  - torch.nn.Conv1d
- - torch.repeat_interleave.yaml
  - dim
  - torch.repeat_interleave
- - torch.svd.yaml
  - compute_uv
  - torch.svd
- - torch.utils.cpp_extension.load_inline.yaml
  - functions
  - torch.utils.cpp_extension.load_inline
- - torch.nn.functional.kl_div.yaml
  - reduction
  - torch.nn.functional.kl_div
- - torch.nn.functional.avg_pool2d.yaml
  - stride
  - torch.nn.functional.avg_pool2d
- - torch.nn.instancenorm1d.yaml
  - eps
  - torch.nn.InstanceNorm1d
- - torch.nn.pairwisedistance.yaml
  - keepdim
  - torch.nn.PairwiseDistance
- - torch.div.yaml
  - other
  - torch.div
- - torch.set_grad_enabled.yaml
  - mode
  - torch.set_grad_enabled
- - torch.nn.gru.yaml
  - hidden_size
  - torch.nn.GRU
- - torch.ones_like.yaml
  - requires_grad
  - torch.ones_like
- - torch.argmax2.yaml
  - dim
  - torch.argmax
- - torch.cholesky_solve.yaml
  - input2
  - torch.cholesky_solve
- - torch.mv.yaml
  - input
  - torch.mv
- - torch.nn.functional.softmax.yaml
  - dtype
  - torch.nn.functional.softmax
- - torch.acos.yaml
  - out
  - torch.acos
- - torch.orgqr.yaml
  - input2
  - torch.orgqr
- - torch.nn.adaptivemaxpool3d.yaml
  - return_indices
  - torch.nn.AdaptiveMaxPool3d
