constraints:
  input:
    descp: Tensor of arbitrary shape
  log_target:
    default: 'False'
    descp: 'A flag indicating whether `target` is passed in the log space. It is recommended
      to pass certain distributions (like `softmax`) in the log space to avoid numerical
      issues caused by explicit `log`. Default: `False`'
    doc_dtype:
    - bool
  reduce:
    default: None
    descp: 'Deprecated (see `reduction`). By default, the losses are averaged or summed
      over observations for each minibatch depending on `size_average`. When `reduce`
      is `False`, returns a loss per batch element instead and ignores `size_average`.
      Default: `True`'
    doc_dtype:
    - bool
  reduction:
    default: mean
    descp: 'Specifies the reduction to apply to the output: `''none''` | `''batchmean''`
      | `''sum''` | `''mean''`. `''none''`: no reduction will be applied `''batchmean''`:
      the sum of the output will be divided by the batchsize `''sum''`: the output
      will be summed `''mean''`: the output will be divided by the number of elements
      in the output Default: `''mean''`'
    doc_dtype:
    - string
  size_average:
    default: None
    descp: 'Deprecated (see `reduction`). By default, the losses are averaged over
      each loss element in the batch. Note that for some losses, there multiple elements
      per sample. If the field `size_average` is set to `False`, the losses are instead
      summed for each minibatch. Ignored when reduce is `False`. Default: `True`'
    doc_dtype:
    - bool
  target:
    descp: Tensor of the same shape as input
inputs:
  optional:
  - size_average
  - reduce
  - reduction
  - log_target
  required:
  - input
  - target
link: https://pytorch.org/docs/1.6.0/nn.functional.html#torch.nn.functional.kl_div
package: torch
target: kl_div
title: torch.nn.functional.kl_div
version: 1.6.0
