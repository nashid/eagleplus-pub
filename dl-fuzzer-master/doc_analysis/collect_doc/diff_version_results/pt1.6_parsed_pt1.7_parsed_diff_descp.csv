API,Param,ratio,pt1.6_parsed,pt1.7_parsed
torch.lt.yaml,out,0.5573770491803278,the output tensor that must be a BoolTensor,the output tensor.
torch.linspace.yaml,steps,0.3010752688172043,number of points to sample between `start` and `end`. Default: `100`.,size of the constructed tensor
torch.random.manual_seed.yaml,seed,0.1328125,The desired seed.,"The desired seed. Value must be within the inclusive range [-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff]. Otherwise, a RuntimeError is raised. Negative inputs are remapped to positive values with the formula 0xffff_ffff_ffff_ffff + seed."
torch.nn.functional.grid_sample.yaml,mode,0.46842105263157896,interpolation mode to calculate output values `'bilinear'` | `'nearest'`. Default: `'bilinear'`,"interpolation mode to calculate output values `'bilinear'` | `'nearest'`. Default: `'bilinear'` Note: When `mode='bilinear'` and the input is 5-D, the interpolation mode used internally will actually be trilinear. However, when the input is 4-D, the interpolation mode will legitimately be bilinear."
torch.stft.yaml,onesided,0.7136150234741784,controls whether to return half of results to avoid redundancy Default: `True`,"controls whether to return half of results to avoid redundancy for real inputs. Default: `True` for real `input` and `window`, `False` otherwise."
torch.ge.yaml,out,0.5573770491803278,the output tensor that must be a BoolTensor,the output tensor.
torch.distributed.new_group.yaml,ranks,0.543859649122807,List of ranks of group members.,"List of ranks of group members. If `None`, will be set to all ranks. Default is `None`."
torch.floor_divide.yaml,input,0.375,the numerator tensor,the dividend
torch.floor_divide.yaml,other,0.6153846153846154,the denominator,the divisor
torch.cuda.comm.scatter.yaml,dim,0.8333333333333334,A dimension along which to chunk the tensor.,A dimension along which to chunk `tensor`. Default: `0`.
torch.cuda.comm.scatter.yaml,devices,0.5954198473282443,"iterable of ints, specifying among which devices the tensor should be scattered.","an iterable of GPU devices, among which to scatter."
torch.cuda.comm.scatter.yaml,tensor,0.6206896551724138,tensor to scatter.,tensor to scatter. Can be on CPU or GPU.
torch.cuda.comm.scatter.yaml,streams,0.0,,"an iterable of Streams, among which to execute the scatter. If not specified, the default stream will be utilized."
torch.gt.yaml,out,0.5573770491803278,the output tensor that must be a BoolTensor,the output tensor.
torch.where.yaml,x,0.7368421052631579,values selected at indices where `condition` is `True`,value (if :attr:x is a scalar) or values selected at indiceswhere `condition` is `True`
torch.where.yaml,y,0.7407407407407407,values selected at indices where `condition` is `False`,value (if :attr:x is a scalar) or values selected at indiceswhere `condition` is `False`
torch.istft.yaml,onesided,0.676923076923077,Whether the STFT is onesided. (Default: `True`),Whether the STFT was onesided. (Default: `True` if `n_fft != fft_size` in the input size)
torch.istft.yaml,input,0.7540983606557377,"The input tensor. Expected to be output of `stft()`, either 3D (`fft_size`, `n_frame`, 2) or 4D (`channel`, `fft_size`, `n_frame`, 2).","The input tensor. Expected to be output of `stft()`, can either be complex (`channel`, `fft_size`, `n_frame`), or real (`channel`, `fft_size`, `n_frame`, 2) where the `channel` dimension is optional."
torch.manual_seed.yaml,seed,0.1328125,The desired seed.,"The desired seed. Value must be within the inclusive range [-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff]. Otherwise, a RuntimeError is raised. Negative inputs are remapped to positive values with the formula 0xffff_ffff_ffff_ffff + seed."
torch.cuda.comm.broadcast.yaml,devices,0.4304932735426009,"an iterable of devices among which to broadcast. Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.","an iterable of GPU devices, among which to broadcast."
torch.cuda.comm.broadcast.yaml,tensor,0.6451612903225806,tensor to broadcast.,tensor to broadcast. Can be on CPU or GPU.
torch.cuda.comm.gather.yaml,tensors,0.4838709677419355,iterable of tensors to gather.,an iterable of tensors to gather. Tensor sizes in all dimensions other than `dim` have to match.
torch.cuda.comm.gather.yaml,destination,0.704,"output device (-1 means CPU, default: current device)",the output device. Can be CPU or CUDA. Default: the current CUDA device.
torch.le.yaml,out,0.5573770491803278,the output tensor that must be a BoolTensor,the output tensor.
torch.digamma.yaml,out,0.0,,the output tensor.
torch.cuda.comm.broadcast_coalesced.yaml,tensors,0.47191011235955055,tensors to broadcast.,"tensors to broadcast. Must be on the same device, either CPU or GPU."
torch.cuda.comm.broadcast_coalesced.yaml,devices,0.4304932735426009,"an iterable of devices among which to broadcast. Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.","an iterable of GPU devices, among which to broadcast."
torch.is_complex.yaml,input,0.6046511627906976,the PyTorch tensor to test,the input tensor.
torch.hub.load.yaml,model,0.6821705426356589,a string of entrypoint name defined in repo's hubconf.py,the name of a callable (entrypoint) defined in the repo/dir's `hubconf.py`.
torch.hub.load.yaml,verbose,0.839344262295082,"If False, mute messages about hitting local caches. Note that the message about first download is cannot be muted. Default is True.","If `False`, mute messages about hitting local caches. Note that the message about first download cannot be muted. Does not have any effect if `source = 'local'`. Default is `True`."
torch.hub.load.yaml,force_reload,0.7685185185185185,whether to force a fresh download of github repo unconditionally. Default is False.,whether to force a fresh download of the github repo unconditionally. Does not have any effect if `source = 'local'`. Default is `False`.
torch.is_nonzero.yaml,input,0.6046511627906976,the PyTorch tensor to test,the input tensor.
torch.ne.yaml,out,0.5573770491803278,the output tensor that must be a BoolTensor,the output tensor.
torch.distributed.init_process_group.yaml,timeout,0.3476923076923077,"Timeout for operations executed against the process group. Default value equals 30 minutes. This is applicable for the `gloo` backend. For `nccl`, this is applicable only if the environment variable `NCCL_BLOCKING_WAIT` is set to 1.","Timeout for operations executed against the process group. Default value equals 30 minutes. This is applicable for the `gloo` backend. For `nccl`, this is applicable only if the environment variable `NCCL_BLOCKING_WAIT` or `NCCL_ASYNC_ERROR_HANDLING` is set to 1. When `NCCL_BLOCKING_WAIT` is set, this is the duration for which the process will block and wait for collectives to complete before throwing an exception. When `NCCL_ASYNC_ERROR_HANDLING` is set, this is the duration after which collectives will be aborted asynchronously and the process will crash. `NCCL_BLOCKING_WAIT` will provide errors to the user which can be caught and handled, but due to its blocking nature, it has a performance overhead. On the other hand, `NCCL_ASYNC_ERROR_HANDLING` has little performance overhead, but crashes the process on errors. This is done since CUDA execution is async and it is no longer safe to continue executing user code since failed async NCCL operations might result in subsequent CUDA operations to run on corrupted data. Only one of these two environment variables should be set."
torch.is_floating_point.yaml,input,0.6046511627906976,the PyTorch tensor to test,the input tensor.
torch.eq.yaml,out,0.631578947368421,the output tensor. Must be a ByteTensor,the output tensor.
torch.distributed.rpc.init_rpc.yaml,backend,0.8982035928143712,The type of RPC backend implementation. Supported values include `BackendType.PROCESS_GROUP` (the default) and `BackendType.TENSORPIPE`. See Backends for more information.,The type of RPC backend implementation. Supported values include `BackendType.TENSORPIPE` (the default) and `BackendType.PROCESS_GROUP`. See Backends for more information.
torch.logspace.yaml,steps,0.3010752688172043,number of points to sample between `start` and `end`. Default: `100`.,size of the constructed tensor
torch.div.yaml,input,0.4827586206896552,the input tensor.,the dividend
torch.div.yaml,other,0.3,the number to be divided to each element of `input`,the divisor
