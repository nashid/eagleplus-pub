constraints:
  Toutput:
    descp: 'A tf.DType from: tf.float32.'
  a:
    descp: 'A Tensor. Must be one of the following types: qint8, quint8, qint32, qint16,
      quint16.'
  b:
    descp: 'A Tensor. Must be one of the following types: qint8, quint8, qint32, qint16,
      quint16.'
  bias:
    descp: 'A Tensor. Must be one of the following types: float32, qint32.'
  input_quant_mode:
    default: MIN_FIRST
    descp: 'An optional string from: "MIN_FIRST", "SCALED". Defaults to "MIN_FIRST".'
  max_a:
    descp: A Tensor of type float32.
  max_b:
    descp: A Tensor of type float32.
  max_freezed_output:
    descp: A Tensor of type float32.
  min_a:
    descp: A Tensor of type float32.
  min_b:
    descp: A Tensor of type float32.
  min_freezed_output:
    descp: A Tensor of type float32.
  name:
    default: None
    descp: A name for the operation (optional).
  transpose_a:
    default: 'False'
    descp: An optional bool. Defaults to False.
  transpose_b:
    default: 'False'
    descp: An optional bool. Defaults to False.
inputs:
  optional:
  - transpose_a
  - transpose_b
  - input_quant_mode
  - name
  required:
  - a
  - b
  - bias
  - min_a
  - max_a
  - min_b
  - max_b
  - min_freezed_output
  - max_freezed_output
  - Toutput
link: https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/raw_ops/QuantizedMatMulWithBiasAndDequantize
outputs:
- A Tensor of type Toutput.
package: tensorflow
target: QuantizedMatMulWithBiasAndDequantize
title: tf.raw_ops.QuantizedMatMulWithBiasAndDequantize
version: 2.2.0
