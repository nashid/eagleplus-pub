{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tree import Tree\n",
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "\n",
    "import ast\n",
    "\n",
    "from itertools import groupby "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_parser = CoreNLPParser(url='http://localhost:9000')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have three functions as below;\n",
    "# (1) find_common_subwords(sen1, sen2);\n",
    "# sen1 : a first sentence; string\n",
    "# sen2 : a second sentence; string\n",
    "# return: the list of sub-words\n",
    "def find_common_subwords(sen1, sen2):\n",
    "    words_list = []\n",
    "\n",
    "    for path in find_common_paths(sub_path_mining(sen1), sub_path_mining(sen2)):\n",
    "        words_list.append(ast.literal_eval(path)[1])\n",
    "        words_list.append(ast.literal_eval(path)[-2])\n",
    "\n",
    "    return list(set(words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) find_common_paths(s1, s2);\n",
    "# s1: a tree of the first sentence ( tree is returned by nlp_parser.raw_parse() )\n",
    "# s2; a tree of the second sentence\n",
    "# the list of all common paths between two sentences\n",
    "def find_common_paths (s1, s2):\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    \n",
    "    def preprocess_path(path):\n",
    "        for i in range(len(path)):\n",
    "            if 3 == len(path[i]):\n",
    "                path[i] = (path[i])[:2]\n",
    "                \n",
    "        \n",
    "        return (path)\n",
    "    \n",
    "    def elem_consecutive_dups(path):\n",
    "        return [x[0] for x in groupby(path)]\n",
    "        \n",
    "    for i in range(len(s1)):\n",
    "        if \"_leaf_\" == (s1[i])[-1]:\n",
    "            l1.append (str(elem_consecutive_dups(preprocess_path(s1[i]))))\n",
    "        \n",
    "    for i in range(len(s2)):\n",
    "        if \"_leaf_\" == (s2[i])[-1]:\n",
    "            # to check reverse as well\n",
    "            l2.append (str(elem_consecutive_dups(preprocess_path(s2[i]))))\n",
    "            \n",
    "            temp_path = elem_consecutive_dups(preprocess_path(s2[i]))\n",
    "            temp_path.reverse()\n",
    "            l2.append (str(temp_path))\n",
    "            \n",
    "    return set(l1).intersection(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) sub_path_mining(tree):\n",
    "# tree: a tree represented sentence\n",
    "# return: all paths of all pairs of words (i.e., if sentence has n words, # of paths will be n(n-1)/2 )/\n",
    "def sub_path_mining(tree):\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    # leaf node\n",
    "    if str == type(tree) :\n",
    "        \n",
    "        # make a length-1 path and start building (a)\n",
    "        return ([[\"_leaf_\", tree]])\n",
    "    \n",
    "    # have a single child tree\n",
    "    elif 1 == len(tree):\n",
    "        for path in sub_path_mining(tree[0]):\n",
    "            if \"_leaf_\" != path[-1]:\n",
    "                # add this label and half_path keeps growing (b)\n",
    "                l.append(path + [tree.label()])\n",
    "                \n",
    "            else :\n",
    "                # if full path found, just keep it (c)\n",
    "                l.append(path)\n",
    "                \n",
    "    # have mulitple child nodes\n",
    "    else :\n",
    "        for i in range(len(tree)):\n",
    "            for path_1 in sub_path_mining(tree[i]):\n",
    "                \n",
    "                # path_1 is fully formed path, just add and continue (d)\n",
    "                if \"_leaf_\" == path_1[-1] :\n",
    "                    l.append(path_1)\n",
    "                    continue\n",
    "                \n",
    "    \n",
    "                l.append(path_1 + [tree.label()])\n",
    "                \n",
    "                for j in range(i+1, len(tree)):\n",
    "                    for path_2 in sub_path_mining(tree[j]):\n",
    "\n",
    "                        # if path_2 is a full path, it should have been already added by (d), (e)\n",
    "                        if \"_leaf_\" != path_2[-1] :\n",
    "                            path_2.reverse()\n",
    "                            \n",
    "                            # construct half_path + half_path and build a full path (f)\n",
    "                            l.append(path_1 + [tree.label()] + path_2)\n",
    "                        \n",
    "    return (l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'A D_STRUCTURE of type D_TYPE'\n",
    "s2 = 'A CONSTANT_NUM D D_STRUCTURE of type D_TYPE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_common_subwords(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = nlp_parser.raw_parse(s1)\n",
    "tree2 = nlp_parser.raw_parse(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_common_paths(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_common_paths(sub_path_mining(s1), sub_path_mining(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_common_subwords(\"probability of an element to be zeroed\", \\\n",
    "                     \"The ground-truth probability of the random value fall in a specific bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docterfuzz",
   "language": "python",
   "name": "docterfuzz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
