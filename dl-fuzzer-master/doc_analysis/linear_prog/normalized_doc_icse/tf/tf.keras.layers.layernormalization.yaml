aliases:
- tf.compat.v1.keras.layers.LayerNormalization
constraints:
  '**kwargs':
    default: null
    descp: ''
    normalized_descp: []
  axis:
    default: '-1'
    descp: Integer or List/Tuple. The axis that should be normalized (typically the
      features axis).
    normalized_default: DEFAULT CONSTANT_NUM
    normalized_descp:
    - D_TYPE or D_STRUCTURE
    - The axis that should be normalized BSTR
  beta_constraint:
    default: None
    descp: Optional constraint for the beta weight.
    normalized_default: DEFAULT None
    normalized_descp:
    - Optional constraint for the beta weight
  beta_initializer:
    default: zeros
    descp: Initializer for the beta weight.
    normalized_default: DEFAULT DF_STR
    normalized_descp:
    - Initializer for the beta weight
  beta_regularizer:
    default: None
    descp: Optional regularizer for the beta weight.
    normalized_default: DEFAULT None
    normalized_descp:
    - Optional regularizer for the beta weight
  center:
    default: 'True'
    descp: If True, add offset of `beta` to normalized tensor. If False, `beta` is
      ignored.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - If CONSTANT_BOOL add offset of QSTR to normalized D_STRUCTURE
    - If CONSTANT_BOOL QSTR is ignored
  epsilon:
    default: '0.001'
    descp: Small float added to variance to avoid dividing by zero.
    normalized_default: DEFAULT CONSTANT_FLOAT
    normalized_descp:
    - Small D_TYPE added to variance to avoid dividing by zero
  gamma_constraint:
    default: None
    descp: Optional constraint for the gamma weight.
    normalized_default: DEFAULT None
    normalized_descp:
    - Optional constraint for the gamma weight
  gamma_initializer:
    default: ones
    descp: Initializer for the gamma weight.
    normalized_default: DEFAULT DF_STR
    normalized_descp:
    - Initializer for the gamma weight
  gamma_regularizer:
    default: None
    descp: Optional regularizer for the gamma weight.
    normalized_default: DEFAULT None
    normalized_descp:
    - Optional regularizer for the gamma weight
  name:
    default: None
    descp: ''
    normalized_default: DEFAULT None
    normalized_descp: []
  scale:
    default: 'True'
    descp: If True, multiply by `gamma`. If False, `gamma` is not used. When the next
      layer is linear (also e.g. `nn.relu`), this can be disabled since the scaling
      will be done by the next layer.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - If CONSTANT_BOOL multiply by QSTR
    - If CONSTANT_BOOL QSTR is not used
    - When the next layer is linear also e g
    - nn relu this can be disabled since the scaling will be done by the next layer
  trainable:
    default: 'True'
    descp: Boolean, if `True` the variables will be marked as trainable.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - D_TYPE if CONSTANT_BOOL the variables will be marked as trainable
inputs:
  optional:
  - axis
  - epsilon
  - center
  - scale
  - beta_initializer
  - gamma_initializer
  - beta_regularizer
  - gamma_regularizer
  - beta_constraint
  - gamma_constraint
  - trainable
  - name
  - '**kwargs'
  required: []
link: https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/layers/LayerNormalization
package: tensorflow
target: LayerNormalization
title: tf.keras.layers.LayerNormalization
version: 2.1.0
