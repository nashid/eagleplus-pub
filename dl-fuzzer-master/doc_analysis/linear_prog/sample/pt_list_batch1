- - torch.linspace.yaml
  - steps
  - torch.linspace
- - torch.nn.functional.adaptive_avg_pool1d.yaml
  - output_size
  - torch.nn.functional.adaptive_avg_pool1d
- - torch.nn.tripletmarginloss.yaml
  - reduction
  - torch.nn.TripletMarginLoss
- - torch.clamp.yaml
  - input
  - torch.clamp
- - torch.addcdiv.yaml
  - input
  - torch.addcdiv
- - torch.logical_and.yaml
  - out
  - torch.logical_and
- - torch.jit.save.yaml
  - _extra_files
  - torch.jit.save
- - torch.sum2.yaml
  - dim
  - torch.sum
- - torch.numel.yaml
  - input
  - torch.numel
- - torch.is_tensor.yaml
  - obj
  - torch.is_tensor
- - torch.nn.utils.spectral_norm.yaml
  - name
  - torch.nn.utils.spectral_norm
- - torch.lobpcg.yaml
  - method
  - torch.lobpcg
- - torch.round.yaml
  - out
  - torch.round
- - torch.nn.ctcloss.yaml
  - zero_infinity
  - torch.nn.CTCLoss
- - torch.nn.utils.prune.random_unstructured.yaml
  - amount
  - torch.nn.utils.prune.random_unstructured
- - torch.rand.yaml
  - layout
  - torch.rand
- - torch.nn.functional.nll_loss.yaml
  - ignore_index
  - torch.nn.functional.nll_loss
- - torch.addr.yaml
  - beta
  - torch.addr
- - torch.nn.functional.avg_pool1d.yaml
  - input
  - torch.nn.functional.avg_pool1d
- - torch.multinomial.yaml
  - generator
  - torch.multinomial
- - torch.distributed.send.yaml
  - dst
  - torch.distributed.send
- - torch.nn.rrelu.yaml
  - inplace
  - torch.nn.RReLU
- - torch.masked_select.yaml
  - input
  - torch.masked_select
- - torch.nn.instancenorm1d.yaml
  - momentum
  - torch.nn.InstanceNorm1d
- - torch.cuda.set_rng_state.yaml
  - new_state
  - torch.cuda.set_rng_state
- - torch.symeig.yaml
  - out
  - torch.symeig
- - torch.floor_divide.yaml
  - other
  - torch.floor_divide
- - torch.addmm.yaml
  - mat1
  - torch.addmm
- - torch.eye.yaml
  - requires_grad
  - torch.eye
- - torch.nn.functional.conv_transpose2d.yaml
  - input
  - torch.nn.functional.conv_transpose2d
- - torch.nn.maxunpool2d.yaml
  - padding
  - torch.nn.MaxUnpool2d
- - torch.autograd.functional.jacobian.yaml
  - strict
  - torch.autograd.functional.jacobian
- - torch.triu.yaml
  - diagonal
  - torch.triu
- - torch.nn.multilabelmarginloss.yaml
  - reduce
  - torch.nn.MultiLabelMarginLoss
- - torch.sigmoid.yaml
  - input
  - torch.sigmoid
- - torch.nn.convtranspose2d.yaml
  - groups
  - torch.nn.ConvTranspose2d
- - torch.triu_indices.yaml
  - row
  - torch.triu_indices
- - torch.distributed.get_world_size.yaml
  - group
  - torch.distributed.get_world_size
- - torch.nn.crossentropyloss.yaml
  - reduction
  - torch.nn.CrossEntropyLoss
- - torch.nn.utils.prune.remove.yaml
  - name
  - torch.nn.utils.prune.remove
- - torch.pca_lowrank.yaml
  - niter
  - torch.pca_lowrank
- - torch.nn.kldivloss.yaml
  - reduction
  - torch.nn.KLDivLoss
- - torch.empty_like.yaml
  - device
  - torch.empty_like
- - torch.distributions.kl.kl_divergence.yaml
  - p
  - torch.distributions.kl.kl_divergence
- - torch.nn.bceloss.yaml
  - reduce
  - torch.nn.BCELoss
- - torch.utils.cpp_extension.load.yaml
  - extra_cflags
  - torch.utils.cpp_extension.load
- - torch.narrow.yaml
  - start
  - torch.narrow
- - torch.nn.batchnorm3d.yaml
  - momentum
  - torch.nn.BatchNorm3d
- - torch.logical_and.yaml
  - input
  - torch.logical_and
- - torch.nn.maxunpool1d.yaml
  - stride
  - torch.nn.MaxUnpool1d
- - torch.hub.download_url_to_file.yaml
  - url
  - torch.hub.download_url_to_file
- - torch.distributed.all_gather.yaml
  - async_op
  - torch.distributed.all_gather
- - torch.nn.adaptivelogsoftmaxwithloss.yaml
  - div_value
  - torch.nn.AdaptiveLogSoftmaxWithLoss
- - torch.mode.yaml
  - out
  - torch.mode
- - torch.mm.yaml
  - input
  - torch.mm
- - torch.ne.yaml
  - other
  - torch.ne
- - torch.nn.constantpad3d.yaml
  - padding
  - torch.nn.ConstantPad3d
- - torch.lu.yaml
  - get_infos
  - torch.lu
- - torch.nn.functional.embedding.yaml
  - padding_idx
  - torch.nn.functional.embedding
- - torch.gt.yaml
  - out
  - torch.gt
- - torch.nn.utils.rnn.pack_padded_sequence.yaml
  - batch_first
  - torch.nn.utils.rnn.pack_padded_sequence
- - torch.nn.conv1d.yaml
  - kernel_size
  - torch.nn.Conv1d
- - torch.cuda.manual_seed.yaml
  - seed
  - torch.cuda.manual_seed
- - torch.nn.tripletmarginloss.yaml
  - reduce
  - torch.nn.TripletMarginLoss
- - torch.nn.lstm.yaml
  - input_size
  - torch.nn.LSTM
- - torch.rand_like.yaml
  - dtype
  - torch.rand_like
- - torch.hub.load_state_dict_from_url.yaml
  - progress
  - torch.hub.load_state_dict_from_url
- - torch.as_strided.yaml
  - storage_offset
  - torch.as_strided
- - torch.nn.avgpool1d.yaml
  - kernel_size
  - torch.nn.AvgPool1d
- - torch.nn.batchnorm3d.yaml
  - affine
  - torch.nn.BatchNorm3d
- - torch.utils.cpp_extension.load.yaml
  - sources
  - torch.utils.cpp_extension.load
- - torch.hamming_window.yaml
  - periodic
  - torch.hamming_window
- - torch.histc.yaml
  - min
  - torch.histc
- - torch.abs.yaml
  - input
  - torch.abs
- - torch.nn.utils.weight_norm.yaml
  - name
  - torch.nn.utils.weight_norm
- - torch.autograd.functional.vjp.yaml
  - create_graph
  - torch.autograd.functional.vjp
- - torch.ones.yaml
  - device
  - torch.ones
- - torch.remainder.yaml
  - input
  - torch.remainder
- - torch.square.yaml
  - input
  - torch.square
- - torch.sum2.yaml
  - keepdim
  - torch.sum
- - torch.nn.maxpool2d.yaml
  - return_indices
  - torch.nn.MaxPool2d
- - torch.logsumexp.yaml
  - out
  - torch.logsumexp
- - torch.einsum.yaml
  - '*operands'
  - torch.einsum
- - torch.norm.yaml
  - input
  - torch.norm
- - torch.addcdiv.yaml
  - value
  - torch.addcdiv
- - torch.normal222.yaml
  - size
  - torch.normal
- - torch.tensordot.yaml
  - a
  - torch.tensordot
- - torch.quantization.propagate_qconfig_.yaml
  - qconfig_dict
  - torch.quantization.propagate_qconfig_
- - torch.nn.utils.prune.global_unstructured.yaml
  - pruning_method
  - torch.nn.utils.prune.global_unstructured
- - torch.nn.init.uniform_.yaml
  - a
  - torch.nn.init.uniform_
- - torch.neg.yaml
  - input
  - torch.neg
- - torch.div.yaml
  - input
  - torch.div
- - torch.ifft.yaml
  - input
  - torch.ifft
- - torch.nn.functional.conv_transpose2d.yaml
  - dilation
  - torch.nn.functional.conv_transpose2d
- - torch.argsort.yaml
  - descending
  - torch.argsort
- - torch.nn.maxpool2d.yaml
  - stride
  - torch.nn.MaxPool2d
- - torch.sparse_coo_tensor.yaml
  - requires_grad
  - torch.sparse_coo_tensor
- - torch.log1p.yaml
  - out
  - torch.log1p
- - torch.autograd.functional.vhp.yaml
  - strict
  - torch.autograd.functional.vhp
- - torch.nn.functional.conv_transpose1d.yaml
  - weight
  - torch.nn.functional.conv_transpose1d
- - torch.tensordot.yaml
  - b
  - torch.tensordot
- - torch.rand_like.yaml
  - input
  - torch.rand_like
- - torch.kthvalue.yaml
  - keepdim
  - torch.kthvalue
- - torch.can_cast.yaml
  - to
  - torch.can_cast
- - torch.repeat_interleave.yaml
  - input
  - torch.repeat_interleave
- - torch.nn.functional.interpolate.yaml
  - align_corners
  - torch.nn.functional.interpolate
- - torch.min2.yaml
  - keepdim
  - torch.min
- - torch.nn.functional.adaptive_max_pool3d.yaml
  - return_indices
  - torch.nn.functional.adaptive_max_pool3d
- - torch.nn.nllloss.yaml
  - reduction
  - torch.nn.NLLLoss
- - torch.utils.cpp_extension.load.yaml
  - is_python_module
  - torch.utils.cpp_extension.load
- - torch.distributed.broadcast.yaml
  - src
  - torch.distributed.broadcast
- - torch.linspace.yaml
  - layout
  - torch.linspace
- - torch.unsqueeze.yaml
  - dim
  - torch.unsqueeze
- - torch.clamp.yaml
  - out
  - torch.clamp
- - torch.nn.quantized.functional.conv3d.yaml
  - scale
  - torch.nn.quantized.functional.conv3d
- - torch.nn.localresponsenorm.yaml
  - alpha
  - torch.nn.LocalResponseNorm
- - torch.nn.functional.avg_pool1d.yaml
  - ceil_mode
  - torch.nn.functional.avg_pool1d
- - torch.nn.rnn.yaml
  - input_size
  - torch.nn.RNN
- - torch.nn.functional.dropout3d.yaml
  - inplace
  - torch.nn.functional.dropout3d
- - torch.nn.functional.poisson_nll_loss.yaml
  - full
  - torch.nn.functional.poisson_nll_loss
- - torch.empty_like.yaml
  - layout
  - torch.empty_like
- - torch.narrow.yaml
  - input
  - torch.narrow
- - torch.nn.functional.kl_div.yaml
  - target
  - torch.nn.functional.kl_div
- - torch.autograd.functional.hessian.yaml
  - strict
  - torch.autograd.functional.hessian
- - torch.utils.dlpack.from_dlpack.yaml
  - dlpack
  - torch.utils.dlpack.from_dlpack
- - torch.nn.functional.gumbel_softmax.yaml
  - dim
  - torch.nn.functional.gumbel_softmax
- - torch.quantize_per_channel.yaml
  - axis
  - torch.quantize_per_channel
- - torch.eye.yaml
  - dtype
  - torch.eye
- - torch.eq.yaml
  - other
  - torch.eq
- - torch.nn.functional.embedding.yaml
  - norm_type
  - torch.nn.functional.embedding
- - torch.nn.batchnorm1d.yaml
  - affine
  - torch.nn.BatchNorm1d
- - torch.logical_not.yaml
  - out
  - torch.logical_not
- - torch.nn.softshrink.yaml
  - lambd
  - torch.nn.Softshrink
- - torch.chunk.yaml
  - chunks
  - torch.chunk
- - torch.cuda.stream.yaml
  - stream
  - torch.cuda.stream
- - torch.nn.unfold.yaml
  - stride
  - torch.nn.Unfold
- - torch.nn.functional.binary_cross_entropy_with_logits.yaml
  - weight
  - torch.nn.functional.binary_cross_entropy_with_logits
- - torch.nn.functional.binary_cross_entropy_with_logits.yaml
  - pos_weight
  - torch.nn.functional.binary_cross_entropy_with_logits
- - torch.utils.checkpoint.checkpoint_sequential.yaml
  - functions
  - torch.utils.checkpoint.checkpoint_sequential
- - torch.nn.init.ones_.yaml
  - tensor
  - torch.nn.init.ones_
- - torch.quantization.swap_module.yaml
  - mapping
  - torch.quantization.swap_module
- - torch.nonzero.yaml
  - input
  - torch.nonzero
- - torch.logical_and.yaml
  - other
  - torch.logical_and
- - torch.cdist.yaml
  - x1
  - torch.cdist
- - torch.distributed.reduce.yaml
  - group
  - torch.distributed.reduce
- - torch.sin.yaml
  - out
  - torch.sin
- - torch.nn.cosinesimilarity.yaml
  - dim
  - torch.nn.CosineSimilarity
- - torch.le.yaml
  - input
  - torch.le
- - torch.rfft.yaml
  - signal_ndim
  - torch.rfft
- - torch.nn.functional.avg_pool1d.yaml
  - padding
  - torch.nn.functional.avg_pool1d
- - torch.autograd.functional.hvp.yaml
  - strict
  - torch.autograd.functional.hvp
- - torch.distributed.all_gather.yaml
  - tensor
  - torch.distributed.all_gather
- - torch.autograd.gradgradcheck.yaml
  - grad_outputs
  - torch.autograd.gradgradcheck
- - torch.cat.yaml
  - tensors
  - torch.cat
- - torch.autograd.gradcheck.yaml
  - rtol
  - torch.autograd.gradcheck
- - torch.logspace.yaml
  - start
  - torch.logspace
- - torch.nn.l1loss.yaml
  - size_average
  - torch.nn.L1Loss
- - torch.nn.transformer.yaml
  - activation
  - torch.nn.Transformer
- - torch.nn.utils.clip_grad_norm_.yaml
  - max_norm
  - torch.nn.utils.clip_grad_norm_
- - torch.jit.save.yaml
  - m
  - torch.jit.save
- - torch.logical_or.yaml
  - out
  - torch.logical_or
- - torch.addcmul.yaml
  - input
  - torch.addcmul
- - torch.sparse.addmm.yaml
  - mat
  - torch.sparse.addmm
- - torch.bartlett_window.yaml
  - dtype
  - torch.bartlett_window
- - torch.pinverse.yaml
  - input
  - torch.pinverse
- - torch.nn.convtranspose3d.yaml
  - bias
  - torch.nn.ConvTranspose3d
- - torch.log.yaml
  - out
  - torch.log
- - torch.nn.quantized.functional.conv2d.yaml
  - bias
  - torch.nn.quantized.functional.conv2d
- - torch.onnx.export.yaml
  - verbose
  - torch.onnx.export
- - torch.nn.instancenorm3d.yaml
  - eps
  - torch.nn.InstanceNorm3d
- - torch.autograd.grad.yaml
  - outputs
  - torch.autograd.grad
- - torch.nn.celu.yaml
  - inplace
  - torch.nn.CELU
- - torch.sparse_coo_tensor.yaml
  - values
  - torch.sparse_coo_tensor
- - torch.nn.functional.affine_grid.yaml
  - theta
  - torch.nn.functional.affine_grid
- - torch.autograd.functional.hessian.yaml
  - create_graph
  - torch.autograd.functional.hessian
- - torch.nn.quantized.functional.avg_pool2d.yaml
  - stride
  - torch.nn.quantized.functional.avg_pool2d
- - torch.autograd.gradcheck.yaml
  - inputs
  - torch.autograd.gradcheck
