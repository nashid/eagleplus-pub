constraints:
  '**kwargs':
    descp: ''
  beta:
    default: _Null
    descp: Per-Coordinate Learning Rate beta.
    doc_dtype:
    - float
    - optional
    - default=1
  clip_gradient:
    default: _Null
    descp: Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient
      <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient),
      -clip_gradient).
    doc_dtype:
    - float
    - optional
    - default=-1
  grad:
    default: None
    descp: Gradient
    doc_dtype:
    - NDArray
  lamda1:
    default: _Null
    descp: The L1 regularization coefficient.
    doc_dtype:
    - float
    - optional
    - default=0.00999999978
  lr:
    default: _Null
    descp: Learning rate
    doc_dtype:
    - float
    - required
  n:
    default: None
    descp: Square of grad
    doc_dtype:
    - NDArray
  name:
    default: None
    descp: ''
  out:
    default: None
    descp: The output NDArray to hold the result.
    doc_dtype:
    - NDArray
    - optional
  rescale_grad:
    default: _Null
    descp: Rescale gradient to grad = rescale_grad*grad.
    doc_dtype:
    - float
    - optional
    - default=1
  wd:
    default: _Null
    descp: Weight decay augments the objective function with a regularization term
      that penalizes large weights. The penalty scales with the square of the magnitude
      of each weight.
    doc_dtype:
    - float
    - optional
    - default=0
  weight:
    default: None
    descp: Weight
    doc_dtype:
    - NDArray
  z:
    default: None
    descp: z
    doc_dtype:
    - NDArray
inputs:
  optional:
  - weight
  - grad
  - z
  - n
  - lr
  - lamda1
  - beta
  - wd
  - rescale_grad
  - clip_gradient
  - out
  - name
  required:
  - '**kwargs'
link: https://mxnet.apache.org/versions/1.6/api/python/docs/api/ndarray/sparse/index.html#mxnet.ndarray.sparse.ftrl_update
package: mxnet
target: ftrl_update
title: mxnet.ndarray.sparse.ftrl_update
version: 1.6.0
