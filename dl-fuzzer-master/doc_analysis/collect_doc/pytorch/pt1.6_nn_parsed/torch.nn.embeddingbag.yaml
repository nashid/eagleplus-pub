constraints:
  _weight:
    default: None
    descp: ''
    sig_dtype: Optional[torch.Tensor]
  embedding_dim:
    descp: the size of each embedding vector
    doc_dtype:
    - int
    sig_dtype: int
  include_last_offset:
    default: 'False'
    descp: 'if `True`, `offsets` has one additional element, where the last element
      is equivalent to the size of indices. This matches the CSR format. Note: this
      option is currently only supported when `mode="sum"`.'
    doc_dtype:
    - bool
    sig_dtype: bool
  max_norm:
    default: None
    descp: If given, each embedding vector with norm larger than `max_norm` is renormalized
      to have norm `max_norm`.
    doc_dtype:
    - float
    sig_dtype: Optional[float]
  mode:
    default: mean
    descp: '`"sum"`, `"mean"` or `"max"`. Specifies the way to reduce the bag. `"sum"`
      computes the weighted sum, taking `per_sample_weights` into consideration. `"mean"`
      computes the average of the values in the bag, `"max"` computes the max value
      over each bag. Default: `"mean"`'
    doc_dtype:
    - string
    sig_dtype: str
  norm_type:
    default: '2.0'
    descp: The p of the p-norm to compute for the `max_norm` option. Default `2`.
    doc_dtype:
    - float
    sig_dtype: float
  num_embeddings:
    descp: size of the dictionary of embeddings
    doc_dtype:
    - int
    sig_dtype: int
  scale_grad_by_freq:
    default: 'False'
    descp: 'if given, this will scale gradients by the inverse of frequency of the
      words in the mini-batch. Default `False`. Note: this option is not supported
      when `mode="max"`.'
    doc_dtype:
    - boolean
    sig_dtype: bool
  sparse:
    default: 'False'
    descp: 'if `True`, gradient w.r.t. `weight` matrix will be a sparse tensor. See
      Notes for more details regarding sparse gradients. Note: this option is not
      supported when `mode="max"`.'
    doc_dtype:
    - bool
    sig_dtype: bool
inputs:
  optional:
  - max_norm
  - norm_type
  - scale_grad_by_freq
  - mode
  - sparse
  - _weight
  - include_last_offset
  required:
  - num_embeddings
  - embedding_dim
link: https://pytorch.org/docs/1.6.0/generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag#torch.nn.EmbeddingBag
package: torch
target: EmbeddingBag
title: torch.nn.EmbeddingBag
version: 1.6.0
