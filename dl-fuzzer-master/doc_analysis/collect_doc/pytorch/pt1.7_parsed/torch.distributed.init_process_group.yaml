constraints:
  backend:
    descp: The backend to use. Depending on build-time configurations, valid values
      include `mpi`, `gloo`, and `nccl`. This field should be given as a lowercase
      string (e.g., `"gloo"`), which can also be accessed via `Backend` attributes
      (e.g., `Backend.GLOO`). If using multiple processes per machine with `nccl`
      backend, each process must have exclusive access to every GPU it uses, as sharing
      GPUs between processes can result in deadlocks.
    doc_dtype:
    - str
    - Backend
  group_name:
    default: ''
    descp: Group name.
    doc_dtype:
    - str
    - deprecated
  init_method:
    default: None
    descp: URL specifying how to initialize the process group. Default is "env://"
      if no `init_method` or `store` is specified. Mutually exclusive with `store`.
    doc_dtype:
    - str
  rank:
    default: '-1'
    descp: Rank of the current process. Required if `store` is specified.
    doc_dtype:
    - int
  store:
    default: None
    descp: Key/value store accessible to all workers, used to exchange connection/address
      information. Mutually exclusive with `init_method`.
    doc_dtype:
    - Store
  timeout:
    default: datetime.timedelta(0,1800)
    descp: Timeout for operations executed against the process group. Default value
      equals 30 minutes. This is applicable for the `gloo` backend. For `nccl`, this
      is applicable only if the environment variable `NCCL_BLOCKING_WAIT` or `NCCL_ASYNC_ERROR_HANDLING`
      is set to 1. When `NCCL_BLOCKING_WAIT` is set, this is the duration for which
      the process will block and wait for collectives to complete before throwing
      an exception. When `NCCL_ASYNC_ERROR_HANDLING` is set, this is the duration
      after which collectives will be aborted asynchronously and the process will
      crash. `NCCL_BLOCKING_WAIT` will provide errors to the user which can be caught
      and handled, but due to its blocking nature, it has a performance overhead.
      On the other hand, `NCCL_ASYNC_ERROR_HANDLING` has little performance overhead,
      but crashes the process on errors. This is done since CUDA execution is async
      and it is no longer safe to continue executing user code since failed async
      NCCL operations might result in subsequent CUDA operations to run on corrupted
      data. Only one of these two environment variables should be set.
    doc_dtype:
    - timedelta
  world_size:
    default: '-1'
    descp: Number of processes participating in the job. Required if `store` is specified.
    doc_dtype:
    - int
inputs:
  optional:
  - init_method
  - timeout
  - world_size
  - rank
  - store
  - group_name
  required:
  - backend
link: https://pytorch.org/docs/1.7.0/distributed.html#torch.distributed.init_process_group
package: torch
target: init_process_group
title: torch.distributed.init_process_group
version: 1.7.0
