,API,Arg,Descp,Normalized_descp,dtype,tensor_t,structure,shape,ndim,range,enum
0,mxnet.ndarray.sparse.add_n,*args,Positional input arguments,Positional input arguments,,,,,,,
1,mxnet.ndarray.stack,*data,List of arrays to stack,D_STRUCTURE of D_STRUCTURE to stack,,,D_STRUCTURE,,,,
2,mxnet.ndarray.linalg_inverse,A,Tensor of square matrix,D_STRUCTURE of square matrix,,D_STRUCTURE,,,,,
3,mxnet.ndarray.linalg_potri,A,Tensor of lower triangular matrices,D_STRUCTURE of lower triangular matrices,,D_STRUCTURE,,,,,
4,mxnet.ndarray.linalg_trsm,A,Tensor of lower triangular matrices,D_STRUCTURE of PARAM triangular matrices,,D_STRUCTURE,,,,,
5,mxnet.ndarray.linalg.potrf,A,Tensor of input matrices to be decomposed,D_STRUCTURE of input matrices to be decomposed,,D_STRUCTURE,,,,,
6,mxnet.ndarray.op.linalg_det,A,Tensor of square matrix,D_STRUCTURE of square matrix,,D_STRUCTURE,,,,,
7,mxnet.ndarray.op.linalg_gemm2,A,Tensor of input matrices,D_STRUCTURE of input matrices,,D_STRUCTURE,,,,,
8,mxnet.ndarray.op.linalg_trmm,A,Tensor of lower triangular matrices,D_STRUCTURE of PARAM triangular matrices,,D_STRUCTURE,,,,,
9,mxnet.ndarray.Activation,act_type,Activation function to be applied.,Activation function to be applied,,,,,,,QSTR
10,mxnet.gluon.nn.Dense,activation,"Activation function to use. See help on Activation layer. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",If you don t specify anything no activation is applied ie,,,,,,,
11,mxnet.gluon.nn.Dense,activation,"Activation function to use. See help on Activation layer. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",QSTR activation a BSTR x,,,,,,,
12,mxnet.gluon.nn.Dense,activation,"Activation function to use. See help on Activation layer. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",See help on activation layer,,,,,,,
13,mxnet.gluon.nn.Dense,activation,"Activation function to use. See help on Activation layer. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",activation function to use,,,,,,,
14,mxnet.gluon.rnn.RNN,activation,The activation function to use.,The activation function to use,,,,,,,
15,mxnet.metric.np,allow_extra_outputs,"Whether prediction output is allowed to have extra outputs. This is useful in cases like RNN where states are also part of output which can then be fed back to the RNN in the next step. By default, extra outputs are not allowed.",By default extra outputs are not allowed,,,,,,,
16,mxnet.metric.np,allow_extra_outputs,"Whether prediction output is allowed to have extra outputs. This is useful in cases like RNN where states are also part of output which can then be fed back to the RNN in the next step. By default, extra outputs are not allowed.",This is useful in cases like RNN where states are also part of output which can then be fed back to the RNN in the next step,,,,,,,
17,mxnet.metric.np,allow_extra_outputs,"Whether prediction output is allowed to have extra outputs. This is useful in cases like RNN where states are also part of output which can then be fed back to the RNN in the next step. By default, extra outputs are not allowed.",Whether prediction output is allowed to have extra outputs,bool,,,,0,,
18,mxnet.gluon.nn.LeakyReLU,alpha,slope coefficient for the negative half axis. Must be >= 0.,Must be REXPR,,,,,,REXPR,
19,mxnet.gluon.nn.LeakyReLU,alpha,slope coefficient for the negative half axis. Must be >= 0.,slope coefficient for the negative half axis,numeric,,,,,,
20,mxnet.ndarray.op.random_generalized_negative_binomial,alpha,Alpha (dispersion) parameter of the negative binomial distribution.,alpha BSTR parameter of the negative binomial distribution,,,,,,,
21,mxnet.ndarray.random_pdf_gamma,alpha,Alpha (shape) parameters of the distributions.,alpha BSTR parameters of the distributions,,,,,,,
22,mxnet.ndarray.random.gamma,alpha,The shape of the gamma distribution. Should be greater than zero.,Should be greater than zero,,,,,,"[0,inf)",
23,mxnet.ndarray.random.gamma,alpha,The shape of the gamma distribution. Should be greater than zero.,The PARAM of the gamma distribution,int,,,,1,"[0,inf)",
24,mxnet.gluon.nn.PReLU,alpha_initializer,Initializer for the embeddings matrix.,Initializer for the embeddings matrix,,,,,,,
25,mxnet.contrib.quantization.quantize_graph,arg_params,Dictionary of name to NDArray.,D_STRUCTURE of name to D_STRUCTURE,string,,D_STRUCTURE,,,,
26,mxnet.model.save_checkpoint,arg_params,"Model parameter, dict of name to NDArray of net's weights.",Model parameter D_STRUCTURE of name to D_STRUCTURE of net weights,string,,D_STRUCTURE,,,,
27,mxnet.contrib.autograd.grad,argnum,The index of argument to calculate gradient for.,The index of argument to calculate gradient for,int,,,,0,,
28,mxnet.io.ImageDetRecordIter,aug_seq,"Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. Make sure you don't use normal augmenters for detection tasks.",Additional keyword parameters will be seen by these augmenters,,,,,,,
29,mxnet.io.ImageDetRecordIter,aug_seq,"Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. Make sure you don't use normal augmenters for detection tasks.",Augmentation Param the augmenter names to represent D_STRUCTURE of augmenters to be applied seperated by comma,string,,,,0,,
30,mxnet.io.ImageDetRecordIter,aug_seq,"Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. Make sure you don't use normal augmenters for detection tasks.",Make sure you don t use normal augmenters for detection tasks,,,,,,,
31,mxnet.contrib.quantization.quantize_graph,aux_params,Dictionary of name to NDArray.,D_STRUCTURE of name to D_STRUCTURE,string,,D_STRUCTURE,,,,
32,mxnet.test_utils.check_symbolic_forward,aux_states,if type is list of np.ndarrayContains all the NumPy arrays corresponding to sym.list_auxiliary_states,if type is D_STRUCTURE of np ndarrayContains all the NumPy D_STRUCTURE corresponding to PARAM list_auxiliary_states,,,D_STRUCTURE,,,,
33,mxnet.test_utils.numeric_grad,aux_states,Auxiliary states values used as location to compute gradient Maps the name of aux_states to the corresponding numpy.ndarray. Value of all the auxiliary arguments must be provided.,Auxiliary states values used as PARAM to compute gradient Maps the name of aux_states to the corresponding numpy D_STRUCTURE,,,,,,,
34,mxnet.test_utils.numeric_grad,aux_states,Auxiliary states values used as location to compute gradient Maps the name of aux_states to the corresponding numpy.ndarray. Value of all the auxiliary arguments must be provided.,Value of all the auxiliary arguments must be provided,,,,,,,
35,mxnet.gluon.nn.Dropout,axes,"The axes on which dropout mask is shared. If empty, regular dropout is applied.",If empty regular dropout is applied,,,,,,,
36,mxnet.gluon.nn.Dropout,axes,"The axes on which dropout mask is shared. If empty, regular dropout is applied.",The axes on which dropout mask is shared,int,,,,1,,
37,mxnet.ndarray.transpose,axes,Target axis order. By default the axes will be inverted.,By default the axes will be inverted,,,,,,,
38,mxnet.ndarray.transpose,axes,Target axis order. By default the axes will be inverted.,Target axis order,int,,,,1,,
39,mxnet.ndarray.op.cumsum,axis,Axis along which the cumulative sum is computed. The default (None) is to compute the cumsum over the flattened array.,The default BSTR is to compute the cumsum over the flattened D_STRUCTURE,,,,,,,
40,mxnet.ndarray.op.cumsum,axis,Axis along which the cumulative sum is computed. The default (None) is to compute the cumsum over the flattened array.,axis along which the cumulative sum is computed,int,,,,1,,
41,mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If PARAM is CONSTANT_BOOL reduction will be performed on the axes that are NOT in axis instead,,,,,,,
42,mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is a D_STRUCTURE of D_TYPE a reduction is performed on all the axes specified in the D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
43,mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is D_TYPE a reduction is performed on a particular axis,D_TYPE,,,,0,,
44,mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",Negative values means indexing from right to left,,,,,,,
45,mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The default axis BSTR,,,,,,,
46,mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The axis or axes along which to perform the reduction,int,,,,0;1,,
47,mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If PARAM is CONSTANT_BOOL reduction will be performed on the axes that are NOT in axis instead,,,,,,,
48,mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is a D_STRUCTURE of D_TYPE a reduction is performed on all the axes specified in the D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
49,mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is D_TYPE a reduction is performed on a particular axis,D_TYPE,,,,0,,
50,mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",Negative values means indexing from right to left,,,,,,,
51,mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The default axis BSTR,,,,,,,
52,mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The axis or axes along which to perform the reduction,int,,,,0;1,,
53,mxnet.ndarray.SequenceLast,axis,The sequence axis. Only values of 0 and 1 are currently supported.,Only values of CONSTANT_NUM are currently supported,,,,,,,CONSTANT_NUM
54,mxnet.ndarray.SequenceLast,axis,The sequence axis. Only values of 0 and 1 are currently supported.,The D_STRUCTURE axis,int,,,,0,,
55,mxnet.ndarray.diag,axis2,The second axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,Ignored when the input is a CONSTANT_NUM D D_STRUCTURE,,,,,,,
56,mxnet.ndarray.diag,axis2,The second axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,The second axis of the sub D_STRUCTURE of interest,int,,,,0,,
57,mxnet.ndarray.op.diag,axis2,The second axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,Ignored when the input is a CONSTANT_NUM D D_STRUCTURE,,,,,,,
58,mxnet.ndarray.op.diag,axis2,The second axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,The second axis of the sub D_STRUCTURE of interest,int,,,,0,,
59,mxnet.ndarray.linalg_trsm,B,Tensor of matrices,D_STRUCTURE of matrices,,D_STRUCTURE,,,,,
60,mxnet.ndarray.contrib.box_nms,background_id,"Optional, id of the background class which will be ignored in nms.",Optional id of the background class which will be ignored in nms,int,,,,0,"[0,inf)",
61,mxnet.gluon.contrib.rnn.VariationalDropoutCell,base_cell,The cell on which to perform variational dropout.,The cell on which to perform variational dropout,,,,,,,
62,mxnet.io.ImageDetRecordIter,batch_size,Batch size.,Batch size,numeric,,,,,,
63,mxnet.io.MNISTIter,batch_size,Batch Param: Batch Size.,Batch Param Batch Size,numeric,,,,,,
64,mxnet.contrib.ndarray.quantized_batch_norm,beta,beta.,beta,,,,,,,
65,mxnet.ndarray.BatchNorm,beta,beta array,beta D_STRUCTURE,,,D_STRUCTURE,,,,
66,mxnet.ndarray.contrib.hawkesll,beta,"Shape (K,) The decay parameter for each process",Shape BSTR The decay parameter for each process,,,,BSTR,,,
67,mxnet.ndarray.ftrl_update,beta,Per-Coordinate Learning Rate beta.,Per Coordinate Learning Rate beta,float,,,,,"[0,1]",
68,mxnet.ndarray.LayerNorm,beta,beta array,beta D_STRUCTURE,,,D_STRUCTURE,,,,
69,mxnet.ndarray.contrib.quantized_conv,bias,bias.,bias,,,,,,,
70,mxnet.ndarray.FullyConnected,bias,Bias parameter.,bias parameter,,,,,,,
71,mxnet.ndarray.op.Deconvolution,bias,Bias added to the result after the deconvolution operation.,bias added to the result after the deconvolution operation,,,,,,,
72,mxnet.gluon.nn.Dense,bias_initializer,Initializer for the bias vector.,Initializer for the bias vector,,,,,,,
73,mxnet.ndarray.ctc_loss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",If QSTR last PARAM value QSTR is reserved for blank PARAM instead and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
74,mxnet.ndarray.ctc_loss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",Set the PARAM that is reserved for blank PARAM If QSTR CONSTANT_NUM th PARAM is reserved and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
75,mxnet.ndarray.CTCLoss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",If QSTR last PARAM value QSTR is reserved for blank PARAM instead and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
76,mxnet.ndarray.CTCLoss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",Set the PARAM that is reserved for blank PARAM If QSTR CONSTANT_NUM th PARAM is reserved and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
77,mxnet.ndarray.op.ctc_loss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",If QSTR last PARAM value QSTR is reserved for blank PARAM instead and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
78,mxnet.ndarray.op.ctc_loss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",Set the PARAM that is reserved for blank PARAM If QSTR CONSTANT_NUM th PARAM is reserved and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
79,mxnet.image.copyMakeBorder,bot,Bottom margin.,Bottom margin,,,,,,,
80,mxnet.contrib.quantization.quantize_model,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",If calib_mode QSTR BSTR the thresholds for quantization will be derived such that the KL divergence between the distributions of D_TYPE layer outputs and quantized layer outputs is minimized based upon the calibration dataset,,,,,,,QSTR
81,mxnet.contrib.quantization.quantize_model,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",If calib_mode QSTR no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators,,,,,,,QSTR
82,mxnet.contrib.quantization.quantize_model,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",If calib_mode QSTR the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization,,,,,,,QSTR
83,mxnet.contrib.quantization.quantize_model,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",The quantized models generated in this mode are normally CONSTANT_NUM slower than those with calibrations during inference,,,,,,,
84,mxnet.ndarray.multi_sgd_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",Clip gradient to the range of BSTR If clip_gradient REXPR gradient clipping is turned off,,,,,,BSTR,
85,mxnet.ndarray.multi_sgd_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",grad max BSTR,,,,,,,
86,mxnet.ndarray.op.where,condition,condition array,condition D_STRUCTURE,,,D_STRUCTURE,,,,
87,mxnet.profiler.set_config,continuous_dump,whether to periodically dump profiling data to file,whether to periodically dump profiling data to file,bool,,,,0,,
88,mxnet.gluon.nn.AvgPool1D,count_include_pad,"When 'False', will exclude padding elements when computing the average value.",When QSTR will exclude PARAM elements when computing the average value,,,,,,,
89,mxnet.contrib.onnx.import_to_gluon,ctx,Loads the model into one or many context(s).,Loads the model into one or many context BSTR,,,,,,,
90,mxnet.gluon.model_zoo.vision.densenet121,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
91,mxnet.gluon.model_zoo.vision.densenet161,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
92,mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
93,mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
94,mxnet.gluon.model_zoo.vision.resnet152_v1,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
95,mxnet.gluon.model_zoo.vision.vgg16_bn,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
96,mxnet.ndarray.array,ctx,Device context (default is the current default context).,Device context BSTR,,,,,,,
97,mxnet.ndarray.contrib.arange_like,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n).Only used for imperative calls.",Context of output in format cpu gpu cpu_pinned BSTR Only used for imperative calls,,,,,,,
98,mxnet.ndarray.random_generalized_negative_binomial,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls.",Context of output in format cpu gpu cpu_pinned BSTR,,,,,,,
99,mxnet.ndarray.random_generalized_negative_binomial,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls.",Only used for imperative calls,,,,,,,
100,mxnet.ndarray.random.generalized_negative_binomial,ctx,Device context of output. Default is current context. Overridden by mu.context when mu is an NDArray.,Default is current context,,,,,,,
101,mxnet.ndarray.random.generalized_negative_binomial,ctx,Device context of output. Default is current context. Overridden by mu.context when mu is an NDArray.,Device context of output,,,,,,,
102,mxnet.ndarray.random.generalized_negative_binomial,ctx,Device context of output. Default is current context. Overridden by mu.context when mu is an NDArray.,Overridden by PARAM context when PARAM is an D_STRUCTURE,,,,,,,
103,mxnet.ndarray.random.randint,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Default is current context,,,,,,,
104,mxnet.ndarray.random.randint,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Device context of output,,,,,,,
105,mxnet.ndarray.random.randint,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Overridden by PARAM context when PARAM is an D_STRUCTURE,,,,,,,
106,mxnet.ndarray.random.randn,ctx,Device context of output. Default is current context. Overridden by loc.context when loc is an NDArray.,Default is current context,,,,,,,
107,mxnet.ndarray.random.randn,ctx,Device context of output. Default is current context. Overridden by loc.context when loc is an NDArray.,Device context of output,,,,,,,
108,mxnet.ndarray.random.randn,ctx,Device context of output. Default is current context. Overridden by loc.context when loc is an NDArray.,Overridden by PARAM context when PARAM is an D_STRUCTURE,,,,,,,
109,mxnet.ndarray.random.uniform,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Default is current context,,,,,,,
110,mxnet.ndarray.random.uniform,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Device context of output,,,,,,,
111,mxnet.ndarray.random.uniform,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Overridden by PARAM context when PARAM is an D_STRUCTURE,,,,,,,
112,mxnet.ndarray.sparse.row_sparse_array,ctx,Device context (default is the current default context).,Device context BSTR,,,,,,,
113,mxnet.ndarray.op.Convolution,cudnn_off,Turn off cudnn for this layer.,Turn off cudnn for this layer,,,,,,,
114,mxnet.ndarray.Deconvolution,cudnn_tune,Whether to pick convolution algorithm by running performance test.,Whether to pick convolution algorithm by running performance test,bool,,,,0,,
115,mxnet.contrib.ndarray.bipartite_matching,data,The input,The input,,,,,,,
116,mxnet.contrib.ndarray.fft,data,Input data to the FFTOp.,Input data to the FFTOp,,,,,,,
117,mxnet.contrib.ndarray.quantized_act,data,Input data.,Input data,,,,,,,
118,mxnet.ndarray.argmin,data,The input,The input,,,,,,,
119,mxnet.ndarray.broadcast_to,data,The input,The input,,,,,,,
120,mxnet.ndarray.choose_element_0index,data,The input array,The input D_STRUCTURE,,,D_STRUCTURE,,,,
121,mxnet.ndarray.contrib.backward_gradientmultiplier,data,source input,source input,,,,,,,
122,mxnet.ndarray.contrib.PSROIPooling,data,"Input data to the pooling operator, a 4D Feature maps",Input data to the pooling operator a CONSTANT_NUM D Feature maps,,,,,,,
123,mxnet.ndarray.depth_to_space,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
124,mxnet.ndarray.expm1,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
125,mxnet.ndarray.image.random_lighting,data,The input.,The input,,,,,,,
126,mxnet.ndarray.image.to_tensor,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
127,mxnet.ndarray.nanprod,data,The input,The input,,,,,,,
128,mxnet.ndarray.op.all_finite,data,Array,D_STRUCTURE,,,D_STRUCTURE,,,,
129,mxnet.ndarray.op.amp_cast,data,The input.,The input,,,,,,,
130,mxnet.ndarray.op.arccos,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
131,mxnet.ndarray.op.ctc_loss,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
132,mxnet.ndarray.op.CTCLoss,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
133,mxnet.ndarray.op.exp,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
134,mxnet.ndarray.op.gather_nd,data,data,data,,,,,,,
135,mxnet.ndarray.op.log,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
136,mxnet.ndarray.op.rcbrt,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
137,mxnet.ndarray.op.ROIPooling,data,"The input array to the pooling operator,  a 4D Feature maps",The input D_STRUCTURE to the pooling operator a CONSTANT_NUM D Feature maps,,,D_STRUCTURE,,CONSTANT_NUM,,
138,mxnet.ndarray.op.sample_multinomial,data,Distribution probabilities. Must sum to one on the last axis.,Distribution probabilities,,,,,,,
139,mxnet.ndarray.op.sample_multinomial,data,Distribution probabilities. Must sum to one on the last axis.,Must sum to one on the last axis,,,,,,,
140,mxnet.ndarray.op.SequenceMask,data,"n-dimensional input array of the form [max_sequence_length, batch_size, other_feature_dims] where n>2",n dimensional input D_STRUCTURE of the form BSTR where n REXPR,,,D_STRUCTURE,,REXPR,,
141,mxnet.ndarray.op.SoftmaxOutput,data,Input array.,Input D_STRUCTURE,,,D_STRUCTURE,,,,
142,mxnet.ndarray.op.square,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
143,mxnet.ndarray.op.swapaxes,data,Input array.,Input D_STRUCTURE,,,D_STRUCTURE,,,,
144,mxnet.ndarray.op.transpose,data,Source input,Source input,,,,,,,
145,mxnet.ndarray.op.unravel_index,data,Array of flat indices,D_STRUCTURE of flat indices,int,,D_STRUCTURE,,,,
146,mxnet.ndarray.radians,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
147,mxnet.ndarray.RNN,data,Input data to RNN,Input data to RNN,,,,,,,
148,mxnet.ndarray.scatter_nd,data,data,data,,,,,,,
149,mxnet.ndarray.shuffle,data,Data to be shuffled.,data to be shuffled,,,,,,,
150,mxnet.ndarray.sign,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
151,mxnet.ndarray.sin,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
152,mxnet.ndarray.SoftmaxOutput,data,Input array.,Input D_STRUCTURE,,,D_STRUCTURE,,,,
153,mxnet.ndarray.sparse.arcsinh,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
154,mxnet.ndarray.sparse.cosh,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
155,mxnet.ndarray.sparse.log,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
156,mxnet.ndarray.sparse.log2,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
157,mxnet.ndarray.sparse.retain,data,The input array for sparse_retain operator.,The input D_STRUCTURE for sparse_retain operator,,,D_STRUCTURE,,,,
158,mxnet.ndarray.sqrt,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
159,mxnet.ndarray.sum,data,The input,The input,,,,,,,
160,mxnet.ndarray.to_dlpack_for_write,data,input data.,input data,,,,,,,
161,mxnet.ndarray.transpose,data,Source input,Source input,,,,,,,
162,mxnet.ndarray.contrib.CTCLoss,data_lengths,Lengths of data for each of the samples. Only required when use_data_lengths is true.,Lengths of PARAM for each of the samples,int,,,,1,"[0,inf)",
163,mxnet.ndarray.contrib.CTCLoss,data_lengths,Lengths of data for each of the samples. Only required when use_data_lengths is true.,Only required when PARAM is CONSTANT_BOOL,,,,,,,
164,mxnet.image.CreateAugmenter,data_shape,Shape for output data,Shape for output data,int,,,,1,"[0,inf)",
165,mxnet.ndarray.rmspropalex_update,delta,delta,delta,,,,,,,
166,mxnet.context.cpu,device_id,The device id of the device. device_id is not needed for CPU. This is included to make interface compatible with GPU.,The device id of the device,int,,,,0,"[0,inf)",
167,mxnet.context.cpu,device_id,The device id of the device. device_id is not needed for CPU. This is included to make interface compatible with GPU.,This is included to make interface compatible with GPU,,,,,,,
168,mxnet.context.cpu,device_id,The device id of the device. device_id is not needed for CPU. This is included to make interface compatible with GPU.,device_id is not needed for CPU,int,,,,0,"[0,inf)",
169,mxnet.gluon.nn.Conv3D,dilation,Specifies the dilation rate to use for dilated convolution.,Specifies the dilation rate to use for dilated convolution,numeric,,,,,,
170,mxnet.ndarray.SwapAxis,dim2,the second axis to be swapped.,the second axis to be swapped,int,,,,0,,
171,mxnet.io.CSVIter,dtype,Output data type. `None` means no change.,Output data type,dtype,,,,,,
172,mxnet.io.CSVIter,dtype,Output data type. `None` means no change.,QSTR means no change,,,,,,,QSTR
173,mxnet.io.LibSVMIter,dtype,Output data type. `None` means no change.,Output data type,dtype,,,,,,
174,mxnet.io.LibSVMIter,dtype,Output data type. `None` means no change.,QSTR means no change,,,,,,,QSTR
175,mxnet.ndarray.arange,dtype,The data type of the NDArray. The default datatype is np.float32.,The data type of the D_STRUCTURE,dtype,,,,,,
176,mxnet.ndarray.arange,dtype,The data type of the NDArray. The default datatype is np.float32.,The default datatype is D_TYPE,,,,,,,
177,mxnet.ndarray.op.random_negative_binomial,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,,,,,,,
178,mxnet.ndarray.op.random_negative_binomial,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,dtype of the output in case this can t be inferred,dtype,,,,,,
179,mxnet.ndarray.random_uniform,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,,,,,,,
180,mxnet.ndarray.random_uniform,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,dtype of the output in case this can t be inferred,dtype,,,,,,
181,mxnet.ndarray.random.gamma,dtype,Data type of output samples. Default is 'float32',Data type of output samples,dtype,,,,,,
182,mxnet.ndarray.random.gamma,dtype,Data type of output samples. Default is 'float32',Default is QSTR,,,,,,,
183,mxnet.ndarray.random.generalized_negative_binomial,dtype,Data type of output samples. Default is 'float32',Data type of output samples,dtype,,,,,,
184,mxnet.ndarray.random.generalized_negative_binomial,dtype,Data type of output samples. Default is 'float32',Default is QSTR,,,,,,,
185,mxnet.ndarray.sample_exponential,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,,,,,,,
186,mxnet.ndarray.sample_exponential,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,dtype of the output in case this can t be inferred,dtype,,,,,,
187,mxnet.ndarray.topk,dtype,"DType of the output indices when ret_typ is ""indices"" or ""both"". An error will be raised if the selected data type cannot precisely represent the indices.",An error will be raised if the selected PARAM type cannot precisely represent the indices,,,,,,,
188,mxnet.ndarray.topk,dtype,"DType of the output indices when ret_typ is ""indices"" or ""both"". An error will be raised if the selected data type cannot precisely represent the indices.",dtype of the output indices when PARAM is QSTR,dtype,,,,,,
189,mxnet.ndarray.zeros,dtype,An optional value type (default is float32),An optional value type BSTR,dtype,,,,0,,
190,mxnet.ndarray.zeros,dtype,An optional value type (default is float32),An optional value type BSTR,dtype,,,,0,,
191,mxnet.contrib.ndarray.quantized_batch_norm,eps,Epsilon to prevent div 0. Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn.h when using cudnn (usually 1e-5),Epsilon to prevent div CONSTANT_NUM,numeric,,,,,,
192,mxnet.contrib.ndarray.quantized_batch_norm,eps,Epsilon to prevent div 0. Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn.h when using cudnn (usually 1e-5),Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn h when using cudnn BSTR,,,,,,,
193,mxnet.ndarray.op.BatchNorm,eps,Epsilon to prevent div 0. Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn.h when using cudnn (usually 1e-5),Epsilon to prevent div CONSTANT_NUM,numeric,,,,,,
194,mxnet.ndarray.op.BatchNorm,eps,Epsilon to prevent div 0. Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn.h when using cudnn (usually 1e-5),Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn h when using cudnn BSTR,,,,,,,
195,mxnet.gluon.nn.LayerNorm,epsilon,Small float added to variance to avoid dividing by zero.,Small D_TYPE added to variance to avoid dividing by zero,D_TYPE,,,,,,
196,mxnet.ndarray.op.rmspropalex_update,epsilon,A small constant for numerical stability.,A small constant for numerical stability,numeric,,,,0,,
197,mxnet.ndarray.rmspropalex_update,epsilon,A small constant for numerical stability.,A small constant for numerical stability,numeric,,,,0,,
198,mxnet.test_utils.assert_almost_equal,equal_nan,The flag determining how to treat NAN values in comparison,The flag determining how to treat NAN values in comparison,,,,,,,
199,mxnet.gluon.utils.split_data,even_split,"Whether to force all slices to have the same number of elements. If True, an error will be raised when num_slice does not evenly divide data.shape[batch_axis].",If CONSTANT_BOOL an error will be raised when PARAM does not evenly divide PARAM shape BSTR,bool,,,,0,,
200,mxnet.gluon.utils.split_data,even_split,"Whether to force all slices to have the same number of elements. If True, an error will be raised when num_slice does not evenly divide data.shape[batch_axis].",Whether to force all slices to have the same number of elements,bool,,,,0,,
201,mxnet.ndarray.op.nansum,exclude,Whether to perform reduction on axis that are NOT in axis instead.,Whether to perform reduction on PARAM that are NOT in PARAM instead,bool,,,,0,,
202,mxnet.ndarray.op.sum_axis,exclude,Whether to perform reduction on axis that are NOT in axis instead.,Whether to perform reduction on PARAM that are NOT in PARAM instead,bool,,,,0,,
203,mxnet.ndarray.sparse.mean,exclude,Whether to perform reduction on axis that are NOT in axis instead.,Whether to perform reduction on PARAM that are NOT in PARAM instead,bool,,,,0,,
204,mxnet.test_utils.check_symbolic_forward,expected,The expected output value   if type is list of np.ndarrayContains arrays corresponding to exe.outputs.,The expected output value if type is D_STRUCTURE of np ndarrayContains D_STRUCTURE corresponding to exe outputs,,,D_STRUCTURE,,,,
205,mxnet.contrib.ndarray.MultiProposal,feature_stride,"The size of the receptive field each unit in the convolution layer of the rpn,for example the product of all stride's prior to this layer.",The size of the receptive field each unit in the convolution layer of the rpn for example the product of all stride prior to this layer,numeric,,,,,,
206,mxnet.ndarray.BatchNorm,fix_gamma,Fix gamma while training,Fix PARAM while training,,,,,,,
207,mxnet.image.imdecode,flag,1 for three channel color output. 0 for grayscale output.,CONSTANT_NUM for grayscale output,,,,,,,CONSTANT_NUM
208,mxnet.image.imdecode,flag,1 for three channel color output. 0 for grayscale output.,CONSTANT_NUM for three channel color output,,,,,,,CONSTANT_NUM
209,mxnet.contrib.ndarray.quantized_fully_connected,flatten,Whether to collapse all but the first axis of the input data tensor.,Whether to collapse all but the first axis of the input PARAM D_STRUCTURE,bool,,,,0,,
210,mxnet.ndarray.utils.save,fname,The filename.,The filename,string,,,,0,,
211,mxnet.ndarray.op.dot,forward_stype,"The desired storage type of the forward output given by user, if thecombination of input storage types and this hint does not matchany implemented ones, the dot operator will perform fallback operationand still produce an output of the desired storage type.",The desired storage type of the forward output given by user if thecombination of input storage types and this hint does not matchany implemented ones the dot operator will perform fallback operationand still produce an output of the desired storage type,,,,,,,QSTR
212,mxnet.ndarray.lamb_update_phase2,g,Output of lamb_update_phase 1,Output of lamb_update_phase CONSTANT_NUM,,,,,,,
213,mxnet.ndarray.rmspropalex_update,g,g,g,,,,,,,
214,mxnet.test_utils.chi_square_check,generator,A function that is assumed to generate i.i.d samples from a specific distribution. generator(N) should generate N random samples.,A function that is assumed to generate i i d samples from a specific distribution,,,,,,,
215,mxnet.test_utils.chi_square_check,generator,A function that is assumed to generate i.i.d samples from a specific distribution. generator(N) should generate N random samples.,generator BSTR should generate N random samples,,,,,,,
216,mxnet.ndarray.sample_multinomial,get_prob,"Whether to also return the log probability of sampled result. This is usually used for differentiating through stochastic variables, e.g. in reinforcement learning.",in reinforcement learning,,,,,,,
217,mxnet.ndarray.sample_multinomial,get_prob,"Whether to also return the log probability of sampled result. This is usually used for differentiating through stochastic variables, e.g. in reinforcement learning.",This is usually used for differentiating through stochastic variables e g,,,,,,,
218,mxnet.ndarray.sample_multinomial,get_prob,"Whether to also return the log probability of sampled result. This is usually used for differentiating through stochastic variables, e.g. in reinforcement learning.",Whether to also return the log probability of sampled result,bool,,,,0,,
219,mxnet.ndarray.contrib.group_adagrad_update,grad,Gradient,Gradient,numeric,,,,,,
220,mxnet.ndarray.ftrl_update,grad,Gradient,Gradient,numeric,,,,,,
221,mxnet.ndarray.mp_lamb_update_phase1,grad,Gradient,Gradient,numeric,,,,,,
222,mxnet.ndarray.op.signum_update,grad,Gradient,Gradient,numeric,,,,,,
223,mxnet.ndarray.signum_update,grad,Gradient,Gradient,numeric,,,,,,
224,mxnet.test_utils.check_symbolic_backward,grad_req,"Gradient requirements. 'write', 'add' or 'null'.",Gradient requirements,,,,,,,
225,mxnet.test_utils.check_symbolic_backward,grad_req,"Gradient requirements. 'write', 'add' or 'null'.",QSTR,,,,,,,QSTR
226,mxnet.ndarray.MakeLoss,grad_scale,Gradient scale as a supplement to unary and binary operators,Gradient scale as a supplement to unary and binary operators,,,,,,,
227,mxnet.ndarray.contrib.PSROIPooling,group_size,fix group size,fix group size,numeric,,,,,,
228,mxnet.gluon.contrib.rnn.Conv1DGRUCell,h2h_dilate,Recurrent convolution dilate.,Recurrent convolution dilate,,,,,,,
229,mxnet.gluon.contrib.rnn.Conv2DLSTMCell,h2h_kernel,Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.,Only odd numbered sizes are supported,,,,,,,
230,mxnet.gluon.contrib.rnn.Conv2DLSTMCell,h2h_kernel,Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.,Recurrent convolution kernel sizes,int,,,,1,,
231,mxnet.contrib.ndarray.interleaved_matmul_encdec_qk,heads,Set number of heads,Set number of heads,,,,,,,
232,mxnet.gluon.contrib.rnn.LSTMPCell,hidden_size,Number of units in cell state symbol.,Number of units in cell state symbol,int,,,,0,"[0,inf)",
233,mxnet.gluon.rnn.LSTM,hidden_size,The number of features in the hidden state h.,The number of features in the hidden state h,int,,,,0,"[0,inf)",
234,mxnet.ndarray.random.uniform,high,Upper boundary of the output interval. All values generated will be less than high. The default value is 1.0.,All values generated will be less than high,,,,,,,
235,mxnet.ndarray.random.uniform,high,Upper boundary of the output interval. All values generated will be less than high. The default value is 1.0.,The default value is CONSTANT_NUM,,,,,,,
236,mxnet.ndarray.random.uniform,high,Upper boundary of the output interval. All values generated will be less than high. The default value is 1.0.,Upper boundary of the output interval,,,,,,,
237,mxnet.ndarray.contrib.calibrate_entropy,hist_edges,A ndarray/symbol of type float32,A D_STRUCTURE symbol of type D_TYPE,D_TYPE,,D_STRUCTURE,,,,
238,mxnet.gluon.contrib.rnn.Conv2DGRUCell,i2h_bias_initializer,Initializer for the input convolution bias vectors.,Initializer for the input convolution bias vectors,,,,,,,
239,mxnet.gluon.contrib.rnn.Conv1DRNNCell,i2h_dilate,Input convolution dilate.,Input convolution dilate,,,,,,,
240,mxnet.gluon.contrib.rnn.Conv3DGRUCell,i2h_kernel,Input convolution kernel sizes.,Input convolution kernel sizes,numeric,,,,,,
241,mxnet.gluon.rnn.RNNCell,i2h_weight_initializer,"Initializer for the input weights matrix, used for the linear transformation of the inputs.",Initializer for the input weights matrix used for the linear transformation of the inputs,,,,,,,
242,mxnet.contrib.ndarray.box_nms,id_index,"Optional, index of the class categories, -1 to disable.",Optional index of the class categories CONSTANT_NUM to disable,int,,,,0,,
243,mxnet.ndarray.contrib.box_nms,id_index,"Optional, index of the class categories, -1 to disable.",Optional index of the class categories CONSTANT_NUM to disable,int,,,,0,,
244,mxnet.ndarray.op.SoftmaxOutput,ignore_label,"The instances whose labels == ignore_label will be ignored during backward, if use_ignore is set to `true`).",The instances whose labels ignore_label will be ignored during backward if PARAM is set to CONSTANT_BOOL,,,,,,,
245,mxnet.io.MNISTIter,image,Dataset Param: Mnist image path.,Dataset Param Mnist image path,,,,,,,
246,mxnet.recordio.pack_img,img_fmt,"Encoding of the image (.jpg for JPEG, .png for PNG).",Encoding of the image BSTR,,,,,,,
247,mxnet.gluon.nn.Conv2DTranspose,in_channels,"The number of input channels to this layer. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",If not specified initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data,,,,,,,
248,mxnet.gluon.nn.Conv2DTranspose,in_channels,"The number of input channels to this layer. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",The number of input PARAM to this layer,int,,,,0,"[0,inf)",
249,mxnet.ndarray.pick,index,The index array,The index D_STRUCTURE,,,D_STRUCTURE,,,,
250,mxnet.contrib.ndarray.SparseEmbedding,input_dim,Vocabulary size of the input indices.,Vocabulary size of the input indices,int,,,,0,"[0,inf)",
251,mxnet.gluon.contrib.rnn.Conv2DRNNCell,input_shape,"Input tensor shape at each time step for each sample, excluding dimension of the batch size and sequence length. Must be consistent with conv_layout. For example, for layout 'NCHW' the shape should be (C, H, W).",For example for layout QSTR the shape should be BSTR,,,,,,,
252,mxnet.gluon.contrib.rnn.Conv2DRNNCell,input_shape,"Input tensor shape at each time step for each sample, excluding dimension of the batch size and sequence length. Must be consistent with conv_layout. For example, for layout 'NCHW' the shape should be (C, H, W).",Input D_STRUCTURE shape at each time step for each sample excluding dimension of the batch size and D_STRUCTURE length,int,,,,1,"[0,inf)",
253,mxnet.gluon.contrib.rnn.Conv2DRNNCell,input_shape,"Input tensor shape at each time step for each sample, excluding dimension of the batch size and sequence length. Must be consistent with conv_layout. For example, for layout 'NCHW' the shape should be (C, H, W).",Must be consistent with PARAM,,,,,,,
254,mxnet.gluon.rnn.RNN,input_size,"The number of expected features in the input x. If not specified, it will be inferred from input.",If not specified it will be inferred from input,,,,,,,
255,mxnet.gluon.rnn.RNN,input_size,"The number of expected features in the input x. If not specified, it will be inferred from input.",The number of expected features in the input x,int,,,,0,"[0,inf)",
256,mxnet.gluon.nn.SymbolBlock,inputs,The Variables in output's argument that should be used as inputs.,The Variables in output argument that should be used as inputs,,,,,,,
257,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",BSTR,,,,,,,
258,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",But when the image is zoomed it is similar to the Nearest Neighbors method,,,,,,,
259,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Area based BSTR,,,,,,,CONSTANT_NUM
260,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Bicubic interpolation over 4x4 pixel neighborhood,,,,,,,CONSTANT_NUM
261,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Bilinear interpolation,,,,,,,CONSTANT_NUM
262,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Cubic for enlarge area for shrink bilinear for others CONSTANT_NUM Random select from interpolation method metioned above,,,,,,,CONSTANT_NUM
263,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Lanczos interpolation over 8x8 pixel neighborhood,,,,,,,CONSTANT_NUM
264,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",Interpolation method default cv2 INTER_LINEAR,,,,,,,
265,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",It may be a preferred method for image decimation as it gives moire free results,,,,,,,
266,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",More details can be found in the documentation of OpenCV please refer to http docs opencv org master da d54 group__imgproc__transform html,,,,,,,
267,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",Note When shrinking an image it will generally look best with AREA based interpolation whereas when enlarging an image it will generally look best with Bicubic BSTR,,,,,,,
268,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",Possible values CONSTANT_NUM Nearest Neighbors Interpolation,,,,,,,CONSTANT_NUM
269,mxnet.ndarray.op.random_pdf_generalized_negative_binomial,is_log,"If set, compute the density of the log-probability instead of the probability.",If set compute the density of the log probability instead of the probability,,,,,,,
270,mxnet.ndarray.random_pdf_gamma,is_log,"If set, compute the density of the log-probability instead of the probability.",If set compute the density of the log probability instead of the probability,,,,,,,
271,mxnet.ndarray.op.random_negative_binomial,k,Limit of unsuccessful experiments.,Limit of unsuccessful experiments,,,,,,,
272,mxnet.ndarray.argmin,keepdims,"If this is set to True, the reduced axis is left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced PARAM is left in the result as dimension with size one,bool,,,,0,,
273,mxnet.ndarray.min_axis,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
274,mxnet.ndarray.nansum,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
275,mxnet.ndarray.op.max,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
276,mxnet.ndarray.op.max_axis,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
277,mxnet.ndarray.op.nanprod,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
278,mxnet.ndarray.Pooling,kernel,"Pooling kernel size: (y, x) or (d, y, x)",Pooling kernel size BSTR,,,,BSTR,,,
279,mxnet.gluon.nn.Conv1DTranspose,kernel_size,Specifies the dimensions of the convolution window.,Specifies the dimensions of the convolution window,int,,,,1,,
280,mxnet.ndarray.contrib.CTCLoss,label,Ground-truth labels for the loss.,Ground truth labels for the loss,,,,,,,
281,mxnet.ndarray.ctc_loss,label,Ground-truth labels for the loss.,Ground truth labels for the loss,,,,,,,
282,mxnet.ndarray.LogisticRegressionOutput,label,Input label to the function.,Input label to the function,,,,,,,
283,mxnet.ndarray.op.softmax_cross_entropy,label,Input label,Input label,,,,,,,
284,mxnet.ndarray.sparse.MAERegressionOutput,label,Input label to the function.,Input label to the function,,,,,,,
285,mxnet.ndarray.contrib.CTCLoss,label_lengths,Lengths of labels for each of the samples. Only required when use_label_lengths is true.,Lengths of labels for each of the samples,int,,,,1,"[0,inf)",
286,mxnet.ndarray.contrib.CTCLoss,label_lengths,Lengths of labels for each of the samples. Only required when use_label_lengths is true.,Only required when PARAM is CONSTANT_BOOL,,,,,,,
287,mxnet.ndarray.op.CTCLoss,label_lengths,Lengths of labels for each of the samples. Only required when use_label_lengths is true.,Lengths of labels for each of the samples,int,,,,1,"[0,inf)",
288,mxnet.ndarray.op.CTCLoss,label_lengths,Lengths of labels for each of the samples. Only required when use_label_lengths is true.,Only required when PARAM is CONSTANT_BOOL,,,,,,,
289,mxnet.gluon.nn.Conv2D,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",Convolution is applied on the QSTR dimensions,,,,,,,
290,mxnet.gluon.nn.Conv2D,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",Dimension ordering of data and weight,,,,,,,
291,mxnet.gluon.nn.Conv2D,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",Only supports QSTR layout for now,,,,,,,QSTR
292,mxnet.gluon.nn.Conv2D,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",QSTR stands for batch channel height and width dimensions respectively,,,,,,,
293,mxnet.gluon.nn.MaxPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Pooling is applied on the W dimension.",Dimension ordering of data and out QSTR,,,,,,,
294,mxnet.gluon.nn.MaxPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Pooling is applied on the W dimension.",Pooling is applied on the W dimension,,,,,,,
295,mxnet.gluon.nn.MaxPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Pooling is applied on the W dimension.",QSTR stands for batch channel and width BSTR dimensions respectively,,,,,,,
296,mxnet.gluon.nn.MaxPool2D,layout,"Dimension ordering of data and out ('NCHW' or 'NHWC'). 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. padding is applied on 'H' and 'W' dimension.",Dimension ordering of data and out QSTR,,,,,,,
297,mxnet.gluon.nn.MaxPool2D,layout,"Dimension ordering of data and out ('NCHW' or 'NHWC'). 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. padding is applied on 'H' and 'W' dimension.",PARAM is applied on QSTR dimension,,,,,,,
298,mxnet.gluon.nn.MaxPool2D,layout,"Dimension ordering of data and out ('NCHW' or 'NHWC'). 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. padding is applied on 'H' and 'W' dimension.",QSTR stands for batch channel height and width dimensions respectively,,,,,,,
299,mxnet.gluon.nn.MaxPool3D,layout,"Dimension ordering of data and out ('NCDHW' or 'NDHWC'). 'N', 'C', 'H', 'W', 'D' stands for batch, channel, height, width and depth dimensions respectively. padding is applied on 'D', 'H' and 'W' dimension.",Dimension ordering of data and out QSTR,,,,,,,
300,mxnet.gluon.nn.MaxPool3D,layout,"Dimension ordering of data and out ('NCDHW' or 'NDHWC'). 'N', 'C', 'H', 'W', 'D' stands for batch, channel, height, width and depth dimensions respectively. padding is applied on 'D', 'H' and 'W' dimension.",PARAM is applied on QSTR dimension,,,,,,,
301,mxnet.gluon.nn.MaxPool3D,layout,"Dimension ordering of data and out ('NCDHW' or 'NDHWC'). 'N', 'C', 'H', 'W', 'D' stands for batch, channel, height, width and depth dimensions respectively. padding is applied on 'D', 'H' and 'W' dimension.",QSTR stands for batch channel height width and depth dimensions respectively,,,,,,,
302,mxnet.gluon.rnn.RNN,layout,"The format of input and output tensors. T, N and C stand for sequence length, batch size, and feature dimensions respectively.",T N and C stand for D_STRUCTURE length batch size and feature dimensions respectively,,,,,,,
303,mxnet.gluon.rnn.RNN,layout,"The format of input and output tensors. T, N and C stand for sequence length, batch size, and feature dimensions respectively.",The format of input and output D_STRUCTURE,,,,,,,
304,mxnet.ndarray.op.mp_sgd_update,lazy_update,"If true, lazy updates are applied if gradient's stype is row_sparse.",If CONSTANT_BOOL lazy updates are applied if gradient stype is row_sparse,bool,,,,0,,
305,mxnet.ndarray.op.sgd_mom_update,lazy_update,"If true, lazy updates are applied if gradient's stype is row_sparse and both weight and momentum have the same stype",If CONSTANT_BOOL lazy updates are applied if gradient stype is row_sparse and both PARAM and PARAM have the same stype,bool,,,,0,,
306,mxnet.image.copyMakeBorder,left,Left margin.,left margin,,,,,,,
307,mxnet.ndarray.batch_dot,lhs,The first input,The first input,,,,,,,
308,mxnet.ndarray.broadcast_not_equal,lhs,First input to the function,First input to the function,,,,,,,
309,mxnet.ndarray.elemwise_div,lhs,first input,first input,,,,,,,
310,mxnet.ndarray.minimum,lhs,First array to be compared.,First D_STRUCTURE to be compared,,,D_STRUCTURE,,,,
311,mxnet.ndarray.op.broadcast_add,lhs,First input to the function,First input to the function,,,,,,,
312,mxnet.ndarray.op.elemwise_add,lhs,first input,first input,,,,,,,
313,mxnet.ndarray.op.reshape_like,lhs,First input.,First input,,,,,,,
314,mxnet.ndarray.sparse.add,lhs,First array to be added.,First D_STRUCTURE to be added,,,D_STRUCTURE,,,,
315,mxnet.ndarray.sparse.elemwise_add,lhs,first input,first input,,,,,,,
316,mxnet.ndarray.sparse.elemwise_sub,lhs,first input,first input,,,,,,,
317,mxnet.ndarray.subtract,lhs,First array to be subtracted.,First D_STRUCTURE to be subtracted,,,D_STRUCTURE,,,,
318,mxnet.contrib.ndarray.BilinearResize2D,like,Resize data to it's shape,Resize PARAM to it shape,,,,,,,
319,mxnet.ndarray.random_normal,loc,Mean of the distribution.,Mean of the distribution,numeric,,,,0,,
320,mxnet.ndarray.random.normal_like,loc,Mean of the distribution.,Mean of the distribution,numeric,,,,0,,
321,mxnet.contrib.ndarray.MultiBoxDetection,loc_pred,Location regression predictions.,Location regression predictions,,,,,,,
322,mxnet.ndarray.random.uniform,low,Lower boundary of the output interval. All values generated will be greater than or equal to low. The default value is 0.,All values generated will be greater than or equal to low,,,,,,,
323,mxnet.ndarray.random.uniform,low,Lower boundary of the output interval. All values generated will be greater than or equal to low. The default value is 0.,Lower boundary of the output interval,,,,,,,
324,mxnet.ndarray.random.uniform,low,Lower boundary of the output interval. All values generated will be greater than or equal to low. The default value is 0.,The default value is CONSTANT_NUM,,,,,,,
325,mxnet.ndarray.op.linalg_trsm,lower,"True if the triangular matrix is lower triangular, false if it is upper triangular.",CONSTANT_BOOL if the triangular matrix is lower triangular CONSTANT_BOOL if it is upper triangular,bool,,,,0,,
326,mxnet.ndarray.mp_lamb_update_phase2,lr,Learning rate,Learning rate,float,,,,0,"[0,1]",
327,mxnet.ndarray.op.adam_update,lr,Learning rate,Learning rate,float,,,,0,"[0,1]",
328,mxnet.ndarray.op.ftml_update,lr,Learning rate.,Learning rate,float,,,,0,"[0,1]",
329,mxnet.ndarray.op.ftrl_update,lr,Learning rate,Learning rate,float,,,,0,"[0,1]",
330,mxnet.ndarray.sgd_mom_update,lr,Learning rate,Learning rate,float,,,,0,"[0,1]",
331,mxnet.ndarray.op.multi_mp_sgd_mom_update,lrs,Learning rates.,Learning rates,float,,,,1,"[0,1]",
332,mxnet.ndarray.op.multi_sgd_mom_update,lrs,Learning rates.,Learning rates,float,,,,1,"[0,1]",
333,mxnet.ndarray.RNN,lstm_state_clip_nan,"Whether to stop NaN from propagating in state by clipping it to min/max. If clipping range is not specified, this option is ignored.",If clipping range is not specified this option is ignored,,,,,,,
334,mxnet.ndarray.RNN,lstm_state_clip_nan,"Whether to stop NaN from propagating in state by clipping it to min/max. If clipping range is not specified, this option is ignored.",Whether to stop NaN from propagating in PARAM by clipping it to min max,bool,,,,0,,
335,mxnet.contrib.ndarray.box_encode,matches,"(B, N) value range [0, M)",BSTR value range BSTR,,,,BSTR,,BSTR,
336,mxnet.ndarray.contrib.quantized_conv,max_bias,Maximum value of bias.,Maximum value of PARAM,numeric,,,,0,,
337,mxnet.ndarray.contrib.quantized_fully_connected,max_bias,Maximum value of bias.,Maximum value of PARAM,numeric,,,,0,,
338,mxnet.ndarray.BatchNorm,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to by quantized batch norm op to calculate primitive scale.Note: this calib_range is to calib bn output.",If present it will be used to by quantized batch norm op to calculate primitive scale Note this calib_range is to calib bn output,,,,,,,
339,mxnet.ndarray.BatchNorm,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to by quantized batch norm op to calculate primitive scale.Note: this calib_range is to calib bn output.",The maximum scalar value in the form of D_TYPE obtained through calibration,D_TYPE,,,,0,,
340,mxnet.ndarray.contrib.requantize,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to requantize the int32 data into int8.",If present it will be used to requantize the D_TYPE PARAM into D_TYPE,,,,,,,
341,mxnet.ndarray.contrib.requantize,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to requantize the int32 data into int8.",The maximum scalar value in the form of D_TYPE obtained through calibration,D_TYPE,,,,0,,
342,mxnet.contrib.ndarray.quantized_batch_norm,max_data,Maximum value of data.,Maximum value of PARAM,numeric,,,,0,,
343,mxnet.io.ImageDetRecordIter,max_random_contrast,Augmentation Param: Maximum random value of delta contrast.,Augmentation Param Maximum random value of delta contrast,numeric,,,,,,
344,mxnet.ndarray.contrib.quantize,max_range,The maximum scalar value possibly produced for the input,The maximum scalar value possibly produced for the input,,,,,0,,
345,mxnet.contrib.ndarray.hawkesll,max_time,the length of the interval where the processes were sampled,the length of the interval where the processes were sampled,int,,,,0,"[0,inf)",
346,mxnet.ndarray.contrib.quantized_conv,max_weight,Maximum value of weight.,Maximum value of PARAM,numeric,,,,0,,
347,mxnet.io.ImageRecordIter,mean_g,The mean value to be subtracted on the G channel,The mean value to be subtracted on the G channel,numeric,,,,,,
348,mxnet.ndarray.contrib.quantize,min_range,The minimum scalar value possibly produced for the input,The minimum scalar value possibly produced for the input,,,,,0,,
349,mxnet.ndarray.contrib.BilinearResize2D,mode,"resizing mode. ""simple"" - output height equals parameter ""height"" if ""scale_height"" parameter is not defined or input height multiplied by ""scale_height"" otherwise. Same for width;""odd_scale"" - if original height or width is odd, then result height is calculated like result_h = (original_h - 1) * scale + 1; for scale > 1 the result shape would be like if we did deconvolution with kernel = (1, 1) and stride = (height_scale, width_scale); and for scale < 1 shape would be like we did convolution with kernel = (1, 1) and stride = (int(1 / height_scale), int( 1/ width_scale);""like"" - resize first input to the height and width of second input; ""to_even_down"" - resize input to nearest lower even height and width (if original height is odd then result height = original height - 1);""to_even_up"" - resize input to nearest bigger even height and width (if original height is odd then result height = original height + 1);""to_odd_down"" - resize input to nearest odd height and width (if original height is odd then result height = original height - 1);""to_odd_up"" - resize input to nearest odd height and width (if original height is odd then result height = original height + 1);",QSTR output PARAM equals parameter PARAM if PARAM parameter is not defined or input PARAM multiplied by PARAM otherwise,,,,,,,QSTR
350,mxnet.ndarray.contrib.BilinearResize2D,mode,"resizing mode. ""simple"" - output height equals parameter ""height"" if ""scale_height"" parameter is not defined or input height multiplied by ""scale_height"" otherwise. Same for width;""odd_scale"" - if original height or width is odd, then result height is calculated like result_h = (original_h - 1) * scale + 1; for scale > 1 the result shape would be like if we did deconvolution with kernel = (1, 1) and stride = (height_scale, width_scale); and for scale < 1 shape would be like we did convolution with kernel = (1, 1) and stride = (int(1 / height_scale), int( 1/ width_scale);""like"" - resize first input to the height and width of second input; ""to_even_down"" - resize input to nearest lower even height and width (if original height is odd then result height = original height - 1);""to_even_up"" - resize input to nearest bigger even height and width (if original height is odd then result height = original height + 1);""to_odd_down"" - resize input to nearest odd height and width (if original height is odd then result height = original height - 1);""to_odd_up"" - resize input to nearest odd height and width (if original height is odd then result height = original height + 1);",resizing mode,,,,,,,
351,mxnet.ndarray.contrib.BilinearResize2D,mode,"resizing mode. ""simple"" - output height equals parameter ""height"" if ""scale_height"" parameter is not defined or input height multiplied by ""scale_height"" otherwise. Same for width;""odd_scale"" - if original height or width is odd, then result height is calculated like result_h = (original_h - 1) * scale + 1; for scale > 1 the result shape would be like if we did deconvolution with kernel = (1, 1) and stride = (height_scale, width_scale); and for scale < 1 shape would be like we did convolution with kernel = (1, 1) and stride = (int(1 / height_scale), int( 1/ width_scale);""like"" - resize first input to the height and width of second input; ""to_even_down"" - resize input to nearest lower even height and width (if original height is odd then result height = original height - 1);""to_even_up"" - resize input to nearest bigger even height and width (if original height is odd then result height = original height + 1);""to_odd_down"" - resize input to nearest odd height and width (if original height is odd then result height = original height - 1);""to_odd_up"" - resize input to nearest odd height and width (if original height is odd then result height = original height + 1);",Same for PARAM QSTR if original PARAM or PARAM is odd then result PARAM is calculated PARAM result_h BSTR scale CONSTANT_NUM for scale REXPR the result shape would be PARAM if we did deconvolution with kernel BSTR and stride BSTR and for scale REXPR shape would be PARAM we did convolution with kernel BSTR and stride BSTR PARAM resize first input to the PARAM and PARAM of second input QSTR resize input to nearest lower even PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM QSTR resize input to nearest bigger even PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM QSTR resize input to nearest odd PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM QSTR resize input to nearest odd PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM,,,,,,,QSTR
352,mxnet.ndarray.Dropout,mode,Whether to only turn on dropout during training or to also turn on for inference.,Whether to only turn on dropout during training or to also turn on for inference,bool,,,,0,,
353,mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",Default is QSTR,,,,,,,
354,mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",QSTR means clip to the range,,,,,,,QSTR
355,mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",QSTR means to wrap around,,,,,,,QSTR
356,mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",So if all indices mentioned are too large they are replaced by the PARAM that addresses the last element along an PARAM,,,,,,,
357,mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",Specify how PARAM of bound indices behave,,,,,,,
358,mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",Default is QSTR,,,,,,,
359,mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",QSTR means clip to the range,,,,,,,QSTR
360,mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",QSTR means to raise an error when index PARAM of range,,,,,,,QSTR
361,mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",QSTR means to wrap around,,,,,,,QSTR
362,mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",So if all PARAM mentioned are too large they are replaced by the index that addresses the last element along an PARAM,,,,,,,
363,mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",Specify how PARAM of bound PARAM bahave,,,,,,,
364,mxnet.ndarray.multi_sgd_mom_update,momentum,The decay rate of momentum estimates at each epoch.,The decay rate of momentum estimates at each epoch,numeric,,,,0,,
365,mxnet.ndarray.op.multi_mp_sgd_mom_update,momentum,The decay rate of momentum estimates at each epoch.,The decay rate of momentum estimates at each epoch,numeric,,,,0,,
366,mxnet.ndarray.BatchNorm,moving_mean,running mean of input,running mean of input,numeric,,,,,,
367,mxnet.ndarray.op.random_generalized_negative_binomial,mu,Mean of the negative binomial distribution.,Mean of the negative binomial distribution,numeric,,,,0,,
368,mxnet.ndarray.sample_generalized_negative_binomial,mu,Means of the distributions.,Means of the distributions,numeric,,,,1,,
369,mxnet.gluon.model_zoo.vision.get_model,name,Name of the model.,name of the model,string,,,,0,,
370,mxnet.contrib.ndarray.quantized_fully_connected,no_bias,Whether to disable bias parameter.,Whether to disable PARAM parameter,bool,,,,0,,
371,mxnet.test_utils.verify_generator,nsamples,The number of samples to generate for the testing,The number of samples to generate for the testing,int,,,,0,"[0,inf)",
372,mxnet.ndarray.LRN,nsize,normalization window width in elements.,normalization window width in elements,numeric,,,,,"[0,inf)",
373,mxnet.ndarray.UpSampling,num_filter,"Input filter. Only used by bilinear sample_type.Since bilinear upsampling uses deconvolution, num_filters is set to the number of channels.",Input filter,,,,,,,
374,mxnet.ndarray.UpSampling,num_filter,"Input filter. Only used by bilinear sample_type.Since bilinear upsampling uses deconvolution, num_filters is set to the number of channels.",Only used by bilinear PARAM Since bilinear upsampling uses deconvolution num_filters is set to the number of channels,,,,,,,
375,mxnet.gluon.nn.GroupNorm,num_groups,Number of groups to separate the channel axis into.,Number of groups to separate the channel axis into,int,,,,0,"[0,inf)",
376,mxnet.ndarray.op.GroupNorm,num_groups,Total number of groups.,Total number of groups,int,,,,0,"[0,inf)",
377,mxnet.ndarray.split,num_outputs,Number of splits. Note that this should evenly divide the length of the axis.,Note that this should evenly divide the length of the PARAM,,,,,,,
378,mxnet.ndarray.split,num_outputs,Number of splits. Note that this should evenly divide the length of the axis.,Number of splits,int,,,,0,"[0,inf)",
379,mxnet.io.ImageDetRecordIter,num_parts,partition the data into multiple parts,partition the data into multiple parts,,,,,,,
380,mxnet.contrib.ndarray.calibrate_entropy,num_quantized_bins,The number of quantized bins.,The number of quantized bins,int,,,,0,"[0,inf)",
381,mxnet.test_utils.np_reduce,numpy_reduce_func,A NumPy reducing function like `np.sum` or `np.max`.,A NumPy reducing function like np sum QSTR np max,,,,,,,
382,mxnet.ndarray.linalg.extracttrian,offset,"Offset of the diagonal versus the main diagonal. 0 corresponds to the main diagonal, a negative/positive value to diagonals below/above the main diagonal.",CONSTANT_NUM corresponds to the main diagonal a negative positive value to diagonals below above the main diagonal,,,,,,,CONSTANT_NUM
383,mxnet.ndarray.linalg.extracttrian,offset,"Offset of the diagonal versus the main diagonal. 0 corresponds to the main diagonal, a negative/positive value to diagonals below/above the main diagonal.",offset of the diagonal versus the main diagonal,,,,,,,
384,mxnet.contrib.onnx.export_model,onnx_file_path,Path where to save the generated onnx file,Path where to save the generated onnx file,string,,,,0,,
385,mxnet.contrib.ndarray.AdaptiveAvgPooling2D,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
386,mxnet.contrib.ndarray.allclose,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
387,mxnet.contrib.ndarray.fft,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
388,mxnet.contrib.ndarray.getnnz,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
389,mxnet.contrib.ndarray.MultiBoxDetection,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
390,mxnet.contrib.ndarray.ROIAlign,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
391,mxnet.contrib.ndarray.SparseEmbedding,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
392,mxnet.image.imresize,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
393,mxnet.ndarray.Activation,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
394,mxnet.ndarray.arccos,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
395,mxnet.ndarray.arctan,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
396,mxnet.ndarray.arctanh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
397,mxnet.ndarray.broadcast_axes,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
398,mxnet.ndarray.broadcast_greater,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
399,mxnet.ndarray.broadcast_logical_and,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
400,mxnet.ndarray.broadcast_mul,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
401,mxnet.ndarray.broadcast_plus,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
402,mxnet.ndarray.cast_storage,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
403,mxnet.ndarray.contrib.backward_hawkesll,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
404,mxnet.ndarray.contrib.CTCLoss,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
405,mxnet.ndarray.contrib.quantized_batch_norm,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
406,mxnet.ndarray.contrib.quantized_conv,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
407,mxnet.ndarray.contrib.quantized_fully_connected,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
408,mxnet.ndarray.contrib.round_ste,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
409,mxnet.ndarray.Dropout,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
410,mxnet.ndarray.ElementWiseSum,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
411,mxnet.ndarray.erfinv,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
412,mxnet.ndarray.LayerNorm,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
413,mxnet.ndarray.linalg_gelqf,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
414,mxnet.ndarray.linalg_trsm,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
415,mxnet.ndarray.MAERegressionOutput,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
416,mxnet.ndarray.MakeLoss,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
417,mxnet.ndarray.multi_mp_sgd_mom_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
418,mxnet.ndarray.ones,out,The output NDArray (default is None).,The output D_STRUCTURE BSTR,,,D_STRUCTURE,,,,
419,mxnet.ndarray.ones_like,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
420,mxnet.ndarray.op.Activation,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
421,mxnet.ndarray.op.arccosh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
422,mxnet.ndarray.op.broadcast_greater_equal,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
423,mxnet.ndarray.op.broadcast_to,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
424,mxnet.ndarray.op.cast_storage,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
425,mxnet.ndarray.op.ceil,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
426,mxnet.ndarray.op.concat,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
427,mxnet.ndarray.op.diag,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
428,mxnet.ndarray.op.exp,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
429,mxnet.ndarray.op.fix,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
430,mxnet.ndarray.op.ftml_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
431,mxnet.ndarray.op.linalg_gelqf,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
432,mxnet.ndarray.op.log1p,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
433,mxnet.ndarray.op.mp_lamb_update_phase1,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
434,mxnet.ndarray.op.nag_mom_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
435,mxnet.ndarray.op.nansum,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
436,mxnet.ndarray.op.pad,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
437,mxnet.ndarray.op.random_poisson,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
438,mxnet.ndarray.op.sample_poisson,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
439,mxnet.ndarray.op.slice_axis,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
440,mxnet.ndarray.preloaded_multi_mp_sgd_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
441,mxnet.ndarray.random.normal,out,Store output to an existing NDArray.,Store output to an existing D_STRUCTURE,,,,,,,
442,mxnet.ndarray.random.normal_like,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
443,mxnet.ndarray.sample_exponential,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
444,mxnet.ndarray.SequenceReverse,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
445,mxnet.ndarray.shuffle,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
446,mxnet.ndarray.sinh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
447,mxnet.ndarray.space_to_depth,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
448,mxnet.ndarray.sparse.cosh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
449,mxnet.ndarray.sparse.elemwise_add,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
450,mxnet.ndarray.sparse.floor,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
451,mxnet.ndarray.sparse.log,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
452,mxnet.ndarray.sqrt,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
453,mxnet.ndarray.take,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
454,mxnet.contrib.ndarray.dequantize,out_type,Output data type.,Output PARAM type,dtype,,,,,,
455,mxnet.ndarray.contrib.quantized_batch_norm,output_mean_var,Output the mean and inverse std,Output the mean and inverse std,numeric,,,,,,
456,mxnet.ndarray.GroupNorm,output_mean_var,Output the mean and std calculated along the given axis.,Output the mean and std calculated along the given axis,numeric,,,,,,
457,mxnet.test_utils.download,overwrite,"Default is false, which means skipping download if the local file exists. If true, then download the url to overwrite the local file if exists.",Default is CONSTANT_BOOL which means skipping download if the local file exists,bool,,,,0,,
458,mxnet.test_utils.download,overwrite,"Default is false, which means skipping download if the local file exists. If true, then download the url to overwrite the local file if exists.",If CONSTANT_BOOL then download the PARAM to overwrite the local file if exists,bool,,,,0,,
459,mxnet.ndarray.random.negative_binomial_like,p,Failure probability in each experiment.,Failure probability in each experiment,float,,,,,"[0,1]",
460,mxnet.ndarray.sample_negative_binomial,p,Failure probabilities in each experiment.,Failure probabilities in each experiment,float,,,,,"[0,1]",
461,mxnet.gluon.nn.Conv3DTranspose,padding,"If padding is non-zero, then the input is implicitly zero-padded on both sides for padding number of points",If padding is non zero then the input is implicitly zero padded on both sides for padding number of points,,,,,,,
462,mxnet.gluon.contrib.rnn.Conv3DGRUCell,params,Container for weight sharing between cells. Created if None.,Container for weight sharing between cells,,,,,,,
463,mxnet.gluon.contrib.rnn.Conv3DGRUCell,params,Container for weight sharing between cells. Created if None.,Created if None,,,,,,,
464,mxnet.gluon.contrib.rnn.Conv3DLSTMCell,params,Container for weight sharing between cells. Created if None.,Container for weight sharing between cells,,,,,,,
465,mxnet.gluon.contrib.rnn.Conv3DLSTMCell,params,Container for weight sharing between cells. Created if None.,Created if None,,,,,,,
466,mxnet.gluon.contrib.rnn.Conv3DRNNCell,params,Container for weight sharing between cells. Created if None.,Container for weight sharing between cells,,,,,,,
467,mxnet.gluon.contrib.rnn.Conv3DRNNCell,params,Container for weight sharing between cells. Created if None.,Created if None,,,,,,,
468,mxnet.callback.do_checkpoint,period,Interval (number of epochs) between checkpoints. Default period is 1.,Default period is CONSTANT_NUM,,,,,,,
469,mxnet.callback.do_checkpoint,period,Interval (number of epochs) between checkpoints. Default period is 1.,Interval BSTR between checkpoints,,,,,,,
470,mxnet.callback.log_train_metric,period,The number of batch to log the training evaluation metric.,The number of batch to log the training evaluation metric,int,,,,0,"[0,inf)",
471,mxnet.gluon.nn.AvgPool1D,pool_size,Size of the average pooling windows.,Size of the average pooling windows,int,,,,,,
472,mxnet.contrib.ndarray.ROIAlign,pooled_size,"ROI Align output roi feature map height and width: (h, w)",ROI Align output roi feature map height and width BSTR,,,,BSTR,,,
473,mxnet.contrib.ndarray.RROIAlign,pooled_size,"RROI align output shape (h,w)",RROI align output shape BSTR,,,,BSTR,,,
474,mxnet.ndarray.op.ROIPooling,pooled_size,"ROI pooling output shape (h,w)",ROI pooling output shape BSTR,,,,BSTR,,,
475,mxnet.ndarray.contrib.quantized_pooling,pooling_convention,Pooling convention to be applied.,Pooling convention to be applied,,,,,,,
476,mxnet.ndarray.op.Pooling,pooling_convention,Pooling convention to be applied.,Pooling convention to be applied,,,,,,,
477,mxnet.io.ImageDetRecordIter,prefetch_buffer,Maximum number of batches to prefetch.,Maximum number of batches to prefetch,int,,,,0,"[0,inf)",
478,mxnet.gluon.contrib.rnn.Conv1DGRUCell,prefix,Prefix for name of layers (and name of weight if params is None).,prefix for name of layers BSTR,string,,,,0,,
479,mxnet.gluon.contrib.rnn.Conv1DLSTMCell,prefix,Prefix for name of layers (and name of weight if params is None).,prefix for name of layers BSTR,string,,,,0,,
480,mxnet.gluon.rnn.GRUCell,prefix,prefix for name of Block`s (and name of weight if params is `None).,prefix for name of Block and name of weight if PARAM is None,string,,,,0,,
481,mxnet.ndarray.op.Softmax,preserve_shape,"If set to `true`, the softmax function will be computed along the last axis (`-1`).",If set to CONSTANT_BOOL the softmax function will be computed along the last axis CONSTANT_NUM,bool,,,,0,,
482,mxnet.ndarray.op.SoftmaxOutput,preserve_shape,"If set to `true`, the softmax function will be computed along the last axis (`-1`).",If set to CONSTANT_BOOL the softmax function will be computed along the last axis CONSTANT_NUM,bool,,,,0,,
483,mxnet.gluon.model_zoo.vision.alexnet,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
484,mxnet.gluon.model_zoo.vision.densenet121,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
485,mxnet.gluon.model_zoo.vision.get_model,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
486,mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
487,mxnet.gluon.model_zoo.vision.resnet50_v2,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
488,mxnet.gluon.model_zoo.vision.vgg11_bn,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
489,mxnet.gluon.model_zoo.vision.vgg13,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
490,mxnet.gluon.model_zoo.vision.vgg19,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
491,mxnet.ndarray.mp_lamb_update_phase2,r1,r1,r1,,,,,,,
492,mxnet.ndarray.op.mp_lamb_update_phase2,r2,r2,r2,,,,,,,
493,mxnet.image.CreateAugmenter,rand_mirror,Whether to apply horizontal flip to image with probability 0.5,Whether to apply horizontal flip to image with probability CONSTANT_NUM,bool,,,,0,,
494,mxnet.image.CreateDetAugmenter,rand_pad,"[0, 1], probability to apply random padding",BSTR probability to apply random padding,numeric,,,,0,"[0,1]",
495,mxnet.io.ImageDetRecordIter,random_illumination_prob,Augmentation Param: Probability to apply random illumination.,Augmentation Param Probability to apply random illumination,numeric,,,,,"[0,1]",
496,mxnet.contrib.ndarray.MultiBoxPrior,ratios,List of aspect ratios of generated MultiBoxPriores.,D_STRUCTURE of aspect ratios of generated MultiBoxPriores,,,D_STRUCTURE,,,,
497,mxnet.ndarray.op.repeat,repeats,The number of repetitions for each element.,The number of repetitions for each element,int,,,,0,"[0,inf)",
498,mxnet.ndarray.ftml_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
499,mxnet.ndarray.multi_lars,rescale_grad,Gradient rescaling factor,Gradient rescaling factor,,,,,,,
500,mxnet.ndarray.op.rmsprop_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
501,mxnet.ndarray.op.signsgd_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
502,mxnet.ndarray.signsgd_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
503,mxnet.ndarray.sparse.adam_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
504,mxnet.io.ImageDetRecordIter,resize_mode,"Augmentation Param: How image data fit in data_shape. force: force reshape to data_shape regardless of aspect ratio; shrink: ensure each side fit in data_shape, preserve aspect ratio; fit: fit image to data_shape, preserve ratio, will upscale if applicable.",Augmentation Param How image data fit in PARAM,,,,,,,
505,mxnet.io.ImageDetRecordIter,resize_mode,"Augmentation Param: How image data fit in data_shape. force: force reshape to data_shape regardless of aspect ratio; shrink: ensure each side fit in data_shape, preserve aspect ratio; fit: fit image to data_shape, preserve ratio, will upscale if applicable.",force force reshape to PARAM regardless of aspect ratio shrink ensure each side fit in PARAM preserve aspect ratio fit fit image to PARAM preserve ratio will upscale if applicable,,,,,,,
506,mxnet.ndarray.broadcast_logical_or,rhs,Second input to the function,Second input to the function,,,,,,,
507,mxnet.ndarray.broadcast_sub,rhs,Second input to the function,Second input to the function,,,,,,,
508,mxnet.ndarray.elemwise_add,rhs,second input,second input,,,,,,,
509,mxnet.ndarray.equal,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",If PARAM shape rhs shape they must be broadcastable to a common shape,,,,,,,
510,mxnet.ndarray.equal,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",Second D_STRUCTURE to be compared,,,D_STRUCTURE,,,,
511,mxnet.ndarray.minimum,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",If PARAM shape rhs shape they must be broadcastable to a common shape,,,,,,,
512,mxnet.ndarray.minimum,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",Second D_STRUCTURE to be compared,,,D_STRUCTURE,,,,
513,mxnet.ndarray.op.broadcast_equal,rhs,Second input to the function,Second input to the function,,,,,,,
514,mxnet.ndarray.op.elemwise_mul,rhs,second input,second input,,,,,,,
515,mxnet.ndarray.sparse.elemwise_sub,rhs,second input,second input,,,,,,,
516,mxnet.ndarray.sparse.subtract,rhs,"Second array to be subtracted. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.__spec__",If PARAM shape rhs shape they must be broadcastable to a common shape spec,,,,,,,
517,mxnet.ndarray.sparse.subtract,rhs,"Second array to be subtracted. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.__spec__",Second D_STRUCTURE to be subtracted,,,D_STRUCTURE,,,,
518,mxnet.image.copyMakeBorder,right,Right margin.,right margin,,,,,,,
519,mxnet.ndarray.linalg_trsm,rightside,Multiply triangular matrix from the right to non-triangular one.,Multiply triangular matrix from the right to non triangular one,,,,,,,
520,mxnet.ndarray.op.linalg_trmm,rightside,Multiply triangular matrix from the right to non-triangular one.,Multiply triangular matrix from the right to non triangular one,,,,,,,
521,mxnet.ndarray.op.linalg_trsm,rightside,Multiply triangular matrix from the right to non-triangular one.,Multiply triangular matrix from the right to non triangular one,,,,,,,
522,mxnet.ndarray.contrib.DeformablePSROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]]. (x1, y1) and (x2, y2) are top left and down right corners of designated region of interest. batch_index indicates the index of corresponding image in the input data",batch_index indicates the index of corresponding image in the input PARAM,int,,,,0,,
523,mxnet.ndarray.contrib.DeformablePSROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]]. (x1, y1) and (x2, y2) are top left and down right corners of designated region of interest. batch_index indicates the index of corresponding image in the input data",Bounding box coordinates a CONSTANT_NUM D D_STRUCTURE of BSTR,,,D_STRUCTURE,BSTR,CONSTANT_NUM,,
524,mxnet.ndarray.contrib.DeformablePSROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]]. (x1, y1) and (x2, y2) are top left and down right corners of designated region of interest. batch_index indicates the index of corresponding image in the input data",BSTR are top left and down right corners of designated region of interest,,,,,,,
525,mxnet.ndarray.ROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]], where (x1, y1) and (x2, y2) are top left and bottom right corners of designated region of interest. batch_index indicates the index of corresponding image in the input array",batch_index indicates the index of corresponding image in the input D_STRUCTURE,int,,,,0,,
526,mxnet.ndarray.ROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]], where (x1, y1) and (x2, y2) are top left and bottom right corners of designated region of interest. batch_index indicates the index of corresponding image in the input array",Bounding box coordinates a CONSTANT_NUM D D_STRUCTURE of BSTR where BSTR are top left and bottom right corners of designated region of interest,,,D_STRUCTURE,BSTR,CONSTANT_NUM,,
527,mxnet.gluon.model_zoo.vision.inception_v3,root,Location for keeping the model parameters.,Location for keeping the model parameters,,,,,,,
528,mxnet.gluon.model_zoo.vision.resnet152_v2,root,Location for keeping the model parameters.,Location for keeping the model parameters,,,,,,,
529,mxnet.contrib.ndarray.MultiProposal,rpn_pre_nms_top_n,Number of top scoring boxes to keep before applying NMS to RPN proposals,Number of top scoring boxes to keep before applying NMS to RPN proposals,int,,,,0,"[0,inf)",
530,mxnet.recordio.unpack,s,String buffer from `MXRecordIO.read`.,D_TYPE buffer from MXRecordIO read,D_TYPE,,,,,,
531,mxnet.ndarray.op.random_pdf_uniform,sample,Samples from the distributions.,Samples from the distributions,,,,,,,
532,mxnet.ndarray.random_pdf_dirichlet,sample,Samples from the distributions.,Samples from the distributions,,,,,,,
533,mxnet.ndarray.random_pdf_exponential,sample,Samples from the distributions.,Samples from the distributions,,,,,,,
534,mxnet.contrib.ndarray.ROIAlign,sample_ratio,"Optional sampling ratio of ROI align, using adaptive size by default.",Optional sampling ratio of ROI align using adaptive size by default,numeric,,,,0,,
535,mxnet.ndarray.contrib.ROIAlign,sample_ratio,"Optional sampling ratio of ROI align, using adaptive size by default.",Optional sampling ratio of ROI align using adaptive size by default,numeric,,,,0,,
536,mxnet.ndarray.UpSampling,sample_type,upsampling method,upsampling method,,,,,,,
537,mxnet.io.ImageRecordIter,saturation,"Add a random value in `[-saturation, saturation]` to the saturation of image.",Add a random value in BSTR to the saturation of image,,,,,,,
538,mxnet.contrib.ndarray.backward_gradientmultiplier,scalar,scalar input,scalar input,,,,,0,,
539,mxnet.contrib.ndarray.gradientmultiplier,scalar,lambda multiplier,lambda multiplier,,,,,,,
540,mxnet.gluon.nn.BatchNorm,scale,"If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.",If CONSTANT_BOOL gamma is not used,bool,,,,0,,
541,mxnet.gluon.nn.BatchNorm,scale,"If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.",If CONSTANT_BOOL multiply by gamma,bool,,,,0,,
542,mxnet.gluon.nn.BatchNorm,scale,"If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.",nn relu this can be disabled since the scaling will be done by the next layer,,,,,,,
543,mxnet.gluon.nn.BatchNorm,scale,"If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.",When the next layer is linear also e g,,,,,,,
544,mxnet.io.ImageDetRecordIter,scale,Augmentation Param: Scale in color space.,Augmentation Param scale in color space,,,,,,,
545,mxnet.ndarray.op.random_normal,scale,Standard deviation of the distribution.,Standard deviation of the distribution,numeric,,,,,,
546,mxnet.ndarray.random.randn,scale,Standard deviation (spread or width) of the distribution.,Standard deviation BSTR of the distribution,numeric,,,,,,
547,mxnet.contrib.ndarray.BilinearResize2D,scale_width,"sampling scale of the width (optional, used in modes ""scale"" and ""odd_scale"")",sampling scale of the PARAM optional used in modes QSTR,,,,,,,
548,mxnet.io.ImageRecordIter,seed_aug,Random seed for augmentations.,Random PARAM for augmentations,,,,,,,
549,mxnet.gluon.utils.download,sha1_hash,Expected sha1 hash in hexadecimal digits. Will ignore existing file when hash is specified but doesn't match.,Expected sha1 hash in hexadecimal digits,,,,,,,
550,mxnet.gluon.utils.download,sha1_hash,Expected sha1 hash in hexadecimal digits. Will ignore existing file when hash is specified but doesn't match.,Will ignore existing file when hash is specified but doesn t match,,,,,,,
551,mxnet.ndarray.op.random_uniform,shape,Shape of the output.,shape of the output,int,,,,1,"[0,inf)",
552,mxnet.ndarray.op.reshape,shape,The target shape,The target shape,int,,,,1,"[0,inf)",
553,mxnet.ndarray.op.sample_exponential,shape,Shape to be sampled from each random distribution.,shape to be sampled from each random distribution,int,,,,1,"[0,inf)",
554,mxnet.ndarray.op.sample_gamma,shape,Shape to be sampled from each random distribution.,shape to be sampled from each random distribution,int,,,,1,"[0,inf)",
555,mxnet.ndarray.random.gamma,shape,"The number of samples to draw. If shape is, e.g., (m, n) and alpha and beta are scalars, output shape will be (m, n). If alpha and beta are NDArrays with shape, e.g., (x, y), then output will have shape (x, y, m, n), where m*n samples are drawn for each [alpha, beta) pair.",If PARAM and PARAM are NDArrays with shape e g BSTR where m n samples are drawn for each BSTR pair,,,,,,,
556,mxnet.ndarray.random.gamma,shape,"The number of samples to draw. If shape is, e.g., (m, n) and alpha and beta are scalars, output shape will be (m, n). If alpha and beta are NDArrays with shape, e.g., (x, y), then output will have shape (x, y, m, n), where m*n samples are drawn for each [alpha, beta) pair.",If shape is e g BSTR,,,,BSTR,,,
557,mxnet.ndarray.random.gamma,shape,"The number of samples to draw. If shape is, e.g., (m, n) and alpha and beta are scalars, output shape will be (m, n). If alpha and beta are NDArrays with shape, e.g., (x, y), then output will have shape (x, y, m, n), where m*n samples are drawn for each [alpha, beta) pair.",The number of samples to draw,int,,,,0,"[0,inf)",
558,mxnet.ndarray.sample_uniform,shape,Shape to be sampled from each random distribution.,shape to be sampled from each random distribution,int,,,,1,"[0,inf)",
559,mxnet.util.set_np,shape,"A boolean value indicating whether the NumPy-shape semantics should be turned on or off. When this flag is set to True, zero-size and zero-dim shapes are all valid shapes in shape inference process, instead of treated as unknown shapes in legacy mode.",A D_TYPE value indicating whether the NumPy shape semantics should be turned on or off,D_TYPE,,,,0,,
560,mxnet.util.set_np,shape,"A boolean value indicating whether the NumPy-shape semantics should be turned on or off. When this flag is set to True, zero-size and zero-dim shapes are all valid shapes in shape inference process, instead of treated as unknown shapes in legacy mode.",When this flag is set to CONSTANT_BOOL zero size and zero dim shapes are all valid shapes in shape inference process instead of treated as unknown shapes in legacy mode,bool,,,,0,,
561,mxnet.ndarray.op.LeakyReLU,slope,Init slope for the activation. (For leaky and elu only),BSTR,,,,,,,
562,mxnet.ndarray.op.LeakyReLU,slope,Init slope for the activation. (For leaky and elu only),Init slope for the activation,,,,,,,
563,mxnet.profiler.dumps,sort_by,"can take 'total', 'avg', 'min', 'max', or 'count' by which stat to sort the entries in each category defaults to 'total'",can take QSTR by which stat to sort the entries in each category defaults to QSTR,,,,,,,QSTR
564,mxnet.ndarray.ROIPooling,spatial_scale,Ratio of input feature map height (or w) to raw image height (or w). Equals the reciprocal of total stride in convolutional layers,Equals the reciprocal of total stride in convolutional layers,,,,,,,
565,mxnet.ndarray.ROIPooling,spatial_scale,Ratio of input feature map height (or w) to raw image height (or w). Equals the reciprocal of total stride in convolutional layers,Ratio of input feature map height BSTR,numeric,,,,,,
566,mxnet.ndarray.op.split,squeeze_axis,"If true, Removes the axis with length 1 from the shapes of the output arrays. Note that setting squeeze_axis to `true` removes axis with length 1 only along the axis which it is split. Also squeeze_axis can be set to `true` only if `input.shape[axis] == num_outputs`.",Also squeeze_axis can be set to CONSTANT_BOOL only if input shape BSTR PARAM,bool,,,,0,,
567,mxnet.ndarray.op.split,squeeze_axis,"If true, Removes the axis with length 1 from the shapes of the output arrays. Note that setting squeeze_axis to `true` removes axis with length 1 only along the axis which it is split. Also squeeze_axis can be set to `true` only if `input.shape[axis] == num_outputs`.",If CONSTANT_BOOL Removes the PARAM with length CONSTANT_NUM from the shapes of the output D_STRUCTURE,bool,,,,0,,
568,mxnet.ndarray.op.split,squeeze_axis,"If true, Removes the axis with length 1 from the shapes of the output arrays. Note that setting squeeze_axis to `true` removes axis with length 1 only along the axis which it is split. Also squeeze_axis can be set to `true` only if `input.shape[axis] == num_outputs`.",Note that setting squeeze_axis to CONSTANT_BOOL removes PARAM with length CONSTANT_NUM only along the PARAM which it is split,,,,,,,
569,mxnet.ndarray.arange,start,Start of interval. The default start value is 0.,The default start value is CONSTANT_NUM,,,,,,,
570,mxnet.ndarray.arange,start,Start of interval. The default start value is 0.,start of interval,,,,,,,
571,mxnet.contrib.ndarray.hawkesll,state,"Shape (N, K) the Hawkes state for each process",Shape BSTR the Hawkes state for each process,,,,BSTR,,,
572,mxnet.ndarray.RNN,state_outputs,Whether to have the states as symbol outputs.,Whether to have the states as symbol outputs,bool,,,,0,,
573,mxnet.ndarray.contrib.box_decode,std2,value to be divided from the 3rd encoded values,value to be divided from the 3rd encoded values,numeric,,,,,,
574,mxnet.ndarray.contrib.arange_like,step,Spacing between values.,Spacing between values,,,,,,,
575,mxnet.gluon.nn.Conv3DTranspose,strides,Specify the strides of the convolution.,Specify the strides of the convolution,int,,,,1,,
576,mxnet.ndarray.zeros,stype,"The storage type of the empty array, such as 'row_sparse', 'csr', etc.",The storage type of the empty D_STRUCTURE such as QSTR etc,,,,,,,QSTR
577,mxnet.test_utils.verify_generator,success_rate,The desired success rate,The desired success rate,numeric,,,,0,,
578,mxnet.test_utils.check_symbolic_forward,sym,output symbol,output symbol,,,,,,,
579,mxnet.ndarray.op.Deconvolution,target_shape,"Shape of the output tensor: (w,), (h, w) or (d, h, w).",Shape of the output D_STRUCTURE BSTR,int,,,,1,"[0,inf)",
580,mxnet.ndarray.contrib.MultiProposal,threshold,"NMS value, below which to suppress.",NMS value below which to suppress,,,,,,,
581,mxnet.contrib.ndarray.box_nms,topk,"Apply nms to topk boxes with descending scores, -1 to no restriction.",Apply nms to topk boxes with descending scores CONSTANT_NUM to no restriction,,,,,,,
582,mxnet.ndarray.contrib.bipartite_matching,topk,"Limit the number of matches to topk, set -1 for no limit",Limit the number of matches to topk set CONSTANT_NUM for no limit,,,,,,,
583,mxnet.ndarray.op.linalg_trmm,transpose,Use transposed of the triangular matrix,Use transposed of the triangular matrix,,,,,,,
584,mxnet.ndarray.linalg_gemm,transpose_a,Multiply with transposed of first input (A).,Multiply with transposed of first input BSTR,,,,,,,
585,mxnet.ndarray.op.linalg_gemm,transpose_a,Multiply with transposed of first input (A).,Multiply with transposed of first input BSTR,,,,,,,
586,mxnet.gluon.nn.Conv2DTranspose,use_bias,Whether the layer uses a bias vector.,Whether the layer uses a bias vector,bool,,,,0,,
587,mxnet.contrib.ndarray.quantized_batch_norm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,This will force change batch norm into a scale shift operator,,,,,,,
588,mxnet.contrib.ndarray.quantized_batch_norm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,Whether use global moving statistics instead of local batch norm,bool,,,,0,,
589,mxnet.contrib.ndarray.SyncBatchNorm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,This will force change batch norm into a scale shift operator,,,,,,,
590,mxnet.contrib.ndarray.SyncBatchNorm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,Whether use global moving statistics instead of local batch norm,bool,,,,0,,
591,mxnet.ndarray.BatchNorm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,This will force change batch norm into a scale shift operator,,,,,,,
592,mxnet.ndarray.BatchNorm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,Whether use global moving statistics instead of local batch norm,bool,,,,0,,
593,mxnet.ndarray.op.softmin,use_length,Whether to use the length input as a mask over the data input.,Whether to use the length input as a mask over the PARAM input,bool,,,,0,,
594,mxnet.ndarray.op.SequenceMask,use_sequence_length,"If set to true, this layer takes in an extra input parameter sequence_length to specify variable length sequence",If set to CONSTANT_BOOL this layer takes in an extra input parameter PARAM to specify variable length D_STRUCTURE,bool,,,,0,,
595,mxnet.ndarray.full,val,Fill value.,Fill value,,,,,,,
596,mxnet.contrib.ndarray.hawkesll,valid_length,The number of valid points in the process,The number of valid points in the process,int,,,,0,"[0,inf)",
597,mxnet.ndarray.op.SequenceMask,value,The value to be used as a mask.,The value to be used as a mask,,,,,,,
598,mxnet.io.ImageRecordIter,verbose,If or not output verbose information.,If or not output verbose information,,,,,,,
599,mxnet.ndarray.mp_nag_mom_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,PARAM decay augments the objective function with a regularization term that penalizes large weights,,,,,,,
600,mxnet.ndarray.mp_nag_mom_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,The penalty scales with the square of the magnitude of each PARAM,,,,,,,
601,mxnet.ndarray.op.ftrl_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,PARAM decay augments the objective function with a regularization term that penalizes large weights,,,,,,,
602,mxnet.ndarray.op.ftrl_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,The penalty scales with the square of the magnitude of each PARAM,,,,,,,
603,mxnet.contrib.ndarray.DeformableConvolution,weight,Weight matrix.,weight matrix,numeric,,,,,,
604,mxnet.contrib.ndarray.quantized_conv,weight,weight.,weight,numeric,,,,,,
605,mxnet.contrib.ndarray.quantized_fully_connected,weight,weight.,weight,numeric,,,,,,
606,mxnet.ndarray.Embedding,weight,The embedding weight matrix.,The embedding weight matrix,numeric,,,,,,
607,mxnet.ndarray.op.Convolution,weight,Weight matrix.,weight matrix,numeric,,,,,,
608,mxnet.ndarray.op.ftml_update,weight,Weight,weight,numeric,,,,,,
609,mxnet.ndarray.op.mp_sgd_mom_update,weight,Weight,weight,numeric,,,,,,
610,mxnet.ndarray.op.sgd_mom_update,weight,Weight,weight,numeric,,,,,,
611,mxnet.ndarray.op.signum_update,weight,Weight,weight,numeric,,,,,,
612,mxnet.ndarray.rmsprop_update,weight,Weight,weight,numeric,,,,,,
613,mxnet.gluon.nn.Conv3DTranspose,weight_initializer,Initializer for the weight weights matrix.,Initializer for the weight weights matrix,,,,,,,
614,mxnet.ndarray.mp_lamb_update_phase1,weight32,Weight32,weight32,numeric,,,,,,
615,mxnet.ndarray.mp_nag_mom_update,weight32,Weight32,weight32,numeric,,,,,,
616,mxnet.ndarray.mp_sgd_update,weight32,Weight32,weight32,numeric,,,,,,
