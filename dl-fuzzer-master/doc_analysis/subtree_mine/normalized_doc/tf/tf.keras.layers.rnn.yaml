aliases:
- tf.compat.v1.keras.layers.RNN
constraints:
  '**kwargs':
    default: null
    descp: ''
    normalized_descp: []
  cell:
    descp: 'A RNN cell instance or a list of RNN cell instances. A RNN cell is a class
      that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t,
      states_at_t_plus_1)`. The call method of the cell can also take the optional
      argument `constants`, see section "Note on passing external constants" below.A
      `state_size` attribute. This can be a single integer (single state) in which
      case it is the size of the recurrent state. This can also be a list/tuple of
      integers (one size per state). The `state_size` can also be TensorShape or tuple/list
      of TensorShape, to represent high dimension state.A `output_size` attribute.
      This can be a single integer or a TensorShape, which represent the shape of
      the output. For backward compatible reason, if this attribute is not available
      for the cell, the value will be inferred by the first element of the`state_size`.A
      `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates
      a tensor meant to be fed to `call()` as the initial state, if the user didn''t
      specify any initial state via other means. The returned initial state should
      have a shape of [batch_size, cell.state_size]. The cell might choose to create
      a tensor full of zeros, or full of other values based on the cell''s implementation.`inputs`
      is the input tensor to the RNN layer, which should contain the batch size as
      its shape[0], and also dtype. Note that the shape[0] might be `None` during
      the graph construction. Either the `inputs` or the pair of `batch_size` and
      `dtype` are provided.`batch_size` is a scalar tensor that represents the batch
      size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs.
      For backward compatible reason, if this method is not implemented by the cell,
      the RNN layer will create a zero filled tensor with the size of [batch_size,
      cell.state_size]. In the case that `cell` is a list of RNN cell instances, the
      cells will be stacked on top of each other in the RNN, resulting in an efficient
      stacked RNN. '
    normalized_descp:
    - A RNN cell instance or a D_STRUCTURE of RNN cell instances
    - A RNN cell is a class that has A call BSTR method, returning BSTR
    - The call method of the cell can also take the optional argument QSTR , see section
      QSTR below A QSTR attribute
    - This can be a single D_TYPE BSTR in which case it is the size of the recurrent
      state
    - This can also be a D_STRUCTURE of D_TYPE BSTR
    - The QSTR can also be TensorShape or D_STRUCTURE of TensorShape, to represent
      high dimension state A QSTR attribute
    - This can be a single D_TYPE or a TensorShape, which represent the shape of the
      output
    - For backward compatible reason, if this attribute is not available for the cell,
      the value will be inferred by the first element of the QSTR A get_initial_state
      inputs None, batch_size None, dtype None QSTR call as the initial state, if
      the user didn t specify any initial state via other means
    - The returned initial state should have a shape of BSTR
    - The cell might choose to create a D_STRUCTURE full of zeros, or full of other
      values based on the cell implementation QSTR is the input D_STRUCTURE to the
      RNN layer, which should contain the batch size as its shape BSTR, and also dtype
    - Note that the shape BSTR might be QSTR during the graph construction
    - Either the QSTR or the pair of QSTR are provided QSTR is a scalar D_STRUCTURE
      that represents the batch size of the inputs
    - QSTR is D_TYPE that represents the dtype of the inputs
    - For backward compatible reason, if this method is not implemented by the cell,
      the RNN layer will create a zero filled D_STRUCTURE with the size of BSTR
    - In the case that QSTR is a D_STRUCTURE of RNN cell instances, the cells will
      be stacked on top of each other in the RNN, resulting in an efficient stacked
      RNN
  go_backwards:
    default: 'False'
    descp: Boolean (default `False`). If True, process the input sequence backwards
      and return the reversed sequence.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - D_TYPE default CONSTANT_BOOL
    - If CONSTANT_BOOL, process the input D_STRUCTURE backwards and return the reversed
      D_STRUCTURE
  return_sequences:
    default: 'False'
    descp: Boolean (default `False`). Whether to return the last output in the output
      sequence, or the full sequence.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - D_TYPE default CONSTANT_BOOL
    - Whether to return the last output in the output D_STRUCTURE, or the full D_STRUCTURE
  return_state:
    default: 'False'
    descp: Boolean (default `False`). Whether to return the last state in addition
      to the output.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - D_TYPE default CONSTANT_BOOL
    - Whether to return the last state in addition to the output
  stateful:
    default: 'False'
    descp: Boolean (default `False`). If True, the last state for each sample at index
      i in a batch will be used as initial state for the sample of index i in the
      following batch.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - D_TYPE default CONSTANT_BOOL
    - If CONSTANT_BOOL, the last state for each sample at index i in a batch will
      be used as initial state for the sample of index i in the following batch
  time_major:
    default: 'False'
    descp: The shape format of the `inputs` and `outputs` tensors. If True, the inputs
      and outputs will be in shape`(timesteps, batch, ...)`, whereas in the False
      case, it will be`(batch, timesteps, ...)`. Using `time_major = True` is a bit
      more efficient because it avoids transposes at the beginning and end of the
      RNN calculation. However, most TensorFlow data is batch-major, so by default
      this function accepts input and emits output in batch-major form.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - The shape format of the QSTR D_STRUCTURE
    - If CONSTANT_BOOL, the inputs and outputs will be in shape BSTR, whereas in the
      CONSTANT_BOOL case, it will be BSTR
    - Using time_major CONSTANT_BOOL is a bit more efficient because it avoids transposes
      at the beginning and end of the RNN calculation
    - However, most TensorFlow data is batch major, so by default this function accepts
      input and emits output in batch major form
  unroll:
    default: 'False'
    descp: Boolean (default `False`). If True, the network will be unrolled, else
      a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends
      to be more memory-intensive. Unrolling is only suitable for short sequences.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - D_TYPE default CONSTANT_BOOL
    - If CONSTANT_BOOL, the network will be unrolled, else a symbolic loop will be
      used
    - Unrolling can speed up a RNN, although it tends to be more memory intensive
    - Unrolling is only suitable for short sequences
exceptions:
- AttributeError: When the RNN layer is not stateful.
- ValueError: When the batch size of the RNN layer is unknown.
- ValueError: When the input numpy array is not compatible with the RNN layer state,
    either size wise or dtype wise.
inputs:
  optional:
  - return_sequences
  - return_state
  - go_backwards
  - stateful
  - unroll
  - time_major
  - '**kwargs'
  required:
  - cell
link: https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/layers/RNN
package: tensorflow
target: RNN
title: tf.keras.layers.RNN
version: 2.1.0
