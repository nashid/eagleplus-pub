constraints:
  batch_size:
    descp: An int representing the number of records to combine in a single batch.
    normalized_descp:
    - An D_TYPE representing the number of records to combine in a single batch
  drop_final_batch:
    default: 'False'
    descp: If `True`, and the batch size does not evenly divide the input dataset
      size, the final smaller batch will be dropped. Defaults to`False`.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - If CONSTANT_BOOL, and the batch size does not evenly divide the input dataset
      size, the final smaller batch will be dropped
    - Defaults to CONSTANT_BOOL
  features:
    descp: A `dict` mapping feature keys to `FixedLenFeature` or`VarLenFeature` values.
      See `tf.io.parse_example`.
    normalized_descp:
    - A D_STRUCTURE mapping feature keys to QSTR values
    - See tf io parse_example
  file_pattern:
    descp: List of files or patterns of file paths containing`Example` records. See
      `tf.io.gfile.glob` for pattern rules.
    normalized_descp:
    - D_STRUCTURE of files or patterns of file paths containing QSTR records
    - See tf io gfile glob for pattern rules
  label_key:
    default: None
    descp: (Optional) A string corresponding to the key labels are stored in`tf.Examples`.
      If provided, it must be one of the `features` key, otherwise results in `ValueError`.
    normalized_default: DEFAULT None
    normalized_descp:
    - BSTR A D_TYPE corresponding to the key labels are stored in tf Examples
    - If provided, it must be one of the PARAM key, otherwise results in QSTR
  num_epochs:
    default: None
    descp: Integer specifying the number of times to read through the dataset. If
      None, cycles through the dataset forever. Defaults to `None`.
    normalized_default: DEFAULT None
    normalized_descp:
    - D_TYPE specifying the number of times to read through the dataset
    - If None, cycles through the dataset forever
    - Defaults to QSTR
  parser_num_threads:
    default: None
    descp: Number of threads to use for parsing `Example` tensors into a dictionary
      of `Feature` tensors. Defaults to `2`.
    normalized_default: DEFAULT None
    normalized_descp:
    - Number of threads to use for parsing QSTR D_STRUCTURE into a D_STRUCTURE of
      QSTR D_STRUCTURE
    - Defaults to CONSTANT_NUM
  prefetch_buffer_size:
    default: None
    descp: Number of feature batches to prefetch in order to improve performance.
      Recommended value is the number of batches consumed per training step. Defaults
      to auto-tune.
    normalized_default: DEFAULT None
    normalized_descp:
    - Number of feature batches to prefetch in order to improve performance
    - Recommended value is the number of batches consumed per training step
    - Defaults to auto tune
  reader:
    default: None
    descp: A function or class that can be called with a `filenames` tensor and (optional)
      `reader_args` and returns a `Dataset` of `Example` tensors. Defaults to `tf.data.TFRecordDataset`.
    normalized_default: DEFAULT None
    normalized_descp:
    - A function or class that can be called with a QSTR D_STRUCTURE and BSTR PARAM
      and returns a QSTR of QSTR D_STRUCTURE
    - Defaults to tf data TFRecordDataset
  reader_args:
    default: None
    descp: Additional arguments to pass to the reader class.
    normalized_default: DEFAULT None
    normalized_descp:
    - Additional arguments to pass to the PARAM class
  reader_num_threads:
    default: None
    descp: Number of threads used to read `Example` records. If >1, the results will
      be interleaved. Defaults to `1`.
    normalized_default: DEFAULT None
    normalized_descp:
    - Number of threads used to read QSTR records
    - If REXPR, the results will be interleaved
    - Defaults to CONSTANT_NUM
  shuffle:
    default: 'True'
    descp: A boolean, indicates whether the input should be shuffled. Defaults to
      `True`.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - A D_TYPE, indicates whether the input should be shuffled
    - Defaults to CONSTANT_BOOL
  shuffle_buffer_size:
    default: '10000'
    descp: Buffer size of the ShuffleDataset. A large capacity ensures better shuffling
      but would increase memory usage and startup time.
    normalized_default: DEFAULT CONSTANT_NUM
    normalized_descp:
    - Buffer size of the ShuffleDataset
    - A large capacity ensures better shuffling but would increase memory usage and
      startup time
  shuffle_seed:
    default: None
    descp: Randomization seed to use for shuffling.
    normalized_default: DEFAULT None
    normalized_descp:
    - Randomization seed to use for shuffling
  sloppy_ordering:
    default: 'False'
    descp: If `True`, reading performance will be improved at the cost of non-deterministic
      ordering. If `False`, the order of elements produced is deterministic prior
      to shuffling (elements are still randomized if `shuffle=True`. Note that if
      the seed is set, then order of elements after shuffling is deterministic). Defaults
      to `False`.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - If CONSTANT_BOOL, reading performance will be improved at the cost of non deterministic
      ordering
    - If CONSTANT_BOOL, the order of elements produced is deterministic prior to shuffling
      elements are still randomized if PARAM CONSTANT_BOOL
    - Note that if the seed is set, then order of elements after shuffling is deterministic
    - Defaults to CONSTANT_BOOL
exceptions:
- TypeError: If `reader` is a `tf.compat.v1.ReaderBase` subclass.
- ValueError: If `label_key` is not one of the `features` keys.
inputs:
  optional:
  - reader
  - label_key
  - reader_args
  - num_epochs
  - shuffle
  - shuffle_buffer_size
  - shuffle_seed
  - prefetch_buffer_size
  - reader_num_threads
  - parser_num_threads
  - sloppy_ordering
  - drop_final_batch
  required:
  - file_pattern
  - batch_size
  - features
link: https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/data/experimental/make_batched_features_dataset
outputs: A dataset of `dict` elements, (or a tuple of `dict` elements and label).
  Each `dict` maps feature keys to `Tensor` or `SparseTensor` objects.
package: tensorflow
target: make_batched_features_dataset
title: tf.data.experimental.make_batched_features_dataset
version: 2.1.0
