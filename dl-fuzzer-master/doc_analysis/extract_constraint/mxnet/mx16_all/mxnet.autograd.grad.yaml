constraints:
  create_graph:
    default: 'False'
    descp: Whether to record gradient graph for computing higher order
    doc_dtype:
    - bool
    dtype:
    - boolean
    ndim:
    - '0'
  head_grads:
    default: None
    descp: Gradients with respect to heads.
    doc_dtype:
    - NDArray
    - list of NDArray
    - None
    structure:
    - list(ndarray)
    - ndarray
  heads:
    descp: Output NDArray(s)
    doc_dtype:
    - NDArray
    - list of NDArray
    structure:
    - list(ndarray)
    - ndarray
  retain_graph:
    default: None
    descp: Whether to keep computation graph to differentiate again, instead of clearing
      history and release memory. Defaults to the same value as create_graph.
    doc_dtype:
    - bool
    dtype:
    - boolean
    ndim:
    - '0'
  train_mode:
    default: 'True'
    descp: Whether to do backward for training or prediction.
    doc_dtype:
    - bool
    - optional
    dtype:
    - boolean
    ndim:
    - '0'
  variables:
    descp: Input variables to compute gradients for.
    doc_dtype:
    - NDArray
    - list of NDArray
    structure:
    - list(ndarray)
    - ndarray
inputs:
  optional:
  - head_grads
  - retain_graph
  - create_graph
  - train_mode
  required:
  - heads
  - variables
link: https://mxnet.apache.org/versions/1.6/api/python/docs/api/autograd/index.html#mxnet.autograd.grad
package: mxnet
target: grad
title: mxnet.autograd.grad
version: 1.6.0
