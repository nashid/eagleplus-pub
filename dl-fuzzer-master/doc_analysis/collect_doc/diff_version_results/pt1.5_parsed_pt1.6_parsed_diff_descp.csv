API,Param,ratio,pt1.5_parsed,pt1.6_parsed
torch.save.yaml,f,0.8888888888888888,a file-like object (has to implement write and flush) or a string containing a file name,a file-like object (has to implement write and flush) or a string or os.PathLike object containing a file name
torch.nn.functional.interpolate.yaml,recompute_scale_factor,0.8356374807987711,"recompute the scale_factor for use in the interpolation calculation.  When scale_factor is passed as a parameter, it is used to compute the output_size.  If recompute_scale_factor is ``True` or not specified, a new scale_factor will be computed based on the output and input sizes for use in the interpolation computation (i.e. the computation will be identical to if the computed output_size were passed-in explicitly).  Otherwise, the passed-in scale_factor will be used in the interpolation computation.  Note that when scale_factor is floating-point, the recomputed scale_factor may differ from the one passed in due to rounding and precision issues.","recompute the scale_factor for use in the interpolation calculation.  When scale_factor is passed as a parameter, it is used to compute the output_size.  If recompute_scale_factor is ``False` or not specified, the passed-in scale_factor will be used in the interpolation computation. Otherwise, a new scale_factor will be computed based on the output and input sizes for use in the interpolation computation (i.e. the computation will be identical to if the computed output_size were passed-in explicitly).  Note that when scale_factor is floating-point, the recomputed scale_factor may differ from the one passed in due to rounding and precision issues."
torch.div2.yaml,out,0.0,,the output tensor.
torch.add.yaml,out,0.0,,the output tensor.
torch.set_printoptions.yaml,sci_mode,0.7692307692307693,"Enable (True) or disable (False) scientific notation. If None (default) is specified, the value is defined by _Formatter","Enable (True) or disable (False) scientific notation. If None (default) is specified, the value is defined by torch._tensor_str._Formatter. This value is automatically chosen by the framework."
torch.floor_divide.yaml,out,0.0,,the output tensor.
torch.onnx.export.yaml,training,0.14385150812064965,"export the model in training mode.  At the moment, ONNX is oriented towards exporting models for inference only, so you will generally not need to set this to True.",TrainingMode.EVAL: export the model in inference mode. TrainingMode.PRESERVE: export the model in inference mode if model.training is False and to a training friendly mode if model.training is True. TrainingMode.TRAINING: export the model in a training friendly mode.
torch.onnx.export.yaml,operator_export_type,0.0,"OperatorExportTypes.ONNX: all ops are exported as regular ONNX ops. OperatorExportTypes.ONNX_ATEN: all ops are exported as ATen ops. OperatorExportTypes.ONNX_ATEN_FALLBACK: if symbolic is missing, fall back on ATen op. OperatorExportTypes.RAW: export raw ir.",
torch.onnx.export.yaml,opset_version,0.0,"by default we export the model to the opset version of the onnx submodule. Since ONNX's latest opset may evolve before next stable release, by default we export to one stable opset version. Right now, supported stable opset version is 9. The opset_version must be _onnx_master_opset or in _onnx_stable_opsets which are defined in torch/onnx/symbolic_helper.py",
torch.onnx.export.yaml,do_constant_folding,0.0,"If True, the constant-folding optimization is applied to the model during export. Constant-folding optimization will replace some of the ops that have all constant inputs, with pre-computed constant nodes.",
torch.onnx.export.yaml,example_outputs,0.0,Model's example outputs being exported. example_outputs must be provided when exporting a ScriptModule or TorchScript Function.,
torch.onnx.export.yaml,strip_doc_string,0.0,"if True, strips the field ""doc_string"" from the exported model, which information about the stack trace.",
torch.quantization.quantize.yaml,model,0.7857142857142857,input model,input float model
torch.quantization.quantize.yaml,run_fn,0.4685714285714286,"a function for evaluating the prepared model, can be a function that simply runs the prepared model or a training loop",a calibration function for calibrating the prepared model
torch.div.yaml,out,0.0,,the output tensor.
