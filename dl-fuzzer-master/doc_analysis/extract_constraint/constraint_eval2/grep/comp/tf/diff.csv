File,Arg,Type,Constr_src,Constr_cmp,Descp
tf.linalg.band_part,num_upper,prim_dtype,['dtype:&num_lower'],['int'],"A `Tensor`. Must have the same type as `num_lower`. 0-D tensor. Number of superdiagonals to keep. If negative, keep entire upper triangle."
tf.keras.layers.RNN,time_major,prim_dtype,"['int', 'tf.bool']",['tf.bool'],"The shape format of the `inputs` and `outputs` tensors. If True, the inputs and outputs will be in shape`(timesteps, batch, ...)`, whereas in the False case, it will be`(batch, timesteps, ...)`. Using `time_major = True` is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form."
tf.data.experimental.make_csv_dataset,use_quote_delim,prim_dtype,['tf.bool'],"['tf.bool', 'tf.float64', 'tf.string']","An optional bool. Defaults to `True`. If false, treats double quotation marks as regular characters inside of the string fields."
tf.feature_column.sequence_numeric_column,default_value,prim_dtype,['float'],"['float', 'tf.dtype']",A single value compatible with `dtype` that is used for padding the sparse data into a dense `Tensor`.
tf.nn.local_response_normalization,depth_radius,prim_dtype,['int'],"['int', 'tf.float16']",An optional `int`. Defaults to `5`. 0-D.  Half-width of the 1-D normalization window.
tf.bitcast,type,prim_dtype,['tf.dtype'],"['tf.bfloat16', 'tf.complex128', 'tf.complex64', 'tf.dtype', 'tf.float16', 'tf.float32', 'tf.float64', 'tf.int16', 'tf.int32', 'tf.int64', 'tf.int8', 'tf.qint16', 'tf.qint32', 'tf.qint8', 'tf.quint16', 'tf.quint8', 'tf.uint16', 'tf.uint32', 'tf.uint64', 'tf.uint8']","A `tf.DType` from: `tf.bfloat16, tf.half, tf.float32, tf.float64, tf.int64, tf.int32, tf.uint8, tf.uint16, tf.uint32, tf.uint64, tf.int8, tf.int16, tf.complex64, tf.complex128, tf.qint8, tf.quint8, tf.qint16, tf.quint16, tf.qint32`."
tf.feature_column.categorical_column_with_hash_bucket,dtype,prim_dtype,"['int', 'tf.dtype']","['int', 'tf.dtype', 'tf.string']",The type of features. Only string and integer types are supported.
tf.nn.max_pool_with_argmax,output_dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.int32', 'tf.int64']","An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`. The dtype of the returned argmax tensor."
tf.data.experimental.sample_from_datasets,weights,prim_dtype,['numeric'],['float'],"(Optional.) A list of `len(datasets)` floating-point values where`weights[i]` represents the probability with which an element should be sampled from `datasets[i]`, or a `tf.data.Dataset` object where each element is such a list. Defaults to a uniform distribution across`datasets`."
tf.signal.idct,type,prim_dtype,"['int', 'tf.dtype']",['int'],"The IDCT type to perform. Must be 1, 2 or 3."
tf.keras.layers.LSTM,time_major,prim_dtype,"['int', 'tf.bool']",['tf.bool'],"The shape format of the `inputs` and `outputs` tensors. If True, the inputs and outputs will be in shape`[timesteps, batch, feature]`, whereas in the False case, it will be`[batch, timesteps, feature]`. Using `time_major = True` is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form."
tf.linalg.tridiagonal_solve,rhs,prim_dtype,['dtype:&diagonals'],['tf.dtype'],"A `Tensor` of shape [..., M] or [..., M, K] and with the same dtype as`diagonals`. Note that if the shape of `rhs` and/or `diags` isn't known statically, `rhs` will be treated as a matrix rather than a vector."
tf.data.experimental.rejection_resample,initial_dist,prim_dtype,"['float', 'tf.dtype']",['float'],"(Optional.)  A floating point type tensor, shaped`[num_classes]`.  If not provided, the true class distribution is estimated live in a streaming fashion."
tf.data.experimental.rejection_resample,target_dist,prim_dtype,"['float', 'tf.dtype']",['float'],"A floating point type tensor, shaped `[num_classes]`."
tf.strings.substr,len,prim_dtype,['dtype:&pos'],['numeric'],A `Tensor`. Must have the same type as `pos`. Scalar defining the number of characters to include in each substring
tf.cast,x,prim_dtype,['numeric'],"['numeric', 'tf.bfloat16', 'tf.complex128', 'tf.complex64', 'tf.float16', 'tf.float32', 'tf.float64', 'tf.int16', 'tf.int32', 'tf.int64', 'tf.int8', 'tf.uint16', 'tf.uint32', 'tf.uint64', 'tf.uint8']","A `Tensor` or `SparseTensor` or `IndexedSlices` of numeric type. It could be `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`,`int64`, `float16`, `float32`, `float64`, `complex64`, `complex128`,`bfloat16`."
tf.strings.ngrams,ngram_width,prim_dtype,['numeric'],['int'],"The width(s) of the ngrams to create. If this is a list or tuple, the op will return ngrams of all specified arities in list order. Values must be non-Tensor integers greater than 0."
tf.ragged.row_splits_to_segment_ids,out_type,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.int64']","The dtype for the return value.  Defaults to `splits.dtype`, or `tf.int64` if `splits` does not have a dtype."
tf.debugging.assert_greater,y,prim_dtype,"['dtype:&x', 'numeric']","['numeric', 'tf.dtype']","Numeric `Tensor`, same dtype as and broadcastable to `x`."
tf.feature_column.sequence_categorical_column_with_vocabulary_file,dtype,prim_dtype,"['int', 'tf.dtype']","['int', 'tf.dtype', 'tf.string']",The type of features. Only string and integer types are supported.
tf.make_tensor_proto,verify_shape,prim_dtype,['tf.bool'],"['int', 'tf.bool']",Boolean that enables verification of a shape of values.
tf.random.categorical,dtype,prim_dtype,"['int', 'tf.dtype']","['int', 'tf.dtype', 'tf.int64']",integer type to use for the output. Defaults to int64.
tf.train.experimental.enable_mixed_precision_graph_rewrite,loss_scale,prim_dtype,"['float', 'int']","['float', 'int', 'tf.string']","Either an int/float, the string `""dynamic""`, or an instance of a`tf.mixed_precision.experimental.LossScale`. The loss scale to use. It is recommended to keep this as its default value of `""dynamic""`, which will adjust the scaling automatically to prevent `Inf` or `NaN` values."
tf.random.stateless_uniform,dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.float16', 'tf.float32', 'tf.float64', 'tf.int32', 'tf.int64']","The type of the output: `float16`, `float32`, `float64`, `int32`, or`int64`."
tf.random.stateless_uniform,maxval,prim_dtype,['tf.dtype'],"['float', 'tf.dtype']",A 0-D Tensor or Python value of type `dtype`. The upper bound on the range of random values to generate.  Defaults to 1 if `dtype` is floating point.
tf.keras.layers.GRU,time_major,prim_dtype,"['int', 'tf.bool']",['tf.bool'],"The shape format of the `inputs` and `outputs` tensors. If True, the inputs and outputs will be in shape`[timesteps, batch, feature]`, whereas in the False case, it will be`[batch, timesteps, feature]`. Using `time_major = True` is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form."
tf.debugging.assert_type,tf_type,prim_dtype,['tf.dtype'],"['tf.bool', 'tf.dtype', 'tf.float32', 'tf.int64']","A tensorflow type (`dtypes.float32`, `tf.int64`, `dtypes.bool`, etc)."
tf.debugging.enable_check_numerics,path_length_limit,prim_dtype,['int'],"['int', 'tf.string']",Limit to the file path included in the printed stack trace. Applicable only to ops in `tf.function`s (graphs).
tf.debugging.assert_less,y,prim_dtype,"['dtype:&x', 'numeric']","['numeric', 'tf.dtype']","Numeric `Tensor`, same dtype as and broadcastable to `x`."
tf.estimator.regressor_parse_example_spec,label_dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.float32']",A `tf.dtype` identifies the type of labels. By default it is`tf.float32`.
tf.quantization.quantize_and_dequantize,round_mode,prim_dtype,['tf.string'],['float'],"Rounding mode when rounding from float values to quantized ones. one of ['HALF_TO_EVEN', 'HALF_UP']"
tf.unique,out_idx,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.int32', 'tf.int64']","An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`."
tf.nn.sparse_softmax_cross_entropy_with_logits,labels,prim_dtype,"['tf.int32', 'tf.int64']","['tf.dtype', 'tf.int32', 'tf.int64']","`Tensor` of shape `[d_0, d_1, ..., d_{r-1}]` (where `r` is rank of`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`must be an index in `[0, num_classes)`. Other values will raise an exception when this op is run on CPU, and return `NaN` for corresponding loss and gradient rows on GPU."
tf.nn.sparse_softmax_cross_entropy_with_logits,logits,prim_dtype,"['tf.float16', 'tf.float32', 'tf.float64']","['tf.dtype', 'tf.float16', 'tf.float32', 'tf.float64']","Unscaled log probabilities of shape `[d_0, d_1, ..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or `float64`."
tf.strings.as_string,precision,prim_dtype,['int'],"['float', 'int']",An optional `int`. Defaults to `-1`. The post-decimal precision to use for floating point numbers. Only used if precision > -1.
tf.strings.as_string,scientific,prim_dtype,['tf.bool'],"['float', 'tf.bool']",An optional `bool`. Defaults to `False`. Use scientific notation for floating point numbers.
tf.strings.as_string,shortest,prim_dtype,['tf.bool'],"['float', 'tf.bool']",An optional `bool`. Defaults to `False`. Use shortest representation (either scientific or standard) for floating point numbers.
tf.strings.as_string,width,prim_dtype,['int'],"['float', 'int']",An optional `int`. Defaults to `-1`. Pad pre-decimal numbers to this width. Applies to both floating point and integer numbers. Only used if width > -1.
tf.unravel_index,dims,prim_dtype,"['dtype:&indices', 'int']",['int'],A `Tensor`. Must have the same type as `indices`. An 1-D `int` Tensor. The shape of the array to use for unraveling indices.
tf.xla.experimental.compile,inputs,prim_dtype,['scalar'],['numeric'],"A list of inputs or `None` (equivalent to an empty list). Each input can be a nested structure containing values that are convertible to tensors. Note that passing an N-dimension list of compatible values will result in a N-dimension list of scalar tensors rather than a single Rank-N tensors. If you need different behavior, convert part of inputs to tensors with `tf.convert_to_tensor`."
tf.config.optimizer.set_experimental_options,options,prim_dtype,['int'],"['tf.float16', 'tf.float32']","Dictionary of experimental optimizer options to configure. Valid keys: layout_optimizer: Optimize tensor layouts e.g. This will try to use NCHW layout on GPU which is faster.constant_folding: Fold constants Statically infer the value of tensors when possible, and materialize the result using constants.shape_optimization: Simplify computations made on shapes.remapping: Remap subgraphs onto more efficient implementations.arithmetic_optimization: Simplify arithmetic ops with common sub-expression elimination and arithmetic simplification.dependency_optimization: Control dependency optimizations. Remove redundant control dependencies, which may enable other optimization. This optimizer is also essential for pruning Identity and NoOp nodes.loop_optimization: Loop optimizations.function_optimization: Function optimizations and inlining.debug_stripper: Strips debug-related nodes from the graph.disable_model_pruning: Disable removal of unnecessary ops from the graphscoped_allocator_optimization: Try to allocate some independent Op outputs contiguously in order to merge or eliminate downstream Ops.pin_to_host_optimization: Force small ops onto the CPU.implementation_selector: Enable the swap of kernel implementations based on the device placement.auto_mixed_precision: Change certain float32 ops to float16 on Volta GPUs and above. Without the use of loss scaling, this can cause numerical underflow (see`keras.mixed_precision.experimental.LossScaleOptimizer`).disable_meta_optimizer: Disable the entire meta optimizer.min_graph_nodes: The minimum number of nodes in a graph to optimizer. For smaller graphs, optimization is skipped. "
tf.sparse.reduce_sum,axis,prim_dtype,['int'],['numeric'],"The dimensions to reduce; list or scalar. If `None` (the default), reduces all dimensions."
tf.debugging.assert_shapes,shapes,nonprim_dtype,['dict'],['list'],dictionary with (`Tensor` to shape) items. A shape must be an iterable.
tf.image.crop_and_resize,box_indices,prim_dtype,['int'],['tf.int32'],"A 1-D tensor of shape `[num_boxes]` with int32 values in `[0, batch)`. The value of `box_ind[i]` specifies the image that the `i`-th box refers to."
tf.io.extract_jpeg_shape,output_type,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.int32', 'tf.int64']","An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`. (Optional) The output type of the operation (int32 or int64). Defaults to int32."
tf.keras.preprocessing.sequence.pad_sequences,dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.string']","Type of the output sequences.     To pad sequences with variable length strings, you can use `object`."
tf.feature_column.categorical_column_with_vocabulary_list,dtype,prim_dtype,"['int', 'tf.dtype']","['int', 'tf.dtype', 'tf.string']","The type of features. Only string and integer types are supported. If`None`, it will be inferred from `vocabulary_list`."
tf.ragged.range,row_splits_dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.int32', 'tf.int64']",`dtype` for the returned `RaggedTensor`'s `row_splits`tensor.  One of `tf.int32` or `tf.int64`.
tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient,inputs,prim_dtype,['tf.float32'],"['float', 'tf.float32']","A `Tensor` of type `float32`. Values passed as inputs to the FakeQuantWithMinMaxVars operation, shape same as `gradients`. min, max: Quantization interval, floats of shape `[d]`."
tf.debugging.assert_rank_in,ranks,prim_dtype,['scalar'],['numeric'],`Iterable` of scalar `Tensor` objects.
tf.sparse.to_indicator,vocab_size,prim_dtype,['tf.int64'],"['int', 'tf.int64']","A scalar int64 Tensor (or Python int) containing the new size of the last dimension, `all(0 <= sp_input.values < vocab_size)`."
tf.searchsorted,out_type,prim_dtype,['tf.dtype'],"['tf.int32', 'tf.int64']",The output type (`int32` or `int64`).  Default is `tf.int32`.
tf.keras.backend.in_test_phase,training,prim_dtype,['numeric'],"['int', 'tf.bool']","Optional scalar tensor (or Python boolean, or Python integer) specifying the learning phase."
tf.keras.preprocessing.sequence.skipgrams,categorical,prim_dtype,['tf.bool'],"['int', 'tf.bool']","bool. if False, labels will be     integers (eg. `[0, 1, 1 .. ]`),     if `True`, labels will be categorical, e.g.     `[[1,0],[0,1],[0,1] .. ]`."
tf.keras.preprocessing.sequence.skipgrams,window_size,prim_dtype,['int'],"['int', 'tf.float16']","Int, size of sampling windows (technically half-window).     The window of a word `w_i` will be     `[i - window_size, i + window_size+1]`."
tf.histogram_fixed_width,value_range,prim_dtype,"['dtype:&values', 'int']",['tf.dtype'],"Shape [2] `Tensor` of same `dtype` as `values`. values <= value_range[0] will be mapped to hist[0], values >= value_range[1] will be mapped to hist[-1]."
tf.debugging.assert_equal,y,prim_dtype,"['dtype:&x', 'numeric']","['numeric', 'tf.dtype']","Numeric `Tensor`, same dtype as and broadcastable to `x`."
tf.random.uniform,dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.float16', 'tf.float32', 'tf.float64', 'tf.int32', 'tf.int64']","The type of the output: `float16`, `float32`, `float64`, `int32`, or `int64`."
tf.random.uniform,maxval,prim_dtype,['tf.dtype'],"['float', 'tf.dtype']","A Tensor or Python value of type `dtype`, broadcastable with`minval`. The upper bound on the range of random values to generate (exclusive). Defaults to 1 if `dtype` is floating point."
tf.sparse.add,threshold,prim_dtype,"['int', 'tf.complex128', 'tf.complex64', 'tf.float32', 'tf.float64']","['int', 'tf.complex128', 'tf.complex64', 'tf.dtype', 'tf.float32', 'tf.float64']","A 0-D `Tensor`. The magnitude threshold that determines if an output value/index pair takes space. Its dtype should match that of the values if they are real; if the latter are complex64/complex128, then the dtype should be float32/float64, correspondingly."
tf.tensordot,axes,prim_dtype,['tf.int32'],"['int', 'tf.int32']","Either a scalar `N`, or a list or an `int32` `Tensor` of shape [2, k]. If axes is a scalar, sum over the last N axes of a and the first N axes of b in order. If axes is a list or `Tensor` the first and second row contain the set of unique integers specifying axes along which the contraction is computed, for `a` and `b`, respectively. The number of axes for `a` and`b` must be equal. If `axes=0`, computes the outer product between `a` and`b`."
tf.xla.experimental.jit_scope,separate_compiled_gradients,prim_dtype,['tf.bool'],"['tf.bool', 'tf.string']","If true put each gradient subgraph into a separate compilation scope. This gives fine-grained control over which portions of the graph will be compiled as a single unit. Compiling gradients separately may yield better performance for some graphs. The scope is named based on the scope of the forward computation as well as the name of the gradients. As a result, the gradients will be compiled in a scope that is separate from both the forward computation, and from other gradients."
tf.keras.backend.in_train_phase,training,prim_dtype,['numeric'],"['int', 'tf.bool']","Optional scalar tensor (or Python boolean, or Python integer) specifying the learning phase."
tf.random.stateless_categorical,dtype,prim_dtype,"['int', 'tf.dtype']","['int', 'tf.dtype', 'tf.int64']",integer type to use for the output. Defaults to int64.
tf.keras.layers.InputLayer,batch_size,prim_dtype,['numeric'],['int'],Optional input batch size (integer or None).
tf.nest.map_structure,**kwargs,prim_dtype,['tf.bool'],"['tf.bool', 'tf.string']","Valid keyword args are: `check_types`: If set to `True` (default) the types of iterables within the structures have to be same (e.g.`map_structure(func, [1], (1,))` raises a `TypeError`exception). To allow this set this argument to `False`. Note that namedtuples with identical name and fields are always considered to have the same shallow structure.`expand_composites`: If set to `True`, then composite tensors such as `tf.SparseTensor` and `tf.RaggedTensor` are expanded into their component tensors.  If `False` (the default), then composite tensors are not expanded. "
tf.image.sobel_edges,image,prim_dtype,"['numeric', 'tf.float32', 'tf.float64']","['tf.float32', 'tf.float64']","Image tensor with shape [batch_size, h, w, d] and type float32 or float64.  The image(s) must be 2x2 or larger."
tf.sparse.sparse_dense_matmul,adjoint_a,prim_dtype,['tf.bool'],"['tf.bool', 'tf.complex']","Use the adjoint of A in the matrix multiply.  If A is complex, this is transpose(conj(A)).  Otherwise it's transpose(A)."
tf.sparse.sparse_dense_matmul,adjoint_b,prim_dtype,['tf.bool'],"['tf.bool', 'tf.complex']","Use the adjoint of B in the matrix multiply.  If B is complex, this is transpose(conj(B)).  Otherwise it's transpose(B)."
tf.sparse.sparse_dense_matmul,b,prim_dtype,['dtype:&sp_a'],['tf.dtype'],A dense Matrix with the same dtype as sp_a.
tf.feature_column.categorical_column_with_vocabulary_file,dtype,prim_dtype,"['int', 'tf.dtype']","['int', 'tf.dtype', 'tf.string']",The type of features. Only string and integer types are supported.
tf.ragged.segment_ids_to_row_splits,out_type,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.int64']","The dtype for the return value.  Defaults to `segment_ids.dtype`, or `tf.int64` if `segment_ids` does not have a dtype."
tf.linalg.tridiagonal_matmul,rhs,prim_dtype,['dtype:&diagonals'],['tf.dtype'],"A `Tensor` of shape [..., M, N] and with the same dtype as `diagonals`."
tf.unique_with_counts,out_idx,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.int32', 'tf.int64']","An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`."
tf.feature_column.weighted_categorical_column,dtype,prim_dtype,['tf.dtype'],"['float', 'int', 'tf.dtype', 'tf.float32']","Type of weights, such as `tf.float32`. Only float and integer weights are supported."
tf.math.unsorted_segment_mean,data,prim_dtype,['float'],"['float', 'tf.complex', 'tf.dtype']",A `Tensor` with floating point or complex dtype.
tf.summary.image,data,prim_dtype,['numeric'],['float'],"A `Tensor` representing pixel data with shape `[k, h, w, c]`, where `k` is the number of images, `h` and `w` are the height and width of the images, and `c` is the number of channels, which should be 1, 2, 3, or 4 (grayscale, grayscale with alpha, RGB, RGBA). Any of the dimensions may be statically unknown (i.e., `None`). Floating point data will be clipped to the range [0,1)."
tf.debugging.assert_none_equal,y,prim_dtype,"['dtype:&x', 'numeric']","['numeric', 'tf.dtype']","Numeric `Tensor`, same dtype as and broadcastable to `x`."
tf.strings.unicode_transcode,replacement_char,prim_dtype,['int'],"['int', 'tf.string']","An optional `int`. Defaults to `65533`. The replacement character codepoint to be used in place of any invalid formatting in the input when `errors='replace'`. Any valid unicode codepoint may be used. The default value is the default unicode replacement character is 0xFFFD or U+65533.)Note that for UTF-8, passing a replacement character expressible in 1 byte, such as ' ', will preserve string alignment to the source since invalid bytes will be replaced with a 1-byte replacement. For UTF-16-BE and UTF-16-LE, any 1 or 2 byte replacement character will preserve byte alignment to the source."
tf.keras.layers.ConvLSTM2D,dilation_rate,nonprim_dtype,"['list', 'list(int)']","['list', 'tuple']","An integer or tuple/list of n integers, specifying the dilation rate to use for dilated convolution. Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any `strides` value != 1."
tf.keras.layers.ConvLSTM2D,kernel_size,nonprim_dtype,"['list', 'list(int)']","['list', 'tuple']","An integer or tuple/list of n integers, specifying the dimensions of the convolution window."
tf.keras.layers.ConvLSTM2D,strides,nonprim_dtype,"['list', 'list(int)']","['list', 'tuple']","An integer or tuple/list of n integers, specifying the strides of the convolution. Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1."
tf.scatter_nd,shape,prim_dtype,"['dtype:&indices', 'int']",['int'],A `Tensor`. Must have the same type as `indices`. 1-D. The shape of the resulting tensor.
tf.io.decode_png,dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.uint16', 'tf.uint8']","An optional `tf.DType` from: `tf.uint8, tf.uint16`. Defaults to `tf.uint8`."
tf.ones,dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.float32']",Optional DType of an element in the resulting `Tensor`. Default is`tf.float32`.
tf.test.compute_gradient,delta,prim_dtype,['float'],"['float', 'numeric']",(optional) perturbation used to compute numeric Jacobian.
tf.math.argmin,output_type,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.int32', 'tf.int64']","An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to`tf.int64`."
tf.nn.embedding_lookup_sparse,sp_weights,prim_dtype,['float'],"['float', 'tf.float64']","either a `SparseTensor` of float / double weights, or `None` to indicate all weights should be taken to be 1. If specified, `sp_weights`must have exactly the same shape and indices as `sp_ids`."
tf.debugging.assert_greater_equal,y,prim_dtype,"['dtype:&x', 'numeric']","['numeric', 'tf.dtype']","Numeric `Tensor`, same dtype as and broadcastable to `x`."
tf.signal.dct,type,prim_dtype,"['int', 'tf.dtype']",['int'],"The DCT type to perform. Must be 1, 2 or 3."
tf.math.argmax,output_type,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.int32', 'tf.int64']","An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to`tf.int64`."
tf.no_gradient,op_type,prim_dtype,"['tf.dtype', 'tf.string']",['tf.string'],The string type of an operation. This corresponds to the`OpDef.name` field for the proto that defines the operation.
tf.scan,infer_shape,prim_dtype,['tf.bool'],"['int', 'tf.bool']",(optional) False disables tests for consistent output shapes.
tf.strings.to_number,out_type,prim_dtype,['tf.dtype'],"['numeric', 'tf.dtype', 'tf.float32', 'tf.float64', 'tf.int32', 'tf.int64', 'tf.string']","An optional `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.int64`. Defaults to `tf.float32`. The numeric type to interpret each string in `string_tensor` as."
tf.nn.depthwise_conv2d_backprop_filter,filter_sizes,prim_dtype,['tf.int32'],"['int', 'tf.int32']","A `Tensor` of type `int32`. An integer vector representing the tensor shape of `filter`, where `filter` is a 4-D`[filter_height, filter_width, in_channels, depthwise_multiplier]` tensor."
tf.nn.RNNCellDropoutWrapper,input_size,prim_dtype,['numeric'],['int'],(optional) (possibly nested tuple of) `TensorShape` objects containing the depth(s) of the input tensors expected to be passed in to the `DropoutWrapper`.  Required and used <strong>iff</strong> `variational_recurrent = True` and `input_keep_prob < 1`.
tf.feature_column.numeric_column,default_value,prim_dtype,['int'],['tf.dtype'],"A single value compatible with `dtype` or an iterable of values compatible with `dtype` which the column takes on during`tf.Example` parsing if data is missing. A default value of `None` will cause `tf.io.parse_example` to fail if an example does not contain this column. If a single value is provided, the same value will be applied as the default value for every item. If an iterable of values is provided, the shape of the `default_value` should be equal to the given `shape`."
tf.feature_column.numeric_column,dtype,prim_dtype,['tf.dtype'],"['float', 'int', 'tf.dtype', 'tf.float32']","defines the type of values. Default value is `tf.float32`. Must be a non-quantized, real integer or floating point type."
tf.nn.safe_embedding_lookup_sparse,sparse_weights,prim_dtype,['numeric'],['float'],"`SparseTensor` of same shape as `sparse_ids`, containing float weights corresponding to `sparse_ids`, or `None` if all weights are be assumed to be 1.0."
tf.sparse.reduce_max,axis,prim_dtype,['int'],['numeric'],"The dimensions to reduce; list or scalar. If `None` (the default), reduces all dimensions."
tf.keras.backend.cast,dtype,prim_dtype,"['tf.dtype', 'tf.string']","['tf.dtype', 'tf.float16', 'tf.float32', 'tf.float64', 'tf.string']","String, either (`'float16'`, `'float32'`, or `'float64'`)."
tf.nn.depthwise_conv2d_backprop_input,input_sizes,prim_dtype,['tf.int32'],"['int', 'tf.int32']","A `Tensor` of type `int32`. An integer vector representing the shape of `input`, based on `data_format`.  For example, if `data_format` is 'NHWC' then`input` is a 4-D `[batch, height, width, channels]` tensor."
tf.estimator.classifier_parse_example_spec,label_dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.float32', 'tf.int64', 'tf.string']","A `tf.dtype` identifies the type of labels. By default it is`tf.int64`. If user defines a `label_vocabulary`, this should be set as`tf.string`. `tf.float32` labels are only supported for binary classification."
tf.pad,constant_values,prim_dtype,"['dtype:&tensor', 'int']",['int'],"In ""CONSTANT"" mode, the scalar pad value to use. Must be same type as `tensor`."
tf.space_to_batch_nd,block_shape,prim_dtype,"['tf.int32', 'tf.int64']","['int', 'tf.int32', 'tf.int64']","A `Tensor`. Must be one of the following types: `int32`, `int64`. 1-D with shape `[M]`, all values must be >= 1."
tf.io.matching_files,pattern,prim_dtype,"['tf.dtype', 'tf.string']",['tf.string'],A `Tensor` of type `string`. Shell wildcard pattern(s). Scalar or vector of type string.
tf.summary.audio,data,prim_dtype,['int'],['float'],"A `Tensor` representing audio data with shape `[k, t, c]`, where `k` is the number of audio clips, `t` is the number of frames, and `c` is the number of channels. Elements should be floating-point values in `[-1.0, 1.0]`. Any of the dimensions may be statically unknown (i.e., `None`)."
tf.random.poisson,dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.float16', 'tf.float32', 'tf.float64', 'tf.int32', 'tf.int64']","The type of the output: `float16`, `float32`, `float64`, `int32` or`int64`."
tf.ragged.constant,pylist,prim_dtype,['numeric'],['tf.dtype'],"A nested `list`, `tuple` or `np.ndarray`.  Any nested element that is not a `list`, `tuple` or `np.ndarray` must be a scalar value compatible with `dtype`."
tf.ragged.constant,pylist,nonprim_dtype,['list'],"['list', 'tuple']","A nested `list`, `tuple` or `np.ndarray`.  Any nested element that is not a `list`, `tuple` or `np.ndarray` must be a scalar value compatible with `dtype`."
tf.ragged.constant,row_splits_dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.int32', 'tf.int64']",data type for the constructed `RaggedTensor`'s row_splits. One of `tf.int32` or `tf.int64`.
tf.shape,out_type,prim_dtype,['tf.dtype'],"['tf.int32', 'tf.int64']",(Optional) The specified output type of the operation (`int32` or`int64`). Defaults to `tf.int32`.
tf.nest.assert_same_structure,check_types,prim_dtype,['tf.bool'],"['tf.bool', 'tf.string']","if `True` (default) types of sequences are checked as well, including the keys of dictionaries. If set to `False`, for example a list and a tuple of objects will look the same if they have the same size. Note that namedtuples with identical name and fields are always considered to have the same shallow structure. Two types will also be considered the same if they are both list subtypes (which allows ""list"" and ""_ListWrapper"" from trackable dependency tracking to compare equal)."
tf.nest.assert_same_structure,check_types,nonprim_dtype,['tuple'],"['list', 'tuple']","if `True` (default) types of sequences are checked as well, including the keys of dictionaries. If set to `False`, for example a list and a tuple of objects will look the same if they have the same size. Note that namedtuples with identical name and fields are always considered to have the same shallow structure. Two types will also be considered the same if they are both list subtypes (which allows ""list"" and ""_ListWrapper"" from trackable dependency tracking to compare equal)."
tf.random.gamma,dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.float16', 'tf.float32', 'tf.float64']","The type of alpha, beta, and the output: `float16`, `float32`, or`float64`."
tf.keras.backend.set_floatx,value,prim_dtype,['tf.string'],"['tf.float16', 'tf.float32', 'tf.float64', 'tf.string']","String; 'float16', 'float32', or 'float64'. Example: `python from keras import backend as K K.floatx() >>> 'float32' K.set_floatx('float16') K.floatx() >>> 'float16'`"
tf.keras.backend.ctc_decode,greedy,prim_dtype,['tf.bool'],"['tf.bool', 'tf.string']",perform much faster best-path search if `true`. This does not use a dictionary.
tf.quantization.quantize,T,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.qint16', 'tf.qint32', 'tf.qint8', 'tf.quint16', 'tf.quint8']","A `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`."
tf.math.count_nonzero,dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.int64']",The output dtype; defaults to `tf.int64`.
tf.math.count_nonzero,input,prim_dtype,['numeric'],"['numeric', 'tf.bool', 'tf.string']","The tensor to reduce. Should be of numeric type, `bool`, or `string`."
tf.feature_column.sequence_categorical_column_with_vocabulary_list,dtype,prim_dtype,"['int', 'tf.dtype']","['int', 'tf.dtype', 'tf.string']","The type of features. Only string and integer types are supported. If `None`, it will be inferred from `vocabulary_list`."
tf.histogram_fixed_width_bins,value_range,prim_dtype,"['dtype:&values', 'int']",['tf.dtype'],"Shape [2] `Tensor` of same `dtype` as `values`. values <= value_range[0] will be mapped to hist[0], values >= value_range[1] will be mapped to hist[-1]."
tf.math.unsorted_segment_sqrt_n,data,prim_dtype,['float'],"['float', 'tf.complex', 'tf.dtype']",A `Tensor` with floating point or complex dtype.
tf.debugging.assert_less_equal,y,prim_dtype,"['dtype:&x', 'numeric']","['numeric', 'tf.dtype']","Numeric `Tensor`, same dtype as and broadcastable to `x`."
tf.keras.utils.to_categorical,dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.float32']",The data type expected by the input. Default: `'float32'`.
tf.numpy_function,Tout,prim_dtype,['tf.bool'],"['tf.bool', 'tf.dtype']","A list or tuple of tensorflow data types or a single tensorflow data type if there is only one, indicating what `func` returns. stateful (bool): If True, the function should be considered stateful. If a function is stateless, when given the same input it will return the same output and have no observable side effects. Optimizations such as common subexpression elimination are only performed on stateless operations."
tf.batch_to_space,block_shape,prim_dtype,"['tf.int32', 'tf.int64']","['int', 'tf.dtype', 'tf.int32', 'tf.int64']","A `Tensor`. Must be one of the following types: `int32`,`int64`. 1-D with shape `[M]`, all values must be >= 1. For backwards compatibility with TF 1.0, this parameter may be an int, in which case it is converted to `numpy.array([block_shape, block_shape], dtype=numpy.int64)`."
tf.keras.Input,batch_size,prim_dtype,['numeric'],['int'],optional static batch size (integer).
tf.keras.Input,dtype,prim_dtype,"['tf.dtype', 'tf.string']","['tf.dtype', 'tf.float32', 'tf.float64', 'tf.int32', 'tf.string']","The data type expected by the input, as a string (`float32`, `float64`, `int32`...)"
tf.data.experimental.Counter,dtype,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.int64']",(Optional.) The data type for counter elements. Defaults to`tf.int64`.
tf.config.list_logical_devices,device_type,prim_dtype,['tf.dtype'],['tf.string'],"(optional string) Only include devices matching this device type. For example ""CPU"" or ""GPU""."
tf.io.decode_csv,use_quote_delim,prim_dtype,['tf.bool'],"['tf.bool', 'tf.float64', 'tf.string']","An optional `bool`. Defaults to `True`. If false, treats double quotation marks as regular characters inside of the string fields (ignoring RFC 4180, Section 2, Bullet 5)."
tf.space_to_batch,block_shape,prim_dtype,"['tf.int32', 'tf.int64']","['int', 'tf.int32', 'tf.int64']","A `Tensor`. Must be one of the following types: `int32`, `int64`. 1-D with shape `[M]`, all values must be >= 1."
tf.nn.dropout,noise_shape,prim_dtype,['tf.int32'],"['int', 'tf.int32']","A 1-D `Tensor` of type `int32`, representing the shape for randomly generated keep/drop flags."
tf.nn.dropout,rate,prim_dtype,['dtype:&x'],['numeric'],"A scalar `Tensor` with the same type as x. The probability that each element is dropped. For example, setting rate=0.1 would drop 10% of input elements."
tf.config.get_visible_devices,device_type,prim_dtype,['tf.dtype'],['tf.string'],"(optional string) Only include devices matching this device type. For example ""CPU"" or ""GPU""."
tf.quantization.fake_quant_with_min_max_vars_gradient,inputs,prim_dtype,['tf.float32'],"['float', 'tf.float32']","A `Tensor` of type `float32`. Values passed as inputs to the FakeQuantWithMinMaxVars operation. min, max: Quantization interval, scalar floats."
tf.keras.backend.clip,max_value,prim_dtype,['float'],"['float', 'int']","Python float, integer, or tensor."
tf.keras.backend.clip,min_value,prim_dtype,['float'],"['float', 'int']","Python float, integer, or tensor."
tf.debugging.assert_near,atol,prim_dtype,['dtype:&x'],['tf.dtype'],"`Tensor`.  Same `dtype` as, and broadcastable to, `x`. The absolute tolerance.  Default is `10 * eps`."
tf.debugging.assert_near,rtol,prim_dtype,['dtype:&x'],['tf.dtype'],"`Tensor`.  Same `dtype` as, and broadcastable to, `x`. The relative tolerance.  Default is `10 * eps`."
tf.debugging.assert_near,y,prim_dtype,"['dtype:&x', 'float', 'tf.complex']","['float', 'tf.complex', 'tf.dtype']","Float or complex `Tensor`, same dtype as and broadcastable to `x`."
tf.required_space_to_batch_paddings,block_shape,prim_dtype,['tf.int32'],"['int', 'tf.int32']",int32 Tensor of shape [N].
tf.required_space_to_batch_paddings,input_shape,prim_dtype,['tf.int32'],"['int', 'tf.int32']",int32 Tensor of shape [N].
tf.feature_column.sequence_categorical_column_with_hash_bucket,dtype,prim_dtype,"['int', 'tf.dtype']","['int', 'tf.dtype', 'tf.string']",The type of features. Only string and integer types are supported.
tf.config.list_physical_devices,device_type,prim_dtype,['tf.dtype'],['tf.string'],"(optional string) Only include devices matching this device type. For example ""CPU"" or ""GPU""."
tf.keras.layers.experimental.preprocessing.TextVectorization,output_mode,prim_dtype,['int'],"['int', 'tf.string']","Optional specification for the output of the layer. Values can be ""int"", ""binary"", ""count"" or ""tf-idf"", configuring the layer as follows: ""int"": Outputs integer indices, one integer index per split string   token. ""binary"": Outputs a single int array per batch, of either vocab_size or   max_tokens size, containing 1s in all elements where the token mapped   to that index exists at least once in the batch item. ""count"": As ""binary"", but the int array contains a count of the number   of times the token at that index appeared in the batch item. ""tf-idf"": As ""binary"", but the TF-IDF algorithm is applied to find the   value in each token slot."
tf.keras.layers.experimental.preprocessing.TextVectorization,output_sequence_length,prim_dtype,['numeric'],['int'],"Only valid in INT mode. If set, the output will have its time dimension padded or truncated to exactly `output_sequence_length`values, resulting in a tensor of shape [batch_size, output_sequence_length] regardless of how many tokens resulted from the splitting step. Defaults to None."
tf.linalg.lu,output_idx_type,prim_dtype,['tf.dtype'],"['tf.dtype', 'tf.int32', 'tf.int64']","An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`."
tf.map_fn,infer_shape,prim_dtype,['tf.bool'],"['int', 'tf.bool']",(optional) False disables tests for consistent output shapes.
tf.sparse.expand_dims,axis,prim_dtype,['int'],['numeric'],"0-D (scalar). Specifies the dimension index at which to expand the shape of `input`. Must be in the range `[-rank(sp_input) - 1, rank(sp_input)]`."
tf.math.logical_xor,x,prim_dtype,['tf.dtype'],['tf.bool'],A `Tensor` type bool.
tf.strings.reduce_join,axis,prim_dtype,['int'],['numeric'],"Which axis to join along. The default behavior is to join all elements, producing a scalar."
tf.shape_n,out_type,prim_dtype,['tf.dtype'],"['tf.int32', 'tf.int64']",The specified output type of the operation (`int32` or `int64`). Defaults to `tf.int32`(optional).
