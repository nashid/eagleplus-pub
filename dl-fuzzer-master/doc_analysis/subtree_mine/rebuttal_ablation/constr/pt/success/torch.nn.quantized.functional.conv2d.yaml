constraints:
  bias:
    descp: non-quantized bias tensor of shape (out _channels) . The tensor type must
      be torch.float.
    dtype:
    - int
    - numeric
    - string
    - torch.bool
    - torch.dtype
    - torch.float32
    ndim:
    - '0'
    - '1'
    - '3'
    range:
    - '[0,1]'
    - '[0,inf)'
    shape:
    - '&input'
    - '[b,p,m]'
    - '[c]'
    - '[out_channels]'
    tensor_t:
    - torch.tensor
  dilation:
    default: '1'
    descp: 'the spacing between kernel elements. Can be a single number or a tuple
      (dH, dW). Default: 1'
    dtype:
    - int
    - torch.bool
    ndim:
    - '0'
    - '1'
    - '2'
    range:
    - '[0,inf)'
    shape:
    - '[1]'
    - '[dh,dw]'
    structure:
    - tuple
  dtype:
    default: torch.quint8
    descp: 'quantization data type to use. Default: `torch.quint8`'
    dtype:
    - int
    - torch.bool
    - torch.dtype
    ndim:
    - '0'
  groups:
    default: '1'
    descp: 'split input into groups, in _channels  should be divisible by the number
      of groups. Default: 1'
    dtype:
    - int
    - torch.bool
    ndim:
    - '0'
    - '1'
    range:
    - '[0,inf)'
  input:
    descp: 'quantized input tensor of shape (minibatch , in _channels , iH , iW) '
    dtype:
    - int
    - numeric
    - string
    - torch.bool
    - torch.dtype
    ndim:
    - '0'
    - '1'
    - '3'
    - '4'
    range:
    - '[0,1]'
    - '[0,inf)'
    shape:
    - '&input'
    - '[b,p,m]'
    - '[c]'
    - '[minibatch,in_channels,ih,iw]'
    tensor_t:
    - torch.tensor
  padding:
    default: '0'
    descp: 'implicit paddings on both sides of the input. Can be a single number or
      a tuple (padH, padW). Default: 0'
    dtype:
    - int
    - torch.bool
    ndim:
    - '0'
    - '1'
    - '2'
    range:
    - '[0,inf)'
    shape:
    - '[1]'
    - '[padh,padw]'
    structure:
    - tuple
  padding_mode:
    default: zeros
    descp: 'the padding mode to use. Only "zeros" is supported for quantized convolution
      at the moment. Default: "zeros"'
    dtype:
    - int
    - string
    - torch.bool
    ndim:
    - '0'
  scale:
    default: '1.0'
    descp: 'quantization scale for the output. Default: 1.0'
    dtype:
    - int
    - torch.float32
    ndim:
    - '0'
  stride:
    default: '1'
    descp: 'the stride of the convolving kernel. Can be a single number or a tuple
      (sH, sW). Default: 1'
    dtype:
    - int
    - torch.bool
    ndim:
    - '0'
    - '1'
    - '2'
    range:
    - '[0,inf)'
    shape:
    - '[1]'
    - '[sh,sw]'
    structure:
    - tuple
  weight:
    descp: 'quantized filters of shape (out _channels ,  in _channels/groups , kH
      , kW) '
    dtype:
    - int
    - numeric
    ndim:
    - '0'
    range:
    - '[0,inf)'
  zero_point:
    default: '0'
    descp: 'quantization zero_point for the output. Default: 0'
    dtype:
    - int
    - torch.bool
    ndim:
    - '0'
    range:
    - '[0,inf)'
inputs:
  optional:
  - stride
  - padding
  - dilation
  - groups
  - padding_mode
  - scale
  - zero_point
  - dtype
  required:
  - input
  - weight
  - bias
link: https://pytorch.org/docs/stable/quantization.html#torch.nn.quantized.functional.conv2d
package: torch
target: conv2d
title: torch.nn.quantized.functional.conv2d
version: 1.5.0
