,idx,support,cnt,itemsets,sentence,api,len
0,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.nn.functional.adaptive_max_pool3d.yaml,2
1,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.empty_strided.yaml,2
2,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.empty_strided.yaml,2
3,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.arange.yaml,2
4,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.cholesky.yaml,2
5,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.nn.quantized.functional.avg_pool2d.yaml,2
6,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.nn.functional.grid_sample.yaml,2
7,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.nn.functional.avg_pool1d.yaml,2
8,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.ones_like.yaml,2
9,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False` Infinite losses mainly occur when the inputs are too short to be aligned to the targets.,torch.nn.functional.ctc_loss.yaml,2
10,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.nn.functional.adaptive_max_pool1d.yaml,2
11,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.irfft.yaml,2
12,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.empty_like.yaml,2
13,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.hann_window.yaml,2
14,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default `False`.,torch.nn.functional.embedding.yaml,2
15,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.nn.functional.affine_grid.yaml,2
16,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.zeros_like.yaml,2
17,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.rand.yaml,2
18,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.nn.functional.adaptive_max_pool2d.yaml,2
19,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.fft.yaml,2
20,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.triangular_solve.yaml,2
21,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.triangular_solve.yaml,2
22,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.nn.functional.avg_pool2d.yaml,2
23,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.eye.yaml,2
24,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.nn.functional.dropout.yaml,2
25,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.randn_like.yaml,2
26,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.ifft.yaml,2
27,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.cholesky_solve.yaml,2
28,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.lu.yaml,2
29,542,0.029172644667623145,61,"frozenset({'false', 'default'})",whether to return an abbreviated summary (default: False).,torch.cuda.memory_summary.yaml,2
30,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.ones.yaml,2
31,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.randperm.yaml,2
32,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default is False.,torch.hub.load.yaml,2
33,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.max2.yaml,2
34,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default is False.,torch.hub.help.yaml,2
35,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: False,torch.utils.model_zoo.load_url.yaml,2
36,542,0.029172644667623145,61,"frozenset({'false', 'default'})",controls whether to return the normalized STFT results Default: `False`,torch.stft.yaml,2
37,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.nn.functional.dropout2d.yaml,2
38,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.linspace.yaml,2
39,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.autograd.grad.yaml,2
40,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.hamming_window.yaml,2
41,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.norm.yaml,2
42,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.blackman_window.yaml,2
43,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.nn.functional.dropout3d.yaml,2
44,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.bartlett_window.yaml,2
45,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.logspace.yaml,2
46,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.nn.quantized.functional.interpolate.yaml,2
47,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.allclose.yaml,2
48,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.tensor.yaml,2
49,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.tensor.yaml,2
50,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.sparse_coo_tensor.yaml,2
51,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.zeros.yaml,2
52,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.randn.yaml,2
53,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False` target *  log(target) - target + 0.5 *  log(2 *  pi * target) .,torch.nn.functional.poisson_nll_loss.yaml,2
54,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.matrix_rank.yaml,2
55,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default is False.,torch.hub.list.yaml,2
56,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.rand_like.yaml,2
57,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.nn.functional.interpolate.yaml,2
58,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: False,torch.hub.load_state_dict_from_url.yaml,2
59,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`.,torch.full.yaml,2
60,542,0.029172644667623145,61,"frozenset({'false', 'default'})",Default: `False`,torch.rfft.yaml,2
61,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.empty_strided.yaml,10
62,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.arange.yaml,10
63,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.hann_window.yaml,10
64,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.rand.yaml,10
65,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.eye.yaml,10
66,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.ones.yaml,10
67,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.randperm.yaml,10
68,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.triu_indices.yaml,10
69,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.tril_indices.yaml,10
70,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.linspace.yaml,10
71,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.hamming_window.yaml,10
72,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.blackman_window.yaml,10
73,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.as_tensor.yaml,10
74,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.bartlett_window.yaml,10
75,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.logspace.yaml,10
76,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.tensor.yaml,10
77,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if None, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.sparse_coo_tensor.yaml,10
78,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.zeros.yaml,10
79,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.randn.yaml,10
80,504,0.016260162601626018,20,"frozenset({'set_default_tensor_type', 'none', 'see', 'tensor', 'uses', 'type', 'default', 'current', 'torch', 'SOME_DTYPE'})","Default: if `None`, uses the current device for the default tensor type (see `torch.set_default_tensor_type()`).",torch.full.yaml,10
81,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.quantized.functional.avg_pool2d.yaml,2
82,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.avg_pool1d.yaml,2
83,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`.,torch.nn.utils.rnn.pack_padded_sequence.yaml,2
84,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.irfft.yaml,2
85,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`.,torch.triangular_solve.yaml,2
86,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.kl_div.yaml,2
87,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.kl_div.yaml,2
88,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.avg_pool2d.yaml,2
89,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.dropout.yaml,2
90,539,0.015781922525107604,33,"frozenset({'true', 'default'})",whether or not to display a progress bar to stderr Default: True,torch.hub.download_url_to_file.yaml,2
91,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default is True.,torch.lobpcg.yaml,2
92,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.binary_cross_entropy.yaml,2
93,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.binary_cross_entropy.yaml,2
94,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`.,torch.nn.utils.rnn.pack_sequence.yaml,2
95,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.lu.yaml,2
96,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default is True.,torch.hub.load.yaml,2
97,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: True,torch.utils.model_zoo.load_url.yaml,2
98,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.stft.yaml,2
99,539,0.015781922525107604,33,"frozenset({'true', 'default'})",controls whether to return half of results to avoid redundancy Default: `True`,torch.stft.yaml,2
100,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.dropout2d.yaml,2
101,539,0.015781922525107604,33,"frozenset({'true', 'default'})","If `True` (default), imports the produced shared library as a Python module.",torch.utils.cpp_extension.load.yaml,2
102,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.nll_loss.yaml,2
103,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.nll_loss.yaml,2
104,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.dropout3d.yaml,2
105,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.cross_entropy.yaml,2
106,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.cross_entropy.yaml,2
107,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.binary_cross_entropy_with_logits.yaml,2
108,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.binary_cross_entropy_with_logits.yaml,2
109,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.poisson_nll_loss.yaml,2
110,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.poisson_nll_loss.yaml,2
111,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.nn.functional.poisson_nll_loss.yaml,2
112,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: True,torch.hub.load_state_dict_from_url.yaml,2
113,539,0.015781922525107604,33,"frozenset({'true', 'default'})",Default: `True`,torch.rfft.yaml,2
114,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.empty_strided.yaml,5
115,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.arange.yaml,5
116,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.ones_like.yaml,5
117,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.empty_like.yaml,5
118,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.hann_window.yaml,5
119,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.zeros_like.yaml,5
120,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.rand.yaml,5
121,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.eye.yaml,5
122,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.randn_like.yaml,5
123,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.ones.yaml,5
124,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.randperm.yaml,5
125,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.linspace.yaml,5
126,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.hamming_window.yaml,5
127,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.blackman_window.yaml,5
128,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.bartlett_window.yaml,5
129,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.logspace.yaml,5
130,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.tensor.yaml,5
131,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.sparse_coo_tensor.yaml,5
132,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.zeros.yaml,5
133,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.randn.yaml,5
134,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.rand_like.yaml,5
135,457,0.010521281683405069,22,"frozenset({'returned', 'tensor', 'operations', 'record', 'autograd'})",If autograd should record operations on the returned tensor.,torch.full.yaml,5
136,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.empty_strided.yaml,6
137,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.arange.yaml,6
138,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.hann_window.yaml,6
139,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.rand.yaml,6
140,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.eye.yaml,6
141,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.ones.yaml,6
142,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.randperm.yaml,6
143,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.triu_indices.yaml,6
144,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.tril_indices.yaml,6
145,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.linspace.yaml,6
146,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.hamming_window.yaml,6
147,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.blackman_window.yaml,6
148,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.as_tensor.yaml,6
149,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.bartlett_window.yaml,6
150,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.logspace.yaml,6
151,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.tensor.yaml,6
152,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.sparse_coo_tensor.yaml,6
153,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.zeros.yaml,6
154,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.randn.yaml,6
155,468,0.009564801530368245,20,"frozenset({'types', 'tensor', 'cuda', 'cpu', 'current', 'SOME_DTYPE'})",`device` will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.,torch.full.yaml,6
156,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on.,torch.distributed.get_backend.yaml,3
157,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.all_reduce.yaml,3
158,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.isend.yaml,3
159,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.barrier.yaml,3
160,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.all_gather.yaml,3
161,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.gather.yaml,3
162,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.recv.yaml,3
163,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.broadcast_multigpu.yaml,3
164,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.reduce.yaml,3
165,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.all_gather_multigpu.yaml,3
166,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.send.yaml,3
167,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.get_world_size.yaml,3
168,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.scatter.yaml,3
169,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.irecv.yaml,3
170,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.reduce_multigpu.yaml,3
171,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.broadcast.yaml,3
172,414,0.008130081300813009,17,"frozenset({'group', 'process', 'work'})",The process group to work on,torch.distributed.get_rank.yaml,3
173,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.std2.yaml,5
174,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.prod2.yaml,5
175,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.mean2.yaml,5
176,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.sum2.yaml,5
177,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.min2.yaml,5
178,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.argmin2.yaml,5
179,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.var_mean2.yaml,5
180,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.median2.yaml,5
181,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.logsumexp.yaml,5
182,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.max2.yaml,5
183,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.argmax2.yaml,5
184,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensors have `dim` retained or not.,torch.norm.yaml,5
185,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.kthvalue.yaml,5
186,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.var2.yaml,5
187,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.mode.yaml,5
188,410,0.007651841224294596,16,"frozenset({'retained', 'tensor', 'output', 'whether', 'dim'})",whether the output tensor has `dim` retained or not.,torch.std_mean2.yaml,5
189,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.empty_strided.yaml,7
190,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.arange.yaml,7
191,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.hann_window.yaml,7
192,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.rand.yaml,7
193,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.eye.yaml,7
194,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.ones.yaml,7
195,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.linspace.yaml,7
196,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.hamming_window.yaml,7
197,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.blackman_window.yaml,7
198,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.bartlett_window.yaml,7
199,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.logspace.yaml,7
200,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.zeros.yaml,7
201,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.randn.yaml,7
202,411,0.007651841224294596,14,"frozenset({'set_default_tensor_type', 'none', 'global', 'see', 'uses', 'default', 'torch'})","Default: if `None`, uses a global default (see `torch.set_default_tensor_type()`).",torch.full.yaml,7
203,409,0.007173601147776184,12,"frozenset({'selected', 'SOME_DTYPE'})",selected device.,torch.cuda.max_memory_reserved.yaml,2
204,409,0.007173601147776184,12,"frozenset({'selected', 'SOME_DTYPE'})",selected device.,torch.cuda.memory_reserved.yaml,2
205,409,0.007173601147776184,12,"frozenset({'selected', 'SOME_DTYPE'})",selected device.,torch.cuda.reset_max_memory_allocated.yaml,2
206,409,0.007173601147776184,12,"frozenset({'selected', 'SOME_DTYPE'})",selected device.,torch.cuda.memory_stats.yaml,2
207,409,0.007173601147776184,12,"frozenset({'selected', 'SOME_DTYPE'})",selected device.,torch.cuda.memory_allocated.yaml,2
208,409,0.007173601147776184,12,"frozenset({'selected', 'SOME_DTYPE'})",selected device.,torch.cuda.current_stream.yaml,2
209,409,0.007173601147776184,12,"frozenset({'selected', 'SOME_DTYPE'})","Returns the currently selected `Stream` for the current device, given by `current_device()`, if `device` is `None` (default).",torch.cuda.current_stream.yaml,2
210,409,0.007173601147776184,12,"frozenset({'selected', 'SOME_DTYPE'})",selected device.,torch.cuda.set_device.yaml,2
211,409,0.007173601147776184,12,"frozenset({'selected', 'SOME_DTYPE'})",selected device.,torch.cuda.max_memory_allocated.yaml,2
212,409,0.007173601147776184,12,"frozenset({'selected', 'SOME_DTYPE'})",selected device.,torch.cuda.memory_summary.yaml,2
213,409,0.007173601147776184,12,"frozenset({'selected', 'SOME_DTYPE'})",selected device.,torch.cuda.default_stream.yaml,2
214,409,0.007173601147776184,12,"frozenset({'selected', 'SOME_DTYPE'})",selected device.,torch.cuda.reset_max_memory_cached.yaml,2
215,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.functional.hvp.yaml,2
216,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.functional.hvp.yaml,2
217,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.functional.vjp.yaml,2
218,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.functional.vjp.yaml,2
219,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.functional.jvp.yaml,2
220,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.functional.jvp.yaml,2
221,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.functional.vhp.yaml,2
222,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.functional.vhp.yaml,2
223,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.functional.jacobian.yaml,2
224,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.functional.jacobian.yaml,2
225,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.backward.yaml,2
226,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.grad.yaml,2
227,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.functional.hessian.yaml,2
228,502,0.006695361071257772,14,"frozenset({'defaults', 'false'})",Defaults to `False`.,torch.autograd.functional.hessian.yaml,2
229,389,0.006695361071257772,6,"frozenset({'value', 'compare', 'tensor'})",the tensor or value to compare,torch.le.yaml,3
230,389,0.006695361071257772,6,"frozenset({'value', 'compare', 'tensor'})",the tensor or value to compare,torch.gt.yaml,3
231,389,0.006695361071257772,6,"frozenset({'value', 'compare', 'tensor'})",the tensor or value to compare,torch.ne.yaml,3
232,389,0.006695361071257772,6,"frozenset({'value', 'compare', 'tensor'})",the tensor or value to compare,torch.eq.yaml,3
233,389,0.006695361071257772,6,"frozenset({'value', 'compare', 'tensor'})",the tensor or value to compare,torch.ge.yaml,3
234,389,0.006695361071257772,6,"frozenset({'value', 'compare', 'tensor'})",the tensor or value to compare,torch.lt.yaml,3
235,538,0.006217120994739359,3,"frozenset({'input', 'output', 'true'})","If set to `True`, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels.",torch.nn.quantized.functional.interpolate.yaml,3
236,538,0.006217120994739359,3,"frozenset({'input', 'output', 'true'})","If set to `True`, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels.",torch.nn.functional.interpolate.yaml,3
237,538,0.006217120994739359,3,"frozenset({'input', 'output', 'true'})"," If recompute_scale_factor is ``True` or not specified, a new scale_factor will be computed based on the output and input sizes for use in the interpolation computation (i.e. the computation will be identical to if the computed output_size were passed-in explicitly).",torch.nn.functional.interpolate.yaml,3
238,541,0.005738880918220947,4,"frozenset({'input', 'number', 'tensor'})",Default is feps ** 0.5 where feps is smallest non-zero floating-point number of the given input tensor A data type.,torch.lobpcg.yaml,3
239,541,0.005738880918220947,4,"frozenset({'input', 'number', 'tensor'})","If set to -1, the number of classes will be inferred as one greater than the largest class value in the input tensor.",torch.nn.functional.one_hot.yaml,3
240,541,0.005738880918220947,4,"frozenset({'input', 'number', 'tensor'})",an input tensor or number,torch.result_type.yaml,3
241,541,0.005738880918220947,4,"frozenset({'input', 'number', 'tensor'})",an input tensor or number,torch.result_type.yaml,3
242,432,0.005738880918220947,12,"frozenset({'deprecated', 'reduction', 'see'})",Deprecated (see `reduction`).,torch.nn.functional.kl_div.yaml,3
243,432,0.005738880918220947,12,"frozenset({'deprecated', 'reduction', 'see'})",Deprecated (see `reduction`).,torch.nn.functional.kl_div.yaml,3
244,432,0.005738880918220947,12,"frozenset({'deprecated', 'reduction', 'see'})",Deprecated (see `reduction`).,torch.nn.functional.binary_cross_entropy.yaml,3
245,432,0.005738880918220947,12,"frozenset({'deprecated', 'reduction', 'see'})",Deprecated (see `reduction`).,torch.nn.functional.binary_cross_entropy.yaml,3
246,432,0.005738880918220947,12,"frozenset({'deprecated', 'reduction', 'see'})",Deprecated (see `reduction`).,torch.nn.functional.nll_loss.yaml,3
247,432,0.005738880918220947,12,"frozenset({'deprecated', 'reduction', 'see'})",Deprecated (see `reduction`).,torch.nn.functional.nll_loss.yaml,3
248,432,0.005738880918220947,12,"frozenset({'deprecated', 'reduction', 'see'})",Deprecated (see `reduction`).,torch.nn.functional.cross_entropy.yaml,3
249,432,0.005738880918220947,12,"frozenset({'deprecated', 'reduction', 'see'})",Deprecated (see `reduction`).,torch.nn.functional.cross_entropy.yaml,3
250,432,0.005738880918220947,12,"frozenset({'deprecated', 'reduction', 'see'})",Deprecated (see `reduction`).,torch.nn.functional.binary_cross_entropy_with_logits.yaml,3
251,432,0.005738880918220947,12,"frozenset({'deprecated', 'reduction', 'see'})",Deprecated (see `reduction`).,torch.nn.functional.binary_cross_entropy_with_logits.yaml,3
252,432,0.005738880918220947,12,"frozenset({'deprecated', 'reduction', 'see'})",Deprecated (see `reduction`).,torch.nn.functional.poisson_nll_loss.yaml,3
253,432,0.005738880918220947,12,"frozenset({'deprecated', 'reduction', 'see'})",Deprecated (see `reduction`).,torch.nn.functional.poisson_nll_loss.yaml,3
254,519,0.005738880918220947,3,"frozenset({'input', 'dimension', 'dimensions', 'tensor'})","If the value is None, matrix norm will be calculated when the input tensor only has two dimensions, vector norm will be calculated when the input tensor only has one dimension.",torch.norm.yaml,4
255,519,0.005738880918220947,3,"frozenset({'input', 'dimension', 'dimensions', 'tensor'})","If the input tensor has more than two dimensions, the vector norm will be applied to last dimension.",torch.norm.yaml,4
256,519,0.005738880918220947,3,"frozenset({'input', 'dimension', 'dimensions', 'tensor'})","the input tensor of size (*, m, n)  where * is zero or more batch dimensions consisting of matrices of dimension m  times n .",torch.qr.yaml,4
257,501,0.0052606408417025345,10,"frozenset({'input', 'none', 'default', 'defaults', 'SOME_DTYPE'})","Default: if `None`, defaults to the device of `input`.",torch.ones_like.yaml,5
258,501,0.0052606408417025345,10,"frozenset({'input', 'none', 'default', 'defaults', 'SOME_DTYPE'})","Default: if `None`, defaults to the layout of `input`.",torch.ones_like.yaml,5
259,501,0.0052606408417025345,10,"frozenset({'input', 'none', 'default', 'defaults', 'SOME_DTYPE'})","Default: if `None`, defaults to the device of `input`.",torch.empty_like.yaml,5
260,501,0.0052606408417025345,10,"frozenset({'input', 'none', 'default', 'defaults', 'SOME_DTYPE'})","Default: if `None`, defaults to the layout of `input`.",torch.empty_like.yaml,5
261,501,0.0052606408417025345,10,"frozenset({'input', 'none', 'default', 'defaults', 'SOME_DTYPE'})","Default: if `None`, defaults to the device of `input`.",torch.zeros_like.yaml,5
262,501,0.0052606408417025345,10,"frozenset({'input', 'none', 'default', 'defaults', 'SOME_DTYPE'})","Default: if `None`, defaults to the layout of `input`.",torch.zeros_like.yaml,5
263,501,0.0052606408417025345,10,"frozenset({'input', 'none', 'default', 'defaults', 'SOME_DTYPE'})","Default: if `None`, defaults to the device of `input`.",torch.randn_like.yaml,5
264,501,0.0052606408417025345,10,"frozenset({'input', 'none', 'default', 'defaults', 'SOME_DTYPE'})","Default: if `None`, defaults to the layout of `input`.",torch.randn_like.yaml,5
265,501,0.0052606408417025345,10,"frozenset({'input', 'none', 'default', 'defaults', 'SOME_DTYPE'})","Default: if `None`, defaults to the device of `input`.",torch.rand_like.yaml,5
266,501,0.0052606408417025345,10,"frozenset({'input', 'none', 'default', 'defaults', 'SOME_DTYPE'})","Default: if `None`, defaults to the layout of `input`.",torch.rand_like.yaml,5
267,442,0.0052606408417025345,9,"frozenset({'dimensional', 'n', 'torch', 'tensor'})","an n-dimensional torch.Tensor, where n  >= 2 ",torch.nn.init.orthogonal_.yaml,4
268,442,0.0052606408417025345,9,"frozenset({'dimensional', 'n', 'torch', 'tensor'})",an n-dimensional torch.Tensor,torch.nn.init.xavier_normal_.yaml,4
269,442,0.0052606408417025345,9,"frozenset({'dimensional', 'n', 'torch', 'tensor'})",an n-dimensional torch.Tensor,torch.nn.init.zeros_.yaml,4
270,442,0.0052606408417025345,9,"frozenset({'dimensional', 'n', 'torch', 'tensor'})",an n-dimensional torch.Tensor,torch.nn.init.uniform_.yaml,4
271,442,0.0052606408417025345,9,"frozenset({'dimensional', 'n', 'torch', 'tensor'})",an n-dimensional torch.Tensor,torch.nn.init.normal_.yaml,4
272,442,0.0052606408417025345,9,"frozenset({'dimensional', 'n', 'torch', 'tensor'})",an n-dimensional torch.Tensor,torch.nn.init.constant_.yaml,4
273,442,0.0052606408417025345,9,"frozenset({'dimensional', 'n', 'torch', 'tensor'})",an n-dimensional torch.Tensor,torch.nn.init.xavier_uniform_.yaml,4
274,442,0.0052606408417025345,9,"frozenset({'dimensional', 'n', 'torch', 'tensor'})",an n-dimensional torch.Tensor,torch.nn.init.sparse_.yaml,4
275,442,0.0052606408417025345,9,"frozenset({'dimensional', 'n', 'torch', 'tensor'})",an n-dimensional torch.Tensor,torch.nn.init.ones_.yaml,4
276,340,0.0052606408417025345,7,"frozenset({'specifies', 'sum', 'none', 'apply', 'mean', '|', 'reduction', 'output'})",Specifies the reduction to apply to the output: `'none'` | `'mean'` | `'sum'`.,torch.nn.functional.ctc_loss.yaml,8
277,340,0.0052606408417025345,7,"frozenset({'specifies', 'sum', 'none', 'apply', 'mean', '|', 'reduction', 'output'})",Specifies the reduction to apply to the output: `'none'` | `'batchmean'` | `'sum'` | `'mean'`.,torch.nn.functional.kl_div.yaml,8
278,340,0.0052606408417025345,7,"frozenset({'specifies', 'sum', 'none', 'apply', 'mean', '|', 'reduction', 'output'})",Specifies the reduction to apply to the output: `'none'` | `'mean'` | `'sum'`.,torch.nn.functional.binary_cross_entropy.yaml,8
279,340,0.0052606408417025345,7,"frozenset({'specifies', 'sum', 'none', 'apply', 'mean', '|', 'reduction', 'output'})",Specifies the reduction to apply to the output: `'none'` | `'mean'` | `'sum'`.,torch.nn.functional.nll_loss.yaml,8
280,340,0.0052606408417025345,7,"frozenset({'specifies', 'sum', 'none', 'apply', 'mean', '|', 'reduction', 'output'})",Specifies the reduction to apply to the output: `'none'` | `'mean'` | `'sum'`.,torch.nn.functional.cross_entropy.yaml,8
281,340,0.0052606408417025345,7,"frozenset({'specifies', 'sum', 'none', 'apply', 'mean', '|', 'reduction', 'output'})",Specifies the reduction to apply to the output: `'none'` | `'mean'` | `'sum'`.,torch.nn.functional.binary_cross_entropy_with_logits.yaml,8
282,340,0.0052606408417025345,7,"frozenset({'specifies', 'sum', 'none', 'apply', 'mean', '|', 'reduction', 'output'})",Specifies the reduction to apply to the output: `'none'` | `'mean'` | `'sum'`.,torch.nn.functional.poisson_nll_loss.yaml,8
283,540,0.0052606408417025345,11,"frozenset({'number', 'default'})","Can be a single number or a tuple (padT, padH, padW), Default: 0",torch.nn.functional.avg_pool3d.yaml,2
284,540,0.0052606408417025345,11,"frozenset({'number', 'default'})","dimension corresponding to number of outputs, the default is `0`, except for modules that are instances of ConvTranspose{1,2,3}d, when it is `1`",torch.nn.utils.spectral_norm.yaml,2
285,540,0.0052606408417025345,11,"frozenset({'number', 'default'})",`'none'`: no reduction will be applied `'batchmean'`: the sum of the output will be divided by the batchsize `'sum'`: the output will be summed `'mean'`: the output will be divided by the number of elements in the output Default: `'mean'`,torch.nn.functional.kl_div.yaml,2
286,540,0.0052606408417025345,11,"frozenset({'number', 'default'})",the number of columns with default being `n`,torch.eye.yaml,2
287,540,0.0052606408417025345,11,"frozenset({'number', 'default'})",Default is the number of X  columns (when specified) or 1.,torch.lobpcg.yaml,2
288,540,0.0052606408417025345,11,"frozenset({'number', 'default'})",Default is feps ** 0.5 where feps is smallest non-zero floating-point number of the given input tensor A data type.,torch.lobpcg.yaml,2
289,540,0.0052606408417025345,11,"frozenset({'number', 'default'})",Number of array items in summary at beginning and end of each dimension (default = 3).,torch.set_printoptions.yaml,2
290,540,0.0052606408417025345,11,"frozenset({'number', 'default'})",The number of characters per line for the purpose of inserting line breaks (default = 80).,torch.set_printoptions.yaml,2
291,540,0.0052606408417025345,11,"frozenset({'number', 'default'})",Number of digits of precision for floating point output (default = 4).,torch.set_printoptions.yaml,2
292,540,0.0052606408417025345,11,"frozenset({'number', 'default'})",Total number of array elements which trigger summarization rather than full repr (default = 1000).,torch.set_printoptions.yaml,2
293,540,0.0052606408417025345,11,"frozenset({'number', 'default'})",number of groups in the conv layer (default: 1),torch.nn.init.dirac_.yaml,2
294,423,0.0052606408417025345,11,"frozenset({'strided', 'torch', 'default'})",Default: `torch.strided`.,torch.empty_strided.yaml,3
295,423,0.0052606408417025345,11,"frozenset({'strided', 'torch', 'default'})",Default: `torch.strided`.,torch.arange.yaml,3
296,423,0.0052606408417025345,11,"frozenset({'strided', 'torch', 'default'})",Default: `torch.strided`.,torch.rand.yaml,3
297,423,0.0052606408417025345,11,"frozenset({'strided', 'torch', 'default'})",Default: `torch.strided`.,torch.eye.yaml,3
298,423,0.0052606408417025345,11,"frozenset({'strided', 'torch', 'default'})",Default: `torch.strided`.,torch.ones.yaml,3
299,423,0.0052606408417025345,11,"frozenset({'strided', 'torch', 'default'})",Default: `torch.strided`.,torch.randperm.yaml,3
300,423,0.0052606408417025345,11,"frozenset({'strided', 'torch', 'default'})",Default: `torch.strided`.,torch.linspace.yaml,3
301,423,0.0052606408417025345,11,"frozenset({'strided', 'torch', 'default'})",Default: `torch.strided`.,torch.logspace.yaml,3
302,423,0.0052606408417025345,11,"frozenset({'strided', 'torch', 'default'})",Default: `torch.strided`.,torch.zeros.yaml,3
303,423,0.0052606408417025345,11,"frozenset({'strided', 'torch', 'default'})",Default: `torch.strided`.,torch.randn.yaml,3
304,423,0.0052606408417025345,11,"frozenset({'strided', 'torch', 'default'})",Default: `torch.strided`.,torch.full.yaml,3
305,334,0.004782400765184123,10,"frozenset({'whether', 'op', 'async'})",Whether this op should be an async op,torch.distributed.all_reduce.yaml,3
306,334,0.004782400765184123,10,"frozenset({'whether', 'op', 'async'})",Whether this op should be an async op,torch.distributed.barrier.yaml,3
307,334,0.004782400765184123,10,"frozenset({'whether', 'op', 'async'})",Whether this op should be an async op,torch.distributed.all_gather.yaml,3
308,334,0.004782400765184123,10,"frozenset({'whether', 'op', 'async'})",Whether this op should be an async op,torch.distributed.gather.yaml,3
309,334,0.004782400765184123,10,"frozenset({'whether', 'op', 'async'})",Whether this op should be an async op,torch.distributed.broadcast_multigpu.yaml,3
310,334,0.004782400765184123,10,"frozenset({'whether', 'op', 'async'})",Whether this op should be an async op,torch.distributed.reduce.yaml,3
311,334,0.004782400765184123,10,"frozenset({'whether', 'op', 'async'})",Whether this op should be an async op,torch.distributed.all_gather_multigpu.yaml,3
312,334,0.004782400765184123,10,"frozenset({'whether', 'op', 'async'})",Whether this op should be an async op,torch.distributed.scatter.yaml,3
313,334,0.004782400765184123,10,"frozenset({'whether', 'op', 'async'})",Whether this op should be an async op,torch.distributed.reduce_multigpu.yaml,3
314,334,0.004782400765184123,10,"frozenset({'whether', 'op', 'async'})",Whether this op should be an async op,torch.distributed.broadcast.yaml,3
315,326,0.004782400765184123,4,"frozenset({'desired', 'state'})",The desired state,torch.set_rng_state.yaml,2
316,326,0.004782400765184123,4,"frozenset({'desired', 'state'})",The desired state,torch.random.set_rng_state.yaml,2
317,326,0.004782400765184123,4,"frozenset({'desired', 'state'})",The desired state,torch.random.set_rng_state2.yaml,2
318,326,0.004782400765184123,4,"frozenset({'desired', 'state'})",The desired state,torch.cuda.set_rng_state.yaml,2
319,470,0.004782400765184123,8,"frozenset({'input', 'second', 'tensor'})",the second input tensor,torch.bitwise_xor.yaml,3
320,470,0.004782400765184123,8,"frozenset({'input', 'second', 'tensor'})",the second input tensor,torch.min22.yaml,3
321,470,0.004782400765184123,8,"frozenset({'input', 'second', 'tensor'})",the second input tensor,torch.max22.yaml,3
322,470,0.004782400765184123,8,"frozenset({'input', 'second', 'tensor'})",the second input tensor,torch.add.yaml,3
323,470,0.004782400765184123,8,"frozenset({'input', 'second', 'tensor'})",the second input tensor,torch.bitwise_and.yaml,3
324,470,0.004782400765184123,8,"frozenset({'input', 'second', 'tensor'})",the second input tensor,torch.cross.yaml,3
325,470,0.004782400765184123,8,"frozenset({'input', 'second', 'tensor'})",the second input tensor,torch.atan2.yaml,3
326,470,0.004782400765184123,8,"frozenset({'input', 'second', 'tensor'})",the second input tensor,torch.bitwise_or.yaml,3
327,333,0.004782400765184123,4,"frozenset({'product', 'computed', 'vector'})",The vector for which the Hessian vector product is computed.,torch.autograd.functional.hvp.yaml,3
328,333,0.004782400765184123,4,"frozenset({'product', 'computed', 'vector'})",The vector for which the vector Jacobian product is computed.,torch.autograd.functional.vjp.yaml,3
329,333,0.004782400765184123,4,"frozenset({'product', 'computed', 'vector'})",The vector for which the Jacobian vector product is computed.,torch.autograd.functional.jvp.yaml,3
330,333,0.004782400765184123,4,"frozenset({'product', 'computed', 'vector'})",The vector for which the vector Hessian product is computed.,torch.autograd.functional.vhp.yaml,3
331,528,0.004782400765184123,3,"frozenset({'single', 'tensor', 'SOME_STRUCTURE'})",an iterable of Tensors or a single Tensor that will have gradients normalized,torch.nn.utils.clip_grad_norm_.yaml,3
332,528,0.004782400765184123,3,"frozenset({'single', 'tensor', 'SOME_STRUCTURE'})",an iterable of Tensors or a single Tensor that will have gradients normalized,torch.nn.utils.clip_grad_value_.yaml,3
333,528,0.004782400765184123,3,"frozenset({'single', 'tensor', 'SOME_STRUCTURE'})",`example_inputs` may also be a single Tensor in which case it is automatically wrapped in a tuple.,torch.jit.trace.yaml,3
334,452,0.00430416068866571,3,"frozenset({'input', 'dimensions', 'batch', 'zero', 'tensor', 'n', 'm', 'size'})","The input tensor of size (*, m, n)  where *  is zero or more batch dimensions",torch.pinverse.yaml,8
335,452,0.00430416068866571,3,"frozenset({'input', 'dimensions', 'batch', 'zero', 'tensor', 'n', 'm', 'size'})","the input tensor of size (*, m, n)  where * is zero or more batch dimensions consisting of matrices of dimension m  times n .",torch.qr.yaml,8
336,452,0.00430416068866571,3,"frozenset({'input', 'dimensions', 'batch', 'zero', 'tensor', 'n', 'm', 'size'})","the input tensor of size (*, m, n)  where * is zero or more batch dimensions consisting of m  times n  matrices.",torch.svd.yaml,8
337,310,0.00430416068866571,9,"frozenset({'preventing', 'data', 'useful', 'type', 'overflows'})",This is useful for preventing data type overflows.,torch.prod2.yaml,5
338,310,0.00430416068866571,9,"frozenset({'preventing', 'data', 'useful', 'type', 'overflows'})",This is useful for preventing data type overflows.,torch.sum2.yaml,5
339,310,0.00430416068866571,9,"frozenset({'preventing', 'data', 'useful', 'type', 'overflows'})",This is useful for preventing data type overflows.,torch.sum.yaml,5
340,310,0.00430416068866571,9,"frozenset({'preventing', 'data', 'useful', 'type', 'overflows'})",This is useful for preventing data type overflows.,torch.nn.functional.log_softmax.yaml,5
341,310,0.00430416068866571,9,"frozenset({'preventing', 'data', 'useful', 'type', 'overflows'})",This is useful for preventing data type overflows.,torch.cumprod.yaml,5
342,310,0.00430416068866571,9,"frozenset({'preventing', 'data', 'useful', 'type', 'overflows'})",This is useful for preventing data type overflows.,torch.prod.yaml,5
343,310,0.00430416068866571,9,"frozenset({'preventing', 'data', 'useful', 'type', 'overflows'})",This is useful for preventing data type overflows.,torch.nn.functional.softmin.yaml,5
344,310,0.00430416068866571,9,"frozenset({'preventing', 'data', 'useful', 'type', 'overflows'})",This is useful for preventing data type overflows.,torch.cumsum.yaml,5
345,310,0.00430416068866571,9,"frozenset({'preventing', 'data', 'useful', 'type', 'overflows'})",This is useful for preventing data type overflows.,torch.nn.functional.softmax.yaml,5
346,312,0.00430416068866571,4,"frozenset({'input', 'zero', 'paddings', 'sides', 'implicit'})",implicit zero paddings on both sides of the input.,torch.nn.functional.avg_pool3d.yaml,5
347,312,0.00430416068866571,4,"frozenset({'input', 'zero', 'paddings', 'sides', 'implicit'})",implicit zero paddings on both sides of the input.,torch.nn.quantized.functional.avg_pool2d.yaml,5
348,312,0.00430416068866571,4,"frozenset({'input', 'zero', 'paddings', 'sides', 'implicit'})",implicit zero paddings on both sides of the input.,torch.nn.functional.avg_pool1d.yaml,5
349,312,0.00430416068866571,4,"frozenset({'input', 'zero', 'paddings', 'sides', 'implicit'})",implicit zero paddings on both sides of the input.,torch.nn.functional.avg_pool2d.yaml,5
350,503,0.003825920612147298,8,"frozenset({'reduce', 'dimension', 'dimensions'})",the dimension or dimensions to reduce.,torch.std2.yaml,3
351,503,0.003825920612147298,8,"frozenset({'reduce', 'dimension', 'dimensions'})",the dimension or dimensions to reduce.,torch.mean2.yaml,3
352,503,0.003825920612147298,8,"frozenset({'reduce', 'dimension', 'dimensions'})",the dimension or dimensions to reduce.,torch.sum2.yaml,3
353,503,0.003825920612147298,8,"frozenset({'reduce', 'dimension', 'dimensions'})",a dimension or a list of dimensions to reduce.,torch.sparse.sum.yaml,3
354,503,0.003825920612147298,8,"frozenset({'reduce', 'dimension', 'dimensions'})",the dimension or dimensions to reduce.,torch.var_mean2.yaml,3
355,503,0.003825920612147298,8,"frozenset({'reduce', 'dimension', 'dimensions'})",the dimension or dimensions to reduce.,torch.logsumexp.yaml,3
356,503,0.003825920612147298,8,"frozenset({'reduce', 'dimension', 'dimensions'})",the dimension or dimensions to reduce.,torch.var2.yaml,3
357,503,0.003825920612147298,8,"frozenset({'reduce', 'dimension', 'dimensions'})",the dimension or dimensions to reduce.,torch.std_mean2.yaml,3
358,289,0.003825920612147298,8,"frozenset({'use', 'whether', 'estimation', 'unbiased'})",whether to use the unbiased estimation or not,torch.std2.yaml,4
359,289,0.003825920612147298,8,"frozenset({'use', 'whether', 'estimation', 'unbiased'})",whether to use the unbiased estimation or not,torch.var_mean.yaml,4
360,289,0.003825920612147298,8,"frozenset({'use', 'whether', 'estimation', 'unbiased'})",whether to use the unbiased estimation or not,torch.var.yaml,4
361,289,0.003825920612147298,8,"frozenset({'use', 'whether', 'estimation', 'unbiased'})",whether to use the unbiased estimation or not,torch.std_mean.yaml,4
362,289,0.003825920612147298,8,"frozenset({'use', 'whether', 'estimation', 'unbiased'})",whether to use the unbiased estimation or not,torch.var_mean2.yaml,4
363,289,0.003825920612147298,8,"frozenset({'use', 'whether', 'estimation', 'unbiased'})",whether to use the unbiased estimation or not,torch.var2.yaml,4
364,289,0.003825920612147298,8,"frozenset({'use', 'whether', 'estimation', 'unbiased'})",whether to use the unbiased estimation or not,torch.std_mean2.yaml,4
365,289,0.003825920612147298,8,"frozenset({'use', 'whether', 'estimation', 'unbiased'})",whether to use the unbiased estimation or not,torch.std.yaml,4
366,290,0.003825920612147298,6,"frozenset({'elements', 'note', 'per', 'losses', 'sample', 'multiple'})","Note that for some losses, there multiple elements per sample.",torch.nn.functional.kl_div.yaml,6
367,290,0.003825920612147298,6,"frozenset({'elements', 'note', 'per', 'losses', 'sample', 'multiple'})","Note that for some losses, there multiple elements per sample.",torch.nn.functional.binary_cross_entropy.yaml,6
368,290,0.003825920612147298,6,"frozenset({'elements', 'note', 'per', 'losses', 'sample', 'multiple'})","Note that for some losses, there multiple elements per sample.",torch.nn.functional.nll_loss.yaml,6
369,290,0.003825920612147298,6,"frozenset({'elements', 'note', 'per', 'losses', 'sample', 'multiple'})","Note that for some losses, there multiple elements per sample.",torch.nn.functional.cross_entropy.yaml,6
370,290,0.003825920612147298,6,"frozenset({'elements', 'note', 'per', 'losses', 'sample', 'multiple'})","Note that for some losses, there multiple elements per sample.",torch.nn.functional.binary_cross_entropy_with_logits.yaml,6
371,290,0.003825920612147298,6,"frozenset({'elements', 'note', 'per', 'losses', 'sample', 'multiple'})","Note that for some losses, there multiple elements per sample.",torch.nn.functional.poisson_nll_loss.yaml,6
372,292,0.003825920612147298,5,"frozenset({'export', 'SOME_DTYPE'})",use operator_export_type] export the model in aten mode.,torch.onnx.export.yaml,2
373,292,0.003825920612147298,5,"frozenset({'export', 'SOME_DTYPE'})","If True, the constant-folding optimization is applied to the model during export.",torch.onnx.export.yaml,2
374,292,0.003825920612147298,5,"frozenset({'export', 'SOME_DTYPE'})", Set this to False if you want to export an untrained model.,torch.onnx.export.yaml,2
375,292,0.003825920612147298,5,"frozenset({'export', 'SOME_DTYPE'})",by default we export the model to the opset version of the onnx submodule.,torch.onnx.export.yaml,2
376,292,0.003825920612147298,5,"frozenset({'export', 'SOME_DTYPE'})",export the model in training mode.,torch.onnx.export.yaml,2
377,293,0.003825920612147298,4,"frozenset({'loss', 'targets'})","When `size_average` is `True`, the loss is averaged over non-ignored targets.",torch.nn.functional.nll_loss.yaml,2
378,293,0.003825920612147298,4,"frozenset({'loss', 'targets'})","(N)  where each value is 0  <= targets[i]  <= C-1 , or (N, d_1, d_2, ..., d_K)  where K  >= 1  for K-dimensional loss.",torch.nn.functional.nll_loss.yaml,2
379,293,0.003825920612147298,4,"frozenset({'loss', 'targets'})","When `size_average` is `True`, the loss is averaged over non-ignored targets.",torch.nn.functional.cross_entropy.yaml,2
380,293,0.003825920612147298,4,"frozenset({'loss', 'targets'})","(N)  where each value is 0  <= targets[i]  <= C-1 , or (N, d_1, d_2, ..., d_K)  where K  >= 1  for K-dimensional loss.",torch.nn.functional.cross_entropy.yaml,2
381,286,0.003825920612147298,8,"frozenset({'split', 'input', 'divisible', 'groups', '_channels', 'number'})","split input into groups, in _channels  should be divisible by the number of groups.",torch.nn.functional.conv_transpose2d.yaml,6
382,286,0.003825920612147298,8,"frozenset({'split', 'input', 'divisible', 'groups', '_channels', 'number'})","split input into groups, in _channels  should be divisible by the number of groups.",torch.nn.functional.conv2d.yaml,6
383,286,0.003825920612147298,8,"frozenset({'split', 'input', 'divisible', 'groups', '_channels', 'number'})","split input into groups, in _channels  should be divisible by the number of groups.",torch.nn.functional.conv_transpose3d.yaml,6
384,286,0.003825920612147298,8,"frozenset({'split', 'input', 'divisible', 'groups', '_channels', 'number'})","split input into groups, in _channels  should be divisible by the number of groups.",torch.nn.functional.conv_transpose1d.yaml,6
385,286,0.003825920612147298,8,"frozenset({'split', 'input', 'divisible', 'groups', '_channels', 'number'})","split input into groups, in _channels  should be divisible by the number of groups.",torch.nn.functional.conv1d.yaml,6
386,286,0.003825920612147298,8,"frozenset({'split', 'input', 'divisible', 'groups', '_channels', 'number'})","split input into groups, in _channels  should be divisible by the number of groups.",torch.nn.functional.conv3d.yaml,6
387,286,0.003825920612147298,8,"frozenset({'split', 'input', 'divisible', 'groups', '_channels', 'number'})","split input into groups, in _channels  should be divisible by the number of groups.",torch.nn.quantized.functional.conv2d.yaml,6
388,286,0.003825920612147298,8,"frozenset({'split', 'input', 'divisible', 'groups', '_channels', 'number'})","split input into groups, in _channels  should be divisible by the number of groups.",torch.nn.quantized.functional.conv3d.yaml,6
389,434,0.003825920612147298,8,"frozenset({'e', 'default'})",Default: 1e-12,torch.nn.functional.normalize.yaml,2
390,434,0.003825920612147298,8,"frozenset({'e', 'default'})",Default: 1e-8,torch.nn.functional.cosine_similarity.yaml,2
391,434,0.003825920612147298,8,"frozenset({'e', 'default'})",Default: 1e-15,torch.pinverse.yaml,2
392,434,0.003825920612147298,8,"frozenset({'e', 'default'})",Default: 1e-08,torch.allclose.yaml,2
393,434,0.003825920612147298,8,"frozenset({'e', 'default'})",Default: 1e-05,torch.allclose.yaml,2
394,434,0.003825920612147298,8,"frozenset({'e', 'default'})","Default: `'cuda'` (i.e., `torch.device('cuda')`, the current CUDA device).",torch.cuda.get_rng_state.yaml,2
395,434,0.003825920612147298,8,"frozenset({'e', 'default'})","Default: `'cuda'` (i.e., `torch.device('cuda')`, the current CUDA device).",torch.cuda.set_rng_state.yaml,2
396,434,0.003825920612147298,8,"frozenset({'e', 'default'})",Default: 1e-8,torch.nn.functional.poisson_nll_loss.yaml,2
397,294,0.003825920612147298,8,"frozenset({'elements', 'spacing', 'kernel'})",the spacing between kernel elements.,torch.nn.functional.conv_transpose2d.yaml,3
398,294,0.003825920612147298,8,"frozenset({'elements', 'spacing', 'kernel'})",the spacing between kernel elements.,torch.nn.functional.conv2d.yaml,3
399,294,0.003825920612147298,8,"frozenset({'elements', 'spacing', 'kernel'})",the spacing between kernel elements.,torch.nn.functional.conv_transpose3d.yaml,3
400,294,0.003825920612147298,8,"frozenset({'elements', 'spacing', 'kernel'})",the spacing between kernel elements.,torch.nn.functional.conv_transpose1d.yaml,3
401,294,0.003825920612147298,8,"frozenset({'elements', 'spacing', 'kernel'})",the spacing between kernel elements.,torch.nn.functional.conv1d.yaml,3
402,294,0.003825920612147298,8,"frozenset({'elements', 'spacing', 'kernel'})",the spacing between kernel elements.,torch.nn.functional.conv3d.yaml,3
403,294,0.003825920612147298,8,"frozenset({'elements', 'spacing', 'kernel'})",the spacing between kernel elements.,torch.nn.quantized.functional.conv2d.yaml,3
404,294,0.003825920612147298,8,"frozenset({'elements', 'spacing', 'kernel'})",the spacing between kernel elements.,torch.nn.quantized.functional.conv3d.yaml,3
405,282,0.003825920612147298,6,"frozenset({'groups', 'kh', '_channels', 'kw', 'shape', 'filters'})","filters of shape (in _channels ,  out _channels/groups , kH , kW) ",torch.nn.functional.conv_transpose2d.yaml,6
406,282,0.003825920612147298,6,"frozenset({'groups', 'kh', '_channels', 'kw', 'shape', 'filters'})","filters of shape (out _channels ,  in _channels/groups , kH , kW) ",torch.nn.functional.conv2d.yaml,6
407,282,0.003825920612147298,6,"frozenset({'groups', 'kh', '_channels', 'kw', 'shape', 'filters'})","filters of shape (in _channels ,  out _channels/groups , kT , kH , kW) ",torch.nn.functional.conv_transpose3d.yaml,6
408,282,0.003825920612147298,6,"frozenset({'groups', 'kh', '_channels', 'kw', 'shape', 'filters'})","filters of shape (out _channels ,  in _channels/groups , kT , kH , kW) ",torch.nn.functional.conv3d.yaml,6
409,282,0.003825920612147298,6,"frozenset({'groups', 'kh', '_channels', 'kw', 'shape', 'filters'})","quantized filters of shape (out _channels ,  in _channels/groups , kH , kW) ",torch.nn.quantized.functional.conv2d.yaml,6
410,282,0.003825920612147298,6,"frozenset({'groups', 'kh', '_channels', 'kw', 'shape', 'filters'})","quantized filters of shape (out _channels ,  in _channels/groups , kD , kH , kW) ",torch.nn.quantized.functional.conv3d.yaml,6
411,283,0.003825920612147298,8,"frozenset({'convolving', 'stride', 'kernel'})",the stride of the convolving kernel.,torch.nn.functional.conv_transpose2d.yaml,3
412,283,0.003825920612147298,8,"frozenset({'convolving', 'stride', 'kernel'})",the stride of the convolving kernel.,torch.nn.functional.conv2d.yaml,3
413,283,0.003825920612147298,8,"frozenset({'convolving', 'stride', 'kernel'})",the stride of the convolving kernel.,torch.nn.functional.conv_transpose3d.yaml,3
414,283,0.003825920612147298,8,"frozenset({'convolving', 'stride', 'kernel'})",the stride of the convolving kernel.,torch.nn.functional.conv_transpose1d.yaml,3
415,283,0.003825920612147298,8,"frozenset({'convolving', 'stride', 'kernel'})",the stride of the convolving kernel.,torch.nn.functional.conv1d.yaml,3
416,283,0.003825920612147298,8,"frozenset({'convolving', 'stride', 'kernel'})",the stride of the convolving kernel.,torch.nn.functional.conv3d.yaml,3
417,283,0.003825920612147298,8,"frozenset({'convolving', 'stride', 'kernel'})",the stride of the convolving kernel.,torch.nn.quantized.functional.conv2d.yaml,3
418,283,0.003825920612147298,8,"frozenset({'convolving', 'stride', 'kernel'})",the stride of the convolving kernel.,torch.nn.quantized.functional.conv3d.yaml,3
419,291,0.003825920612147298,3,"frozenset({'e', 'SOME_DTYPE', 'g'})","the inputs to the model, e.g., such that `model(*args)` is a valid invocation of the model.",torch.onnx.export.yaml,3
420,291,0.003825920612147298,3,"frozenset({'e', 'SOME_DTYPE', 'g'})","This field should be given as a lowercase string (e.g., `""gloo""`), which can also be accessed via `Backend` attributes (e.g., `Backend.GLOO`).",torch.distributed.init_process_group.yaml,3
421,291,0.003825920612147298,3,"frozenset({'e', 'SOME_DTYPE', 'g'})","This field should be given as a lowercase string (e.g., `""gloo""`), which can also be accessed via `Backend` attributes (e.g., `Backend.GLOO`).",torch.distributed.new_group.yaml,3
422,264,0.003347680535628886,5,"frozenset({'p', 'norm'})","p value for the p-norm distance to calculate between each vector pair  in [0,  infty] .",torch.nn.functional.pdist.yaml,2
423,264,0.003347680535628886,5,"frozenset({'p', 'norm'})",type of the used p-norm.,torch.nn.utils.clip_grad_norm_.yaml,2
424,264,0.003347680535628886,5,"frozenset({'p', 'norm'})","p value for the p-norm distance to calculate between each vector pair  in [0,  infty] .",torch.cdist.yaml,2
425,264,0.003347680535628886,5,"frozenset({'p', 'norm'})",The p of the p-norm to compute for the `max_norm` option.,torch.nn.functional.embedding.yaml,2
426,264,0.003347680535628886,5,"frozenset({'p', 'norm'})",See documentation of valid entries for argument `p` in `torch.norm()`.,torch.nn.utils.prune.ln_structured.yaml,2
427,376,0.003347680535628886,7,"frozenset({'source', 'rank'})",Source rank.,torch.distributed.recv.yaml,2
428,376,0.003347680535628886,7,"frozenset({'source', 'rank'})",Source rank.,torch.distributed.broadcast_multigpu.yaml,2
429,376,0.003347680535628886,7,"frozenset({'source', 'rank'})",Source tensor rank within `tensor_list`,torch.distributed.broadcast_multigpu.yaml,2
430,376,0.003347680535628886,7,"frozenset({'source', 'rank'})","List of tensors to scatter (default is None, must be specified on the source rank)",torch.distributed.scatter.yaml,2
431,376,0.003347680535628886,7,"frozenset({'source', 'rank'})",Source rank (default is 0),torch.distributed.scatter.yaml,2
432,376,0.003347680535628886,7,"frozenset({'source', 'rank'})",Source rank.,torch.distributed.irecv.yaml,2
433,376,0.003347680535628886,7,"frozenset({'source', 'rank'})",Source rank.,torch.distributed.broadcast.yaml,2
434,263,0.003347680535628886,5,"frozenset({'return', 'controls', 'normalized', 'whether', 'results'})",controls whether to return normalized results.,torch.irfft.yaml,5
435,263,0.003347680535628886,5,"frozenset({'return', 'controls', 'normalized', 'whether', 'results'})",controls whether to return normalized results.,torch.fft.yaml,5
436,263,0.003347680535628886,5,"frozenset({'return', 'controls', 'normalized', 'whether', 'results'})",controls whether to return normalized results.,torch.ifft.yaml,5
437,263,0.003347680535628886,5,"frozenset({'return', 'controls', 'normalized', 'whether', 'results'})",controls whether to return the normalized STFT results Default: `False`,torch.stft.yaml,5
438,263,0.003347680535628886,5,"frozenset({'return', 'controls', 'normalized', 'whether', 'results'})",controls whether to return normalized results.,torch.rfft.yaml,5
439,266,0.003347680535628886,7,"frozenset({'name', 'act', 'pruning', 'parameter', 'within', 'SOME_DTYPE'})",parameter name within `module` on which pruning will act.,torch.nn.utils.prune.l1_unstructured.yaml,6
440,266,0.003347680535628886,7,"frozenset({'name', 'act', 'pruning', 'parameter', 'within', 'SOME_DTYPE'})",parameter name within `module` on which pruning will act.,torch.nn.utils.prune.random_unstructured.yaml,6
441,266,0.003347680535628886,7,"frozenset({'name', 'act', 'pruning', 'parameter', 'within', 'SOME_DTYPE'})",parameter name within `module` on which pruning will act.,torch.nn.utils.prune.ln_structured.yaml,6
442,266,0.003347680535628886,7,"frozenset({'name', 'act', 'pruning', 'parameter', 'within', 'SOME_DTYPE'})",parameter name within `module` on which pruning will act.,torch.nn.utils.prune.random_structured.yaml,6
443,266,0.003347680535628886,7,"frozenset({'name', 'act', 'pruning', 'parameter', 'within', 'SOME_DTYPE'})",parameter name within `module` on which pruning will act.,torch.nn.utils.prune.remove.yaml,6
444,266,0.003347680535628886,7,"frozenset({'name', 'act', 'pruning', 'parameter', 'within', 'SOME_DTYPE'})",parameter name within `module` on which pruning will act.,torch.nn.utils.prune.custom_from_mask.yaml,6
445,266,0.003347680535628886,7,"frozenset({'name', 'act', 'pruning', 'parameter', 'within', 'SOME_DTYPE'})",parameter name within `module` on which pruning will act.,torch.nn.utils.prune.identity.yaml,6
446,267,0.003347680535628886,5,"frozenset({'multiplier', 'input', 'beta'})",multiplier for `input` ( beta ),torch.baddbmm.yaml,3
447,267,0.003347680535628886,5,"frozenset({'multiplier', 'input', 'beta'})",multiplier for `input` ( beta ),torch.addr.yaml,3
448,267,0.003347680535628886,5,"frozenset({'multiplier', 'input', 'beta'})",multiplier for `input` ( beta ),torch.addbmm.yaml,3
449,267,0.003347680535628886,5,"frozenset({'multiplier', 'input', 'beta'})",multiplier for `input` ( beta ),torch.addmm.yaml,3
450,267,0.003347680535628886,5,"frozenset({'multiplier', 'input', 'beta'})",multiplier for `input` ( beta ),torch.addmv.yaml,3
451,450,0.003347680535628886,4,"frozenset({'input', 'd', 'tensor'})","float 1D tensor of scales to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,3
452,450,0.003347680535628886,4,"frozenset({'input', 'd', 'tensor'})","integer 1D tensor of offset to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,3
453,450,0.003347680535628886,4,"frozenset({'input', 'd', 'tensor'})","the input 2-D tensor u , a upper or lower triangular Cholesky factor",torch.cholesky_inverse.yaml,3
454,450,0.003347680535628886,4,"frozenset({'input', 'd', 'tensor'})",the input 2-D tensor,torch.matrix_rank.yaml,3
455,535,0.003347680535628886,3,"frozenset({'torch', 'SOME_DTYPE', 'SOME_STRUCTURE'})","a function, `torch.device`, string or a dict specifying how to remap storage locations",torch.load.yaml,3
456,535,0.003347680535628886,3,"frozenset({'torch', 'SOME_DTYPE', 'SOME_STRUCTURE'})",A `torch.nn.Sequential` or the list of modules or functions (comprising the model) to run sequentially.,torch.utils.checkpoint.checkpoint_sequential.yaml,3
457,535,0.003347680535628886,3,"frozenset({'torch', 'SOME_DTYPE', 'SOME_STRUCTURE'})","a list, tuple, or `torch.Size` of integers defining the shape of the output tensor.",torch.full.yaml,3
458,467,0.003347680535628886,7,"frozenset({'prune', 'SOME_DTYPE', 'containing', 'tensor'})",module containing the tensor to prune,torch.nn.utils.prune.l1_unstructured.yaml,4
459,467,0.003347680535628886,7,"frozenset({'prune', 'SOME_DTYPE', 'containing', 'tensor'})",module containing the tensor to prune,torch.nn.utils.prune.random_unstructured.yaml,4
460,467,0.003347680535628886,7,"frozenset({'prune', 'SOME_DTYPE', 'containing', 'tensor'})",module containing the tensor to prune,torch.nn.utils.prune.ln_structured.yaml,4
461,467,0.003347680535628886,7,"frozenset({'prune', 'SOME_DTYPE', 'containing', 'tensor'})",module containing the tensor to prune,torch.nn.utils.prune.random_structured.yaml,4
462,467,0.003347680535628886,7,"frozenset({'prune', 'SOME_DTYPE', 'containing', 'tensor'})",module containing the tensor to prune,torch.nn.utils.prune.remove.yaml,4
463,467,0.003347680535628886,7,"frozenset({'prune', 'SOME_DTYPE', 'containing', 'tensor'})",module containing the tensor to prune,torch.nn.utils.prune.custom_from_mask.yaml,4
464,467,0.003347680535628886,7,"frozenset({'prune', 'SOME_DTYPE', 'containing', 'tensor'})",module containing the tensor to prune.,torch.nn.utils.prune.identity.yaml,4
465,461,0.003347680535628886,3,"frozenset({'matrix', 'first', 'multiplied'})",the first matrix to be multiplied,torch.addmm.yaml,3
466,461,0.003347680535628886,3,"frozenset({'matrix', 'first', 'multiplied'})",the first sparse matrix to be multiplied,torch.sparse.mm.yaml,3
467,461,0.003347680535628886,3,"frozenset({'matrix', 'first', 'multiplied'})",the first matrix to be multiplied,torch.mm.yaml,3
468,462,0.003347680535628886,3,"frozenset({'matrix', 'second', 'multiplied'})",the second matrix to be multiplied,torch.addmm.yaml,3
469,462,0.003347680535628886,3,"frozenset({'matrix', 'second', 'multiplied'})",the second dense matrix to be multiplied,torch.sparse.mm.yaml,3
470,462,0.003347680535628886,3,"frozenset({'matrix', 'second', 'multiplied'})",the second matrix to be multiplied,torch.mm.yaml,3
471,464,0.003347680535628886,7,"frozenset({'mean', 'default'})",Default: `'mean'`,torch.nn.functional.ctc_loss.yaml,2
472,464,0.003347680535628886,7,"frozenset({'mean', 'default'})",`'none'`: no reduction will be applied `'batchmean'`: the sum of the output will be divided by the batchsize `'sum'`: the output will be summed `'mean'`: the output will be divided by the number of elements in the output Default: `'mean'`,torch.nn.functional.kl_div.yaml,2
473,464,0.003347680535628886,7,"frozenset({'mean', 'default'})",Default: `'mean'`,torch.nn.functional.binary_cross_entropy.yaml,2
474,464,0.003347680535628886,7,"frozenset({'mean', 'default'})",Default: `'mean'`,torch.nn.functional.nll_loss.yaml,2
475,464,0.003347680535628886,7,"frozenset({'mean', 'default'})",Default: `'mean'`,torch.nn.functional.cross_entropy.yaml,2
476,464,0.003347680535628886,7,"frozenset({'mean', 'default'})",Default: `'mean'`,torch.nn.functional.binary_cross_entropy_with_logits.yaml,2
477,464,0.003347680535628886,7,"frozenset({'mean', 'default'})",Default: `'mean'`,torch.nn.functional.poisson_nll_loss.yaml,2
478,275,0.003347680535628886,5,"frozenset({'returned', 'desired', 'format', 'tensor', 'memory'})",the desired memory format of returned Tensor.,torch.ones_like.yaml,5
479,275,0.003347680535628886,5,"frozenset({'returned', 'desired', 'format', 'tensor', 'memory'})",the desired memory format of returned Tensor.,torch.empty_like.yaml,5
480,275,0.003347680535628886,5,"frozenset({'returned', 'desired', 'format', 'tensor', 'memory'})",the desired memory format of returned Tensor.,torch.zeros_like.yaml,5
481,275,0.003347680535628886,5,"frozenset({'returned', 'desired', 'format', 'tensor', 'memory'})",the desired memory format of returned Tensor.,torch.randn_like.yaml,5
482,275,0.003347680535628886,5,"frozenset({'returned', 'desired', 'format', 'tensor', 'memory'})",the desired memory format of returned Tensor.,torch.rand_like.yaml,5
483,276,0.003347680535628886,3,"frozenset({'names', 'SOME_STRUCTURE'})",A list of function names for which to generate function bindings.,torch.utils.cpp_extension.load_inline.yaml,2
484,276,0.003347680535628886,3,"frozenset({'names', 'SOME_STRUCTURE'})","If a dictionary is given, it should map function names to docstrings (which are otherwise just the function names).",torch.utils.cpp_extension.load_inline.yaml,2
485,276,0.003347680535628886,3,"frozenset({'names', 'SOME_STRUCTURE'})",list of list of module names to fuse.,torch.quantization.fuse_modules.yaml,2
486,308,0.003347680535628886,7,"frozenset({'rank', 'destination'})",Destination rank.,torch.distributed.isend.yaml,2
487,308,0.003347680535628886,7,"frozenset({'rank', 'destination'})",Destination rank (default is 0),torch.distributed.gather.yaml,2
488,308,0.003347680535628886,7,"frozenset({'rank', 'destination'})","List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)",torch.distributed.gather.yaml,2
489,308,0.003347680535628886,7,"frozenset({'rank', 'destination'})",Destination rank,torch.distributed.reduce.yaml,2
490,308,0.003347680535628886,7,"frozenset({'rank', 'destination'})",Destination rank.,torch.distributed.send.yaml,2
491,308,0.003347680535628886,7,"frozenset({'rank', 'destination'})",Destination rank,torch.distributed.reduce_multigpu.yaml,2
492,308,0.003347680535628886,7,"frozenset({'rank', 'destination'})",Destination tensor rank within `tensor_list`,torch.distributed.reduce_multigpu.yaml,2
493,476,0.003347680535628886,5,"frozenset({'input', 'first', 'tensor'})",the first input tensor,torch.bitwise_xor.yaml,3
494,476,0.003347680535628886,5,"frozenset({'input', 'first', 'tensor'})",the first input tensor,torch.add.yaml,3
495,476,0.003347680535628886,5,"frozenset({'input', 'first', 'tensor'})",the first input tensor,torch.bitwise_and.yaml,3
496,476,0.003347680535628886,5,"frozenset({'input', 'first', 'tensor'})",the first input tensor,torch.atan2.yaml,3
497,476,0.003347680535628886,5,"frozenset({'input', 'first', 'tensor'})",the first input tensor,torch.bitwise_or.yaml,3
498,280,0.003347680535628886,3,"frozenset({'used', 'grad', 'false'})","If `False`, the graph used to compute the grad will be freed.",torch.autograd.backward.yaml,3
499,280,0.003347680535628886,3,"frozenset({'used', 'grad', 'false'})","If `False`, specifying inputs that were not used when computing outputs (and therefore their grad is always zero) is an error.",torch.autograd.grad.yaml,3
500,280,0.003347680535628886,3,"frozenset({'used', 'grad', 'false'})","If `False`, the graph used to compute the grad will be freed.",torch.autograd.grad.yaml,3
501,239,0.0028694404591104736,6,"frozenset({'statistic', 'returns', 'none', 'given', 'default', 'current', 'current_device', 'SOME_DTYPE'})","Returns statistic for the current device, given by `current_device()`, if `device` is `None` (default).",torch.cuda.max_memory_reserved.yaml,8
502,239,0.0028694404591104736,6,"frozenset({'statistic', 'returns', 'none', 'given', 'default', 'current', 'current_device', 'SOME_DTYPE'})","Returns statistic for the current device, given by `current_device()`, if `device` is `None` (default).",torch.cuda.memory_reserved.yaml,8
503,239,0.0028694404591104736,6,"frozenset({'statistic', 'returns', 'none', 'given', 'default', 'current', 'current_device', 'SOME_DTYPE'})","Returns statistic for the current device, given by `current_device()`, if `device` is `None` (default).",torch.cuda.reset_max_memory_allocated.yaml,8
504,239,0.0028694404591104736,6,"frozenset({'statistic', 'returns', 'none', 'given', 'default', 'current', 'current_device', 'SOME_DTYPE'})","Returns statistic for the current device, given by `current_device()`, if `device` is `None` (default).",torch.cuda.memory_allocated.yaml,8
505,239,0.0028694404591104736,6,"frozenset({'statistic', 'returns', 'none', 'given', 'default', 'current', 'current_device', 'SOME_DTYPE'})","Returns statistic for the current device, given by `current_device()`, if `device` is `None` (default).",torch.cuda.max_memory_allocated.yaml,8
506,239,0.0028694404591104736,6,"frozenset({'statistic', 'returns', 'none', 'given', 'default', 'current', 'current_device', 'SOME_DTYPE'})","Returns statistic for the current device, given by `current_device()`, if `device` is `None` (default).",torch.cuda.reset_max_memory_cached.yaml,8
507,249,0.0028694404591104736,5,"frozenset({'input', 'determine', 'tensor', 'size', 'output'})",the size of `input` will determine size of the output tensor.,torch.ones_like.yaml,5
508,249,0.0028694404591104736,5,"frozenset({'input', 'determine', 'tensor', 'size', 'output'})",the size of `input` will determine size of the output tensor.,torch.empty_like.yaml,5
509,249,0.0028694404591104736,5,"frozenset({'input', 'determine', 'tensor', 'size', 'output'})",the size of `input` will determine size of the output tensor.,torch.zeros_like.yaml,5
510,249,0.0028694404591104736,5,"frozenset({'input', 'determine', 'tensor', 'size', 'output'})",the size of `input` will determine size of the output tensor.,torch.randn_like.yaml,5
511,249,0.0028694404591104736,5,"frozenset({'input', 'determine', 'tensor', 'size', 'output'})",the size of `input` will determine size of the output tensor.,torch.rand_like.yaml,5
512,250,0.0028694404591104736,6,"frozenset({'exists', 'input', 'outputs', 'raised', 'independent', 'detect', 'error', 'true'})","If `True`, an error will be raised when we detect that there exists an input such that all the outputs are independent of it.",torch.autograd.functional.hvp.yaml,8
513,250,0.0028694404591104736,6,"frozenset({'exists', 'input', 'outputs', 'raised', 'independent', 'detect', 'error', 'true'})","If `True`, an error will be raised when we detect that there exists an input such that all the outputs are independent of it.",torch.autograd.functional.vjp.yaml,8
514,250,0.0028694404591104736,6,"frozenset({'exists', 'input', 'outputs', 'raised', 'independent', 'detect', 'error', 'true'})","If `True`, an error will be raised when we detect that there exists an input such that all the outputs are independent of it.",torch.autograd.functional.jvp.yaml,8
515,250,0.0028694404591104736,6,"frozenset({'exists', 'input', 'outputs', 'raised', 'independent', 'detect', 'error', 'true'})","If `True`, an error will be raised when we detect that there exists an input such that all the outputs are independent of it.",torch.autograd.functional.vhp.yaml,8
516,250,0.0028694404591104736,6,"frozenset({'exists', 'input', 'outputs', 'raised', 'independent', 'detect', 'error', 'true'})","If `True`, an error will be raised when we detect that there exists an input such that all the outputs are independent of it.",torch.autograd.functional.jacobian.yaml,8
517,250,0.0028694404591104736,6,"frozenset({'exists', 'input', 'outputs', 'raised', 'independent', 'detect', 'error', 'true'})","If `True`, an error will be raised when we detect that there exists an input such that all the outputs are independent of it.",torch.autograd.functional.hessian.yaml,8
518,226,0.0028694404591104736,6,"frozenset({'ignores', 'returns', 'reduce', 'element', 'batch', 'size_average', 'false', 'per', 'loss', 'instead'})","When `reduce` is `False`, returns a loss per batch element instead and ignores `size_average`.",torch.nn.functional.kl_div.yaml,10
519,226,0.0028694404591104736,6,"frozenset({'ignores', 'returns', 'reduce', 'element', 'batch', 'size_average', 'false', 'per', 'loss', 'instead'})","When `reduce` is `False`, returns a loss per batch element instead and ignores `size_average`.",torch.nn.functional.binary_cross_entropy.yaml,10
520,226,0.0028694404591104736,6,"frozenset({'ignores', 'returns', 'reduce', 'element', 'batch', 'size_average', 'false', 'per', 'loss', 'instead'})","When `reduce` is `False`, returns a loss per batch element instead and ignores `size_average`.",torch.nn.functional.nll_loss.yaml,10
521,226,0.0028694404591104736,6,"frozenset({'ignores', 'returns', 'reduce', 'element', 'batch', 'size_average', 'false', 'per', 'loss', 'instead'})","When `reduce` is `False`, returns a loss per batch element instead and ignores `size_average`.",torch.nn.functional.cross_entropy.yaml,10
522,226,0.0028694404591104736,6,"frozenset({'ignores', 'returns', 'reduce', 'element', 'batch', 'size_average', 'false', 'per', 'loss', 'instead'})","When `reduce` is `False`, returns a loss per batch element instead and ignores `size_average`.",torch.nn.functional.binary_cross_entropy_with_logits.yaml,10
523,226,0.0028694404591104736,6,"frozenset({'ignores', 'returns', 'reduce', 'element', 'batch', 'size_average', 'false', 'per', 'loss', 'instead'})","When `reduce` is `False`, returns a loss per batch element instead and ignores `size_average`.",torch.nn.functional.poisson_nll_loss.yaml,10
524,227,0.0028694404591104736,3,"frozenset({'ssparse', 'tensor'})","If `True`, gradient w.r.t. `weight` will be a sparse tensor.",torch.nn.functional.embedding.yaml,2
525,227,0.0028694404591104736,3,"frozenset({'ssparse', 'tensor'})",Size of the sparse tensor.,torch.sparse_coo_tensor.yaml,2
526,227,0.0028694404591104736,3,"frozenset({'ssparse', 'tensor'})","If `True`, gradient w.r.t. `input` will be a sparse tensor.",torch.gather.yaml,2
527,229,0.0028694404591104736,6,"frozenset({'gradients', 'strict', 'result', 'note', 'false', 'disconnected', 'require', 'inputs'})","Note that when `strict` is `False`, the result can not require gradients or be disconnected from the inputs.",torch.autograd.functional.hvp.yaml,8
528,229,0.0028694404591104736,6,"frozenset({'gradients', 'strict', 'result', 'note', 'false', 'disconnected', 'require', 'inputs'})","Note that when `strict` is `False`, the result can not require gradients or be disconnected from the inputs.",torch.autograd.functional.vjp.yaml,8
529,229,0.0028694404591104736,6,"frozenset({'gradients', 'strict', 'result', 'note', 'false', 'disconnected', 'require', 'inputs'})","Note that when `strict` is `False`, the result can not require gradients or be disconnected from the inputs.",torch.autograd.functional.jvp.yaml,8
530,229,0.0028694404591104736,6,"frozenset({'gradients', 'strict', 'result', 'note', 'false', 'disconnected', 'require', 'inputs'})","Note that when `strict` is `False`, the result can not require gradients or be disconnected from the inputs.",torch.autograd.functional.vhp.yaml,8
531,229,0.0028694404591104736,6,"frozenset({'gradients', 'strict', 'result', 'note', 'false', 'disconnected', 'require', 'inputs'})","Note that when `strict` is `False`, the result can not require gradients or be disconnected from the inputs.",torch.autograd.functional.jacobian.yaml,8
532,229,0.0028694404591104736,6,"frozenset({'gradients', 'strict', 'result', 'note', 'false', 'disconnected', 'require', 'inputs'})","Note that when `strict` is `False`, the result can not require gradients or be disconnected from the inputs.",torch.autograd.functional.hessian.yaml,8
533,397,0.0028694404591104736,6,"frozenset({'reduce', 'ignored', 'false'})",Ignored when reduce is `False`.,torch.nn.functional.kl_div.yaml,3
534,397,0.0028694404591104736,6,"frozenset({'reduce', 'ignored', 'false'})",Ignored when reduce is `False`.,torch.nn.functional.binary_cross_entropy.yaml,3
535,397,0.0028694404591104736,6,"frozenset({'reduce', 'ignored', 'false'})",Ignored when reduce is `False`.,torch.nn.functional.nll_loss.yaml,3
536,397,0.0028694404591104736,6,"frozenset({'reduce', 'ignored', 'false'})",Ignored when reduce is `False`.,torch.nn.functional.cross_entropy.yaml,3
537,397,0.0028694404591104736,6,"frozenset({'reduce', 'ignored', 'false'})",Ignored when reduce is `False`.,torch.nn.functional.binary_cross_entropy_with_logits.yaml,3
538,397,0.0028694404591104736,6,"frozenset({'reduce', 'ignored', 'false'})",Ignored when reduce is `False`.,torch.nn.functional.poisson_nll_loss.yaml,3
539,230,0.0028694404591104736,6,"frozenset({'said', 'return', 'false', 'expected', 'mathematical', 'zeros', 'tensor', 'inputs', 'value'})","If `False`, we return a Tensor of zeros as the hvp for said inputs, which is the expected mathematical value.",torch.autograd.functional.hvp.yaml,9
540,230,0.0028694404591104736,6,"frozenset({'said', 'return', 'false', 'expected', 'mathematical', 'zeros', 'tensor', 'inputs', 'value'})","If `False`, we return a Tensor of zeros as the vjp for said inputs, which is the expected mathematical value.",torch.autograd.functional.vjp.yaml,9
541,230,0.0028694404591104736,6,"frozenset({'said', 'return', 'false', 'expected', 'mathematical', 'zeros', 'tensor', 'inputs', 'value'})","If `False`, we return a Tensor of zeros as the jvp for said inputs, which is the expected mathematical value.",torch.autograd.functional.jvp.yaml,9
542,230,0.0028694404591104736,6,"frozenset({'said', 'return', 'false', 'expected', 'mathematical', 'zeros', 'tensor', 'inputs', 'value'})","If `False`, we return a Tensor of zeros as the vhp for said inputs, which is the expected mathematical value.",torch.autograd.functional.vhp.yaml,9
543,230,0.0028694404591104736,6,"frozenset({'said', 'return', 'false', 'expected', 'mathematical', 'zeros', 'tensor', 'inputs', 'value'})","If `False`, we return a Tensor of zeros as the jacobian for said inputs, which is the expected mathematical value.",torch.autograd.functional.jacobian.yaml,9
544,230,0.0028694404591104736,6,"frozenset({'said', 'return', 'false', 'expected', 'mathematical', 'zeros', 'tensor', 'inputs', 'value'})","If `False`, we return a Tensor of zeros as the hessian for said inputs, which is the expected mathematical value.",torch.autograd.functional.hessian.yaml,9
545,228,0.0028694404591104736,3,"frozenset({'forward', 'optional', 'build', 'SOME_STRUCTURE'})",optional list of compiler flags to forward to the build.,torch.utils.cpp_extension.load.yaml,4
546,228,0.0028694404591104736,3,"frozenset({'forward', 'optional', 'build', 'SOME_STRUCTURE'})",optional list of include directories to forward to the build.,torch.utils.cpp_extension.load.yaml,4
547,228,0.0028694404591104736,3,"frozenset({'forward', 'optional', 'build', 'SOME_STRUCTURE'})",optional list of linker flags to forward to the build.,torch.utils.cpp_extension.load.yaml,4
548,248,0.0028694404591104736,6,"frozenset({'single', 'dw', 'dh', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple `(dH, dW)`.",torch.nn.functional.conv_transpose2d.yaml,5
549,248,0.0028694404591104736,6,"frozenset({'single', 'dw', 'dh', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple (dH, dW).",torch.nn.functional.conv2d.yaml,5
550,248,0.0028694404591104736,6,"frozenset({'single', 'dw', 'dh', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple (dT, dH, dW).",torch.nn.functional.conv_transpose3d.yaml,5
551,248,0.0028694404591104736,6,"frozenset({'single', 'dw', 'dh', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple (dT, dH, dW).",torch.nn.functional.conv3d.yaml,5
552,248,0.0028694404591104736,6,"frozenset({'single', 'dw', 'dh', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple (dH, dW).",torch.nn.quantized.functional.conv2d.yaml,5
553,248,0.0028694404591104736,6,"frozenset({'single', 'dw', 'dh', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple (dD, dH, dW).",torch.nn.quantized.functional.conv3d.yaml,5
554,247,0.0028694404591104736,4,"frozenset({'backend', 'gloo'})","This field should be given as a lowercase string (e.g., `""gloo""`), which can also be accessed via `Backend` attributes (e.g., `Backend.GLOO`).",torch.distributed.init_process_group.yaml,2
555,247,0.0028694404591104736,4,"frozenset({'backend', 'gloo'})",This is applicable for the `gloo` backend.,torch.distributed.init_process_group.yaml,2
556,247,0.0028694404591104736,4,"frozenset({'backend', 'gloo'})","This field should be given as a lowercase string (e.g., `""gloo""`), which can also be accessed via `Backend` attributes (e.g., `Backend.GLOO`).",torch.distributed.new_group.yaml,2
557,247,0.0028694404591104736,4,"frozenset({'backend', 'gloo'})",This is only applicable for the `gloo` backend.,torch.distributed.new_group.yaml,2
558,390,0.0028694404591104736,6,"frozenset({'batch', 'element', 'losses', 'loss', 'default', 'averaged'})","By default, the losses are averaged over each loss element in the batch.",torch.nn.functional.kl_div.yaml,6
559,390,0.0028694404591104736,6,"frozenset({'batch', 'element', 'losses', 'loss', 'default', 'averaged'})","By default, the losses are averaged over each loss element in the batch.",torch.nn.functional.binary_cross_entropy.yaml,6
560,390,0.0028694404591104736,6,"frozenset({'batch', 'element', 'losses', 'loss', 'default', 'averaged'})","By default, the losses are averaged over each loss element in the batch.",torch.nn.functional.nll_loss.yaml,6
561,390,0.0028694404591104736,6,"frozenset({'batch', 'element', 'losses', 'loss', 'default', 'averaged'})","By default, the losses are averaged over each loss element in the batch.",torch.nn.functional.cross_entropy.yaml,6
562,390,0.0028694404591104736,6,"frozenset({'batch', 'element', 'losses', 'loss', 'default', 'averaged'})","By default, the losses are averaged over each loss element in the batch.",torch.nn.functional.binary_cross_entropy_with_logits.yaml,6
563,390,0.0028694404591104736,6,"frozenset({'batch', 'element', 'losses', 'loss', 'default', 'averaged'})","By default, the losses are averaged over each loss element in the batch.",torch.nn.functional.poisson_nll_loss.yaml,6
564,238,0.0028694404591104736,3,"frozenset({'region', 'divisor', 'pooling', 'specified', 'size', 'used', 'otherwise'})","if specified, it will be used as divisor, otherwise size of the pooling region will be used.",torch.nn.functional.avg_pool3d.yaml,7
565,238,0.0028694404591104736,3,"frozenset({'region', 'divisor', 'pooling', 'specified', 'size', 'used', 'otherwise'})","if specified, it will be used as divisor, otherwise size of the pooling region will be used.",torch.nn.quantized.functional.avg_pool2d.yaml,7
566,238,0.0028694404591104736,3,"frozenset({'region', 'divisor', 'pooling', 'specified', 'size', 'used', 'otherwise'})","if specified, it will be used as divisor, otherwise size of the pooling region will be used.",torch.nn.functional.avg_pool2d.yaml,7
567,246,0.0028694404591104736,6,"frozenset({'depending', 'size_average', 'summed', 'losses', 'observations', 'default', 'averaged', 'minibatch'})","By default, the losses are averaged or summed over observations for each minibatch depending on `size_average`.",torch.nn.functional.kl_div.yaml,8
568,246,0.0028694404591104736,6,"frozenset({'depending', 'size_average', 'summed', 'losses', 'observations', 'default', 'averaged', 'minibatch'})","By default, the losses are averaged or summed over observations for each minibatch depending on `size_average`.",torch.nn.functional.binary_cross_entropy.yaml,8
569,246,0.0028694404591104736,6,"frozenset({'depending', 'size_average', 'summed', 'losses', 'observations', 'default', 'averaged', 'minibatch'})","By default, the losses are averaged or summed over observations for each minibatch depending on `size_average`.",torch.nn.functional.nll_loss.yaml,8
570,246,0.0028694404591104736,6,"frozenset({'depending', 'size_average', 'summed', 'losses', 'observations', 'default', 'averaged', 'minibatch'})","By default, the losses are averaged or summed over observations for each minibatch depending on `size_average`.",torch.nn.functional.cross_entropy.yaml,8
571,246,0.0028694404591104736,6,"frozenset({'depending', 'size_average', 'summed', 'losses', 'observations', 'default', 'averaged', 'minibatch'})","By default, the losses are averaged or summed over observations for each minibatch depending on `size_average`.",torch.nn.functional.binary_cross_entropy_with_logits.yaml,8
572,246,0.0028694404591104736,6,"frozenset({'depending', 'size_average', 'summed', 'losses', 'observations', 'default', 'averaged', 'minibatch'})","By default, the losses are averaged or summed over observations for each minibatch depending on `size_average`.",torch.nn.functional.poisson_nll_loss.yaml,8
573,244,0.0028694404591104736,5,"frozenset({'represents', 'prune', 'absolute', 'parameters', 'number', 'SOME_DTYPE'})","If `int`, it represents the absolute number of parameters to prune.",torch.nn.utils.prune.l1_unstructured.yaml,6
574,244,0.0028694404591104736,5,"frozenset({'represents', 'prune', 'absolute', 'parameters', 'number', 'SOME_DTYPE'})","If `int`, it represents the absolute number of parameters to prune.",torch.nn.utils.prune.random_unstructured.yaml,6
575,244,0.0028694404591104736,5,"frozenset({'represents', 'prune', 'absolute', 'parameters', 'number', 'SOME_DTYPE'})","If `int`, it represents the absolute number of parameters to prune.",torch.nn.utils.prune.ln_structured.yaml,6
576,244,0.0028694404591104736,5,"frozenset({'represents', 'prune', 'absolute', 'parameters', 'number', 'SOME_DTYPE'})","If `int`, it represents the absolute number of parameters to prune.",torch.nn.utils.prune.global_unstructured.yaml,6
577,244,0.0028694404591104736,5,"frozenset({'represents', 'prune', 'absolute', 'parameters', 'number', 'SOME_DTYPE'})","If `int`, it represents the absolute number of parameters to prune.",torch.nn.utils.prune.random_structured.yaml,6
578,235,0.0028694404591104736,3,"frozenset({'onnx', 'export'})",use operator_export_type] export the internal IR directly instead of converting it to ONNX ops.,torch.onnx.export.yaml,2
579,235,0.0028694404591104736,3,"frozenset({'onnx', 'export'})",by default we export the model to the opset version of the onnx submodule.,torch.onnx.export.yaml,2
580,235,0.0028694404591104736,3,"frozenset({'onnx', 'export'})","Since ONNX's latest opset may evolve before next stable release, by default we export to one stable opset version.",torch.onnx.export.yaml,2
581,243,0.0028694404591104736,5,"frozenset({'prune', 'fraction', 'parameters', 'represent', 'SOME_DTYPE'})","If `float`, should be between 0.0 and 1.0 and represent the fraction of parameters to prune.",torch.nn.utils.prune.l1_unstructured.yaml,5
582,243,0.0028694404591104736,5,"frozenset({'prune', 'fraction', 'parameters', 'represent', 'SOME_DTYPE'})","If `float`, should be between 0.0 and 1.0 and represent the fraction of parameters to prune.",torch.nn.utils.prune.random_unstructured.yaml,5
583,243,0.0028694404591104736,5,"frozenset({'prune', 'fraction', 'parameters', 'represent', 'SOME_DTYPE'})","If `float`, should be between 0.0 and 1.0 and represent the fraction of parameters to prune.",torch.nn.utils.prune.ln_structured.yaml,5
584,243,0.0028694404591104736,5,"frozenset({'prune', 'fraction', 'parameters', 'represent', 'SOME_DTYPE'})","If `float`, should be between 0.0 and 1.0 and represent the fraction of parameters to prune.",torch.nn.utils.prune.global_unstructured.yaml,5
585,243,0.0028694404591104736,5,"frozenset({'prune', 'fraction', 'parameters', 'represent', 'SOME_DTYPE'})","If `float`, should be between 0.0 and 1.0 and represent the fraction of parameters to prune.",torch.nn.utils.prune.random_structured.yaml,5
586,451,0.0028694404591104736,5,"frozenset({'input', 'matrix', 'dimensions', 'batch', 'zero', 'm', 'size'})","the input triangular coefficient matrix of size (*, m, m)  where *  is zero or more batch dimensions",torch.triangular_solve.yaml,7
587,451,0.0028694404591104736,5,"frozenset({'input', 'matrix', 'dimensions', 'batch', 'zero', 'm', 'size'})","input matrix b  of size (*, m, k) , where *  is zero or more batch dimensions",torch.cholesky_solve.yaml,7
588,451,0.0028694404591104736,5,"frozenset({'input', 'matrix', 'dimensions', 'batch', 'zero', 'm', 'size'})","input matrix u  of size (*, m, m) , where *  is zero of more batch dimensions composed of upper or lower triangular Cholesky factor",torch.cholesky_solve.yaml,7
589,451,0.0028694404591104736,5,"frozenset({'input', 'matrix', 'dimensions', 'batch', 'zero', 'm', 'size'})","input square matrix of size (*, m, m) , where *  is zero or more batch dimensions.",torch.solve.yaml,7
590,451,0.0028694404591104736,5,"frozenset({'input', 'matrix', 'dimensions', 'batch', 'zero', 'm', 'size'})","input matrix B  of size (*, m, k)  , where *  is zero or more batch dimensions.",torch.solve.yaml,7
591,253,0.0028694404591104736,6,"frozenset({'tensor', 'shape', 'output', 'SOME_DTYPE', 'SOME_STRUCTURE', 'defining'})",a sequence of integers defining the shape of the output tensor.,torch.rand.yaml,6
592,253,0.0028694404591104736,6,"frozenset({'tensor', 'shape', 'output', 'SOME_DTYPE', 'SOME_STRUCTURE', 'defining'})",a sequence of integers defining the shape of the output tensor.,torch.ones.yaml,6
593,253,0.0028694404591104736,6,"frozenset({'tensor', 'shape', 'output', 'SOME_DTYPE', 'SOME_STRUCTURE', 'defining'})",a sequence of integers defining the shape of the output tensor.,torch.normal222.yaml,6
594,253,0.0028694404591104736,6,"frozenset({'tensor', 'shape', 'output', 'SOME_DTYPE', 'SOME_STRUCTURE', 'defining'})",a sequence of integers defining the shape of the output tensor.,torch.zeros.yaml,6
595,253,0.0028694404591104736,6,"frozenset({'tensor', 'shape', 'output', 'SOME_DTYPE', 'SOME_STRUCTURE', 'defining'})",a sequence of integers defining the shape of the output tensor.,torch.randn.yaml,6
596,253,0.0028694404591104736,6,"frozenset({'tensor', 'shape', 'output', 'SOME_DTYPE', 'SOME_STRUCTURE', 'defining'})","a list, tuple, or `torch.Size` of integers defining the shape of the output tensor.",torch.full.yaml,6
597,325,0.0028694404591104736,6,"frozenset({'rng', 'state'})", CPU RNG state is always forked.,torch.random.fork_rng.yaml,2
598,325,0.0028694404591104736,6,"frozenset({'rng', 'state'})", CPU RNG state is always forked.,torch.random.fork_rng2.yaml,2
599,325,0.0028694404591104736,6,"frozenset({'rng', 'state'})",Omit stashing and restoring the RNG state during each checkpoint.,torch.utils.checkpoint.checkpoint_sequential.yaml,2
600,325,0.0028694404591104736,6,"frozenset({'rng', 'state'})",The device to return the RNG state of.,torch.cuda.get_rng_state.yaml,2
601,325,0.0028694404591104736,6,"frozenset({'rng', 'state'})",The device to set the RNG state.,torch.cuda.set_rng_state.yaml,2
602,325,0.0028694404591104736,6,"frozenset({'rng', 'state'})",Omit stashing and restoring the RNG state during each checkpoint.,torch.utils.checkpoint.checkpoint.yaml,2
603,296,0.0028694404591104736,5,"frozenset({'returns', 'python', 'tensor', 'takes', 'function', 'inputs', 'SOME_STRUCTURE'})",a Python function that takes Tensor inputs and returns a tuple of Tensors or a Tensor.,torch.autograd.functional.vjp.yaml,7
604,296,0.0028694404591104736,5,"frozenset({'returns', 'python', 'tensor', 'takes', 'function', 'inputs', 'SOME_STRUCTURE'})",a Python function that takes Tensor inputs and returns a Tensor or a tuple of Tensors,torch.autograd.gradgradcheck.yaml,7
605,296,0.0028694404591104736,5,"frozenset({'returns', 'python', 'tensor', 'takes', 'function', 'inputs', 'SOME_STRUCTURE'})",a Python function that takes Tensor inputs and returns a tuple of Tensors or a Tensor.,torch.autograd.functional.jvp.yaml,7
606,296,0.0028694404591104736,5,"frozenset({'returns', 'python', 'tensor', 'takes', 'function', 'inputs', 'SOME_STRUCTURE'})",a Python function that takes Tensor inputs and returns a tuple of Tensors or a Tensor.,torch.autograd.functional.jacobian.yaml,7
607,296,0.0028694404591104736,5,"frozenset({'returns', 'python', 'tensor', 'takes', 'function', 'inputs', 'SOME_STRUCTURE'})",a Python function that takes Tensor inputs and returns a Tensor or a tuple of Tensors,torch.autograd.gradcheck.yaml,7
608,372,0.0028694404591104736,6,"frozenset({'diagonal', 'consider'})",the diagonal to consider,torch.diag.yaml,2
609,372,0.0028694404591104736,6,"frozenset({'diagonal', 'consider'})",which diagonal to consider.,torch.diag_embed.yaml,2
610,372,0.0028694404591104736,6,"frozenset({'diagonal', 'consider'})",the diagonal to consider,torch.tril.yaml,2
611,372,0.0028694404591104736,6,"frozenset({'diagonal', 'consider'})",the diagonal to consider,torch.triu.yaml,2
612,372,0.0028694404591104736,6,"frozenset({'diagonal', 'consider'})",which diagonal to consider.,torch.diagonal.yaml,2
613,372,0.0028694404591104736,6,"frozenset({'diagonal', 'consider'})",the diagonal to consider.,torch.diagflat.yaml,2
614,527,0.0028694404591104736,3,"frozenset({'none', 'value', 'default'})","If set to `None` (default), this value is automatically determined based on whether `cuda_sources` is provided.",torch.utils.cpp_extension.load_inline.yaml,3
615,527,0.0028694404591104736,3,"frozenset({'none', 'value', 'default'})","If None (default) is specified, the value is defined by _Formatter",torch.set_printoptions.yaml,3
616,527,0.0028694404591104736,3,"frozenset({'none', 'value', 'default'})","If set to `None` (default), this value is automatically determined based on the existence of `.cu` or `.cuh` in `sources`.",torch.utils.cpp_extension.load.yaml,3
617,498,0.0028694404591104736,5,"frozenset({'output', 'SOME_DTYPE', 'tensor', 'must'})",the output tensor that must be a BoolTensor,torch.le.yaml,4
618,498,0.0028694404591104736,5,"frozenset({'output', 'SOME_DTYPE', 'tensor', 'must'})",the output tensor that must be a BoolTensor,torch.gt.yaml,4
619,498,0.0028694404591104736,5,"frozenset({'output', 'SOME_DTYPE', 'tensor', 'must'})",the output tensor that must be a BoolTensor,torch.ne.yaml,4
620,498,0.0028694404591104736,5,"frozenset({'output', 'SOME_DTYPE', 'tensor', 'must'})",the output tensor that must be a BoolTensor,torch.ge.yaml,4
621,498,0.0028694404591104736,5,"frozenset({'output', 'SOME_DTYPE', 'tensor', 'must'})",the output tensor that must be a BoolTensor,torch.lt.yaml,4
622,317,0.0028694404591104736,6,"frozenset({'elements', 'number', 'sum', 'none', 'applied', 'mean', 'summed', 'divided', 'reduction', 'output'})",`'none'`: no reduction will be applied `'batchmean'`: the sum of the output will be divided by the batchsize `'sum'`: the output will be summed `'mean'`: the output will be divided by the number of elements in the output Default: `'mean'`,torch.nn.functional.kl_div.yaml,10
623,317,0.0028694404591104736,6,"frozenset({'elements', 'number', 'sum', 'none', 'applied', 'mean', 'summed', 'divided', 'reduction', 'output'})","`'none'`: no reduction will be applied, `'mean'`: the sum of the output will be divided by the number of elements in the output, `'sum'`: the output will be summed.",torch.nn.functional.binary_cross_entropy.yaml,10
624,317,0.0028694404591104736,6,"frozenset({'elements', 'number', 'sum', 'none', 'applied', 'mean', 'summed', 'divided', 'reduction', 'output'})","`'none'`: no reduction will be applied, `'mean'`: the sum of the output will be divided by the number of elements in the output, `'sum'`: the output will be summed.",torch.nn.functional.nll_loss.yaml,10
625,317,0.0028694404591104736,6,"frozenset({'elements', 'number', 'sum', 'none', 'applied', 'mean', 'summed', 'divided', 'reduction', 'output'})","`'none'`: no reduction will be applied, `'mean'`: the sum of the output will be divided by the number of elements in the output, `'sum'`: the output will be summed.",torch.nn.functional.cross_entropy.yaml,10
626,317,0.0028694404591104736,6,"frozenset({'elements', 'number', 'sum', 'none', 'applied', 'mean', 'summed', 'divided', 'reduction', 'output'})","`'none'`: no reduction will be applied, `'mean'`: the sum of the output will be divided by the number of elements in the output, `'sum'`: the output will be summed.",torch.nn.functional.binary_cross_entropy_with_logits.yaml,10
627,317,0.0028694404591104736,6,"frozenset({'elements', 'number', 'sum', 'none', 'applied', 'mean', 'summed', 'divided', 'reduction', 'output'})","`'none'`: no reduction will be applied, `'mean'`: the sum of the output will be divided by the number of elements in the output, `'sum'`: the output will be summed.",torch.nn.functional.poisson_nll_loss.yaml,10
628,319,0.0028694404591104736,6,"frozenset({'shape', 'optional', '_channels', 'bias'})",optional bias of shape (out _channels) .,torch.nn.functional.conv_transpose2d.yaml,4
629,319,0.0028694404591104736,6,"frozenset({'shape', 'optional', '_channels', 'bias'})",optional bias tensor of shape (out _channels) .,torch.nn.functional.conv2d.yaml,4
630,319,0.0028694404591104736,6,"frozenset({'shape', 'optional', '_channels', 'bias'})",optional bias of shape (out _channels) .,torch.nn.functional.conv_transpose3d.yaml,4
631,319,0.0028694404591104736,6,"frozenset({'shape', 'optional', '_channels', 'bias'})",optional bias of shape (out _channels) .,torch.nn.functional.conv_transpose1d.yaml,4
632,319,0.0028694404591104736,6,"frozenset({'shape', 'optional', '_channels', 'bias'})",optional bias of shape (out _channels) .,torch.nn.functional.conv1d.yaml,4
633,319,0.0028694404591104736,6,"frozenset({'shape', 'optional', '_channels', 'bias'})",optional bias tensor of shape (out _channels) .,torch.nn.functional.conv3d.yaml,4
634,321,0.0028694404591104736,6,"frozenset({'input', 'iw', 'ih', 'tensor', '_channels', 'shape', 'minibatch'})","input tensor of shape (minibatch , in _channels , iH , iW) ",torch.nn.functional.conv_transpose2d.yaml,7
635,321,0.0028694404591104736,6,"frozenset({'input', 'iw', 'ih', 'tensor', '_channels', 'shape', 'minibatch'})","input tensor of shape (minibatch , in _channels , iH , iW) ",torch.nn.functional.conv2d.yaml,7
636,321,0.0028694404591104736,6,"frozenset({'input', 'iw', 'ih', 'tensor', '_channels', 'shape', 'minibatch'})","input tensor of shape (minibatch , in _channels , iT , iH , iW) ",torch.nn.functional.conv_transpose3d.yaml,7
637,321,0.0028694404591104736,6,"frozenset({'input', 'iw', 'ih', 'tensor', '_channels', 'shape', 'minibatch'})","input tensor of shape (minibatch , in _channels , iT , iH , iW) ",torch.nn.functional.conv3d.yaml,7
638,321,0.0028694404591104736,6,"frozenset({'input', 'iw', 'ih', 'tensor', '_channels', 'shape', 'minibatch'})","quantized input tensor of shape (minibatch , in _channels , iH , iW) ",torch.nn.quantized.functional.conv2d.yaml,7
639,321,0.0028694404591104736,6,"frozenset({'input', 'iw', 'ih', 'tensor', '_channels', 'shape', 'minibatch'})","quantized input tensor of shape (minibatch , in _channels , iD , iH , iW) ",torch.nn.quantized.functional.conv3d.yaml,7
640,408,0.0028694404591104736,6,"frozenset({'function', 'inputs', 'func'})",inputs to the function `func`.,torch.autograd.functional.hvp.yaml,3
641,408,0.0028694404591104736,6,"frozenset({'function', 'inputs', 'func'})",inputs to the function `func`.,torch.autograd.functional.vjp.yaml,3
642,408,0.0028694404591104736,6,"frozenset({'function', 'inputs', 'func'})",inputs to the function `func`.,torch.autograd.functional.jvp.yaml,3
643,408,0.0028694404591104736,6,"frozenset({'function', 'inputs', 'func'})",inputs to the function `func`.,torch.autograd.functional.vhp.yaml,3
644,408,0.0028694404591104736,6,"frozenset({'function', 'inputs', 'func'})",inputs to the function `func`.,torch.autograd.functional.jacobian.yaml,3
645,408,0.0028694404591104736,6,"frozenset({'function', 'inputs', 'func'})",inputs to the function `func`.,torch.autograd.functional.hessian.yaml,3
646,454,0.0028694404591104736,4,"frozenset({'returned', 'window', 'size'})",the size of returned window,torch.hann_window.yaml,3
647,454,0.0028694404591104736,4,"frozenset({'returned', 'window', 'size'})",the size of returned window,torch.hamming_window.yaml,3
648,454,0.0028694404591104736,4,"frozenset({'returned', 'window', 'size'})",the size of returned window,torch.blackman_window.yaml,3
649,454,0.0028694404591104736,4,"frozenset({'returned', 'window', 'size'})",the size of returned window,torch.bartlett_window.yaml,3
650,262,0.0028694404591104736,3,"frozenset({'url', 'download', 'object'})",URL of the object to download,torch.hub.download_url_to_file.yaml,3
651,262,0.0028694404591104736,3,"frozenset({'url', 'download', 'object'})",URL of the object to download,torch.utils.model_zoo.load_url.yaml,3
652,262,0.0028694404591104736,3,"frozenset({'url', 'download', 'object'})",URL of the object to download,torch.hub.load_state_dict_from_url.yaml,3
653,261,0.0028694404591104736,3,"frozenset({'defined', 'SOME_DTYPE'})","a dictionary that maps from float module type to quantized module type, can be overwrritten to allow swapping user defined Modules",torch.quantization.convert.yaml,2
654,261,0.0028694404591104736,3,"frozenset({'defined', 'SOME_DTYPE'})",a string of entrypoint name defined in repo's hubconf.py,torch.hub.load.yaml,2
655,261,0.0028694404591104736,3,"frozenset({'defined', 'SOME_DTYPE'})",a string of entrypoint name defined in repo's hubconf.py,torch.hub.help.yaml,2
656,260,0.0028694404591104736,3,"frozenset({'number', 'end'})",Number of array items in summary at beginning and end of each dimension (default = 3).,torch.set_printoptions.yaml,2
657,260,0.0028694404591104736,3,"frozenset({'number', 'end'})",number of points to sample between `start` and `end`.,torch.linspace.yaml,2
658,260,0.0028694404591104736,3,"frozenset({'number', 'end'})",number of points to sample between `start` and `end`.,torch.logspace.yaml,2
659,330,0.0028694404591104736,6,"frozenset({'field', 'size_average', 'summed', 'false', 'losses', 'set', 'instead', 'minibatch'})","If the field `size_average` is set to `False`, the losses are instead summed for each minibatch.",torch.nn.functional.kl_div.yaml,8
660,330,0.0028694404591104736,6,"frozenset({'field', 'size_average', 'summed', 'false', 'losses', 'set', 'instead', 'minibatch'})","If the field `size_average` is set to `False`, the losses are instead summed for each minibatch.",torch.nn.functional.binary_cross_entropy.yaml,8
661,330,0.0028694404591104736,6,"frozenset({'field', 'size_average', 'summed', 'false', 'losses', 'set', 'instead', 'minibatch'})","If the field `size_average` is set to `False`, the losses are instead summed for each minibatch.",torch.nn.functional.nll_loss.yaml,8
662,330,0.0028694404591104736,6,"frozenset({'field', 'size_average', 'summed', 'false', 'losses', 'set', 'instead', 'minibatch'})","If the field `size_average` is set to `False`, the losses are instead summed for each minibatch.",torch.nn.functional.cross_entropy.yaml,8
663,330,0.0028694404591104736,6,"frozenset({'field', 'size_average', 'summed', 'false', 'losses', 'set', 'instead', 'minibatch'})","If the field `size_average` is set to `False`, the losses are instead summed for each minibatch.",torch.nn.functional.binary_cross_entropy_with_logits.yaml,8
664,330,0.0028694404591104736,6,"frozenset({'field', 'size_average', 'summed', 'false', 'losses', 'set', 'instead', 'minibatch'})","If the field `size_average` is set to `False`, the losses are instead summed for each minibatch.",torch.nn.functional.poisson_nll_loss.yaml,8
665,258,0.0028694404591104736,3,"frozenset({'number', 'matrix', 'columns'})","The embedding matrix with number of rows equal to the maximum possible index + 1, and number of columns equal to the embedding size",torch.nn.functional.embedding.yaml,3
666,258,0.0028694404591104736,3,"frozenset({'number', 'matrix', 'columns'})",number of columns in the 2-D matrix.,torch.triu_indices.yaml,3
667,258,0.0028694404591104736,3,"frozenset({'number', 'matrix', 'columns'})",number of columns in the 2-D matrix.,torch.tril_indices.yaml,3
668,257,0.0028694404591104736,4,"frozenset({'output', 'way', 'result', 'differentiable', 'computed', 'true'})","If `True`, both the output and result will be computed in a differentiable way.",torch.autograd.functional.hvp.yaml,6
669,257,0.0028694404591104736,4,"frozenset({'output', 'way', 'result', 'differentiable', 'computed', 'true'})","If `True`, both the output and result will be computed in a differentiable way.",torch.autograd.functional.vjp.yaml,6
670,257,0.0028694404591104736,4,"frozenset({'output', 'way', 'result', 'differentiable', 'computed', 'true'})","If `True`, both the output and result will be computed in a differentiable way.",torch.autograd.functional.jvp.yaml,6
671,257,0.0028694404591104736,4,"frozenset({'output', 'way', 'result', 'differentiable', 'computed', 'true'})","If `True`, both the output and result will be computed in a differentiable way.",torch.autograd.functional.vhp.yaml,6
672,255,0.0028694404591104736,4,"frozenset({'input', 'dimensions', 'tensor', 'signal_ndim', 'least'})",the input tensor of at least `signal_ndim` `+ 1` dimensions,torch.irfft.yaml,5
673,255,0.0028694404591104736,4,"frozenset({'input', 'dimensions', 'tensor', 'signal_ndim', 'least'})",the input tensor of at least `signal_ndim` `+ 1` dimensions,torch.fft.yaml,5
674,255,0.0028694404591104736,4,"frozenset({'input', 'dimensions', 'tensor', 'signal_ndim', 'least'})",the input tensor of at least `signal_ndim` `+ 1` dimensions,torch.ifft.yaml,5
675,255,0.0028694404591104736,4,"frozenset({'input', 'dimensions', 'tensor', 'signal_ndim', 'least'})",the input tensor of at least `signal_ndim` dimensions,torch.rfft.yaml,5
676,221,0.0023912003825920613,3,"frozenset({'data', 'initial', 'tensor'})",Initial data for the tensor.,torch.as_tensor.yaml,3
677,221,0.0023912003825920613,3,"frozenset({'data', 'initial', 'tensor'})",Initial data for the tensor.,torch.tensor.yaml,3
678,221,0.0023912003825920613,3,"frozenset({'data', 'initial', 'tensor'})",Initial data for the tensor.,torch.sparse_coo_tensor.yaml,3
679,215,0.0023912003825920613,4,"frozenset({'input', 'returned', 'none', 'flattened'})","If `None`, the argmin of the flattened input is returned.",torch.argmin2.yaml,4
680,215,0.0023912003825920613,4,"frozenset({'input', 'returned', 'none', 'flattened'})","If `None`, the argmax of the flattened input is returned.",torch.argmax2.yaml,4
681,215,0.0023912003825920613,4,"frozenset({'input', 'returned', 'none', 'flattened'})","If `None`, the unique of the flattened input is returned.",torch.unique.yaml,4
682,215,0.0023912003825920613,4,"frozenset({'input', 'returned', 'none', 'flattened'})","If `None`, the unique of the flattened input is returned.",torch.unique_consecutive.yaml,4
683,217,0.0023912003825920613,3,"frozenset({'specified', 'store'})","Default is ""env://"" if no `init_method` or `store` is specified.",torch.distributed.init_process_group.yaml,2
684,217,0.0023912003825920613,3,"frozenset({'specified', 'store'})",Required if `store` is specified.,torch.distributed.init_process_group.yaml,2
685,217,0.0023912003825920613,3,"frozenset({'specified', 'store'})",Required if `store` is specified.,torch.distributed.init_process_group.yaml,2
686,218,0.0023912003825920613,3,"frozenset({'points', 'starting', 'set', 'value'})",the starting value for the set of points.,torch.arange.yaml,4
687,218,0.0023912003825920613,3,"frozenset({'points', 'starting', 'set', 'value'})",the starting value for the set of points,torch.linspace.yaml,4
688,218,0.0023912003825920613,3,"frozenset({'points', 'starting', 'set', 'value'})",the starting value for the set of points,torch.logspace.yaml,4
689,213,0.0023912003825920613,5,"frozenset({'like', 'name', 'implement', 'object', 'containing', 'SOME_DTYPE', 'file'})",a file-like object (has to implement write and flush) or a string containing a file name,torch.save.yaml,7
690,213,0.0023912003825920613,5,"frozenset({'like', 'name', 'implement', 'object', 'containing', 'SOME_DTYPE', 'file'})",a file-like object (has to implement fileno that returns a file descriptor) or a string containing a file name.,torch.onnx.export.yaml,7
691,213,0.0023912003825920613,5,"frozenset({'like', 'name', 'implement', 'object', 'containing', 'SOME_DTYPE', 'file'})",A file-like object (has to implement write and flush) or a string containing a file name.,torch.jit.save.yaml,7
692,213,0.0023912003825920613,5,"frozenset({'like', 'name', 'implement', 'object', 'containing', 'SOME_DTYPE', 'file'})","a file-like object (has to implement `read()`, :meth`readline`, :meth`tell`, and :meth`seek`), or a string containing a file name",torch.load.yaml,7
693,213,0.0023912003825920613,5,"frozenset({'like', 'name', 'implement', 'object', 'containing', 'SOME_DTYPE', 'file'})","a file-like object (has to implement read, readline, tell, and seek), or a string containing a file name",torch.jit.load.yaml,7
694,220,0.0023912003825920613,3,"frozenset({'points', 'value', 'set', 'ending'})",the ending value for the set of points,torch.arange.yaml,4
695,220,0.0023912003825920613,3,"frozenset({'points', 'value', 'set', 'ending'})",the ending value for the set of points,torch.linspace.yaml,4
696,220,0.0023912003825920613,3,"frozenset({'points', 'value', 'set', 'ending'})",the ending value for the set of points,torch.logspace.yaml,4
697,192,0.0023912003825920613,4,"frozenset({'warning', 'SOME_DTYPE'})"," By default, `fork_rng()` operates on all devices, but will emit a warning if your machine has a lot of devices, since this function will run very slowly in that case.",torch.random.fork_rng.yaml,2
698,192,0.0023912003825920613,4,"frozenset({'warning', 'SOME_DTYPE'})","If you explicitly specify devices, this warning will be suppressed",torch.random.fork_rng.yaml,2
699,192,0.0023912003825920613,4,"frozenset({'warning', 'SOME_DTYPE'})"," By default, `fork_rng()` operates on all devices, but will emit a warning if your machine has a lot of devices, since this function will run very slowly in that case.",torch.random.fork_rng2.yaml,2
700,192,0.0023912003825920613,4,"frozenset({'warning', 'SOME_DTYPE'})","If you explicitly specify devices, this warning will be suppressed",torch.random.fork_rng2.yaml,2
701,359,0.0023912003825920613,3,"frozenset({'input', 'times', 'tensor', 'n', 'm'})",input tensor of shape N  times M .,torch.nn.functional.pdist.yaml,5
702,359,0.0023912003825920613,3,"frozenset({'input', 'times', 'tensor', 'n', 'm'})","the input tensor of size (*, m, n)  where * is zero or more batch dimensions consisting of matrices of dimension m  times n .",torch.qr.yaml,5
703,359,0.0023912003825920613,3,"frozenset({'input', 'times', 'tensor', 'n', 'm'})","the input tensor of size (*, m, n)  where * is zero or more batch dimensions consisting of m  times n  matrices.",torch.svd.yaml,5
704,225,0.0023912003825920613,4,"frozenset({'fill', 'tensor'})",Tensor to fill with received data.,torch.distributed.recv.yaml,2
705,225,0.0023912003825920613,4,"frozenset({'fill', 'tensor'})",the value to fill the tensor with,torch.nn.init.constant_.yaml,2
706,225,0.0023912003825920613,4,"frozenset({'fill', 'tensor'})",Tensor to fill with received data.,torch.distributed.irecv.yaml,2
707,225,0.0023912003825920613,4,"frozenset({'fill', 'tensor'})",the number to fill the output tensor with.,torch.full.yaml,2
708,350,0.0023912003825920613,4,"frozenset({'input', 'm', 'b'})",input tensor of shape B  times P  times M .,torch.cdist.yaml,3
709,350,0.0023912003825920613,4,"frozenset({'input', 'm', 'b'})",input tensor of shape B  times R  times M .,torch.cdist.yaml,3
710,350,0.0023912003825920613,4,"frozenset({'input', 'm', 'b'})","input matrix b  of size (*, m, k) , where *  is zero or more batch dimensions",torch.cholesky_solve.yaml,3
711,350,0.0023912003825920613,4,"frozenset({'input', 'm', 'b'})","input matrix B  of size (*, m, k)  , where *  is zero or more batch dimensions.",torch.solve.yaml,3
712,345,0.0023912003825920613,5,"frozenset({'SOME_DTYPE', 'exported'})"," Any non-Tensor arguments will be hard-coded into the exported model; any Tensor arguments will become inputs of the exported model, in the order they occur in args.",torch.onnx.export.yaml,2
713,345,0.0023912003825920613,5,"frozenset({'SOME_DTYPE', 'exported'})",Model's example outputs being exported.,torch.onnx.export.yaml,2
714,345,0.0023912003825920613,5,"frozenset({'SOME_DTYPE', 'exported'})","In this case, the exported model will first take all of its parameters as arguments, the ordering as specified by `model.state_dict().values()`",torch.onnx.export.yaml,2
715,345,0.0023912003825920613,5,"frozenset({'SOME_DTYPE', 'exported'})",the model to be exported.,torch.onnx.export.yaml,2
716,345,0.0023912003825920613,5,"frozenset({'SOME_DTYPE', 'exported'})","if True, strips the field ""doc_string"" from the exported model, which information about the stack trace.",torch.onnx.export.yaml,2
717,241,0.0023912003825920613,4,"frozenset({'hand', 'right', 'side'})",The right hand side follows after -> and gives the indices for the output.,torch.einsum.yaml,3
718,241,0.0023912003825920613,4,"frozenset({'hand', 'right', 'side'})","If the -> and right hand side are omitted, it implicitly defined as the alphabetically sorted list of all indices appearing exactly once in the left hand side.",torch.einsum.yaml,3
719,241,0.0023912003825920613,4,"frozenset({'hand', 'right', 'side'})","If the right hand side is inferred, the ellipsis dimensions are at the beginning of the output.",torch.einsum.yaml,3
720,241,0.0023912003825920613,4,"frozenset({'hand', 'right', 'side'})",the Right-hand-side input tensor,torch.dist.yaml,3
721,211,0.0023912003825920613,3,"frozenset({'torch', 'quantized', 'quint'})","Has to be one of the quantized dtypes: `torch.quint8`, `torch.qint8`, `torch.qint32`",torch.quantize_per_channel.yaml,3
722,211,0.0023912003825920613,3,"frozenset({'torch', 'quantized', 'quint'})",Quantized input of type torch.quint8,torch.nn.quantized.functional.linear.yaml,3
723,211,0.0023912003825920613,3,"frozenset({'torch', 'quantized', 'quint'})","Has to be one of the quantized dtypes: `torch.quint8`, `torch.qint8`, `torch.qint32`",torch.quantize_per_tensor.yaml,3
724,311,0.0023912003825920613,5,"frozenset({'operation', 'input', 'performed', 'tensor', 'casted', 'specified', 'dtype'})","If specified, the input tensor is casted to `dtype` before the operation is performed.",torch.nn.functional.log_softmax.yaml,7
725,311,0.0023912003825920613,5,"frozenset({'operation', 'input', 'performed', 'tensor', 'casted', 'specified', 'dtype'})","If specified, the input tensor is casted to `dtype` before the operation is performed.",torch.cumprod.yaml,7
726,311,0.0023912003825920613,5,"frozenset({'operation', 'input', 'performed', 'tensor', 'casted', 'specified', 'dtype'})","If specified, the input tensor is casted to `dtype` before the operation is performed.",torch.nn.functional.softmin.yaml,7
727,311,0.0023912003825920613,5,"frozenset({'operation', 'input', 'performed', 'tensor', 'casted', 'specified', 'dtype'})","If specified, the input tensor is casted to `dtype` before the operation is performed.",torch.cumsum.yaml,7
728,311,0.0023912003825920613,5,"frozenset({'operation', 'input', 'performed', 'tensor', 'casted', 'specified', 'dtype'})","If specified, the input tensor is casted to `dtype` before the operation is performed.",torch.nn.functional.softmax.yaml,7
729,304,0.0023912003825920613,3,"frozenset({'matrix', 'triangular', 'lower', 'upper', 'whether'})",flag that indicates whether to return a upper or lower triangular matrix.,torch.cholesky.yaml,5
730,304,0.0023912003825920613,3,"frozenset({'matrix', 'triangular', 'lower', 'upper', 'whether'})",whether to consider the Cholesky factor as a lower or upper triangular matrix.,torch.cholesky_solve.yaml,5
731,304,0.0023912003825920613,3,"frozenset({'matrix', 'triangular', 'lower', 'upper', 'whether'})",whether to return a lower (default) or upper triangular matrix,torch.cholesky_inverse.yaml,5
732,212,0.0023912003825920613,3,"frozenset({'computed', 'eigenvectors'})","`True` to compute both eigenvalues and eigenvectors; otherwise, only eigenvalues will be computed",torch.eig.yaml,2
733,212,0.0023912003825920613,3,"frozenset({'computed', 'eigenvectors'})",the square matrix of shape (n  times n)  for which the eigenvalues and eigenvectors will be computed,torch.eig.yaml,2
734,212,0.0023912003825920613,3,"frozenset({'computed', 'eigenvectors'})",controls whether eigenvectors have to be computed,torch.symeig.yaml,2
735,301,0.0023912003825920613,5,"frozenset({'SOME_DTYPE', 'nn'})","The `nn.Module`, function, or class type to compile.",torch.jit.script.yaml,2
736,301,0.0023912003825920613,5,"frozenset({'SOME_DTYPE', 'nn'})",a dictionary that maps from nn module to nnq module,torch.quantization.swap_module.yaml,2
737,301,0.0023912003825920613,5,"frozenset({'SOME_DTYPE', 'nn'})","module must be of type `nn.Module`, and name must be a string.",torch.nn.utils.prune.global_unstructured.yaml,2
738,301,0.0023912003825920613,5,"frozenset({'SOME_DTYPE', 'nn'})",A Python function or `torch.nn.Module` that will be run with `example_inputs`.,torch.jit.trace.yaml,2
739,301,0.0023912003825920613,5,"frozenset({'SOME_DTYPE', 'nn'})",A `torch.nn.Sequential` or the list of modules or functions (comprising the model) to run sequentially.,torch.utils.checkpoint.checkpoint_sequential.yaml,2
740,181,0.0023912003825920613,4,"frozenset({'number', 'signal', 'dimensions'})",the number of dimensions in each signal.,torch.irfft.yaml,3
741,181,0.0023912003825920613,4,"frozenset({'number', 'signal', 'dimensions'})",the number of dimensions in each signal.,torch.fft.yaml,3
742,181,0.0023912003825920613,4,"frozenset({'number', 'signal', 'dimensions'})",the number of dimensions in each signal.,torch.ifft.yaml,3
743,181,0.0023912003825920613,4,"frozenset({'number', 'signal', 'dimensions'})",the number of dimensions in each signal.,torch.rfft.yaml,3
744,191,0.0023912003825920613,5,"frozenset({'torch', 'preserve_format', 'default'})",Default: `torch.preserve_format`.,torch.ones_like.yaml,3
745,191,0.0023912003825920613,5,"frozenset({'torch', 'preserve_format', 'default'})",Default: `torch.preserve_format`.,torch.empty_like.yaml,3
746,191,0.0023912003825920613,5,"frozenset({'torch', 'preserve_format', 'default'})",Default: `torch.preserve_format`.,torch.zeros_like.yaml,3
747,191,0.0023912003825920613,5,"frozenset({'torch', 'preserve_format', 'default'})",Default: `torch.preserve_format`.,torch.randn_like.yaml,3
748,191,0.0023912003825920613,5,"frozenset({'torch', 'preserve_format', 'default'})",Default: `torch.preserve_format`.,torch.rand_like.yaml,3
749,489,0.0023912003825920613,5,"frozenset({'use', 'input'})","float 1D tensor of scales to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,2
750,489,0.0023912003825920613,5,"frozenset({'use', 'input'})","integer 1D tensor of offset to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,2
751,489,0.0023912003825920613,5,"frozenset({'use', 'input'})","The dimension along which to repeat values.By default, use the flattened input array, and return a flat outputarray.",torch.repeat_interleave.yaml,2
752,489,0.0023912003825920613,5,"frozenset({'use', 'input'})","For example, in LSTM, if user passes `(activation, hidden)`, `function` should correctly use the first input as `activation` and the second input as `hidden`",torch.utils.checkpoint.checkpoint.yaml,2
753,489,0.0023912003825920613,5,"frozenset({'use', 'input'})"," If recompute_scale_factor is ``True` or not specified, a new scale_factor will be computed based on the output and input sizes for use in the interpolation computation (i.e. the computation will be identical to if the computed output_size were passed-in explicitly).",torch.nn.functional.interpolate.yaml,2
754,371,0.0023912003825920613,5,"frozenset({'also', 'SOME_STRUCTURE'})",`example_inputs` may also be a single Tensor in which case it is automatically wrapped in a tuple.,torch.jit.trace.yaml,2
755,371,0.0023912003825920613,5,"frozenset({'also', 'SOME_STRUCTURE'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique.yaml,2
756,371,0.0023912003825920613,5,"frozenset({'also', 'SOME_STRUCTURE'})",Can also be a list of strings if there is only a single list of modules to fuse.,torch.quantization.fuse_modules.yaml,2
757,371,0.0023912003825920613,5,"frozenset({'also', 'SOME_STRUCTURE'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique_consecutive.yaml,2
758,371,0.0023912003825920613,5,"frozenset({'also', 'SOME_STRUCTURE'})",It should also know how to handle the inputs passed as the tuple.,torch.utils.checkpoint.checkpoint.yaml,2
759,174,0.0023912003825920613,5,"frozenset({'seed', 'desired'})",The desired seed.,torch.cuda.manual_seed.yaml,2
760,174,0.0023912003825920613,5,"frozenset({'seed', 'desired'})",The desired seed.,torch.manual_seed.yaml,2
761,174,0.0023912003825920613,5,"frozenset({'seed', 'desired'})",The desired seed.,torch.random.manual_seed2.yaml,2
762,174,0.0023912003825920613,5,"frozenset({'seed', 'desired'})",The desired seed.,torch.random.manual_seed.yaml,2
763,174,0.0023912003825920613,5,"frozenset({'seed', 'desired'})",The desired seed.,torch.cuda.manual_seed_all.yaml,2
764,175,0.0023912003825920613,3,"frozenset({'may', 'tensor'})","the divisor, which may be either a number or a tensor of the same shape as the dividend",torch.fmod.yaml,2
765,175,0.0023912003825920613,3,"frozenset({'may', 'tensor'})",the divisor that may be either a number or a Tensor of the same shape as the dividend,torch.remainder.yaml,2
766,175,0.0023912003825920613,3,"frozenset({'may', 'tensor'})",`example_inputs` may also be a single Tensor in which case it is automatically wrapped in a tuple.,torch.jit.trace.yaml,2
767,179,0.0023912003825920613,4,"frozenset({'maps', 'SOME_DTYPE', 'SOME_STRUCTURE'})",dictionary that maps float modules to quantized modules to be replaced.,torch.quantization.prepare_qat.yaml,3
768,179,0.0023912003825920613,4,"frozenset({'maps', 'SOME_DTYPE', 'SOME_STRUCTURE'})",a dictionary that maps from nn module to nnq module,torch.quantization.swap_module.yaml,3
769,179,0.0023912003825920613,4,"frozenset({'maps', 'SOME_DTYPE', 'SOME_STRUCTURE'})","a dictionary that maps from float module type to quantized module type, can be overwrritten to allow swapping user defined Modules",torch.quantization.convert.yaml,3
770,179,0.0023912003825920613,4,"frozenset({'maps', 'SOME_DTYPE', 'SOME_STRUCTURE'})","dictionary that maps from name or type of submodule to quantization configuration, qconfig applies to all submodules of a given module unless qconfig for the submodules are specified (when the submodule already has qconfig attribute)",torch.quantization.propagate_qconfig_.yaml,3
771,507,0.0023912003825920613,5,"frozenset({'return', 'SOME_DTYPE'})",device for which to return the name.,torch.cuda.get_device_name.yaml,2
772,507,0.0023912003825920613,5,"frozenset({'return', 'SOME_DTYPE'})",device for which to return the device capability.,torch.cuda.get_device_capability.yaml,2
773,507,0.0023912003825920613,5,"frozenset({'return', 'SOME_DTYPE'})",controls whether to return half of results to avoid redundancy Default: `True`,torch.stft.yaml,2
774,507,0.0023912003825920613,5,"frozenset({'return', 'SOME_DTYPE'})",The device to return the RNG state of.,torch.cuda.get_rng_state.yaml,2
775,507,0.0023912003825920613,5,"frozenset({'return', 'SOME_DTYPE'})",controls whether to return half of results to avoid redundancy.,torch.rfft.yaml,2
776,180,0.0023912003825920613,3,"frozenset({'small', 'avoid', 'value'})",small value to avoid division by zero.,torch.nn.functional.normalize.yaml,3
777,180,0.0023912003825920613,3,"frozenset({'small', 'avoid', 'value'})",Small value to avoid division by zero.,torch.nn.functional.cosine_similarity.yaml,3
778,180,0.0023912003825920613,3,"frozenset({'small', 'avoid', 'value'})",Small value to avoid evaluation of  log(0)  when `log_input`=``False``.,torch.nn.functional.poisson_nll_loss.yaml,3
779,182,0.0023912003825920613,3,"frozenset({'log', 'false'})",Small value to avoid evaluation of  log(0)  when `log_input`=``False``.,torch.nn.functional.poisson_nll_loss.yaml,2
780,182,0.0023912003825920613,3,"frozenset({'log', 'false'})",Default: `False` target *  log(target) - target + 0.5 *  log(2 *  pi * target) .,torch.nn.functional.poisson_nll_loss.yaml,2
781,182,0.0023912003825920613,3,"frozenset({'log', 'false'})","if `True` the loss is computed as  exp(input) - target * input , if `False` then loss is input - target *  log(input+eps) .",torch.nn.functional.poisson_nll_loss.yaml,2
782,184,0.0023912003825920613,3,"frozenset({'SOME_DTYPE', 'corresponding'})","dimension corresponding to number of outputs, the default is `0`, except for modules that are instances of ConvTranspose{1,2,3}d, when it is `1`",torch.nn.utils.spectral_norm.yaml,2
783,184,0.0023912003825920613,3,"frozenset({'SOME_DTYPE', 'corresponding'})",the corresponding kwargs for callable model.,torch.hub.load.yaml,2
784,184,0.0023912003825920613,3,"frozenset({'SOME_DTYPE', 'corresponding'})",the corresponding args for callable model.,torch.hub.load.yaml,2
785,185,0.0023912003825920613,5,"frozenset({'number', 'classes'})","(N, C)  where C = number of classes or (N, C, H, W)  in case of 2D Loss, or (N, C, d_1, d_2, ..., d_K)  where K  >= 1  in the case of K-dimensional loss.",torch.nn.functional.nll_loss.yaml,2
786,185,0.0023912003825920613,5,"frozenset({'number', 'classes'})",Total number of classes.,torch.nn.functional.one_hot.yaml,2
787,185,0.0023912003825920613,5,"frozenset({'number', 'classes'})","If set to -1, the number of classes will be inferred as one greater than the largest class value in the input tensor.",torch.nn.functional.one_hot.yaml,2
788,185,0.0023912003825920613,5,"frozenset({'number', 'classes'})","(N, C)  where C = number of classes or (N, C, H, W)  in case of 2D Loss, or (N, C, d_1, d_2, ..., d_K)  where K  >= 1  in the case of K-dimensional loss.",torch.nn.functional.cross_entropy.yaml,2
789,185,0.0023912003825920613,5,"frozenset({'number', 'classes'})",Must be a vector with length equal to the number of classes.,torch.nn.functional.binary_cross_entropy_with_logits.yaml,2
790,508,0.0023912003825920613,4,"frozenset({'whether', 'return', 'default'})",whether to return an abbreviated summary (default: False).,torch.cuda.memory_summary.yaml,3
791,508,0.0023912003825920613,4,"frozenset({'whether', 'return', 'default'})",controls whether to return the normalized STFT results Default: `False`,torch.stft.yaml,3
792,508,0.0023912003825920613,4,"frozenset({'whether', 'return', 'default'})",controls whether to return half of results to avoid redundancy Default: `True`,torch.stft.yaml,3
793,508,0.0023912003825920613,4,"frozenset({'whether', 'return', 'default'})",whether to return a lower (default) or upper triangular matrix,torch.cholesky_inverse.yaml,3
794,187,0.0023912003825920613,5,"frozenset({'prune', 'parameters', 'quantity'})",quantity of parameters to prune.,torch.nn.utils.prune.l1_unstructured.yaml,3
795,187,0.0023912003825920613,5,"frozenset({'prune', 'parameters', 'quantity'})",quantity of parameters to prune.,torch.nn.utils.prune.random_unstructured.yaml,3
796,187,0.0023912003825920613,5,"frozenset({'prune', 'parameters', 'quantity'})",quantity of parameters to prune.,torch.nn.utils.prune.ln_structured.yaml,3
797,187,0.0023912003825920613,5,"frozenset({'prune', 'parameters', 'quantity'})",other keyword arguments such as: amount (int or float): quantity of parameters to prune across the specified parameters.,torch.nn.utils.prune.global_unstructured.yaml,3
798,187,0.0023912003825920613,5,"frozenset({'prune', 'parameters', 'quantity'})",quantity of parameters to prune.,torch.nn.utils.prune.random_structured.yaml,3
799,406,0.0023912003825920613,5,"frozenset({'single', 'size', 'output', 'SOME_DTYPE', 'target', 'SOME_STRUCTURE'})",the target output size (single integer or triple-integer tuple),torch.nn.functional.adaptive_max_pool3d.yaml,6
800,406,0.0023912003825920613,5,"frozenset({'single', 'size', 'output', 'SOME_DTYPE', 'target', 'SOME_STRUCTURE'})",the target output size (single integer or triple-integer tuple),torch.nn.functional.adaptive_avg_pool3d.yaml,6
801,406,0.0023912003825920613,5,"frozenset({'single', 'size', 'output', 'SOME_DTYPE', 'target', 'SOME_STRUCTURE'})",the target output size (single integer or double-integer tuple),torch.nn.quantized.functional.adaptive_avg_pool2d.yaml,6
802,406,0.0023912003825920613,5,"frozenset({'single', 'size', 'output', 'SOME_DTYPE', 'target', 'SOME_STRUCTURE'})",the target output size (single integer or double-integer tuple),torch.nn.functional.adaptive_max_pool2d.yaml,6
803,406,0.0023912003825920613,5,"frozenset({'single', 'size', 'output', 'SOME_DTYPE', 'target', 'SOME_STRUCTURE'})",the target output size (single integer or double-integer tuple),torch.nn.functional.adaptive_avg_pool2d.yaml,6
804,388,0.0023912003825920613,4,"frozenset({'match', 'input', 'size'})","float 1D tensor of scales to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,3
805,388,0.0023912003825920613,4,"frozenset({'match', 'input', 'size'})","integer 1D tensor of offset to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,3
806,388,0.0023912003825920613,4,"frozenset({'match', 'input', 'size'})",Has to match input size if it is a tuple.,torch.nn.quantized.functional.interpolate.yaml,3
807,388,0.0023912003825920613,4,"frozenset({'match', 'input', 'size'})",Has to match input size if it is a tuple.,torch.nn.functional.interpolate.yaml,3
808,197,0.0023912003825920613,3,"frozenset({'function', 'operates', 'place'})",The function operates in-place.,torch.distributed.all_reduce.yaml,3
809,197,0.0023912003825920613,3,"frozenset({'function', 'operates', 'place'})",The function operates in-place.,torch.distributed.reduce.yaml,3
810,197,0.0023912003825920613,3,"frozenset({'function', 'operates', 'place'})",The function operates in-place.,torch.distributed.reduce_multigpu.yaml,3
811,300,0.0023912003825920613,5,"frozenset({'torch', 'nn'})",The logarithmized probabilities of the outputs (e.g. obtained with `torch.nn.functional.log_softmax()`).,torch.nn.functional.ctc_loss.yaml,2
812,300,0.0023912003825920613,5,"frozenset({'torch', 'nn'})",See Notes under `torch.nn.Embedding` for more details regarding sparse gradients.,torch.nn.functional.embedding.yaml,2
813,300,0.0023912003825920613,5,"frozenset({'torch', 'nn'})",A Python function or `torch.nn.Module` that will be run with `example_inputs`.,torch.jit.trace.yaml,2
814,300,0.0023912003825920613,5,"frozenset({'torch', 'nn'})",A `torch.nn.Sequential` or the list of modules or functions (comprising the model) to run sequentially.,torch.utils.checkpoint.checkpoint_sequential.yaml,2
815,300,0.0023912003825920613,5,"frozenset({'torch', 'nn'})","For example, fuser_func([convModule, BNModule]) returns the list [ConvBNModule, nn.Identity()] Defaults to torch.quantization.fuse_known_modules",torch.quantization.fuse_modules.yaml,2
816,208,0.0023912003825920613,5,"frozenset({'reduce', 'args', 'meantime', 'size_average', 'note', 'override', 'process', 'two', 'deprecated', 'reduction', 'specifying', 'either'})","Note: `size_average` and `reduce` are in the process of being deprecated, and in the meantime, specifying either of those two args will override `reduction`.",torch.nn.functional.binary_cross_entropy.yaml,12
817,208,0.0023912003825920613,5,"frozenset({'reduce', 'args', 'meantime', 'size_average', 'note', 'override', 'process', 'two', 'deprecated', 'reduction', 'specifying', 'either'})","Note: `size_average` and `reduce` are in the process of being deprecated, and in the meantime, specifying either of those two args will override `reduction`.",torch.nn.functional.nll_loss.yaml,12
818,208,0.0023912003825920613,5,"frozenset({'reduce', 'args', 'meantime', 'size_average', 'note', 'override', 'process', 'two', 'deprecated', 'reduction', 'specifying', 'either'})","Note: `size_average` and `reduce` are in the process of being deprecated, and in the meantime, specifying either of those two args will override `reduction`.",torch.nn.functional.cross_entropy.yaml,12
819,208,0.0023912003825920613,5,"frozenset({'reduce', 'args', 'meantime', 'size_average', 'note', 'override', 'process', 'two', 'deprecated', 'reduction', 'specifying', 'either'})","Note: `size_average` and `reduce` are in the process of being deprecated, and in the meantime, specifying either of those two args will override `reduction`.",torch.nn.functional.binary_cross_entropy_with_logits.yaml,12
820,208,0.0023912003825920613,5,"frozenset({'reduce', 'args', 'meantime', 'size_average', 'note', 'override', 'process', 'two', 'deprecated', 'reduction', 'specifying', 'either'})","Note: `size_average` and `reduce` are in the process of being deprecated, and in the meantime, specifying either of those two args will override `reduction`.",torch.nn.functional.poisson_nll_loss.yaml,12
821,193,0.0023912003825920613,3,"frozenset({'upper', 'bound'})",upper-bound of the range to be clamped to,torch.clamp.yaml,2
822,193,0.0023912003825920613,3,"frozenset({'upper', 'bound'})",the upper bound (exclusive),torch.randperm.yaml,2
823,193,0.0023912003825920613,3,"frozenset({'upper', 'bound'})",the upper bound of the uniform distribution,torch.nn.init.uniform_.yaml,2
824,194,0.0023912003825920613,3,"frozenset({'ops', 'exported'})","If using aten mode, all the ops original exported by the functions in symbolic_opset<version>.py are exported as ATen ops.",torch.onnx.export.yaml,2
825,194,0.0023912003825920613,3,"frozenset({'ops', 'exported'})",OperatorExportTypes.ONNX: all ops are exported as regular ONNX ops.,torch.onnx.export.yaml,2
826,194,0.0023912003825920613,3,"frozenset({'ops', 'exported'})",OperatorExportTypes.ONNX_ATEN: all ops are exported as ATen ops.,torch.onnx.export.yaml,2
827,440,0.0023912003825920613,5,"frozenset({'compute', 'tensor'})",the tensor to compute OR with,torch.logical_or.yaml,2
828,440,0.0023912003825920613,5,"frozenset({'compute', 'tensor'})",the tensor to compute AND with,torch.logical_and.yaml,2
829,440,0.0023912003825920613,5,"frozenset({'compute', 'tensor'})",the tensor to compute the multivariate log-gamma function,torch.mvlgamma.yaml,2
830,440,0.0023912003825920613,5,"frozenset({'compute', 'tensor'})",the tensor to compute XOR with,torch.logical_xor.yaml,2
831,440,0.0023912003825920613,5,"frozenset({'compute', 'tensor'})",the tensor to compute the digamma function on,torch.digamma.yaml,2
832,456,0.0023912003825920613,5,"frozenset({'input', 'defaults', 'none', 'default', 'dtype'})","Default: if `None`, defaults to the dtype of `input`.",torch.ones_like.yaml,5
833,456,0.0023912003825920613,5,"frozenset({'input', 'defaults', 'none', 'default', 'dtype'})","Default: if `None`, defaults to the dtype of `input`.",torch.empty_like.yaml,5
834,456,0.0023912003825920613,5,"frozenset({'input', 'defaults', 'none', 'default', 'dtype'})","Default: if `None`, defaults to the dtype of `input`.",torch.zeros_like.yaml,5
835,456,0.0023912003825920613,5,"frozenset({'input', 'defaults', 'none', 'default', 'dtype'})","Default: if `None`, defaults to the dtype of `input`.",torch.randn_like.yaml,5
836,456,0.0023912003825920613,5,"frozenset({'input', 'defaults', 'none', 'default', 'dtype'})","Default: if `None`, defaults to the dtype of `input`.",torch.rand_like.yaml,5
837,523,0.0023912003825920613,3,"frozenset({'input', 'n', 'shape'})","input of shape (N, C, H_in, W_in)  (4-D case) or (N, C, D_in, H_in, W_in)  (5-D case)",torch.nn.functional.grid_sample.yaml,3
838,523,0.0023912003825920613,3,"frozenset({'input', 'n', 'shape'})",input tensor of shape N  times M .,torch.nn.functional.pdist.yaml,3
839,523,0.0023912003825920613,3,"frozenset({'input', 'n', 'shape'})",input batch of affine matrices with shape (N  times 2  times 3 ) for 2D or (N  times 3  times 4 ) for 3D,torch.nn.functional.affine_grid.yaml,3
840,537,0.0023912003825920613,5,"frozenset({'true', 'SOME_DTYPE'})","If True, the constant-folding optimization is applied to the model during export.",torch.onnx.export.yaml,2
841,537,0.0023912003825920613,5,"frozenset({'true', 'SOME_DTYPE'})","if True, strips the field ""doc_string"" from the exported model, which information about the stack trace.",torch.onnx.export.yaml,2
842,537,0.0023912003825920613,5,"frozenset({'true', 'SOME_DTYPE'})"," At the moment, ONNX is oriented towards exporting models for inference only, so you will generally not need to set this to True.",torch.onnx.export.yaml,2
843,537,0.0023912003825920613,5,"frozenset({'true', 'SOME_DTYPE'})",controls whether to return half of results to avoid redundancy Default: `True`,torch.stft.yaml,2
844,537,0.0023912003825920613,5,"frozenset({'true', 'SOME_DTYPE'})","If `True` (default), imports the produced shared library as a Python module.",torch.utils.cpp_extension.load.yaml,2
845,198,0.0023912003825920613,4,"frozenset({'diagonal', 'take', 'dimension', 'respect'})",first dimension with respect to which to take diagonal.,torch.diag_embed.yaml,4
846,198,0.0023912003825920613,4,"frozenset({'diagonal', 'take', 'dimension', 'respect'})",second dimension with respect to which to take diagonal.,torch.diag_embed.yaml,4
847,198,0.0023912003825920613,4,"frozenset({'diagonal', 'take', 'dimension', 'respect'})",first dimension with respect to which to take diagonal.,torch.diagonal.yaml,4
848,198,0.0023912003825920613,4,"frozenset({'diagonal', 'take', 'dimension', 'respect'})",second dimension with respect to which to take diagonal.,torch.diagonal.yaml,4
849,381,0.0023912003825920613,5,"frozenset({'true', 'otherwise'})","output will be in `B x T x *` if True, or in `T x B x *` otherwise",torch.nn.utils.rnn.pad_sequence.yaml,2
850,381,0.0023912003825920613,5,"frozenset({'true', 'otherwise'})","`True` to compute both eigenvalues and eigenvectors; otherwise, only eigenvalues will be computed",torch.eig.yaml,2
851,381,0.0023912003825920613,5,"frozenset({'true', 'otherwise'})","When True (nonzero), yield x, otherwise yield y",torch.where.yaml,2
852,381,0.0023912003825920613,5,"frozenset({'true', 'otherwise'})","The dimensions of Q and R are (*, m, k)  and (*, k, n)  respectively, where k =  min(m, n)  if `some:` is `True` and k = m  otherwise.",torch.qr.yaml,2
853,381,0.0023912003825920613,5,"frozenset({'true', 'otherwise'})","if True, center the input tensor, otherwise, assume that the input is centered.",torch.pca_lowrank.yaml,2
854,533,0.0023912003825920613,5,"frozenset({'input', 'whether'})","controls whether `input` was halfed to avoid redundancy, e.g., by `rfft()`.",torch.irfft.yaml,2
855,533,0.0023912003825920613,5,"frozenset({'input', 'whether'})",whether to pad `input` on both sides so that the t -th frame is centered at time t  times hop _length .,torch.stft.yaml,2
856,533,0.0023912003825920613,5,"frozenset({'input', 'whether'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique.yaml,2
857,533,0.0023912003825920613,5,"frozenset({'input', 'whether'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique_consecutive.yaml,2
858,533,0.0023912003825920613,5,"frozenset({'input', 'whether'})",indicates whether `input` is symmetric.,torch.matrix_rank.yaml,2
859,443,0.0023912003825920613,4,"frozenset({'per', 'tensor', 'element'})",the tensor of per-element means,torch.normal.yaml,3
860,443,0.0023912003825920613,4,"frozenset({'per', 'tensor', 'element'})",the tensor of per-element standard deviations,torch.normal.yaml,3
861,443,0.0023912003825920613,4,"frozenset({'per', 'tensor', 'element'})",the tensor of per-element means,torch.normal22.yaml,3
862,443,0.0023912003825920613,4,"frozenset({'per', 'tensor', 'element'})",the tensor of per-element standard deviations,torch.normal2.yaml,3
863,469,0.001912960306073649,4,"frozenset({'dimension', 'second'})",second dimension with respect to which to take diagonal.,torch.diag_embed.yaml,2
864,469,0.001912960306073649,4,"frozenset({'dimension', 'second'})","The indices are the coordinates of the non-zero values in the matrix, and thus should be two-dimensional where the first dimension is the number of tensor dimensions and the second dimension is the number of non-zero values.",torch.sparse_coo_tensor.yaml,2
865,469,0.001912960306073649,4,"frozenset({'dimension', 'second'})",the second dimension to be transposed,torch.transpose.yaml,2
866,469,0.001912960306073649,4,"frozenset({'dimension', 'second'})",second dimension with respect to which to take diagonal.,torch.diagonal.yaml,2
867,316,0.001912960306073649,4,"frozenset({'broadcast', 'SOME_DTYPE'})",an iterable of devices among which to broadcast.,torch.cuda.comm.broadcast_coalesced.yaml,2
868,316,0.001912960306073649,4,"frozenset({'broadcast', 'SOME_DTYPE'})","Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.",torch.cuda.comm.broadcast_coalesced.yaml,2
869,316,0.001912960306073649,4,"frozenset({'broadcast', 'SOME_DTYPE'})",an iterable of devices among which to broadcast.,torch.cuda.comm.broadcast.yaml,2
870,316,0.001912960306073649,4,"frozenset({'broadcast', 'SOME_DTYPE'})","Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.",torch.cuda.comm.broadcast.yaml,2
871,459,0.001912960306073649,4,"frozenset({'input', 'vector'})","If the value is None, matrix norm will be calculated when the input tensor only has two dimensions, vector norm will be calculated when the input tensor only has one dimension.",torch.norm.yaml,2
872,459,0.001912960306073649,4,"frozenset({'input', 'vector'})","If the input tensor has more than two dimensions, the vector norm will be applied to last dimension.",torch.norm.yaml,2
873,459,0.001912960306073649,4,"frozenset({'input', 'vector'})",1-D input vector,torch.ger.yaml,2
874,459,0.001912960306073649,4,"frozenset({'input', 'vector'})",1-D input vector,torch.ger.yaml,2
875,318,0.001912960306073649,4,"frozenset({'shape', '_channels', 'tensor', 'bias'})",optional bias tensor of shape (out _channels) .,torch.nn.functional.conv2d.yaml,4
876,318,0.001912960306073649,4,"frozenset({'shape', '_channels', 'tensor', 'bias'})",optional bias tensor of shape (out _channels) .,torch.nn.functional.conv3d.yaml,4
877,318,0.001912960306073649,4,"frozenset({'shape', '_channels', 'tensor', 'bias'})",non-quantized bias tensor of shape (out _channels) .,torch.nn.quantized.functional.conv2d.yaml,4
878,318,0.001912960306073649,4,"frozenset({'shape', '_channels', 'tensor', 'bias'})",non-quantized bias tensor of shape (out _channels) .,torch.nn.quantized.functional.conv3d.yaml,4
879,466,0.001912960306073649,4,"frozenset({'operation', 'dimension'})",the dimension to do the operation over,torch.cummax.yaml,2
880,466,0.001912960306073649,4,"frozenset({'operation', 'dimension'})",the dimension to do the operation over,torch.cummin.yaml,2
881,466,0.001912960306073649,4,"frozenset({'operation', 'dimension'})",the dimension to do the operation over,torch.cumprod.yaml,2
882,466,0.001912960306073649,4,"frozenset({'operation', 'dimension'})",the dimension to do the operation over,torch.cumsum.yaml,2
883,460,0.001912960306073649,4,"frozenset({'multiplied', 'tensor'})",the tensor to be multiplied,torch.addcmul.yaml,2
884,460,0.001912960306073649,4,"frozenset({'multiplied', 'tensor'})",the tensor to be multiplied,torch.addcmul.yaml,2
885,460,0.001912960306073649,4,"frozenset({'multiplied', 'tensor'})",the first tensor to be multiplied,torch.matmul.yaml,2
886,460,0.001912960306073649,4,"frozenset({'multiplied', 'tensor'})",the second tensor to be multiplied,torch.matmul.yaml,2
887,313,0.001912960306073649,4,"frozenset({'results', 'default'})","When running identical inputs through the differentiation, the results must either match exactly (default, 0.0) or be within this tolerance.",torch.autograd.gradgradcheck.yaml,2
888,313,0.001912960306073649,4,"frozenset({'results', 'default'})",controls whether to return the normalized STFT results Default: `False`,torch.stft.yaml,2
889,313,0.001912960306073649,4,"frozenset({'results', 'default'})",controls whether to return half of results to avoid redundancy Default: `True`,torch.stft.yaml,2
890,313,0.001912960306073649,4,"frozenset({'results', 'default'})","When running identical inputs through the differentiation, the results must either match exactly (default, 0.0) or be within this tolerance.",torch.autograd.gradcheck.yaml,2
891,366,0.001912960306073649,4,"frozenset({'size', 'c'})","(T, N, C)  where C = number of characters in alphabet including blank, T = input length, and N = batch size.",torch.nn.functional.ctc_loss.yaml,2
892,366,0.001912960306073649,4,"frozenset({'size', 'c'})","(N  times C  times H  times W  for 2D or N  times C  times D  times H  times W  for 3D) Example: torch.Size((32, 3, 24, 24))",torch.nn.functional.affine_grid.yaml,2
893,366,0.001912960306073649,4,"frozenset({'size', 'c'})","If given, has to be a Tensor of size C",torch.nn.functional.nll_loss.yaml,2
894,366,0.001912960306073649,4,"frozenset({'size', 'c'})","If given, has to be a Tensor of size C",torch.nn.functional.cross_entropy.yaml,2
895,475,0.001912960306073649,4,"frozenset({'dimension', 'first'})",first dimension with respect to which to take diagonal.,torch.diag_embed.yaml,2
896,475,0.001912960306073649,4,"frozenset({'dimension', 'first'})","The indices are the coordinates of the non-zero values in the matrix, and thus should be two-dimensional where the first dimension is the number of tensor dimensions and the second dimension is the number of non-zero values.",torch.sparse_coo_tensor.yaml,2
897,475,0.001912960306073649,4,"frozenset({'dimension', 'first'})",the first dimension to be transposed,torch.transpose.yaml,2
898,475,0.001912960306073649,4,"frozenset({'dimension', 'first'})",first dimension with respect to which to take diagonal.,torch.diagonal.yaml,2
899,485,0.001912960306073649,4,"frozenset({'output', 'optional'})",This argument is optional when `func`'s output contains a single element and (if it is not provided) will be set as a Tensor containing a single `1`.,torch.autograd.functional.vjp.yaml,2
900,485,0.001912960306073649,4,"frozenset({'output', 'optional'})",optional output tuple.,torch.lu.yaml,2
901,485,0.001912960306073649,4,"frozenset({'output', 'optional'})",optional output tuple.,torch.solve.yaml,2
902,485,0.001912960306073649,4,"frozenset({'output', 'optional'})",optional output matrix,torch.ger.yaml,2
903,496,0.001912960306073649,4,"frozenset({'specified', 'must'})","If another specific group is specified, the calling process must be part of `group`.",torch.distributed.get_backend.yaml,2
904,496,0.001912960306073649,4,"frozenset({'specified', 'must'})","List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)",torch.distributed.gather.yaml,2
905,496,0.001912960306073649,4,"frozenset({'specified', 'must'})","If X  is specifed, the value of n (when specified) must be the number of X  columns.",torch.lobpcg.yaml,2
906,496,0.001912960306073649,4,"frozenset({'specified', 'must'})","List of tensors to scatter (default is None, must be specified on the source rank)",torch.distributed.scatter.yaml,2
907,497,0.001912960306073649,4,"frozenset({'default', 'must'})","When running identical inputs through the differentiation, the results must either match exactly (default, 0.0) or be within this tolerance.",torch.autograd.gradgradcheck.yaml,2
908,497,0.001912960306073649,4,"frozenset({'default', 'must'})","List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)",torch.distributed.gather.yaml,2
909,497,0.001912960306073649,4,"frozenset({'default', 'must'})","When running identical inputs through the differentiation, the results must either match exactly (default, 0.0) or be within this tolerance.",torch.autograd.gradcheck.yaml,2
910,497,0.001912960306073649,4,"frozenset({'default', 'must'})","List of tensors to scatter (default is None, must be specified on the source rank)",torch.distributed.scatter.yaml,2
911,506,0.001912960306073649,4,"frozenset({'elements', 'whether', 'return'})",controls whether to return largest or smallest elements,torch.topk.yaml,3
912,506,0.001912960306073649,4,"frozenset({'elements', 'whether', 'return'})",controls whether to return the elements in sorted order,torch.topk.yaml,3
913,506,0.001912960306073649,4,"frozenset({'elements', 'whether', 'return'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique.yaml,3
914,506,0.001912960306073649,4,"frozenset({'elements', 'whether', 'return'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique_consecutive.yaml,3
915,453,0.001912960306073649,4,"frozenset({'returned', 'desired', 'window', 'tensor', 'SOME_DTYPE'})",the desired layout of returned window tensor.,torch.hann_window.yaml,5
916,453,0.001912960306073649,4,"frozenset({'returned', 'desired', 'window', 'tensor', 'SOME_DTYPE'})",the desired layout of returned window tensor.,torch.hamming_window.yaml,5
917,453,0.001912960306073649,4,"frozenset({'returned', 'desired', 'window', 'tensor', 'SOME_DTYPE'})",the desired layout of returned window tensor.,torch.blackman_window.yaml,5
918,453,0.001912960306073649,4,"frozenset({'returned', 'desired', 'window', 'tensor', 'SOME_DTYPE'})",the desired layout of returned window tensor.,torch.bartlett_window.yaml,5
919,307,0.001912960306073649,4,"frozenset({'destination', 'tensor'})","List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)",torch.distributed.gather.yaml,2
920,307,0.001912960306073649,4,"frozenset({'destination', 'tensor'})",the optional destination tensor,torch.lstsq.yaml,2
921,307,0.001912960306073649,4,"frozenset({'destination', 'tensor'})",Destination tensor rank within `tensor_list`,torch.distributed.reduce_multigpu.yaml,2
922,307,0.001912960306073649,4,"frozenset({'destination', 'tensor'})",the destination tensor,torch.gather.yaml,2
923,509,0.001912960306073649,3,"frozenset({'current', 'process', 'tensor'})",Tensor to be broadcast from current process.,torch.distributed.all_gather.yaml,3
924,509,0.001912960306073649,3,"frozenset({'current', 'process', 'tensor'})",List of tensors(on different GPUs) to be broadcast from current process.,torch.distributed.all_gather_multigpu.yaml,3
925,509,0.001912960306073649,3,"frozenset({'current', 'process', 'tensor'})","Data to be sent if `src` is the rank of current process, and tensor to be used to save received data otherwise.",torch.distributed.broadcast.yaml,3
926,515,0.001912960306073649,4,"frozenset({'none', 'specified', 'tensor'})","List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)",torch.distributed.gather.yaml,3
927,515,0.001912960306073649,4,"frozenset({'none', 'specified', 'tensor'})",None values can be specified for scalar Tensors or ones that don't require grad.,torch.autograd.backward.yaml,3
928,515,0.001912960306073649,4,"frozenset({'none', 'specified', 'tensor'})",None values can be specified for scalar Tensors or ones that don't require grad.,torch.autograd.grad.yaml,3
929,515,0.001912960306073649,4,"frozenset({'none', 'specified', 'tensor'})","List of tensors to scatter (default is None, must be specified on the source rank)",torch.distributed.scatter.yaml,3
930,517,0.001912960306073649,4,"frozenset({'set', 'SOME_DTYPE'})", Set this to False if you want to export an untrained model.,torch.onnx.export.yaml,2
931,517,0.001912960306073649,4,"frozenset({'set', 'SOME_DTYPE'})"," At the moment, ONNX is oriented towards exporting models for inference only, so you will generally not need to set this to True.",torch.onnx.export.yaml,2
932,517,0.001912960306073649,4,"frozenset({'set', 'SOME_DTYPE'})",A simplified version of `map_location` in `torch.save` used to dynamically remap storages to an alternative set of devices.,torch.jit.load.yaml,2
933,517,0.001912960306073649,4,"frozenset({'set', 'SOME_DTYPE'})",The device to set the RNG state.,torch.cuda.set_rng_state.yaml,2
934,521,0.001912960306073649,4,"frozenset({'inputs', 'SOME_DTYPE'})",Default: `False` Infinite losses mainly occur when the inputs are too short to be aligned to the targets.,torch.nn.functional.ctc_loss.yaml,2
935,521,0.001912960306073649,4,"frozenset({'inputs', 'SOME_DTYPE'})",inputs to the module,torch.nn.parallel.data_parallel.yaml,2
936,521,0.001912960306073649,4,"frozenset({'inputs', 'SOME_DTYPE'})","the inputs to the model, e.g., such that `model(*args)` is a valid invocation of the model.",torch.onnx.export.yaml,2
937,521,0.001912960306073649,4,"frozenset({'inputs', 'SOME_DTYPE'})"," Any non-Tensor arguments will be hard-coded into the exported model; any Tensor arguments will become inputs of the exported model, in the order they occur in args.",torch.onnx.export.yaml,2
938,536,0.001912960306073649,4,"frozenset({'true', 'false'})",Enable (True) or disable (False) scientific notation.,torch.set_printoptions.yaml,2
939,536,0.001912960306073649,4,"frozenset({'true', 'false'})",Set to `True` for reduced QR decomposition and `False` for complete QR decomposition.,torch.qr.yaml,2
940,536,0.001912960306073649,4,"frozenset({'true', 'false'})","if `True` the loss is computed as  exp(input) - target * input , if `False` then loss is input - target *  log(input+eps) .",torch.nn.functional.poisson_nll_loss.yaml,2
941,536,0.001912960306073649,4,"frozenset({'true', 'false'})","Flag whether to enable grad (`True`), or disable (`False`).",torch.set_grad_enabled.yaml,2
942,324,0.001912960306073649,4,"frozenset({'rng', 'SOME_DTYPE'})",CUDA devices for which to fork the RNG.,torch.random.fork_rng.yaml,2
943,324,0.001912960306073649,4,"frozenset({'rng', 'SOME_DTYPE'})",CUDA devices for which to fork the RNG.,torch.random.fork_rng2.yaml,2
944,324,0.001912960306073649,4,"frozenset({'rng', 'SOME_DTYPE'})",The device to return the RNG state of.,torch.cuda.get_rng_state.yaml,2
945,324,0.001912960306073649,4,"frozenset({'rng', 'SOME_DTYPE'})",The device to set the RNG state.,torch.cuda.set_rng_state.yaml,2
946,413,0.001912960306073649,4,"frozenset({'matrix', 'added'})",matrix to be added,torch.addr.yaml,2
947,413,0.001912960306073649,4,"frozenset({'matrix', 'added'})",matrix to be added,torch.addbmm.yaml,2
948,413,0.001912960306073649,4,"frozenset({'matrix', 'added'})",matrix to be added,torch.addmm.yaml,2
949,413,0.001912960306073649,4,"frozenset({'matrix', 'added'})",a dense matrix to be added,torch.sparse.addmm.yaml,2
950,449,0.001912960306073649,4,"frozenset({'number', 'matrix', 'd'})",number of columns in the 2-D matrix.,torch.triu_indices.yaml,3
951,449,0.001912960306073649,4,"frozenset({'number', 'matrix', 'd'})",number of rows in the 2-D matrix.,torch.triu_indices.yaml,3
952,449,0.001912960306073649,4,"frozenset({'number', 'matrix', 'd'})",number of columns in the 2-D matrix.,torch.tril_indices.yaml,3
953,449,0.001912960306073649,4,"frozenset({'number', 'matrix', 'd'})",number of rows in the 2-D matrix.,torch.tril_indices.yaml,3
954,448,0.001912960306073649,3,"frozenset({'d', 'SOME_DTYPE', 'tensor'})","float 1D tensor of scales to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,3
955,448,0.001912960306073649,3,"frozenset({'d', 'SOME_DTYPE', 'tensor'})","integer 1D tensor of offset to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,3
956,448,0.001912960306073649,3,"frozenset({'d', 'SOME_DTYPE', 'tensor'})",1-d int tensor,torch.bincount.yaml,3
957,374,0.001912960306073649,4,"frozenset({'source', 'SOME_DTYPE'})","A string, or list of strings, containing C++ source code.",torch.utils.cpp_extension.load_inline.yaml,2
958,374,0.001912960306073649,4,"frozenset({'source', 'SOME_DTYPE'})","A string, or list of strings, containing CUDA source code.",torch.utils.cpp_extension.load_inline.yaml,2
959,374,0.001912960306073649,4,"frozenset({'source', 'SOME_DTYPE'})","Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.",torch.cuda.comm.broadcast_coalesced.yaml,2
960,374,0.001912960306073649,4,"frozenset({'source', 'SOME_DTYPE'})","Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.",torch.cuda.comm.broadcast.yaml,2
961,375,0.001912960306073649,4,"frozenset({'source', 'SOME_STRUCTURE'})","A string, or list of strings, containing C++ source code.",torch.utils.cpp_extension.load_inline.yaml,2
962,375,0.001912960306073649,4,"frozenset({'source', 'SOME_STRUCTURE'})","A string, or list of strings, containing CUDA source code.",torch.utils.cpp_extension.load_inline.yaml,2
963,375,0.001912960306073649,4,"frozenset({'source', 'SOME_STRUCTURE'})",A list of relative or absolute paths to C++ source files.,torch.utils.cpp_extension.load.yaml,2
964,375,0.001912960306073649,4,"frozenset({'source', 'SOME_STRUCTURE'})","List of tensors to scatter (default is None, must be specified on the source rank)",torch.distributed.scatter.yaml,2
965,380,0.001912960306073649,4,"frozenset({'true', 'order'})","if `True`, the input is expected to contain sequences sorted by length in a decreasing order.",torch.nn.utils.rnn.pack_padded_sequence.yaml,2
966,380,0.001912960306073649,4,"frozenset({'true', 'order'})","if `True`, checks that the input contains sequences sorted by length in a decreasing order.",torch.nn.utils.rnn.pack_sequence.yaml,2
967,380,0.001912960306073649,4,"frozenset({'true', 'order'})","If `True`, graph of the derivative will be constructed, allowing to compute higher order derivative products.",torch.autograd.backward.yaml,2
968,380,0.001912960306073649,4,"frozenset({'true', 'order'})","If `True`, graph of the derivative will be constructed, allowing to compute higher order derivative products.",torch.autograd.grad.yaml,2
969,383,0.001912960306073649,4,"frozenset({'arguments', 'SOME_DTYPE'})",other keyword arguments such as: amount (int or float): quantity of parameters to prune across the specified parameters.,torch.nn.utils.prune.global_unstructured.yaml,2
970,383,0.001912960306073649,4,"frozenset({'arguments', 'SOME_DTYPE'})"," Any non-Tensor arguments will be hard-coded into the exported model; any Tensor arguments will become inputs of the exported model, in the order they occur in args.",torch.onnx.export.yaml,2
971,383,0.001912960306073649,4,"frozenset({'arguments', 'SOME_DTYPE'})",(Note: passing keyword arguments to the model is not currently supported.,torch.onnx.export.yaml,2
972,383,0.001912960306073649,4,"frozenset({'arguments', 'SOME_DTYPE'})","In this case, the exported model will first take all of its parameters as arguments, the ordering as specified by `model.state_dict().values()`",torch.onnx.export.yaml,2
973,352,0.001912960306073649,4,"frozenset({'supported', 'point', 'types', 'floating'})",Only floating point types are supported.,torch.hann_window.yaml,4
974,352,0.001912960306073649,4,"frozenset({'supported', 'point', 'types', 'floating'})",Only floating point types are supported.,torch.hamming_window.yaml,4
975,352,0.001912960306073649,4,"frozenset({'supported', 'point', 'types', 'floating'})",Only floating point types are supported.,torch.blackman_window.yaml,4
976,352,0.001912960306073649,4,"frozenset({'supported', 'point', 'types', 'floating'})",Only floating point types are supported.,torch.bartlett_window.yaml,4
977,386,0.001912960306073649,3,"frozenset({'match', 'SOME_DTYPE', 'tensor', 'size'})","float 1D tensor of scales to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,4
978,386,0.001912960306073649,3,"frozenset({'match', 'SOME_DTYPE', 'tensor', 'size'})","integer 1D tensor of offset to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,4
979,386,0.001912960306073649,3,"frozenset({'match', 'SOME_DTYPE', 'tensor', 'size'})",It should match `devices` in length and sum to `tensor.size(dim)`.,torch.cuda.comm.scatter.yaml,4
980,387,0.001912960306073649,4,"frozenset({'match', 'input', 'tensor'})","float 1D tensor of scales to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,3
981,387,0.001912960306073649,4,"frozenset({'match', 'input', 'tensor'})","integer 1D tensor of offset to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,3
982,387,0.001912960306073649,4,"frozenset({'match', 'input', 'tensor'})",a manual rescaling weight if provided it's repeated to match input tensor shape,torch.nn.functional.binary_cross_entropy.yaml,3
983,387,0.001912960306073649,4,"frozenset({'match', 'input', 'tensor'})",a manual rescaling weight if provided it's repeated to match input tensor shape,torch.nn.functional.binary_cross_entropy_with_logits.yaml,3
984,351,0.001912960306073649,4,"frozenset({'point', 'floating', 'default'})","If any of start, end, or stop are floating-point, the dtype is inferred to be the default dtype, see `get_default_dtype()`.",torch.arange.yaml,3
985,351,0.001912960306073649,4,"frozenset({'point', 'floating', 'default'})",the floating point dtype to make the default,torch.set_default_dtype.yaml,3
986,351,0.001912960306073649,4,"frozenset({'point', 'floating', 'default'})",Default is feps ** 0.5 where feps is smallest non-zero floating-point number of the given input tensor A data type.,torch.lobpcg.yaml,3
987,351,0.001912960306073649,4,"frozenset({'point', 'floating', 'default'})",Number of digits of precision for floating point output (default = 4).,torch.set_printoptions.yaml,3
988,349,0.001912960306073649,4,"frozenset({'matrix', 'b'})","When not specified, B is interpereted as identity matrix.",torch.lobpcg.yaml,2
989,349,0.001912960306073649,4,"frozenset({'matrix', 'b'})","input matrix b  of size (*, m, k) , where *  is zero or more batch dimensions",torch.cholesky_solve.yaml,2
990,349,0.001912960306073649,4,"frozenset({'matrix', 'b'})","input matrix B  of size (*, m, k)  , where *  is zero or more batch dimensions.",torch.solve.yaml,2
991,349,0.001912960306073649,4,"frozenset({'matrix', 'b'})",the matrix B ,torch.lstsq.yaml,2
992,347,0.001912960306073649,4,"frozenset({'length', 'SOME_STRUCTURE'})",list of variable length sequences.,torch.nn.utils.rnn.pad_sequence.yaml,2
993,347,0.001912960306073649,4,"frozenset({'length', 'SOME_STRUCTURE'})",A list of sequences of decreasing length.,torch.nn.utils.rnn.pack_sequence.yaml,2
994,347,0.001912960306073649,4,"frozenset({'length', 'SOME_STRUCTURE'})",Function that takes in a list of modules and outputs a list of fused modules of the same length.,torch.quantization.fuse_modules.yaml,2
995,347,0.001912960306073649,4,"frozenset({'length', 'SOME_STRUCTURE'})",This method will throw `ValueError` if `total_length` is less than the max sequence length in `sequence`.,torch.nn.utils.rnn.pad_packed_sequence.yaml,2
996,339,0.001912960306073649,4,"frozenset({'also', 'whether', 'unique', 'return'})",Whether to also return the counts for each unique element.,torch.unique.yaml,4
997,339,0.001912960306073649,4,"frozenset({'also', 'whether', 'unique', 'return'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique.yaml,4
998,339,0.001912960306073649,4,"frozenset({'also', 'whether', 'unique', 'return'})",Whether to also return the counts for each unique element.,torch.unique_consecutive.yaml,4
999,339,0.001912960306073649,4,"frozenset({'also', 'whether', 'unique', 'return'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique_consecutive.yaml,4
1000,392,0.001912960306073649,4,"frozenset({'parameter', 'name', 'weight'})",name of weight parameter,torch.nn.utils.spectral_norm.yaml,3
1001,392,0.001912960306073649,4,"frozenset({'parameter', 'name', 'weight'})",name of weight parameter,torch.nn.utils.remove_weight_norm.yaml,3
1002,392,0.001912960306073649,4,"frozenset({'parameter', 'name', 'weight'})",name of weight parameter,torch.nn.utils.weight_norm.yaml,3
1003,392,0.001912960306073649,4,"frozenset({'parameter', 'name', 'weight'})",name of weight parameter,torch.nn.utils.remove_spectral_norm.yaml,3
1004,395,0.001912960306073649,4,"frozenset({'split', 'tensor'})",dimension along which to split the tensor.,torch.split.yaml,2
1005,395,0.001912960306073649,4,"frozenset({'split', 'tensor'})",tensor to split.,torch.split.yaml,2
1006,395,0.001912960306073649,4,"frozenset({'split', 'tensor'})",dimension along which to split the tensor,torch.chunk.yaml,2
1007,395,0.001912960306073649,4,"frozenset({'split', 'tensor'})",the tensor to split,torch.chunk.yaml,2
1008,396,0.001912960306073649,4,"frozenset({'none', 'ignored', 'dim'})",Ignored if `dim=None`.,torch.argmin2.yaml,3
1009,396,0.001912960306073649,4,"frozenset({'none', 'ignored', 'dim'})",Ignored if `dim=None`.,torch.argmax2.yaml,3
1010,396,0.001912960306073649,4,"frozenset({'none', 'ignored', 'dim'})",Ignored if `dim` = `None` and `out` = `None`.,torch.norm.yaml,3
1011,396,0.001912960306073649,4,"frozenset({'none', 'ignored', 'dim'})",Ignored if `dim` = `None` and `out` = `None`.,torch.norm.yaml,3
1012,404,0.001912960306073649,3,"frozenset({'result', 'tensor', 'two', 'indices', 'values', 'output', 'SOME_STRUCTURE'})","the result tuple of two output tensors (values, indices)",torch.cummax.yaml,7
1013,404,0.001912960306073649,3,"frozenset({'result', 'tensor', 'two', 'indices', 'values', 'output', 'SOME_STRUCTURE'})","the result tuple of two output tensors (values, indices)",torch.cummin.yaml,7
1014,404,0.001912960306073649,3,"frozenset({'result', 'tensor', 'two', 'indices', 'values', 'output', 'SOME_STRUCTURE'})","the result tuple of two output tensors (values, indices)",torch.mode.yaml,7
1015,338,0.001912960306073649,4,"frozenset({'input', 'returned', 'unique'})","If `None`, the unique of the flattened input is returned.",torch.unique.yaml,3
1016,338,0.001912960306073649,4,"frozenset({'input', 'returned', 'unique'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique.yaml,3
1017,338,0.001912960306073649,4,"frozenset({'input', 'returned', 'unique'})","If `None`, the unique of the flattened input is returned.",torch.unique_consecutive.yaml,3
1018,338,0.001912960306073649,4,"frozenset({'input', 'returned', 'unique'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique_consecutive.yaml,3
1019,405,0.001912960306073649,4,"frozenset({'input', 'target'})",Specifies a target value that is ignored and does not contribute to the input gradient.,torch.nn.functional.nll_loss.yaml,2
1020,405,0.001912960306073649,4,"frozenset({'input', 'target'})",Specifies a target value that is ignored and does not contribute to the input gradient.,torch.nn.functional.cross_entropy.yaml,2
1021,405,0.001912960306073649,4,"frozenset({'input', 'target'})","if `True` the loss is computed as  exp(input) - target * input , if `False` then loss is input - target *  log(input+eps) .",torch.nn.functional.poisson_nll_loss.yaml,2
1022,405,0.001912960306073649,4,"frozenset({'input', 'target'})",random sample target  sim Poisson(input) .,torch.nn.functional.poisson_nll_loss.yaml,2
1023,407,0.001912960306073649,3,"frozenset({'func', 'input', 'size', 'must'})",Must be the same size as the input of `func`.,torch.autograd.functional.hvp.yaml,4
1024,407,0.001912960306073649,3,"frozenset({'func', 'input', 'size', 'must'})",Must be the same size as the input of `func`.,torch.autograd.functional.jvp.yaml,4
1025,407,0.001912960306073649,3,"frozenset({'func', 'input', 'size', 'must'})",Must be the same size as the input of `func`.,torch.autograd.functional.vhp.yaml,4
1026,417,0.001912960306073649,4,"frozenset({'shape', 'quantized', '_channels', 'tensor'})",non-quantized bias tensor of shape (out _channels) .,torch.nn.quantized.functional.conv2d.yaml,4
1027,417,0.001912960306073649,4,"frozenset({'shape', 'quantized', '_channels', 'tensor'})","quantized input tensor of shape (minibatch , in _channels , iH , iW) ",torch.nn.quantized.functional.conv2d.yaml,4
1028,417,0.001912960306073649,4,"frozenset({'shape', 'quantized', '_channels', 'tensor'})",non-quantized bias tensor of shape (out _channels) .,torch.nn.quantized.functional.conv3d.yaml,4
1029,417,0.001912960306073649,4,"frozenset({'shape', 'quantized', '_channels', 'tensor'})","quantized input tensor of shape (minibatch , in _channels , iD , iH , iW) ",torch.nn.quantized.functional.conv3d.yaml,4
1030,420,0.001912960306073649,3,"frozenset({'value', 'norm', 'vector'})","p value for the p-norm distance to calculate between each vector pair  in [0,  infty] .",torch.nn.functional.pdist.yaml,3
1031,420,0.001912960306073649,3,"frozenset({'value', 'norm', 'vector'})","p value for the p-norm distance to calculate between each vector pair  in [0,  infty] .",torch.cdist.yaml,3
1032,420,0.001912960306073649,3,"frozenset({'value', 'norm', 'vector'})","If the value is None, matrix norm will be calculated when the input tensor only has two dimensions, vector norm will be calculated when the input tensor only has one dimension.",torch.norm.yaml,3
1033,422,0.001912960306073649,4,"frozenset({'non', 'zero'})",Default is feps ** 0.5 where feps is smallest non-zero floating-point number of the given input tensor A data type.,torch.lobpcg.yaml,2
1034,422,0.001912960306073649,4,"frozenset({'non', 'zero'})","The indices are the coordinates of the non-zero values in the matrix, and thus should be two-dimensional where the first dimension is the number of tensor dimensions and the second dimension is the number of non-zero values.",torch.sparse_coo_tensor.yaml,2
1035,422,0.001912960306073649,4,"frozenset({'non', 'zero'})",If not provided the size will be inferred as the minimum size big enough to hold all non-zero elements.,torch.sparse_coo_tensor.yaml,2
1036,422,0.001912960306073649,4,"frozenset({'non', 'zero'})",the standard deviation of the normal distribution used to generate the non-zero values,torch.nn.init.sparse_.yaml,2
1037,427,0.001912960306073649,4,"frozenset({'rank', 'default'})",Destination rank (default is 0),torch.distributed.gather.yaml,2
1038,427,0.001912960306073649,4,"frozenset({'rank', 'default'})","List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)",torch.distributed.gather.yaml,2
1039,427,0.001912960306073649,4,"frozenset({'rank', 'default'})","List of tensors to scatter (default is None, must be specified on the source rank)",torch.distributed.scatter.yaml,2
1040,427,0.001912960306073649,4,"frozenset({'rank', 'default'})",Source rank (default is 0),torch.distributed.scatter.yaml,2
1041,437,0.001912960306073649,4,"frozenset({'computed', 'along', 'dimension'})",A dimension along which softmax will be computed.,torch.nn.functional.gumbel_softmax.yaml,3
1042,437,0.001912960306073649,4,"frozenset({'computed', 'along', 'dimension'})",A dimension along which log_softmax will be computed.,torch.nn.functional.log_softmax.yaml,3
1043,437,0.001912960306073649,4,"frozenset({'computed', 'along', 'dimension'})",A dimension along which softmin will be computed (so every slice along dim will sum to 1).,torch.nn.functional.softmin.yaml,3
1044,437,0.001912960306073649,4,"frozenset({'computed', 'along', 'dimension'})",A dimension along which softmax will be computed.,torch.nn.functional.softmax.yaml,3
1045,438,0.001912960306073649,4,"frozenset({'along', 'dimension', 'tensor'})",dimension along which to split the tensor.,torch.split.yaml,3
1046,438,0.001912960306073649,4,"frozenset({'along', 'dimension', 'tensor'})",A dimension along which to chunk the tensor.,torch.cuda.comm.scatter.yaml,3
1047,438,0.001912960306073649,4,"frozenset({'along', 'dimension', 'tensor'})",dimension along which to split the tensor,torch.chunk.yaml,3
1048,438,0.001912960306073649,4,"frozenset({'along', 'dimension', 'tensor'})",a dimension along which the tensors will be concatenated.,torch.cuda.comm.gather.yaml,3
1049,441,0.001912960306073649,4,"frozenset({'dimensional', 'number'})",any number of 1 dimensional tensors.,torch.cartesian_prod.yaml,2
1050,441,0.001912960306073649,4,"frozenset({'dimensional', 'number'})","(N, C)  where C = number of classes or (N, C, H, W)  in case of 2D Loss, or (N, C, d_1, d_2, ..., d_K)  where K  >= 1  in the case of K-dimensional loss.",torch.nn.functional.nll_loss.yaml,2
1051,441,0.001912960306073649,4,"frozenset({'dimensional', 'number'})","(N, C)  where C = number of classes or (N, C, H, W)  in case of 2D Loss, or (N, C, d_1, d_2, ..., d_K)  where K  >= 1  in the case of K-dimensional loss.",torch.nn.functional.cross_entropy.yaml,2
1052,441,0.001912960306073649,4,"frozenset({'dimensional', 'number'})","The indices are the coordinates of the non-zero values in the matrix, and thus should be two-dimensional where the first dimension is the number of tensor dimensions and the second dimension is the number of non-zero values.",torch.sparse_coo_tensor.yaml,2
1053,328,0.001912960306073649,4,"frozenset({'output', 'quantization'})",quantization scale for the output.,torch.nn.quantized.functional.conv2d.yaml,2
1054,328,0.001912960306073649,4,"frozenset({'output', 'quantization'})",quantization zero_point for the output.,torch.nn.quantized.functional.conv2d.yaml,2
1055,328,0.001912960306073649,4,"frozenset({'output', 'quantization'})",quantization scale for the output.,torch.nn.quantized.functional.conv3d.yaml,2
1056,328,0.001912960306073649,4,"frozenset({'output', 'quantization'})",quantization zero_point for the output.,torch.nn.quantized.functional.conv3d.yaml,2
1057,544,0.001912960306073649,4,"frozenset({'output', 'default'})",`'none'`: no reduction will be applied `'batchmean'`: the sum of the output will be divided by the batchsize `'sum'`: the output will be summed `'mean'`: the output will be divided by the number of elements in the output Default: `'mean'`,torch.nn.functional.kl_div.yaml,2
1058,544,0.001912960306073649,4,"frozenset({'output', 'default'})",Number of digits of precision for floating point output (default = 4).,torch.set_printoptions.yaml,2
1059,544,0.001912960306073649,4,"frozenset({'output', 'default'})",a device on which the output will be placed (default: current device).,torch.cuda.comm.reduce_add.yaml,2
1060,544,0.001912960306073649,4,"frozenset({'output', 'default'})","output device (-1 means CPU, default: current device)",torch.cuda.comm.gather.yaml,2
1061,128,0.001912960306073649,3,"frozenset({'bilinear', '|', 'nearest'})",interpolation mode to calculate output values `'bilinear'` | `'nearest'`.,torch.nn.functional.grid_sample.yaml,3
1062,128,0.001912960306073649,3,"frozenset({'bilinear', '|', 'nearest'})",algorithm used for upsampling: `'nearest'` | `'bilinear'`,torch.nn.quantized.functional.interpolate.yaml,3
1063,128,0.001912960306073649,3,"frozenset({'bilinear', '|', 'nearest'})",algorithm used for upsampling: `'nearest'` | `'linear'` | `'bilinear'` | `'bicubic'` | `'trilinear'` | `'area'`.,torch.nn.functional.interpolate.yaml,3
1064,162,0.001912960306073649,3,"frozenset({'concatenated', 'tensor'})",Has to be between 0 and the number of dimensions of concatenated tensors (inclusive),torch.stack.yaml,2
1065,162,0.001912960306073649,3,"frozenset({'concatenated', 'tensor'})",the dimension over which the tensors are concatenated,torch.cat.yaml,2
1066,162,0.001912960306073649,3,"frozenset({'concatenated', 'tensor'})",a dimension along which the tensors will be concatenated.,torch.cuda.comm.gather.yaml,2
1067,147,0.001912960306073649,4,"frozenset({'input', 'returned', 'desired', 'data', 'performed', 'tensor', 'casted', 'specified', 'type', 'dtype', 'operationis'})","the desired data type of returned tensor.If specified, the input tensor is casted to `dtype` before the operationis performed.",torch.prod2.yaml,11
1068,147,0.001912960306073649,4,"frozenset({'input', 'returned', 'desired', 'data', 'performed', 'tensor', 'casted', 'specified', 'type', 'dtype', 'operationis'})","the desired data type of returned tensor.If specified, the input tensor is casted to `dtype` before the operationis performed.",torch.sum2.yaml,11
1069,147,0.001912960306073649,4,"frozenset({'input', 'returned', 'desired', 'data', 'performed', 'tensor', 'casted', 'specified', 'type', 'dtype', 'operationis'})","the desired data type of returned tensor.If specified, the input tensor is casted to `dtype` before the operationis performed.",torch.sum.yaml,11
1070,147,0.001912960306073649,4,"frozenset({'input', 'returned', 'desired', 'data', 'performed', 'tensor', 'casted', 'specified', 'type', 'dtype', 'operationis'})","the desired data type of returned tensor.If specified, the input tensor is casted to `dtype` before the operationis performed.",torch.prod.yaml,11
1071,148,0.001912960306073649,4,"frozenset({'torch', 'geqrf'})",the a from `torch.geqrf()`.,torch.ormqr.yaml,2
1072,148,0.001912960306073649,4,"frozenset({'torch', 'geqrf'})",the tau from `torch.geqrf()`.,torch.ormqr.yaml,2
1073,148,0.001912960306073649,4,"frozenset({'torch', 'geqrf'})",the a from `torch.geqrf()`.,torch.orgqr.yaml,2
1074,148,0.001912960306073649,4,"frozenset({'torch', 'geqrf'})",the tau from `torch.geqrf()`.,torch.orgqr.yaml,2
1075,149,0.001912960306073649,4,"frozenset({'input', 'matrices', 'dimensions', 'batch', 'consisting', 'zero', 'tensor', 'n', 'size'})","the input tensor A  of size (*, n, n)  where * is zero or more batch dimensions consisting of symmetric positive-definite matrices.",torch.cholesky.yaml,9
1076,149,0.001912960306073649,4,"frozenset({'input', 'matrices', 'dimensions', 'batch', 'consisting', 'zero', 'tensor', 'n', 'size'})","the input tensor of size (*, n, n)  where * is zero or more batch dimensions consisting of symmetric matrices.",torch.symeig.yaml,9
1077,149,0.001912960306073649,4,"frozenset({'input', 'matrices', 'dimensions', 'batch', 'consisting', 'zero', 'tensor', 'n', 'size'})","the input tensor of size (*, m, n)  where * is zero or more batch dimensions consisting of matrices of dimension m  times n .",torch.qr.yaml,9
1078,149,0.001912960306073649,4,"frozenset({'input', 'matrices', 'dimensions', 'batch', 'consisting', 'zero', 'tensor', 'n', 'size'})","the input tensor of size (*, m, n)  where * is zero or more batch dimensions consisting of m  times n  matrices.",torch.svd.yaml,9
1079,151,0.001912960306073649,4,"frozenset({'variable', 'like', 'arguments', 'collection', 'number', 'SOME_STRUCTURE'})",Can be a variable number of arguments or a collection like a list or tuple.,torch.rand.yaml,6
1080,151,0.001912960306073649,4,"frozenset({'variable', 'like', 'arguments', 'collection', 'number', 'SOME_STRUCTURE'})",Can be a variable number of arguments or a collection like a list or tuple.,torch.ones.yaml,6
1081,151,0.001912960306073649,4,"frozenset({'variable', 'like', 'arguments', 'collection', 'number', 'SOME_STRUCTURE'})",Can be a variable number of arguments or a collection like a list or tuple.,torch.zeros.yaml,6
1082,151,0.001912960306073649,4,"frozenset({'variable', 'like', 'arguments', 'collection', 'number', 'SOME_STRUCTURE'})",Can be a variable number of arguments or a collection like a list or tuple.,torch.randn.yaml,6
1083,157,0.001912960306073649,3,"frozenset({'output', 'ceil', 'use', 'shape', 'instead', 'compute', 'formula', 'true', 'floor'})","when True, will use ceil instead of floor in the formula to compute the output shape",torch.nn.functional.avg_pool3d.yaml,9
1084,157,0.001912960306073649,3,"frozenset({'output', 'ceil', 'use', 'shape', 'instead', 'compute', 'formula', 'true', 'floor'})","when True, will use ceil instead of floor in the formula to compute the output shape.",torch.nn.quantized.functional.avg_pool2d.yaml,9
1085,157,0.001912960306073649,3,"frozenset({'output', 'ceil', 'use', 'shape', 'instead', 'compute', 'formula', 'true', 'floor'})","when True, will use ceil instead of floor in the formula to compute the output shape.",torch.nn.functional.avg_pool2d.yaml,9
1086,161,0.001912960306073649,4,"frozenset({'d_', 'dimensional', 'n', 'loss', 'd_k', 'c', 'k'})","(N, C)  where C = number of classes or (N, C, H, W)  in case of 2D Loss, or (N, C, d_1, d_2, ..., d_K)  where K  >= 1  in the case of K-dimensional loss.",torch.nn.functional.nll_loss.yaml,7
1087,161,0.001912960306073649,4,"frozenset({'d_', 'dimensional', 'n', 'loss', 'd_k', 'c', 'k'})","(N)  where each value is 0  <= targets[i]  <= C-1 , or (N, d_1, d_2, ..., d_K)  where K  >= 1  for K-dimensional loss.",torch.nn.functional.nll_loss.yaml,7
1088,161,0.001912960306073649,4,"frozenset({'d_', 'dimensional', 'n', 'loss', 'd_k', 'c', 'k'})","(N, C)  where C = number of classes or (N, C, H, W)  in case of 2D Loss, or (N, C, d_1, d_2, ..., d_K)  where K  >= 1  in the case of K-dimensional loss.",torch.nn.functional.cross_entropy.yaml,7
1089,161,0.001912960306073649,4,"frozenset({'d_', 'dimensional', 'n', 'loss', 'd_k', 'c', 'k'})","(N)  where each value is 0  <= targets[i]  <= C-1 , or (N, d_1, d_2, ..., d_K)  where K  >= 1  for K-dimensional loss.",torch.nn.functional.cross_entropy.yaml,7
1090,167,0.001912960306073649,4,"frozenset({'order', 'ascending'})","The points at which the function y is sampled.If x is not in ascending order, intervals on which it is decreasingcontribute negatively to the estimated integral (i.e., the convention int_a^b f = - int_b^a f is followed).",torch.trapz.yaml,2
1091,167,0.001912960306073649,4,"frozenset({'order', 'ascending'})",controls the sorting order (ascending or descending),torch.argsort.yaml,2
1092,167,0.001912960306073649,4,"frozenset({'order', 'ascending'})",controls the sorting order (ascending or descending),torch.sort.yaml,2
1093,167,0.001912960306073649,4,"frozenset({'order', 'ascending'})",Whether to sort the unique elements in ascending order before returning as output.,torch.unique.yaml,2
1094,252,0.001912960306073649,4,"frozenset({'product', 'vector', 'jacobian'})",The vector for which the vector Jacobian product is computed.,torch.autograd.functional.vjp.yaml,3
1095,252,0.001912960306073649,4,"frozenset({'product', 'vector', 'jacobian'})",The vector for which the Jacobian vector product is computed.,torch.autograd.functional.jvp.yaml,3
1096,252,0.001912960306073649,4,"frozenset({'product', 'vector', 'jacobian'})","The ""vector"" in the Jacobian-vector product, usually gradients w.r.t. each element of corresponding tensors.",torch.autograd.backward.yaml,3
1097,252,0.001912960306073649,4,"frozenset({'product', 'vector', 'jacobian'})","The ""vector"" in the Jacobian-vector product.",torch.autograd.grad.yaml,3
1098,170,0.001912960306073649,4,"frozenset({'include', 'calculation', 'zero', 'padding', 'true', 'averaging'})","when True, will include the zero-padding in the averaging calculation",torch.nn.functional.avg_pool3d.yaml,6
1099,170,0.001912960306073649,4,"frozenset({'include', 'calculation', 'zero', 'padding', 'true', 'averaging'})","when True, will include the zero-padding in the averaging calculation.",torch.nn.quantized.functional.avg_pool2d.yaml,6
1100,170,0.001912960306073649,4,"frozenset({'include', 'calculation', 'zero', 'padding', 'true', 'averaging'})","when True, will include the zero-padding in the averaging calculation.",torch.nn.functional.avg_pool1d.yaml,6
1101,170,0.001912960306073649,4,"frozenset({'include', 'calculation', 'zero', 'padding', 'true', 'averaging'})","when True, will include the zero-padding in the averaging calculation.",torch.nn.functional.avg_pool2d.yaml,6
1102,172,0.001912960306073649,4,"frozenset({'deviation', 'standard'})",the standard deviation for all distributions,torch.normal222.yaml,2
1103,172,0.001912960306073649,4,"frozenset({'deviation', 'standard'})",the standard deviation for all distributions,torch.normal22.yaml,2
1104,172,0.001912960306073649,4,"frozenset({'deviation', 'standard'})",the standard deviation of the normal distribution,torch.nn.init.normal_.yaml,2
1105,172,0.001912960306073649,4,"frozenset({'deviation', 'standard'})",the standard deviation of the normal distribution used to generate the non-zero values,torch.nn.init.sparse_.yaml,2
1106,178,0.001912960306073649,3,"frozenset({'input', 'single', 'contains', 'element', 'argument', 'provided', 'tensor', 'func', 'set', 'optional', 'containing'})",This argument is optional when `func`'s input contains a single element and (if it is not provided) will be set as a Tensor containing a single `1`.,torch.autograd.functional.hvp.yaml,11
1107,178,0.001912960306073649,3,"frozenset({'input', 'single', 'contains', 'element', 'argument', 'provided', 'tensor', 'func', 'set', 'optional', 'containing'})",This argument is optional when `func`'s input contains a single element and (if it is not provided) will be set as a Tensor containing a single `1`.,torch.autograd.functional.jvp.yaml,11
1108,178,0.001912960306073649,3,"frozenset({'input', 'single', 'contains', 'element', 'argument', 'provided', 'tensor', 'func', 'set', 'optional', 'containing'})",This argument is optional when `func`'s input contains a single element and (if it is not provided) will be set as a Tensor containing a single `1`.,torch.autograd.functional.vhp.yaml,11
1109,189,0.001912960306073649,4,"frozenset({'input', 'tensor', 'points', 'set', 'corner', 'pixels', 'values', 'output', 'aligned'})","If set to `True`, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels.",torch.nn.quantized.functional.interpolate.yaml,9
1110,189,0.001912960306073649,4,"frozenset({'input', 'tensor', 'points', 'set', 'corner', 'pixels', 'values', 'output', 'aligned'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.quantized.functional.interpolate.yaml,9
1111,189,0.001912960306073649,4,"frozenset({'input', 'tensor', 'points', 'set', 'corner', 'pixels', 'values', 'output', 'aligned'})","If set to `True`, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels.",torch.nn.functional.interpolate.yaml,9
1112,189,0.001912960306073649,4,"frozenset({'input', 'tensor', 'points', 'set', 'corner', 'pixels', 'values', 'output', 'aligned'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.functional.interpolate.yaml,9
1113,121,0.001912960306073649,4,"frozenset({'spatial', 'size'})",multiplier for spatial size.,torch.nn.quantized.functional.interpolate.yaml,2
1114,121,0.001912960306073649,4,"frozenset({'spatial', 'size'})",output spatial size.,torch.nn.quantized.functional.interpolate.yaml,2
1115,121,0.001912960306073649,4,"frozenset({'spatial', 'size'})",multiplier for spatial size.,torch.nn.functional.interpolate.yaml,2
1116,121,0.001912960306073649,4,"frozenset({'spatial', 'size'})",output spatial size.,torch.nn.functional.interpolate.yaml,2
1117,236,0.001912960306073649,4,"frozenset({'graph', 'order'})","names to assign to the input nodes of the graph, in order",torch.onnx.export.yaml,2
1118,236,0.001912960306073649,4,"frozenset({'graph', 'order'})","names to assign to the output nodes of the graph, in order",torch.onnx.export.yaml,2
1119,236,0.001912960306073649,4,"frozenset({'graph', 'order'})","If `True`, graph of the derivative will be constructed, allowing to compute higher order derivative products.",torch.autograd.backward.yaml,2
1120,236,0.001912960306073649,4,"frozenset({'graph', 'order'})","If `True`, graph of the derivative will be constructed, allowing to compute higher order derivative products.",torch.autograd.grad.yaml,2
1121,145,0.001912960306073649,3,"frozenset({'element', 'src', 'broadcast'})","Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.",torch.cuda.comm.broadcast_coalesced.yaml,3
1122,145,0.001912960306073649,3,"frozenset({'element', 'src', 'broadcast'})","If `src` is the rank, then the specified `src_tensor` element of `tensor_list` (`tensor_list[src_tensor]`) will be broadcast to all other tensors (on different GPUs) in the src process and all tensors in `tensor_list` of other non-src processes.",torch.distributed.broadcast_multigpu.yaml,3
1123,145,0.001912960306073649,3,"frozenset({'element', 'src', 'broadcast'})","Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.",torch.cuda.comm.broadcast.yaml,3
1124,143,0.001912960306073649,3,"frozenset({'tolerance', 'relative'})",relative tolerance,torch.autograd.gradgradcheck.yaml,2
1125,143,0.001912960306073649,3,"frozenset({'tolerance', 'relative'})",relative tolerance,torch.autograd.gradcheck.yaml,2
1126,143,0.001912960306073649,3,"frozenset({'tolerance', 'relative'})",relative tolerance.,torch.allclose.yaml,2
1127,139,0.001912960306073649,3,"frozenset({'along', 'dimension', 'sort'})",the dimension to sort along,torch.topk.yaml,3
1128,139,0.001912960306073649,3,"frozenset({'along', 'dimension', 'sort'})",the dimension to sort along,torch.argsort.yaml,3
1129,139,0.001912960306073649,3,"frozenset({'along', 'dimension', 'sort'})",the dimension to sort along,torch.sort.yaml,3
1130,137,0.001912960306073649,3,"frozenset({'dimension', 'last'})","The dimension along which to integrate.By default, use the last dimension.",torch.trapz.yaml,2
1131,137,0.001912960306073649,3,"frozenset({'dimension', 'last'})","The dimension along which to integrate.By default, use the last dimension.",torch.trapz2.yaml,2
1132,137,0.001912960306073649,3,"frozenset({'dimension', 'last'})","If the input tensor has more than two dimensions, the vector norm will be applied to last dimension.",torch.norm.yaml,2
1133,134,0.001912960306073649,3,"frozenset({'computed', 'hessian'})",The vector for which the Hessian vector product is computed.,torch.autograd.functional.hvp.yaml,2
1134,134,0.001912960306073649,3,"frozenset({'computed', 'hessian'})",The vector for which the vector Hessian product is computed.,torch.autograd.functional.vhp.yaml,2
1135,134,0.001912960306073649,3,"frozenset({'computed', 'hessian'})","If `True`, the Hessian will be computed in a differentiable manner.",torch.autograd.functional.hessian.yaml,2
1136,133,0.001912960306073649,4,"frozenset({'manual', 'rescaling', 'weight'})",a manual rescaling weight if provided it's repeated to match input tensor shape,torch.nn.functional.binary_cross_entropy.yaml,3
1137,133,0.001912960306073649,4,"frozenset({'manual', 'rescaling', 'weight'})",a manual rescaling weight given to each class.,torch.nn.functional.nll_loss.yaml,3
1138,133,0.001912960306073649,4,"frozenset({'manual', 'rescaling', 'weight'})",a manual rescaling weight given to each class.,torch.nn.functional.cross_entropy.yaml,3
1139,133,0.001912960306073649,4,"frozenset({'manual', 'rescaling', 'weight'})",a manual rescaling weight if provided it's repeated to match input tensor shape,torch.nn.functional.binary_cross_entropy_with_logits.yaml,3
1140,130,0.001912960306073649,3,"frozenset({'rows', 'matrix', 'number'})","The embedding matrix with number of rows equal to the maximum possible index + 1, and number of columns equal to the embedding size",torch.nn.functional.embedding.yaml,3
1141,130,0.001912960306073649,3,"frozenset({'rows', 'matrix', 'number'})",number of rows in the 2-D matrix.,torch.triu_indices.yaml,3
1142,130,0.001912960306073649,3,"frozenset({'rows', 'matrix', 'number'})",number of rows in the 2-D matrix.,torch.tril_indices.yaml,3
1143,112,0.001912960306073649,4,"frozenset({'contents', 'hash', 'file'})","If True, the filename part of the URL should follow the naming convention `filename-<sha256>.ext` where `<sha256>` is the first eight or more digits of the SHA256 hash of the contents of the file.",torch.utils.model_zoo.load_url.yaml,3
1144,112,0.001912960306073649,4,"frozenset({'contents', 'hash', 'file'})",The hash is used to ensure unique names and to verify the contents of the file.,torch.utils.model_zoo.load_url.yaml,3
1145,112,0.001912960306073649,4,"frozenset({'contents', 'hash', 'file'})","If True, the filename part of the URL should follow the naming convention `filename-<sha256>.ext` where `<sha256>` is the first eight or more digits of the SHA256 hash of the contents of the file.",torch.hub.load_state_dict_from_url.yaml,3
1146,112,0.001912960306073649,4,"frozenset({'contents', 'hash', 'file'})",The hash is used to ensure unique names and to verify the contents of the file.,torch.hub.load_state_dict_from_url.yaml,3
1147,127,0.001912960306073649,4,"frozenset({'ndarray', 'types', 'numpy', 'SOME_DTYPE', 'SOME_STRUCTURE'})","Can be a list, tuple, NumPy `ndarray`, scalar, and other types.",torch.as_tensor.yaml,5
1148,127,0.001912960306073649,4,"frozenset({'ndarray', 'types', 'numpy', 'SOME_DTYPE', 'SOME_STRUCTURE'})","Can be a list, tuple, NumPy `ndarray`, scalar, and other types.",torch.tensor.yaml,5
1149,127,0.001912960306073649,4,"frozenset({'ndarray', 'types', 'numpy', 'SOME_DTYPE', 'SOME_STRUCTURE'})","Can be a list, tuple, NumPy `ndarray`, scalar, and other types.",torch.sparse_coo_tensor.yaml,5
1150,127,0.001912960306073649,4,"frozenset({'ndarray', 'types', 'numpy', 'SOME_DTYPE', 'SOME_STRUCTURE'})","Can be a list, tuple, NumPy `ndarray`, scalar, and other types.",torch.sparse_coo_tensor.yaml,5
1151,114,0.001912960306073649,4,"frozenset({'rng', 'forked'})", CPU RNG state is always forked.,torch.random.fork_rng.yaml,2
1152,114,0.001912960306073649,4,"frozenset({'rng', 'forked'})","if `False`, the RNG is not forked.",torch.random.fork_rng.yaml,2
1153,114,0.001912960306073649,4,"frozenset({'rng', 'forked'})", CPU RNG state is always forked.,torch.random.fork_rng2.yaml,2
1154,114,0.001912960306073649,4,"frozenset({'rng', 'forked'})","if `False`, the RNG is not forked.",torch.random.fork_rng2.yaml,2
1155,126,0.001912960306073649,3,"frozenset({'multiplier', 'alpha', 'mat'})",multiplier for mat1 @ mat2  ( alpha ),torch.addmm.yaml,3
1156,126,0.001912960306073649,3,"frozenset({'multiplier', 'alpha', 'mat'})",multiplier for mat1 @ mat2  ( alpha ),torch.sparse.addmm.yaml,3
1157,126,0.001912960306073649,3,"frozenset({'multiplier', 'alpha', 'mat'})",multiplier for mat @ vec  ( alpha ),torch.addmv.yaml,3
1158,115,0.001912960306073649,3,"frozenset({'start', 'end'})","If any of start, end, or stop are floating-point, the dtype is inferred to be the default dtype, see `get_default_dtype()`.",torch.arange.yaml,2
1159,115,0.001912960306073649,3,"frozenset({'start', 'end'})",number of points to sample between `start` and `end`.,torch.linspace.yaml,2
1160,115,0.001912960306073649,3,"frozenset({'start', 'end'})",number of points to sample between `start` and `end`.,torch.logspace.yaml,2
1161,116,0.001912960306073649,3,"frozenset({'defined', 'py'})",The opset_version must be _onnx_master_opset or in _onnx_stable_opsets which are defined in torch/onnx/symbolic_helper.py,torch.onnx.export.yaml,2
1162,116,0.001912960306073649,3,"frozenset({'defined', 'py'})",a string of entrypoint name defined in repo's hubconf.py,torch.hub.load.yaml,2
1163,116,0.001912960306073649,3,"frozenset({'defined', 'py'})",a string of entrypoint name defined in repo's hubconf.py,torch.hub.help.yaml,2
1164,124,0.001912960306073649,3,"frozenset({'max', 'SOME_STRUCTURE'})","the result tuple of two output tensors (max, max_indices)",torch.median2.yaml,2
1165,124,0.001912960306073649,3,"frozenset({'max', 'SOME_STRUCTURE'})","the result tuple of two output tensors (max, max_indices)",torch.max2.yaml,2
1166,124,0.001912960306073649,3,"frozenset({'max', 'SOME_STRUCTURE'})",This method will throw `ValueError` if `total_length` is less than the max sequence length in `sequence`.,torch.nn.utils.rnn.pad_packed_sequence.yaml,2
1167,119,0.001912960306073649,4,"frozenset({'match', 'recv', 'remote', 'send', 'tag'})",Tag to match send with remote recv,torch.distributed.isend.yaml,5
1168,119,0.001912960306073649,4,"frozenset({'match', 'recv', 'remote', 'send', 'tag'})",Tag to match recv with remote send,torch.distributed.recv.yaml,5
1169,119,0.001912960306073649,4,"frozenset({'match', 'recv', 'remote', 'send', 'tag'})",Tag to match send with remote recv,torch.distributed.send.yaml,5
1170,119,0.001912960306073649,4,"frozenset({'match', 'recv', 'remote', 'send', 'tag'})",Tag to match recv with remote send,torch.distributed.irecv.yaml,5
1171,123,0.001912960306073649,4,"frozenset({'mutated', 'carry', 'original', 'transformations', 'place', 'SOME_DTYPE'})","carry out model transformations in-place, the original module is mutated",torch.quantization.prepare_qat.yaml,6
1172,123,0.001912960306073649,4,"frozenset({'mutated', 'carry', 'original', 'transformations', 'place', 'SOME_DTYPE'})","carry out model transformations in-place, the original module is mutated",torch.quantization.quantize.yaml,6
1173,123,0.001912960306073649,4,"frozenset({'mutated', 'carry', 'original', 'transformations', 'place', 'SOME_DTYPE'})","carry out model transformations in-place, the original module is mutated",torch.quantization.convert.yaml,6
1174,123,0.001912960306073649,4,"frozenset({'mutated', 'carry', 'original', 'transformations', 'place', 'SOME_DTYPE'})","carry out model transformations in-place, the original module is mutated",torch.quantization.prepare.yaml,6
1175,120,0.001912960306073649,4,"frozenset({'headers', 'libraries', 'cuda'})",Determines whether CUDA headers and libraries are added to the build.,torch.utils.cpp_extension.load_inline.yaml,3
1176,120,0.001912960306073649,4,"frozenset({'headers', 'libraries', 'cuda'})",Set it to `True` to force CUDA headers and libraries to be included.,torch.utils.cpp_extension.load_inline.yaml,3
1177,120,0.001912960306073649,4,"frozenset({'headers', 'libraries', 'cuda'})",Determines whether CUDA headers and libraries are added to the build.,torch.utils.cpp_extension.load.yaml,3
1178,120,0.001912960306073649,4,"frozenset({'headers', 'libraries', 'cuda'})",Set it to True` to force CUDA headers and libraries to be included.,torch.utils.cpp_extension.load.yaml,3
1179,237,0.001912960306073649,4,"frozenset({'graph', 'compute'})","If `True`, graph of the derivative will be constructed, allowing to compute higher order derivative products.",torch.autograd.backward.yaml,2
1180,237,0.001912960306073649,4,"frozenset({'graph', 'compute'})","If `False`, the graph used to compute the grad will be freed.",torch.autograd.backward.yaml,2
1181,237,0.001912960306073649,4,"frozenset({'graph', 'compute'})","If `True`, graph of the derivative will be constructed, allowing to compute higher order derivative products.",torch.autograd.grad.yaml,2
1182,237,0.001912960306073649,4,"frozenset({'graph', 'compute'})","If `False`, the graph used to compute the grad will be freed.",torch.autograd.grad.yaml,2
1183,122,0.001912960306073649,4,"frozenset({'window', 'returns', 'function', 'used', 'true', 'periodic'})","If True, returns a window to be used as periodic function.",torch.hann_window.yaml,6
1184,122,0.001912960306073649,4,"frozenset({'window', 'returns', 'function', 'used', 'true', 'periodic'})","If True, returns a window to be used as periodic function.",torch.hamming_window.yaml,6
1185,122,0.001912960306073649,4,"frozenset({'window', 'returns', 'function', 'used', 'true', 'periodic'})","If True, returns a window to be used as periodic function.",torch.blackman_window.yaml,6
1186,122,0.001912960306073649,4,"frozenset({'window', 'returns', 'function', 'used', 'true', 'periodic'})","If True, returns a window to be used as periodic function.",torch.bartlett_window.yaml,6
1187,274,0.001912960306073649,4,"frozenset({'kernel_size', 'default'})",Default: `kernel_size`,torch.nn.functional.avg_pool3d.yaml,2
1188,274,0.001912960306073649,4,"frozenset({'kernel_size', 'default'})",Default: `kernel_size`,torch.nn.quantized.functional.avg_pool2d.yaml,2
1189,274,0.001912960306073649,4,"frozenset({'kernel_size', 'default'})",Default: `kernel_size`,torch.nn.functional.avg_pool1d.yaml,2
1190,274,0.001912960306073649,4,"frozenset({'kernel_size', 'default'})",Default: `kernel_size`,torch.nn.functional.avg_pool2d.yaml,2
1191,273,0.001912960306073649,4,"frozenset({'passed', 'scale_factor'})"," When scale_factor is passed as a parameter, it is used to compute the output_size.",torch.nn.functional.interpolate.yaml,2
1192,273,0.001912960306073649,4,"frozenset({'passed', 'scale_factor'})"," If recompute_scale_factor is ``True` or not specified, a new scale_factor will be computed based on the output and input sizes for use in the interpolation computation (i.e. the computation will be identical to if the computed output_size were passed-in explicitly).",torch.nn.functional.interpolate.yaml,2
1193,273,0.001912960306073649,4,"frozenset({'passed', 'scale_factor'})"," Otherwise, the passed-in scale_factor will be used in the interpolation computation.",torch.nn.functional.interpolate.yaml,2
1194,273,0.001912960306073649,4,"frozenset({'passed', 'scale_factor'})"," Note that when scale_factor is floating-point, the recomputed scale_factor may differ from the one passed in due to rounding and precision issues.",torch.nn.functional.interpolate.yaml,2
1195,271,0.001912960306073649,4,"frozenset({'symmetric', 'window', 'return', 'false'})","If False, return a symmetric window.",torch.hann_window.yaml,4
1196,271,0.001912960306073649,4,"frozenset({'symmetric', 'window', 'return', 'false'})","If False, return a symmetric window.",torch.hamming_window.yaml,4
1197,271,0.001912960306073649,4,"frozenset({'symmetric', 'window', 'return', 'false'})","If False, return a symmetric window.",torch.blackman_window.yaml,4
1198,271,0.001912960306073649,4,"frozenset({'symmetric', 'window', 'return', 'false'})","If False, return a symmetric window.",torch.bartlett_window.yaml,4
1199,259,0.001912960306073649,3,"frozenset({'diagonal', 'main', 'default'})",Default: 0 (main diagonal).,torch.diag_embed.yaml,3
1200,259,0.001912960306073649,3,"frozenset({'diagonal', 'main', 'default'})",Default: 0 (main diagonal).,torch.diagonal.yaml,3
1201,259,0.001912960306073649,3,"frozenset({'diagonal', 'main', 'default'})",Default: 0 (main diagonal).,torch.diagflat.yaml,3
1202,285,0.001912960306073649,4,"frozenset({'supported', 'dense', 'strided', 'torch', 'SOME_DTYPE'})",Only `torch.strided` (dense layout) is supported.,torch.hann_window.yaml,5
1203,285,0.001912960306073649,4,"frozenset({'supported', 'dense', 'strided', 'torch', 'SOME_DTYPE'})",Only `torch.strided` (dense layout) is supported.,torch.hamming_window.yaml,5
1204,285,0.001912960306073649,4,"frozenset({'supported', 'dense', 'strided', 'torch', 'SOME_DTYPE'})",Only `torch.strided` (dense layout) is supported.,torch.blackman_window.yaml,5
1205,285,0.001912960306073649,4,"frozenset({'supported', 'dense', 'strided', 'torch', 'SOME_DTYPE'})",Only `torch.strided` (dense layout) is supported.,torch.bartlett_window.yaml,5
1206,516,0.0014347202295552368,3,"frozenset({'matrix', 'tensor'})",Tensor containing indices into the embedding matrix,torch.nn.functional.embedding.yaml,2
1207,516,0.0014347202295552368,3,"frozenset({'matrix', 'tensor'})","If the value is None, matrix norm will be calculated when the input tensor only has two dimensions, vector norm will be calculated when the input tensor only has one dimension.",torch.norm.yaml,2
1208,516,0.0014347202295552368,3,"frozenset({'matrix', 'tensor'})","The indices are the coordinates of the non-zero values in the matrix, and thus should be two-dimensional where the first dimension is the number of tensor dimensions and the second dimension is the number of non-zero values.",torch.sparse_coo_tensor.yaml,2
1209,530,0.0014347202295552368,3,"frozenset({'number', 'dimension'})","dimension corresponding to number of outputs, the default is `0`, except for modules that are instances of ConvTranspose{1,2,3}d, when it is `1`",torch.nn.utils.spectral_norm.yaml,2
1210,530,0.0014347202295552368,3,"frozenset({'number', 'dimension'})",Number of array items in summary at beginning and end of each dimension (default = 3).,torch.set_printoptions.yaml,2
1211,530,0.0014347202295552368,3,"frozenset({'number', 'dimension'})","The indices are the coordinates of the non-zero values in the matrix, and thus should be two-dimensional where the first dimension is the number of tensor dimensions and the second dimension is the number of non-zero values.",torch.sparse_coo_tensor.yaml,2
1212,24,0.0014347202295552368,3,"frozenset({'branch', 'specified', 'master', 'default'})",The default branch is master if not specified.,torch.hub.load.yaml,4
1213,24,0.0014347202295552368,3,"frozenset({'branch', 'specified', 'master', 'default'})",The default branch is master if not specified.,torch.hub.help.yaml,4
1214,24,0.0014347202295552368,3,"frozenset({'branch', 'specified', 'master', 'default'})",The default branch is master if not specified.,torch.hub.list.yaml,4
1215,25,0.0014347202295552368,3,"frozenset({'method', 'lobpcg'})",select LOBPCG method.,torch.lobpcg.yaml,2
1216,25,0.0014347202295552368,3,"frozenset({'method', 'lobpcg'})","various parameters to LOBPCG algorithm when using method=""ortho"".",torch.lobpcg.yaml,2
1217,25,0.0014347202295552368,3,"frozenset({'method', 'lobpcg'})","various parameters to LOBPCG algorithm when using method=""ortho"".",torch.lobpcg.yaml,2
1218,526,0.0014347202295552368,3,"frozenset({'value', 'size'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.quantized.functional.interpolate.yaml,2
1219,526,0.0014347202295552368,3,"frozenset({'value', 'size'})","If shifts is a tuple, dims must be a tuple of the same size, and each dimension will be rolled by the corresponding value",torch.roll.yaml,2
1220,526,0.0014347202295552368,3,"frozenset({'value', 'size'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.functional.interpolate.yaml,2
1221,99,0.0014347202295552368,3,"frozenset({'triangular', 'factor', 'lower', 'cholesky', 'upper'})","input matrix u  of size (*, m, m) , where *  is zero of more batch dimensions composed of upper or lower triangular Cholesky factor",torch.cholesky_solve.yaml,5
1222,99,0.0014347202295552368,3,"frozenset({'triangular', 'factor', 'lower', 'cholesky', 'upper'})",whether to consider the Cholesky factor as a lower or upper triangular matrix.,torch.cholesky_solve.yaml,5
1223,99,0.0014347202295552368,3,"frozenset({'triangular', 'factor', 'lower', 'cholesky', 'upper'})","the input 2-D tensor u , a upper or lower triangular Cholesky factor",torch.cholesky_inverse.yaml,5
1224,95,0.0014347202295552368,3,"frozenset({'quantized', 'torch', 'qint'})","Has to be one of the quantized dtypes: `torch.quint8`, `torch.qint8`, `torch.qint32`",torch.quantize_per_channel.yaml,3
1225,95,0.0014347202295552368,3,"frozenset({'quantized', 'torch', 'qint'})",Quantized weight of type torch.qint8,torch.nn.quantized.functional.linear.yaml,3
1226,95,0.0014347202295552368,3,"frozenset({'quantized', 'torch', 'qint'})","Has to be one of the quantized dtypes: `torch.quint8`, `torch.qint8`, `torch.qint32`",torch.quantize_per_tensor.yaml,3
1227,458,0.0014347202295552368,3,"frozenset({'vector', 'tensor'})","The ""vector"" in the Jacobian-vector product, usually gradients w.r.t. each element of corresponding tensors.",torch.autograd.backward.yaml,2
1228,458,0.0014347202295552368,3,"frozenset({'vector', 'tensor'})","If the value is None, matrix norm will be calculated when the input tensor only has two dimensions, vector norm will be calculated when the input tensor only has one dimension.",torch.norm.yaml,2
1229,458,0.0014347202295552368,3,"frozenset({'vector', 'tensor'})","If the input tensor has more than two dimensions, the vector norm will be applied to last dimension.",torch.norm.yaml,2
1230,92,0.0014347202295552368,3,"frozenset({'among', 'SOME_DTYPE', 'SOME_STRUCTURE'})",an iterable of devices among which to broadcast.,torch.cuda.comm.broadcast_coalesced.yaml,3
1231,92,0.0014347202295552368,3,"frozenset({'among', 'SOME_DTYPE', 'SOME_STRUCTURE'})","iterable of ints, specifying among which devices the tensor should be scattered.",torch.cuda.comm.scatter.yaml,3
1232,92,0.0014347202295552368,3,"frozenset({'among', 'SOME_DTYPE', 'SOME_STRUCTURE'})",an iterable of devices among which to broadcast.,torch.cuda.comm.broadcast.yaml,3
1233,91,0.0014347202295552368,3,"frozenset({'version', 'opset'})",by default we export the model to the opset version of the onnx submodule.,torch.onnx.export.yaml,2
1234,91,0.0014347202295552368,3,"frozenset({'version', 'opset'})","Since ONNX's latest opset may evolve before next stable release, by default we export to one stable opset version.",torch.onnx.export.yaml,2
1235,91,0.0014347202295552368,3,"frozenset({'version', 'opset'})","Right now, supported stable opset version is 9.",torch.onnx.export.yaml,2
1236,90,0.0014347202295552368,3,"frozenset({'attributes', 'SOME_DTYPE'})","This field should be given as a lowercase string (e.g., `""gloo""`), which can also be accessed via `Backend` attributes (e.g., `Backend.GLOO`).",torch.distributed.init_process_group.yaml,2
1237,90,0.0014347202295552368,3,"frozenset({'attributes', 'SOME_DTYPE'})",input module with qconfig attributes for all the leaf modules that we want to quantize,torch.quantization.add_observer_.yaml,2
1238,90,0.0014347202295552368,3,"frozenset({'attributes', 'SOME_DTYPE'})","This field should be given as a lowercase string (e.g., `""gloo""`), which can also be accessed via `Backend` attributes (e.g., `Backend.GLOO`).",torch.distributed.new_group.yaml,2
1239,525,0.0014347202295552368,3,"frozenset({'value', 'dimension'})","If the value is None, matrix norm will be calculated when the input tensor only has two dimensions, vector norm will be calculated when the input tensor only has one dimension.",torch.norm.yaml,2
1240,525,0.0014347202295552368,3,"frozenset({'value', 'dimension'})",the dimension to find the kth value along,torch.kthvalue.yaml,2
1241,525,0.0014347202295552368,3,"frozenset({'value', 'dimension'})","If shifts is a tuple, dims must be a tuple of the same size, and each dimension will be rolled by the corresponding value",torch.roll.yaml,2
1242,524,0.0014347202295552368,3,"frozenset({'function', 'see'})",See the description of the function above.,torch.lobpcg.yaml,2
1243,524,0.0014347202295552368,3,"frozenset({'function', 'see'})",a function or a dict specifying how to remap storage locations (see torch.load),torch.utils.model_zoo.load_url.yaml,2
1244,524,0.0014347202295552368,3,"frozenset({'function', 'see'})",a function or a dict specifying how to remap storage locations (see torch.load),torch.hub.load_state_dict_from_url.yaml,2
1245,29,0.0014347202295552368,3,"frozenset({'input', 'false', 'set', 'corner', 'pixels', 'points', 'making'})","If set to `False`, they are instead considered as referring to the corner points of the input's corner pixels, making the sampling more resolution agnostic.",torch.nn.functional.grid_sample.yaml,7
1246,29,0.0014347202295552368,3,"frozenset({'input', 'false', 'set', 'corner', 'pixels', 'points', 'making'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.quantized.functional.interpolate.yaml,7
1247,29,0.0014347202295552368,3,"frozenset({'input', 'false', 'set', 'corner', 'pixels', 'points', 'making'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.functional.interpolate.yaml,7
1248,89,0.0014347202295552368,3,"frozenset({'default', 'array'})","The dimension along which to repeat values.By default, use the flattened input array, and return a flat outputarray.",torch.repeat_interleave.yaml,2
1249,89,0.0014347202295552368,3,"frozenset({'default', 'array'})",Number of array items in summary at beginning and end of each dimension (default = 3).,torch.set_printoptions.yaml,2
1250,89,0.0014347202295552368,3,"frozenset({'default', 'array'})",Total number of array elements which trigger summarization rather than full repr (default = 1000).,torch.set_printoptions.yaml,2
1251,463,0.0014347202295552368,3,"frozenset({'specified', 'parameters'})",other keyword arguments such as: amount (int or float): quantity of parameters to prune across the specified parameters.,torch.nn.utils.prune.global_unstructured.yaml,2
1252,463,0.0014347202295552368,3,"frozenset({'specified', 'parameters'})","if specified, all parameters will be exported.",torch.onnx.export.yaml,2
1253,463,0.0014347202295552368,3,"frozenset({'specified', 'parameters'})","In this case, the exported model will first take all of its parameters as arguments, the ordering as specified by `model.state_dict().values()`",torch.onnx.export.yaml,2
1254,522,0.0014347202295552368,3,"frozenset({'n', 'default'})",the number of columns with default being `n`,torch.eye.yaml,2
1255,522,0.0014347202295552368,3,"frozenset({'n', 'default'})",Default value for n is k.,torch.lobpcg.yaml,2
1256,522,0.0014347202295552368,3,"frozenset({'n', 'default'})","By default, `q = min(6, m, n)`.",torch.pca_lowrank.yaml,2
1257,88,0.0014347202295552368,3,"frozenset({'redundancy', 'whether', 'avoid', 'controls'})","controls whether `input` was halfed to avoid redundancy, e.g., by `rfft()`.",torch.irfft.yaml,4
1258,88,0.0014347202295552368,3,"frozenset({'redundancy', 'whether', 'avoid', 'controls'})",controls whether to return half of results to avoid redundancy Default: `True`,torch.stft.yaml,4
1259,88,0.0014347202295552368,3,"frozenset({'redundancy', 'whether', 'avoid', 'controls'})",controls whether to return half of results to avoid redundancy.,torch.rfft.yaml,4
1260,32,0.0014347202295552368,3,"frozenset({'sha', 'file'})","If not None, the SHA256 downloaded file should start with hash_prefix.",torch.hub.download_url_to_file.yaml,2
1261,32,0.0014347202295552368,3,"frozenset({'sha', 'file'})","If True, the filename part of the URL should follow the naming convention `filename-<sha256>.ext` where `<sha256>` is the first eight or more digits of the SHA256 hash of the contents of the file.",torch.utils.model_zoo.load_url.yaml,2
1262,32,0.0014347202295552368,3,"frozenset({'sha', 'file'})","If True, the filename part of the URL should follow the naming convention `filename-<sha256>.ext` where `<sha256>` is the first eight or more digits of the SHA256 hash of the contents of the file.",torch.hub.load_state_dict_from_url.yaml,2
1263,520,0.0014347202295552368,3,"frozenset({'inputs', 'default'})",Default: `False` Infinite losses mainly occur when the inputs are too short to be aligned to the targets.,torch.nn.functional.ctc_loss.yaml,2
1264,520,0.0014347202295552368,3,"frozenset({'inputs', 'default'})","When running identical inputs through the differentiation, the results must either match exactly (default, 0.0) or be within this tolerance.",torch.autograd.gradgradcheck.yaml,2
1265,520,0.0014347202295552368,3,"frozenset({'inputs', 'default'})","When running identical inputs through the differentiation, the results must either match exactly (default, 0.0) or be within this tolerance.",torch.autograd.gradcheck.yaml,2
1266,529,0.0014347202295552368,3,"frozenset({'shape', 'number'})","the divisor, which may be either a number or a tensor of the same shape as the dividend",torch.fmod.yaml,2
1267,529,0.0014347202295552368,3,"frozenset({'shape', 'number'})",The number of repetitions for each element.repeats is broadcasted to fit the shape of the given axis.,torch.repeat_interleave.yaml,2
1268,529,0.0014347202295552368,3,"frozenset({'shape', 'number'})",the divisor that may be either a number or a Tensor of the same shape as the dividend,torch.remainder.yaml,2
1269,455,0.0014347202295552368,3,"frozenset({'dtype', 'torch'})","Otherwise, the dtype is inferred to be torch.int64.",torch.arange.yaml,2
1270,455,0.0014347202295552368,3,"frozenset({'dtype', 'torch'})",The original `torch.dtype`.,torch.can_cast.yaml,2
1271,455,0.0014347202295552368,3,"frozenset({'dtype', 'torch'})",The target `torch.dtype`.,torch.can_cast.yaml,2
1272,37,0.0014347202295552368,3,"frozenset({'rather', 'input', 'consider', 'geometrically', 'pixels', 'points', 'squares'})","Geometrically, we consider the pixels of the input  as squares rather than points.",torch.nn.functional.grid_sample.yaml,7
1273,37,0.0014347202295552368,3,"frozenset({'rather', 'input', 'consider', 'geometrically', 'pixels', 'points', 'squares'})","Geometrically, we consider the pixels of the input and output as squares rather than points.",torch.nn.quantized.functional.interpolate.yaml,7
1274,37,0.0014347202295552368,3,"frozenset({'rather', 'input', 'consider', 'geometrically', 'pixels', 'points', 'squares'})","Geometrically, we consider the pixels of the input and output as squares rather than points.",torch.nn.functional.interpolate.yaml,7
1275,446,0.0014347202295552368,3,"frozenset({'d', 'vector'})",1D vector.,torch.combinations.yaml,2
1276,446,0.0014347202295552368,3,"frozenset({'d', 'vector'})",1-D input vector,torch.ger.yaml,2
1277,446,0.0014347202295552368,3,"frozenset({'d', 'vector'})",1-D input vector,torch.ger.yaml,2
1278,439,0.0014347202295552368,3,"frozenset({'used', 'compute'})","If `False`, the graph used to compute the grad will be freed.",torch.autograd.backward.yaml,2
1279,439,0.0014347202295552368,3,"frozenset({'used', 'compute'})","If `False`, the graph used to compute the grad will be freed.",torch.autograd.grad.yaml,2
1280,439,0.0014347202295552368,3,"frozenset({'used', 'compute'})"," When scale_factor is passed as a parameter, it is used to compute the output_size.",torch.nn.functional.interpolate.yaml,2
1281,543,0.0014347202295552368,3,"frozenset({'default', 'SOME_STRUCTURE'})","Can be a single number or a tuple (padT, padH, padW), Default: 0",torch.nn.functional.avg_pool3d.yaml,2
1282,543,0.0014347202295552368,3,"frozenset({'default', 'SOME_STRUCTURE'})","List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)",torch.distributed.gather.yaml,2
1283,543,0.0014347202295552368,3,"frozenset({'default', 'SOME_STRUCTURE'})","List of tensors to scatter (default is None, must be specified on the source rank)",torch.distributed.scatter.yaml,2
1284,3,0.0014347202295552368,3,"frozenset({'none', 'treated', 'default'})",Default: `None` (treated as equal to `floor(n_fft / 4)`),torch.stft.yaml,3
1285,3,0.0014347202295552368,3,"frozenset({'none', 'treated', 'default'})",Default: `None`  (treated as equal to `n_fft`),torch.stft.yaml,3
1286,3,0.0014347202295552368,3,"frozenset({'none', 'treated', 'default'})",Default: `None` (treated as window of all 1  s),torch.stft.yaml,3
1287,9,0.0014347202295552368,3,"frozenset({'keyword', 'arguments'})",other keyword arguments such as: amount (int or float): quantity of parameters to prune across the specified parameters.,torch.nn.utils.prune.global_unstructured.yaml,2
1288,9,0.0014347202295552368,3,"frozenset({'keyword', 'arguments'})",(Note: passing keyword arguments to the model is not currently supported.,torch.onnx.export.yaml,2
1289,9,0.0014347202295552368,3,"frozenset({'keyword', 'arguments'})","(Python 3 only) optional keyword arguments passed over to `pickle_module.load()` and `pickle_module.Unpickler()`, e.g., `errors=...`.",torch.load.yaml,2
1290,11,0.0014347202295552368,3,"frozenset({'training', 'SOME_DTYPE'})","a function for evaluating the prepared model, can be a function that simply runs the prepared model or a training loop",torch.quantization.quantize.yaml,2
1291,11,0.0014347202295552368,3,"frozenset({'training', 'SOME_DTYPE'})",export the model in training mode.,torch.onnx.export.yaml,2
1292,11,0.0014347202295552368,3,"frozenset({'training', 'SOME_DTYPE'})","a function for evaluating the prepared model, can be a function that simply runs the prepared model or a training loop",torch.quantization.quantize_qat.yaml,2
1293,13,0.0014347202295552368,3,"frozenset({'number', 'iterations'})",number of power iterations to calculate spectral norm,torch.nn.utils.spectral_norm.yaml,2
1294,13,0.0014347202295552368,3,"frozenset({'number', 'iterations'})",maximum number of iterations.,torch.lobpcg.yaml,2
1295,13,0.0014347202295552368,3,"frozenset({'number', 'iterations'})","the number of subspace iterations to conduct; niter must be a nonnegative integer, and defaults to 2.",torch.pca_lowrank.yaml,2
1296,15,0.0014347202295552368,3,"frozenset({'kw', 'kh', 'kt'})","Can be a single number or a tuple (kT, kH, kW)",torch.nn.functional.avg_pool3d.yaml,3
1297,15,0.0014347202295552368,3,"frozenset({'kw', 'kh', 'kt'})","filters of shape (in _channels ,  out _channels/groups , kT , kH , kW) ",torch.nn.functional.conv_transpose3d.yaml,3
1298,15,0.0014347202295552368,3,"frozenset({'kw', 'kh', 'kt'})","filters of shape (out _channels ,  in _channels/groups , kT , kH , kW) ",torch.nn.functional.conv3d.yaml,3
1299,444,0.0014347202295552368,3,"frozenset({'true', 'loss'})","When `size_average` is `True`, the loss is averaged over non-ignored targets.",torch.nn.functional.nll_loss.yaml,2
1300,444,0.0014347202295552368,3,"frozenset({'true', 'loss'})","When `size_average` is `True`, the loss is averaged over non-ignored targets.",torch.nn.functional.cross_entropy.yaml,2
1301,444,0.0014347202295552368,3,"frozenset({'true', 'loss'})","if `True` the loss is computed as  exp(input) - target * input , if `False` then loss is input - target *  log(input+eps) .",torch.nn.functional.poisson_nll_loss.yaml,2
1302,445,0.0014347202295552368,3,"frozenset({'shape', 'd', 'n'})","flow-field of shape (N, H_out, W_out, 2)  (4-D case) or (N, D_out, H_out, W_out, 3)  (5-D case)",torch.nn.functional.grid_sample.yaml,3
1303,445,0.0014347202295552368,3,"frozenset({'shape', 'd', 'n'})","input of shape (N, C, H_in, W_in)  (4-D case) or (N, C, D_in, H_in, W_in)  (5-D case)",torch.nn.functional.grid_sample.yaml,3
1304,445,0.0014347202295552368,3,"frozenset({'shape', 'd', 'n'})",input batch of affine matrices with shape (N  times 2  times 3 ) for 2D or (N  times 3  times 4 ) for 3D,torch.nn.functional.affine_grid.yaml,3
1305,16,0.0014347202295552368,3,"frozenset({'whether', 'determines'})",Determines whether CUDA headers and libraries are added to the build.,torch.utils.cpp_extension.load_inline.yaml,2
1306,16,0.0014347202295552368,3,"frozenset({'whether', 'determines'})",Determines whether pytorch error and warning macros are handled by pytorch instead of pybind.,torch.utils.cpp_extension.load_inline.yaml,2
1307,16,0.0014347202295552368,3,"frozenset({'whether', 'determines'})",Determines whether CUDA headers and libraries are added to the build.,torch.utils.cpp_extension.load.yaml,2
1308,447,0.0014347202295552368,3,"frozenset({'d', 'size'})","float 1D tensor of scales to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,2
1309,447,0.0014347202295552368,3,"frozenset({'d', 'size'})","integer 1D tensor of offset to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,2
1310,447,0.0014347202295552368,3,"frozenset({'d', 'size'})","(N  times C  times H  times W  for 2D or N  times C  times D  times H  times W  for 3D) Example: torch.Size((32, 3, 24, 24))",torch.nn.functional.affine_grid.yaml,2
1311,531,0.0014347202295552368,3,"frozenset({'true', 'whether'})",whether or not to display a progress bar to stderr Default: True,torch.hub.download_url_to_file.yaml,2
1312,531,0.0014347202295552368,3,"frozenset({'true', 'whether'})",controls whether to return half of results to avoid redundancy Default: `True`,torch.stft.yaml,2
1313,531,0.0014347202295552368,3,"frozenset({'true', 'whether'})","Flag whether to enable grad (`True`), or disable (`False`).",torch.set_grad_enabled.yaml,2
1314,17,0.0014347202295552368,3,"frozenset({'since', 'default'})"," By default, `fork_rng()` operates on all devices, but will emit a warning if your machine has a lot of devices, since this function will run very slowly in that case.",torch.random.fork_rng.yaml,2
1315,17,0.0014347202295552368,3,"frozenset({'since', 'default'})"," By default, `fork_rng()` operates on all devices, but will emit a warning if your machine has a lot of devices, since this function will run very slowly in that case.",torch.random.fork_rng2.yaml,2
1316,17,0.0014347202295552368,3,"frozenset({'since', 'default'})","Since ONNX's latest opset may evolve before next stable release, by default we export to one stable opset version.",torch.onnx.export.yaml,2
1317,18,0.0014347202295552368,3,"frozenset({'remap', 'locations', 'function', 'specifying', 'storage', 'torch', 'SOME_STRUCTURE'})",a function or a dict specifying how to remap storage locations (see torch.load),torch.utils.model_zoo.load_url.yaml,7
1318,18,0.0014347202295552368,3,"frozenset({'remap', 'locations', 'function', 'specifying', 'storage', 'torch', 'SOME_STRUCTURE'})","a function, `torch.device`, string or a dict specifying how to remap storage locations",torch.load.yaml,7
1319,18,0.0014347202295552368,3,"frozenset({'remap', 'locations', 'function', 'specifying', 'storage', 'torch', 'SOME_STRUCTURE'})",a function or a dict specifying how to remap storage locations (see torch.load),torch.hub.load_state_dict_from_url.yaml,7
1320,108,0.0014347202295552368,3,"frozenset({'SOME_DTYPE', 'ones'})","parameters of the model to prune in a global fashion, i.e. by aggregating all weights prior to deciding which ones to prune.",torch.nn.utils.prune.global_unstructured.yaml,2
1321,108,0.0014347202295552368,3,"frozenset({'SOME_DTYPE', 'ones'})",None values can be specified for scalar Tensors or ones that don't require grad.,torch.autograd.backward.yaml,2
1322,108,0.0014347202295552368,3,"frozenset({'SOME_DTYPE', 'ones'})",None values can be specified for scalar Tensors or ones that don't require grad.,torch.autograd.grad.yaml,2
1323,534,0.0014347202295552368,3,"frozenset({'type', 'SOME_STRUCTURE'})","a dictionary that maps from float module type to quantized module type, can be overwrritten to allow swapping user defined Modules",torch.quantization.convert.yaml,2
1324,534,0.0014347202295552368,3,"frozenset({'type', 'SOME_STRUCTURE'})","dictionary that maps from name or type of submodule to quantization configuration, qconfig applies to all submodules of a given module unless qconfig for the submodules are specified (when the submodule already has qconfig attribute)",torch.quantization.propagate_qconfig_.yaml,2
1325,534,0.0014347202295552368,3,"frozenset({'type', 'SOME_STRUCTURE'})",any python sequence of tensors of the same type.,torch.cat.yaml,2
1326,106,0.0014347202295552368,3,"frozenset({'zeroed', 'probability'})",probability of an element to be zeroed.,torch.nn.functional.dropout.yaml,2
1327,106,0.0014347202295552368,3,"frozenset({'zeroed', 'probability'})",probability of a channel to be zeroed.,torch.nn.functional.dropout2d.yaml,2
1328,106,0.0014347202295552368,3,"frozenset({'zeroed', 'probability'})",probability of a channel to be zeroed.,torch.nn.functional.dropout3d.yaml,2
1329,103,0.0014347202295552368,3,"frozenset({'numerator', 'tensor'})",the numerator tensor,torch.addcdiv.yaml,2
1330,103,0.0014347202295552368,3,"frozenset({'numerator', 'tensor'})",the numerator tensor,torch.div2.yaml,2
1331,103,0.0014347202295552368,3,"frozenset({'numerator', 'tensor'})",the numerator tensor,torch.floor_divide.yaml,2
1332,21,0.0014347202295552368,3,"frozenset({'setting', 'option'})",A grid generated by `affine_grid()` should be passed to `grid_sample()` with the same setting for this option.,torch.nn.functional.affine_grid.yaml,2
1333,21,0.0014347202295552368,3,"frozenset({'setting', 'option'})",Note that in nearly all cases setting this option to `True` is not needed and often can be worked around in a much more efficient way.,torch.autograd.backward.yaml,2
1334,21,0.0014347202295552368,3,"frozenset({'setting', 'option'})",Note that in nearly all cases setting this option to `True` is not needed and often can be worked around in a much more efficient way.,torch.autograd.grad.yaml,2
1335,102,0.0014347202295552368,3,"frozenset({'distribution', 'normal'})",the mean of the normal distribution,torch.nn.init.normal_.yaml,2
1336,102,0.0014347202295552368,3,"frozenset({'distribution', 'normal'})",the standard deviation of the normal distribution,torch.nn.init.normal_.yaml,2
1337,102,0.0014347202295552368,3,"frozenset({'distribution', 'normal'})",the standard deviation of the normal distribution used to generate the non-zero values,torch.nn.init.sparse_.yaml,2
1338,100,0.0014347202295552368,3,"frozenset({'additional', 'added', 'dimension', 'shape', 'side', 'size', 'output', 'one'})",additional size added to one side of each dimension in the output shape.,torch.nn.functional.conv_transpose2d.yaml,8
1339,100,0.0014347202295552368,3,"frozenset({'additional', 'added', 'dimension', 'shape', 'side', 'size', 'output', 'one'})",additional size added to one side of each dimension in the output shape.,torch.nn.functional.conv_transpose3d.yaml,8
1340,100,0.0014347202295552368,3,"frozenset({'additional', 'added', 'dimension', 'shape', 'side', 'size', 'output', 'one'})",additional size added to one side of each dimension in the output shape.,torch.nn.functional.conv_transpose1d.yaml,8
1341,532,0.0014347202295552368,3,"frozenset({'whether', 'false'})",whether to return an abbreviated summary (default: False).,torch.cuda.memory_summary.yaml,2
1342,532,0.0014347202295552368,3,"frozenset({'whether', 'false'})",controls whether to return the normalized STFT results Default: `False`,torch.stft.yaml,2
1343,532,0.0014347202295552368,3,"frozenset({'whether', 'false'})","Flag whether to enable grad (`True`), or disable (`False`).",torch.set_grad_enabled.yaml,2
1344,465,0.0014347202295552368,3,"frozenset({'operation', 'value'})",the scalar base value for the power operation,torch.pow2.yaml,2
1345,465,0.0014347202295552368,3,"frozenset({'operation', 'value'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.quantized.functional.interpolate.yaml,2
1346,465,0.0014347202295552368,3,"frozenset({'operation', 'value'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.functional.interpolate.yaml,2
1347,85,0.0014347202295552368,3,"frozenset({'padw', 'single', 'padt', 'padh', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple (padT, padH, padW), Default: 0",torch.nn.functional.avg_pool3d.yaml,6
1348,85,0.0014347202295552368,3,"frozenset({'padw', 'single', 'padt', 'padh', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple `(padT, padH, padW)`.",torch.nn.functional.conv_transpose3d.yaml,6
1349,85,0.0014347202295552368,3,"frozenset({'padw', 'single', 'padt', 'padh', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple (padT, padH, padW).",torch.nn.functional.conv3d.yaml,6
1350,40,0.0014347202295552368,3,"frozenset({'reduceop', 'distributed', 'enum', 'values', 'torch', 'one'})",One of the values from `torch.distributed.ReduceOp` enum.,torch.distributed.all_reduce.yaml,6
1351,40,0.0014347202295552368,3,"frozenset({'reduceop', 'distributed', 'enum', 'values', 'torch', 'one'})",One of the values from `torch.distributed.ReduceOp` enum.,torch.distributed.reduce.yaml,6
1352,40,0.0014347202295552368,3,"frozenset({'reduceop', 'distributed', 'enum', 'values', 'torch', 'one'})",One of the values from `torch.distributed.ReduceOp` enum.,torch.distributed.reduce_multigpu.yaml,6
1353,518,0.0014347202295552368,3,"frozenset({'input', 'set', 'value', 'tensor'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.quantized.functional.interpolate.yaml,4
1354,518,0.0014347202295552368,3,"frozenset({'input', 'set', 'value', 'tensor'})","If set to -1, the number of classes will be inferred as one greater than the largest class value in the input tensor.",torch.nn.functional.one_hot.yaml,4
1355,518,0.0014347202295552368,3,"frozenset({'input', 'set', 'value', 'tensor'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.functional.interpolate.yaml,4
1356,495,0.0014347202295552368,3,"frozenset({'number', 'must'})","If X  is specifed, the value of n (when specified) must be the number of X  columns.",torch.lobpcg.yaml,2
1357,495,0.0014347202295552368,3,"frozenset({'number', 'must'})",Must be a vector with length equal to the number of classes.,torch.nn.functional.binary_cross_entropy_with_logits.yaml,2
1358,495,0.0014347202295552368,3,"frozenset({'number', 'must'})","the number of subspace iterations to conduct; niter must be a nonnegative integer, and defaults to 2.",torch.pca_lowrank.yaml,2
1359,65,0.0014347202295552368,3,"frozenset({'w', 'h', 'd', 'n', 'c'})","(N  times C  times H  times W  for 2D or N  times C  times D  times H  times W  for 3D) Example: torch.Size((32, 3, 24, 24))",torch.nn.functional.affine_grid.yaml,5
1360,65,0.0014347202295552368,3,"frozenset({'w', 'h', 'd', 'n', 'c'})","(N, C)  where C = number of classes or (N, C, H, W)  in case of 2D Loss, or (N, C, d_1, d_2, ..., d_K)  where K  >= 1  in the case of K-dimensional loss.",torch.nn.functional.nll_loss.yaml,5
1361,65,0.0014347202295552368,3,"frozenset({'w', 'h', 'd', 'n', 'c'})","(N, C)  where C = number of classes or (N, C, H, W)  in case of 2D Loss, or (N, C, d_1, d_2, ..., d_K)  where K  >= 1  in the case of K-dimensional loss.",torch.nn.functional.cross_entropy.yaml,5
1362,64,0.0014347202295552368,3,"frozenset({'true', 'apply', 'dropout'})",apply dropout if is `True`.,torch.nn.functional.dropout.yaml,3
1363,64,0.0014347202295552368,3,"frozenset({'true', 'apply', 'dropout'})",apply dropout if is `True`.,torch.nn.functional.dropout2d.yaml,3
1364,64,0.0014347202295552368,3,"frozenset({'true', 'apply', 'dropout'})",apply dropout if is `True`.,torch.nn.functional.dropout3d.yaml,3
1365,63,0.0014347202295552368,3,"frozenset({'vision', 'example', 'pytorch', 'hub'})",Example: 'pytorch/vision[:hub]',torch.hub.load.yaml,4
1366,63,0.0014347202295552368,3,"frozenset({'vision', 'example', 'pytorch', 'hub'})",Example: 'pytorch/vision[:hub]',torch.hub.help.yaml,4
1367,63,0.0014347202295552368,3,"frozenset({'vision', 'example', 'pytorch', 'hub'})",Example: 'pytorch/vision[:hub]',torch.hub.list.yaml,4
1368,499,0.0014347202295552368,3,"frozenset({'input', 'given'})","If dtype is not given, infer the data type from the other input arguments.",torch.arange.yaml,2
1369,499,0.0014347202295552368,3,"frozenset({'input', 'given'})",Default is feps ** 0.5 where feps is smallest non-zero floating-point number of the given input tensor A data type.,torch.lobpcg.yaml,2
1370,499,0.0014347202295552368,3,"frozenset({'input', 'given'})","if given, the input will be squeezed only in this dimension",torch.squeeze.yaml,2
1371,500,0.0014347202295552368,3,"frozenset({'type', 'given'})","If dtype is not given, infer the data type from the other input arguments.",torch.arange.yaml,2
1372,500,0.0014347202295552368,3,"frozenset({'type', 'given'})",Default is feps ** 0.5 where feps is smallest non-zero floating-point number of the given input tensor A data type.,torch.lobpcg.yaml,2
1373,500,0.0014347202295552368,3,"frozenset({'type', 'given'})","dictionary that maps from name or type of submodule to quantization configuration, qconfig applies to all submodules of a given module unless qconfig for the submodules are specified (when the submodule already has qconfig attribute)",torch.quantization.propagate_qconfig_.yaml,2
1374,59,0.0014347202295552368,3,"frozenset({'data', 'infers', 'none', 'type', 'default'})","Default: if `None`, infers data type from `data`.",torch.as_tensor.yaml,5
1375,59,0.0014347202295552368,3,"frozenset({'data', 'infers', 'none', 'type', 'default'})","Default: if `None`, infers data type from `data`.",torch.tensor.yaml,5
1376,59,0.0014347202295552368,3,"frozenset({'data', 'infers', 'none', 'type', 'default'})","Default: if None, infers data type from `values`.",torch.sparse_coo_tensor.yaml,5
1377,56,0.0014347202295552368,3,"frozenset({'input', 'added', 'dimension', 'zero', 'kernel_size', 'dilation', 'padding', 'sides'})",`dilation * (kernel_size - 1) - padding` zero-padding will be added to both sides of each dimension in the input.,torch.nn.functional.conv_transpose2d.yaml,8
1378,56,0.0014347202295552368,3,"frozenset({'input', 'added', 'dimension', 'zero', 'kernel_size', 'dilation', 'padding', 'sides'})",`dilation * (kernel_size - 1) - padding` zero-padding will be added to both sides of each dimension in the input.,torch.nn.functional.conv_transpose3d.yaml,8
1379,56,0.0014347202295552368,3,"frozenset({'input', 'added', 'dimension', 'zero', 'kernel_size', 'dilation', 'padding', 'sides'})",`dilation * (kernel_size - 1) - padding` zero-padding will be added to both sides of each dimension in the input.,torch.nn.functional.conv_transpose1d.yaml,8
1380,53,0.0014347202295552368,3,"frozenset({'process', 'gpus'})","If using multiple processes per machine with `nccl` backend, each process must have exclusive access to every GPU it uses, as sharing GPUs between processes can result in deadlocks.",torch.distributed.init_process_group.yaml,2
1381,53,0.0014347202295552368,3,"frozenset({'process', 'gpus'})","If `src` is the rank, then the specified `src_tensor` element of `tensor_list` (`tensor_list[src_tensor]`) will be broadcast to all other tensors (on different GPUs) in the src process and all tensors in `tensor_list` of other non-src processes.",torch.distributed.broadcast_multigpu.yaml,2
1382,53,0.0014347202295552368,3,"frozenset({'process', 'gpus'})",List of tensors(on different GPUs) to be broadcast from current process.,torch.distributed.all_gather_multigpu.yaml,2
1383,50,0.0014347202295552368,3,"frozenset({'contents', 'part', 'filename'})",Map from filename to contents which will be stored as part of 'f'.,torch.jit.save.yaml,3
1384,50,0.0014347202295552368,3,"frozenset({'contents', 'part', 'filename'})","If True, the filename part of the URL should follow the naming convention `filename-<sha256>.ext` where `<sha256>` is the first eight or more digits of the SHA256 hash of the contents of the file.",torch.utils.model_zoo.load_url.yaml,3
1385,50,0.0014347202295552368,3,"frozenset({'contents', 'part', 'filename'})","If True, the filename part of the URL should follow the naming convention `filename-<sha256>.ext` where `<sha256>` is the first eight or more digits of the SHA256 hash of the contents of the file.",torch.hub.load_state_dict_from_url.yaml,3
1386,505,0.0014347202295552368,3,"frozenset({'input', 'return'})","The dimension along which to repeat values.By default, use the flattened input array, and return a flat outputarray.",torch.repeat_interleave.yaml,2
1387,505,0.0014347202295552368,3,"frozenset({'input', 'return'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique.yaml,2
1388,505,0.0014347202295552368,3,"frozenset({'input', 'return'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique_consecutive.yaml,2
1389,493,0.0014347202295552368,3,"frozenset({'type', 'SOME_DTYPE', 'must'})","module must be of type `nn.Module`, and name must be a string.",torch.nn.utils.prune.global_unstructured.yaml,3
1390,493,0.0014347202295552368,3,"frozenset({'type', 'SOME_DTYPE', 'must'})",The tensor type must be torch.float.,torch.nn.quantized.functional.conv2d.yaml,3
1391,493,0.0014347202295552368,3,"frozenset({'type', 'SOME_DTYPE', 'must'})",The tensor type must be torch.float.,torch.nn.quantized.functional.conv3d.yaml,3
1392,38,0.0014347202295552368,3,"frozenset({'generator', 'number', 'sampling', 'pseudorandom'})",a pseudorandom number generator for sampling,torch.bernoulli.yaml,4
1393,38,0.0014347202295552368,3,"frozenset({'generator', 'number', 'sampling', 'pseudorandom'})",a pseudorandom number generator for sampling,torch.normal.yaml,4
1394,38,0.0014347202295552368,3,"frozenset({'generator', 'number', 'sampling', 'pseudorandom'})",a pseudorandom number generator for sampling,torch.multinomial.yaml,4
1395,47,0.0014347202295552368,3,"frozenset({'forward', 'optional', 'flags', 'SOME_STRUCTURE'})",optional list of compiler flags to forward to the build.,torch.utils.cpp_extension.load.yaml,4
1396,47,0.0014347202295552368,3,"frozenset({'forward', 'optional', 'flags', 'SOME_STRUCTURE'})",optional list of compiler flags to forward to nvcc when building CUDA sources.,torch.utils.cpp_extension.load.yaml,4
1397,47,0.0014347202295552368,3,"frozenset({'forward', 'optional', 'flags', 'SOME_STRUCTURE'})",optional list of linker flags to forward to the build.,torch.utils.cpp_extension.load.yaml,4
1398,45,0.0014347202295552368,3,"frozenset({'force', 'whether', 'fresh', 'download'})",whether to force a fresh download of github repo unconditionally.,torch.hub.load.yaml,4
1399,45,0.0014347202295552368,3,"frozenset({'force', 'whether', 'fresh', 'download'})",whether to discard the existing cache and force a fresh download.,torch.hub.help.yaml,4
1400,45,0.0014347202295552368,3,"frozenset({'force', 'whether', 'fresh', 'download'})",whether to discard the existing cache and force a fresh download.,torch.hub.list.yaml,4
1401,44,0.0014347202295552368,3,"frozenset({'display', 'bar', 'stderr', 'whether', 'progress'})",whether or not to display a progress bar to stderr Default: True,torch.hub.download_url_to_file.yaml,5
1402,44,0.0014347202295552368,3,"frozenset({'display', 'bar', 'stderr', 'whether', 'progress'})",whether or not to display a progress bar to stderr.,torch.utils.model_zoo.load_url.yaml,5
1403,44,0.0014347202295552368,3,"frozenset({'display', 'bar', 'stderr', 'whether', 'progress'})",whether or not to display a progress bar to stderr.,torch.hub.load_state_dict_from_url.yaml,5
1404,43,0.0014347202295552368,3,"frozenset({'quantize', 'SOME_DTYPE'})",float tensor to quantize,torch.quantize_per_channel.yaml,2
1405,43,0.0014347202295552368,3,"frozenset({'quantize', 'SOME_DTYPE'})",input module with qconfig attributes for all the leaf modules that we want to quantize,torch.quantization.add_observer_.yaml,2
1406,43,0.0014347202295552368,3,"frozenset({'quantize', 'SOME_DTYPE'})",float tensor to quantize,torch.quantize_per_tensor.yaml,2
1407,510,0.0014347202295552368,3,"frozenset({'elements', 'tensor'})","If `get_infos` is `True`, then the elements in the tuple are Tensor, IntTensor, and IntTensor.",torch.lu.yaml,2
1408,510,0.0014347202295552368,3,"frozenset({'elements', 'tensor'})","If `get_infos` is `False`, then the elements in the tuple are Tensor, IntTensor.",torch.lu.yaml,2
1409,510,0.0014347202295552368,3,"frozenset({'elements', 'tensor'})",The number of places by which the elements of the tensor are shifted.,torch.roll.yaml,2
1410,511,0.0014347202295552368,3,"frozenset({'elements', 'input', 'SOME_STRUCTURE'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique.yaml,3
1411,511,0.0014347202295552368,3,"frozenset({'elements', 'input', 'SOME_STRUCTURE'})","m-elements tuple, where  m/2  <=  input dimensions and m  is even.",torch.nn.functional.pad.yaml,3
1412,511,0.0014347202295552368,3,"frozenset({'elements', 'input', 'SOME_STRUCTURE'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique_consecutive.yaml,3
1413,512,0.0014347202295552368,3,"frozenset({'value', 'zero'})",small value to avoid division by zero.,torch.nn.functional.normalize.yaml,2
1414,512,0.0014347202295552368,3,"frozenset({'value', 'zero'})",Small value to avoid division by zero.,torch.nn.functional.cosine_similarity.yaml,2
1415,512,0.0014347202295552368,3,"frozenset({'value', 'zero'})",offset in integer value that maps to float zero,torch.quantize_per_tensor.yaml,2
1416,513,0.0014347202295552368,3,"frozenset({'specified', 'SOME_STRUCTURE'})","List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)",torch.distributed.gather.yaml,2
1417,513,0.0014347202295552368,3,"frozenset({'specified', 'SOME_STRUCTURE'})","dictionary that maps from name or type of submodule to quantization configuration, qconfig applies to all submodules of a given module unless qconfig for the submodules are specified (when the submodule already has qconfig attribute)",torch.quantization.propagate_qconfig_.yaml,2
1418,513,0.0014347202295552368,3,"frozenset({'specified', 'SOME_STRUCTURE'})","List of tensors to scatter (default is None, must be specified on the source rank)",torch.distributed.scatter.yaml,2
1419,514,0.0014347202295552368,3,"frozenset({'none', 'specified', 'default'})","List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)",torch.distributed.gather.yaml,3
1420,514,0.0014347202295552368,3,"frozenset({'none', 'specified', 'default'})","If None (default) is specified, the value is defined by _Formatter",torch.set_printoptions.yaml,3
1421,514,0.0014347202295552368,3,"frozenset({'none', 'specified', 'default'})","List of tensors to scatter (default is None, must be specified on the source rank)",torch.distributed.scatter.yaml,3
1422,494,0.0014347202295552368,3,"frozenset({'torch', 'must'})",The opset_version must be _onnx_master_opset or in _onnx_stable_opsets which are defined in torch/onnx/symbolic_helper.py,torch.onnx.export.yaml,2
1423,494,0.0014347202295552368,3,"frozenset({'torch', 'must'})",The tensor type must be torch.float.,torch.nn.quantized.functional.conv2d.yaml,2
1424,494,0.0014347202295552368,3,"frozenset({'torch', 'must'})",The tensor type must be torch.float.,torch.nn.quantized.functional.conv3d.yaml,2
1425,492,0.0014347202295552368,3,"frozenset({'SOME_STRUCTURE', 'must'})","List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)",torch.distributed.gather.yaml,2
1426,492,0.0014347202295552368,3,"frozenset({'SOME_STRUCTURE', 'must'})","List of tensors to scatter (default is None, must be specified on the source rank)",torch.distributed.scatter.yaml,2
1427,492,0.0014347202295552368,3,"frozenset({'SOME_STRUCTURE', 'must'})","If shifts is a tuple, dims must be a tuple of the same size, and each dimension will be rolled by the corresponding value",torch.roll.yaml,2
1428,84,0.0014347202295552368,3,"frozenset({'shape', 'arbitrary', 'tensor'})",Tensor of arbitrary shape,torch.nn.functional.kl_div.yaml,3
1429,84,0.0014347202295552368,3,"frozenset({'shape', 'arbitrary', 'tensor'})",Tensor of arbitrary shape,torch.nn.functional.binary_cross_entropy.yaml,3
1430,84,0.0014347202295552368,3,"frozenset({'shape', 'arbitrary', 'tensor'})",Tensor of arbitrary shape,torch.nn.functional.binary_cross_entropy_with_logits.yaml,3
1431,478,0.0014347202295552368,3,"frozenset({'values', 'true'})",values selected at indices where `condition` is `True`,torch.where.yaml,2
1432,478,0.0014347202295552368,3,"frozenset({'values', 'true'})","If set to `True`, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels.",torch.nn.quantized.functional.interpolate.yaml,2
1433,478,0.0014347202295552368,3,"frozenset({'values', 'true'})","If set to `True`, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels.",torch.nn.functional.interpolate.yaml,2
1434,83,0.0014347202295552368,3,"frozenset({'scaling', 'optional', 'factor'})",optional scaling factor,torch.nn.init.orthogonal_.yaml,3
1435,83,0.0014347202295552368,3,"frozenset({'scaling', 'optional', 'factor'})",an optional scaling factor,torch.nn.init.xavier_normal_.yaml,3
1436,83,0.0014347202295552368,3,"frozenset({'scaling', 'optional', 'factor'})",an optional scaling factor,torch.nn.init.xavier_uniform_.yaml,3
1437,82,0.0014347202295552368,3,"frozenset({'received', 'tensor', 'data'})",Tensor to fill with received data.,torch.distributed.recv.yaml,3
1438,82,0.0014347202295552368,3,"frozenset({'received', 'tensor', 'data'})",Tensor to fill with received data.,torch.distributed.irecv.yaml,3
1439,82,0.0014347202295552368,3,"frozenset({'received', 'tensor', 'data'})","Data to be sent if `src` is the rank of current process, and tensor to be used to save received data otherwise.",torch.distributed.broadcast.yaml,3
1440,78,0.0014347202295552368,3,"frozenset({'out_padw', 'single', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple `(out_padH, out_padW)`.",torch.nn.functional.conv_transpose2d.yaml,4
1441,78,0.0014347202295552368,3,"frozenset({'out_padw', 'single', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple `(out_padT, out_padH, out_padW)`.",torch.nn.functional.conv_transpose3d.yaml,4
1442,78,0.0014347202295552368,3,"frozenset({'out_padw', 'single', 'number', 'SOME_STRUCTURE'})",Can be a single number or a tuple `(out_padW)`.,torch.nn.functional.conv_transpose1d.yaml,4
1443,471,0.0014347202295552368,3,"frozenset({'note', 'SOME_DTYPE'})","Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.",torch.cuda.comm.broadcast_coalesced.yaml,2
1444,471,0.0014347202295552368,3,"frozenset({'note', 'SOME_DTYPE'})",(Note: passing keyword arguments to the model is not currently supported.,torch.onnx.export.yaml,2
1445,471,0.0014347202295552368,3,"frozenset({'note', 'SOME_DTYPE'})","Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.",torch.cuda.comm.broadcast.yaml,2
1446,472,0.0014347202295552368,3,"frozenset({'note', 'first'})","Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.",torch.cuda.comm.broadcast_coalesced.yaml,2
1447,472,0.0014347202295552368,3,"frozenset({'note', 'first'})",Note that the message about first download is cannot be muted.,torch.hub.load.yaml,2
1448,472,0.0014347202295552368,3,"frozenset({'note', 'first'})","Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.",torch.cuda.comm.broadcast.yaml,2
1449,473,0.0014347202295552368,3,"frozenset({'name', 'type'})","module must be of type `nn.Module`, and name must be a string.",torch.nn.utils.prune.global_unstructured.yaml,2
1450,473,0.0014347202295552368,3,"frozenset({'name', 'type'})","dictionary that maps from name or type of submodule to quantization configuration, qconfig applies to all submodules of a given module unless qconfig for the submodules are specified (when the submodule already has qconfig attribute)",torch.quantization.propagate_qconfig_.yaml,2
1451,473,0.0014347202295552368,3,"frozenset({'name', 'type'})",the floating point tensor type or its name,torch.set_default_tensor_type.yaml,2
1452,474,0.0014347202295552368,3,"frozenset({'first', 'SOME_DTYPE'})","Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.",torch.cuda.comm.broadcast_coalesced.yaml,2
1453,474,0.0014347202295552368,3,"frozenset({'first', 'SOME_DTYPE'})","In this case, the exported model will first take all of its parameters as arguments, the ordering as specified by `model.state_dict().values()`",torch.onnx.export.yaml,2
1454,474,0.0014347202295552368,3,"frozenset({'first', 'SOME_DTYPE'})","Note that it should be like (src, dst1, dst2,  u2026), the first element of which is the source device to broadcast from.",torch.cuda.comm.broadcast.yaml,2
1455,73,0.0014347202295552368,3,"frozenset({'buffers', 'tensor', 'given', 'optionally', 'used', 'output', 'SOME_DTYPE', 'SOME_STRUCTURE'})","the output tuple of (Tensor, LongTensor) that can be optionally given to be used as output buffers",torch.topk.yaml,8
1456,73,0.0014347202295552368,3,"frozenset({'buffers', 'tensor', 'given', 'optionally', 'used', 'output', 'SOME_DTYPE', 'SOME_STRUCTURE'})","the output tuple of (Tensor, LongTensor) that can be optionally given to be used as output buffers",torch.sort.yaml,8
1457,73,0.0014347202295552368,3,"frozenset({'buffers', 'tensor', 'given', 'optionally', 'used', 'output', 'SOME_DTYPE', 'SOME_STRUCTURE'})","the output tuple of (Tensor, LongTensor) can be optionally given to be used as output buffers",torch.kthvalue.yaml,8
1458,72,0.0014347202295552368,3,"frozenset({'specifies', 'operation', 'element', 'reductions', 'wise', 'used'})", Specifies an operation used for element-wise reductions.,torch.distributed.all_reduce.yaml,6
1459,72,0.0014347202295552368,3,"frozenset({'specifies', 'operation', 'element', 'reductions', 'wise', 'used'})", Specifies an operation used for element-wise reductions.,torch.distributed.reduce.yaml,6
1460,72,0.0014347202295552368,3,"frozenset({'specifies', 'operation', 'element', 'reductions', 'wise', 'used'})", Specifies an operation used for element-wise reductions.,torch.distributed.reduce_multigpu.yaml,6
1461,477,0.0014347202295552368,3,"frozenset({'containing', 'SOME_STRUCTURE'})","A string, or list of strings, containing C++ source code.",torch.utils.cpp_extension.load_inline.yaml,2
1462,477,0.0014347202295552368,3,"frozenset({'containing', 'SOME_STRUCTURE'})","A string, or list of strings, containing CUDA source code.",torch.utils.cpp_extension.load_inline.yaml,2
1463,477,0.0014347202295552368,3,"frozenset({'containing', 'SOME_STRUCTURE'})",tuple containing inputs to the `function`,torch.utils.checkpoint.checkpoint.yaml,2
1464,479,0.0014347202295552368,3,"frozenset({'values', 'false'})",values selected at indices where `condition` is `False`,torch.where.yaml,2
1465,479,0.0014347202295552368,3,"frozenset({'values', 'false'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.quantized.functional.interpolate.yaml,2
1466,479,0.0014347202295552368,3,"frozenset({'values', 'false'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.functional.interpolate.yaml,2
1467,491,0.0014347202295552368,3,"frozenset({'inputs', 'must'})",Lengths of the inputs (must each be  <= T ),torch.nn.functional.ctc_loss.yaml,2
1468,491,0.0014347202295552368,3,"frozenset({'inputs', 'must'})","When running identical inputs through the differentiation, the results must either match exactly (default, 0.0) or be within this tolerance.",torch.autograd.gradgradcheck.yaml,2
1469,491,0.0014347202295552368,3,"frozenset({'inputs', 'must'})","When running identical inputs through the differentiation, the results must either match exactly (default, 0.0) or be within this tolerance.",torch.autograd.gradcheck.yaml,2
1470,480,0.0014347202295552368,3,"frozenset({'values', 'value'})",A floating point value to determine the cutoff for small singular values.,torch.pinverse.yaml,2
1471,480,0.0014347202295552368,3,"frozenset({'values', 'value'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.quantized.functional.interpolate.yaml,2
1472,480,0.0014347202295552368,3,"frozenset({'values', 'value'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.functional.interpolate.yaml,2
1473,481,0.0014347202295552368,3,"frozenset({'values', 'specified', 'SOME_DTYPE'})","In this case, the exported model will first take all of its parameters as arguments, the ordering as specified by `model.state_dict().values()`",torch.onnx.export.yaml,3
1474,481,0.0014347202295552368,3,"frozenset({'values', 'specified', 'SOME_DTYPE'})",None values can be specified for scalar Tensors or ones that don't require grad.,torch.autograd.backward.yaml,3
1475,481,0.0014347202295552368,3,"frozenset({'values', 'specified', 'SOME_DTYPE'})",None values can be specified for scalar Tensors or ones that don't require grad.,torch.autograd.grad.yaml,3
1476,482,0.0014347202295552368,3,"frozenset({'values', 'none'})",None values can be specified for scalar Tensors or ones that don't require grad.,torch.autograd.backward.yaml,2
1477,482,0.0014347202295552368,3,"frozenset({'values', 'none'})",None values can be specified for scalar Tensors or ones that don't require grad.,torch.autograd.grad.yaml,2
1478,482,0.0014347202295552368,3,"frozenset({'values', 'none'})","Default: if None, infers data type from `values`.",torch.sparse_coo_tensor.yaml,2
1479,483,0.0014347202295552368,3,"frozenset({'true', 'cuda'})","If True, includes CUDA-specific include paths.",torch.utils.cpp_extension.include_paths.yaml,2
1480,483,0.0014347202295552368,3,"frozenset({'true', 'cuda'})",Set it to `True` to force CUDA headers and libraries to be included.,torch.utils.cpp_extension.load_inline.yaml,2
1481,483,0.0014347202295552368,3,"frozenset({'true', 'cuda'})",Set it to True` to force CUDA headers and libraries to be included.,torch.utils.cpp_extension.load.yaml,2
1482,67,0.0014347202295552368,3,"frozenset({'branch', 'format', 'tag_name', 'repo_name', 'optional', 'tag', 'repo_owner', 'SOME_DTYPE'})","a string with format ""repo_owner/repo_name[:tag_name]"" with an optional tag/branch.",torch.hub.load.yaml,8
1483,67,0.0014347202295552368,3,"frozenset({'branch', 'format', 'tag_name', 'repo_name', 'optional', 'tag', 'repo_owner', 'SOME_DTYPE'})",a string with format <repo_owner/repo_name[:tag_name]> with an optional tag/branch.,torch.hub.help.yaml,8
1484,67,0.0014347202295552368,3,"frozenset({'branch', 'format', 'tag_name', 'repo_name', 'optional', 'tag', 'repo_owner', 'SOME_DTYPE'})","a string with format ""repo_owner/repo_name[:tag_name]"" with an optional tag/branch.",torch.hub.list.yaml,8
1485,486,0.0014347202295552368,3,"frozenset({'use', 'tensor'})","List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)",torch.distributed.gather.yaml,2
1486,486,0.0014347202295552368,3,"frozenset({'use', 'tensor'})","float 1D tensor of scales to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,2
1487,486,0.0014347202295552368,3,"frozenset({'use', 'tensor'})","integer 1D tensor of offset to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,2
1488,487,0.0014347202295552368,3,"frozenset({'use', 'data'})","List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)",torch.distributed.gather.yaml,2
1489,487,0.0014347202295552368,3,"frozenset({'use', 'data'})",quantization data type to use.,torch.nn.quantized.functional.conv2d.yaml,2
1490,487,0.0014347202295552368,3,"frozenset({'use', 'data'})",quantization data type to use.,torch.nn.quantized.functional.conv3d.yaml,2
1491,488,0.0014347202295552368,3,"frozenset({'use', 'SOME_DTYPE'})","float 1D tensor of scales to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,2
1492,488,0.0014347202295552368,3,"frozenset({'use', 'SOME_DTYPE'})","integer 1D tensor of offset to use, size should match `input.size(axis)`",torch.quantize_per_channel.yaml,2
1493,488,0.0014347202295552368,3,"frozenset({'use', 'SOME_DTYPE'})",use operator_export_type] export the model in aten mode.,torch.onnx.export.yaml,2
1494,66,0.0014347202295552368,3,"frozenset({'single', 'st', 'sh', 'number', 'sw', 'SOME_STRUCTURE'})","Can be a single number or a tuple (sT, sH, sW).",torch.nn.functional.avg_pool3d.yaml,6
1495,66,0.0014347202295552368,3,"frozenset({'single', 'st', 'sh', 'number', 'sw', 'SOME_STRUCTURE'})","Can be a single number or a tuple `(sT, sH, sW)`.",torch.nn.functional.conv_transpose3d.yaml,6
1496,66,0.0014347202295552368,3,"frozenset({'single', 'st', 'sh', 'number', 'sw', 'SOME_STRUCTURE'})","Can be a single number or a tuple (sT, sH, sW).",torch.nn.functional.conv3d.yaml,6
1497,490,0.0014347202295552368,3,"frozenset({'process', 'must'})","If another specific group is specified, the calling process must be part of `group`.",torch.distributed.get_backend.yaml,2
1498,490,0.0014347202295552368,3,"frozenset({'process', 'must'})","If using multiple processes per machine with `nccl` backend, each process must have exclusive access to every GPU it uses, as sharing GPUs between processes can result in deadlocks.",torch.distributed.init_process_group.yaml,2
1499,490,0.0014347202295552368,3,"frozenset({'process', 'must'})",Must be executable in a shell process.,torch.utils.cpp_extension.check_compiler_abi_compatibility.yaml,2
1500,484,0.0014347202295552368,3,"frozenset({'optional', 'value'})","If a None value would be acceptable for all grad_tensors, then this argument is optional.",torch.autograd.backward.yaml,2
1501,484,0.0014347202295552368,3,"frozenset({'optional', 'value'})","If a None value would be acceptable for all grad_tensors, then this argument is optional.",torch.autograd.grad.yaml,2
1502,484,0.0014347202295552368,3,"frozenset({'optional', 'value'})","optional, weight for each value in the input tensor.",torch.bincount.yaml,2
1503,299,0.0014347202295552368,3,"frozenset({'nn', 'SOME_STRUCTURE'})",a dictionary that maps from nn module to nnq module,torch.quantization.swap_module.yaml,2
1504,299,0.0014347202295552368,3,"frozenset({'nn', 'SOME_STRUCTURE'})",A `torch.nn.Sequential` or the list of modules or functions (comprising the model) to run sequentially.,torch.utils.checkpoint.checkpoint_sequential.yaml,2
1505,299,0.0014347202295552368,3,"frozenset({'nn', 'SOME_STRUCTURE'})","For example, fuser_func([convModule, BNModule]) returns the list [ConvBNModule, nn.Identity()] Defaults to torch.quantization.fuse_known_modules",torch.quantization.fuse_modules.yaml,2
1506,436,0.0014347202295552368,3,"frozenset({'along', 'dim'})",index of the dim along which we define channels to prune.,torch.nn.utils.prune.ln_structured.yaml,2
1507,436,0.0014347202295552368,3,"frozenset({'along', 'dim'})",index of the dim along which we define channels to prune.,torch.nn.utils.prune.random_structured.yaml,2
1508,436,0.0014347202295552368,3,"frozenset({'along', 'dim'})",A dimension along which softmin will be computed (so every slice along dim will sum to 1).,torch.nn.functional.softmin.yaml,2
1509,331,0.0014347202295552368,3,"frozenset({'true', 'x', 'b'})","output will be in `B x T x *` if True, or in `T x B x *` otherwise",torch.nn.utils.rnn.pad_sequence.yaml,3
1510,331,0.0014347202295552368,3,"frozenset({'true', 'x', 'b'})","if `True`, the input is expected in `B x T x *` format.",torch.nn.utils.rnn.pack_padded_sequence.yaml,3
1511,331,0.0014347202295552368,3,"frozenset({'true', 'x', 'b'})","if `True`, the output will be in `B x T x *` format.",torch.nn.utils.rnn.pad_packed_sequence.yaml,3
1512,254,0.0014347202295552368,3,"frozenset({'bilinear', 'mode'})",interpolation mode to calculate output values `'bilinear'` | `'nearest'`.,torch.nn.functional.grid_sample.yaml,2
1513,254,0.0014347202295552368,3,"frozenset({'bilinear', 'mode'})",This only has an effect when `mode` is `'bilinear'`.,torch.nn.quantized.functional.interpolate.yaml,2
1514,254,0.0014347202295552368,3,"frozenset({'bilinear', 'mode'})","This only has an effect when `mode` is `'linear'`, `'bilinear'`, `'bicubic'` or `'trilinear'`.",torch.nn.functional.interpolate.yaml,2
1515,335,0.0014347202295552368,3,"frozenset({'padding', 'mode'})",padding mode for outside grid values `'zeros'` | `'border'` | `'reflection'`.,torch.nn.functional.grid_sample.yaml,2
1516,335,0.0014347202295552368,3,"frozenset({'padding', 'mode'})",the padding mode to use.,torch.nn.quantized.functional.conv2d.yaml,2
1517,335,0.0014347202295552368,3,"frozenset({'padding', 'mode'})",the padding mode to use.,torch.nn.quantized.functional.conv3d.yaml,2
1518,336,0.0014347202295552368,3,"frozenset({'use', 'mode'})",use operator_export_type] export the model in aten mode.,torch.onnx.export.yaml,2
1519,336,0.0014347202295552368,3,"frozenset({'use', 'mode'})",the padding mode to use.,torch.nn.quantized.functional.conv2d.yaml,2
1520,336,0.0014347202295552368,3,"frozenset({'use', 'mode'})",the padding mode to use.,torch.nn.quantized.functional.conv3d.yaml,2
1521,337,0.0014347202295552368,3,"frozenset({'elements', 'whether', 'unique'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique.yaml,3
1522,337,0.0014347202295552368,3,"frozenset({'elements', 'whether', 'unique'})",Whether to sort the unique elements in ascending order before returning as output.,torch.unique.yaml,3
1523,337,0.0014347202295552368,3,"frozenset({'elements', 'whether', 'unique'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique_consecutive.yaml,3
1524,251,0.0014347202295552368,3,"frozenset({'computed', 'jacobian'})",The vector for which the vector Jacobian product is computed.,torch.autograd.functional.vjp.yaml,2
1525,251,0.0014347202295552368,3,"frozenset({'computed', 'jacobian'})",The vector for which the Jacobian vector product is computed.,torch.autograd.functional.jvp.yaml,2
1526,251,0.0014347202295552368,3,"frozenset({'computed', 'jacobian'})","If `True`, the Jacobian will be computed in a differentiable manner.",torch.autograd.functional.jacobian.yaml,2
1527,242,0.0014347202295552368,3,"frozenset({'first', 'take'})","In this case, the exported model will first take all of its parameters as arguments, the ordering as specified by `model.state_dict().values()`",torch.onnx.export.yaml,2
1528,242,0.0014347202295552368,3,"frozenset({'first', 'take'})",first dimension with respect to which to take diagonal.,torch.diag_embed.yaml,2
1529,242,0.0014347202295552368,3,"frozenset({'first', 'take'})",first dimension with respect to which to take diagonal.,torch.diagonal.yaml,2
1530,240,0.0014347202295552368,3,"frozenset({'hand', 'dimensions'})","The left hand side lists the operands dimensions, separated by commas.",torch.einsum.yaml,2
1531,240,0.0014347202295552368,3,"frozenset({'hand', 'dimensions'})","If the right hand side is inferred, the ellipsis dimensions are at the beginning of the output.",torch.einsum.yaml,2
1532,240,0.0014347202295552368,3,"frozenset({'hand', 'dimensions'})","multiple right-hand sides of size (*, m, k)  where *  is zero of more batch dimensions (b )",torch.triangular_solve.yaml,2
1533,341,0.0014347202295552368,3,"frozenset({'index', 'tensor'})",There should be one index letter per tensor dimension.,torch.einsum.yaml,2
1534,341,0.0014347202295552368,3,"frozenset({'index', 'tensor'})",the tensor containing the binary mask to index with,torch.masked_select.yaml,2
1535,341,0.0014347202295552368,3,"frozenset({'index', 'tensor'})",the 1-D tensor containing the indices to index,torch.index_select.yaml,2
1536,342,0.0014347202295552368,3,"frozenset({'dimension', 'index'})",There should be one index letter per tensor dimension.,torch.einsum.yaml,2
1537,342,0.0014347202295552368,3,"frozenset({'dimension', 'index'})",the dimension in which we index,torch.index_select.yaml,2
1538,342,0.0014347202295552368,3,"frozenset({'dimension', 'index'})",the index at which to insert the singleton dimension,torch.unsqueeze.yaml,2
1539,343,0.0014347202295552368,3,"frozenset({'along', 'index'})",index of the dim along which we define channels to prune.,torch.nn.utils.prune.ln_structured.yaml,2
1540,343,0.0014347202295552368,3,"frozenset({'along', 'index'})",index of the dim along which we define channels to prune.,torch.nn.utils.prune.random_structured.yaml,2
1541,343,0.0014347202295552368,3,"frozenset({'along', 'index'})",the axis along which to index,torch.gather.yaml,2
1542,344,0.0014347202295552368,3,"frozenset({'specified', 'exported'})","if specified, all parameters will be exported.",torch.onnx.export.yaml,2
1543,344,0.0014347202295552368,3,"frozenset({'specified', 'exported'})","In this case, the exported model will first take all of its parameters as arguments, the ordering as specified by `model.state_dict().values()`",torch.onnx.export.yaml,2
1544,344,0.0014347202295552368,3,"frozenset({'specified', 'exported'})","if specified, we will print out a debug description of the trace being exported.",torch.onnx.export.yaml,2
1545,346,0.0014347202295552368,3,"frozenset({'input', 'length'})","(T, N, C)  where C = number of characters in alphabet including blank, T = input length, and N = batch size.",torch.nn.functional.ctc_loss.yaml,2
1546,346,0.0014347202295552368,3,"frozenset({'input', 'length'})","if `True`, the input is expected to contain sequences sorted by length in a decreasing order.",torch.nn.utils.rnn.pack_padded_sequence.yaml,2
1547,346,0.0014347202295552368,3,"frozenset({'input', 'length'})","if `True`, checks that the input contains sequences sorted by length in a decreasing order.",torch.nn.utils.rnn.pack_sequence.yaml,2
1548,348,0.0014347202295552368,3,"frozenset({'dimensions', 'batch', 'zero', 'm', 'b', 'size', 'k'})","multiple right-hand sides of size (*, m, k)  where *  is zero of more batch dimensions (b )",torch.triangular_solve.yaml,7
1549,348,0.0014347202295552368,3,"frozenset({'dimensions', 'batch', 'zero', 'm', 'b', 'size', 'k'})","input matrix b  of size (*, m, k) , where *  is zero or more batch dimensions",torch.cholesky_solve.yaml,7
1550,348,0.0014347202295552368,3,"frozenset({'dimensions', 'batch', 'zero', 'm', 'b', 'size', 'k'})","input matrix B  of size (*, m, k)  , where *  is zero or more batch dimensions.",torch.solve.yaml,7
1551,234,0.0014347202295552368,3,"frozenset({'quantization', 'scale'})",scale to apply in quantization formula,torch.quantize_per_tensor.yaml,2
1552,234,0.0014347202295552368,3,"frozenset({'quantization', 'scale'})",quantization scale for the output.,torch.nn.quantized.functional.conv2d.yaml,2
1553,234,0.0014347202295552368,3,"frozenset({'quantization', 'scale'})",quantization scale for the output.,torch.nn.quantized.functional.conv3d.yaml,2
1554,233,0.0014347202295552368,3,"frozenset({'output', 'scale'})",output scale.,torch.nn.quantized.functional.linear.yaml,2
1555,233,0.0014347202295552368,3,"frozenset({'output', 'scale'})",quantization scale for the output.,torch.nn.quantized.functional.conv2d.yaml,2
1556,233,0.0014347202295552368,3,"frozenset({'output', 'scale'})",quantization scale for the output.,torch.nn.quantized.functional.conv3d.yaml,2
1557,232,0.0014347202295552368,3,"frozenset({'sequences', 'SOME_STRUCTURE'})",list of variable length sequences.,torch.nn.utils.rnn.pad_sequence.yaml,2
1558,232,0.0014347202295552368,3,"frozenset({'sequences', 'SOME_STRUCTURE'})",list of sequences lengths of each batch element.,torch.nn.utils.rnn.pack_padded_sequence.yaml,2
1559,232,0.0014347202295552368,3,"frozenset({'sequences', 'SOME_STRUCTURE'})",A list of sequences of decreasing length.,torch.nn.utils.rnn.pack_sequence.yaml,2
1560,224,0.0014347202295552368,3,"frozenset({'tensor_list', 'processes'})","If `src` is the rank, then the specified `src_tensor` element of `tensor_list` (`tensor_list[src_tensor]`) will be broadcast to all other tensors (on different GPUs) in the src process and all tensors in `tensor_list` of other non-src processes.",torch.distributed.broadcast_multigpu.yaml,2
1561,224,0.0014347202295552368,3,"frozenset({'tensor_list', 'processes'})",You also need to make sure that `len(tensor_list)` is the same for all the distributed processes calling this function.,torch.distributed.broadcast_multigpu.yaml,2
1562,224,0.0014347202295552368,3,"frozenset({'tensor_list', 'processes'})",You also need to make sure that `len(tensor_list)` is the same for all the distributed processes calling this function.,torch.distributed.reduce_multigpu.yaml,2
1563,353,0.0014347202295552368,3,"frozenset({'used', 'file'})",The hash is used to ensure unique names and to verify the contents of the file.,torch.utils.model_zoo.load_url.yaml,2
1564,353,0.0014347202295552368,3,"frozenset({'used', 'file'})",module used for unpickling metadata and objects (has to match the `pickle_module` used to serialize file),torch.load.yaml,2
1565,353,0.0014347202295552368,3,"frozenset({'used', 'file'})",The hash is used to ensure unique names and to verify the contents of the file.,torch.hub.load_state_dict_from_url.yaml,2
1566,354,0.0014347202295552368,3,"frozenset({'specifying', 'SOME_DTYPE'})","iterable of ints, specifying among which devices the tensor should be scattered.",torch.cuda.comm.scatter.yaml,2
1567,354,0.0014347202295552368,3,"frozenset({'specifying', 'SOME_DTYPE'})","a function, `torch.device`, string or a dict specifying how to remap storage locations",torch.load.yaml,2
1568,354,0.0014347202295552368,3,"frozenset({'specifying', 'SOME_DTYPE'})","bool specifying if fusion happens in place on the model, by default a new model is returned",torch.quantization.fuse_modules.yaml,2
1569,355,0.0014347202295552368,3,"frozenset({'times', 'n', 'size'})","(N  times C  times H  times W  for 2D or N  times C  times D  times H  times W  for 3D) Example: torch.Size((32, 3, 24, 24))",torch.nn.functional.affine_grid.yaml,3
1570,355,0.0014347202295552368,3,"frozenset({'times', 'n', 'size'})","the input tensor of size (*, m, n)  where * is zero or more batch dimensions consisting of matrices of dimension m  times n .",torch.qr.yaml,3
1571,355,0.0014347202295552368,3,"frozenset({'times', 'n', 'size'})","the input tensor of size (*, m, n)  where * is zero or more batch dimensions consisting of m  times n  matrices.",torch.svd.yaml,3
1572,356,0.0014347202295552368,3,"frozenset({'input', 'matrices', 'batch', 'times', 'n'})",input batch of affine matrices with shape (N  times 2  times 3 ) for 2D or (N  times 3  times 4 ) for 3D,torch.nn.functional.affine_grid.yaml,5
1573,356,0.0014347202295552368,3,"frozenset({'input', 'matrices', 'batch', 'times', 'n'})","the input tensor of size (*, m, n)  where * is zero or more batch dimensions consisting of matrices of dimension m  times n .",torch.qr.yaml,5
1574,356,0.0014347202295552368,3,"frozenset({'input', 'matrices', 'batch', 'times', 'n'})","the input tensor of size (*, m, n)  where * is zero or more batch dimensions consisting of m  times n  matrices.",torch.svd.yaml,5
1575,357,0.0014347202295552368,3,"frozenset({'shape', 'times', 'n'})",the square matrix of shape (n  times n)  for which the eigenvalues and eigenvectors will be computed,torch.eig.yaml,3
1576,357,0.0014347202295552368,3,"frozenset({'shape', 'times', 'n'})",input tensor of shape N  times M .,torch.nn.functional.pdist.yaml,3
1577,357,0.0014347202295552368,3,"frozenset({'shape', 'times', 'n'})",input batch of affine matrices with shape (N  times 2  times 3 ) for 2D or (N  times 3  times 4 ) for 3D,torch.nn.functional.affine_grid.yaml,3
1578,358,0.0014347202295552368,3,"frozenset({'input', 'times', 'tensor', 'm', 'shape'})",input tensor of shape N  times M .,torch.nn.functional.pdist.yaml,5
1579,358,0.0014347202295552368,3,"frozenset({'input', 'times', 'tensor', 'm', 'shape'})",input tensor of shape B  times P  times M .,torch.cdist.yaml,5
1580,358,0.0014347202295552368,3,"frozenset({'input', 'times', 'tensor', 'm', 'shape'})",input tensor of shape B  times R  times M .,torch.cdist.yaml,5
1581,332,0.0014347202295552368,3,"frozenset({'specified', 'x'})",Default is the number of X  columns (when specified) or 1.,torch.lobpcg.yaml,2
1582,332,0.0014347202295552368,3,"frozenset({'specified', 'x'})",if X  is not specified then n specifies the size of the generated random approximation of eigenvectors.,torch.lobpcg.yaml,2
1583,332,0.0014347202295552368,3,"frozenset({'specified', 'x'})","If X  is specifed, the value of n (when specified) must be the number of X  columns.",torch.lobpcg.yaml,2
1584,329,0.0014347202295552368,3,"frozenset({'field', 'SOME_DTYPE'})","if True, strips the field ""doc_string"" from the exported model, which information about the stack trace.",torch.onnx.export.yaml,2
1585,329,0.0014347202295552368,3,"frozenset({'field', 'SOME_DTYPE'})","This field should be given as a lowercase string (e.g., `""gloo""`), which can also be accessed via `Backend` attributes (e.g., `Backend.GLOO`).",torch.distributed.init_process_group.yaml,2
1586,329,0.0014347202295552368,3,"frozenset({'field', 'SOME_DTYPE'})","This field should be given as a lowercase string (e.g., `""gloo""`), which can also be accessed via `Backend` attributes (e.g., `Backend.GLOO`).",torch.distributed.new_group.yaml,2
1587,435,0.0014347202295552368,3,"frozenset({'use', 'along', 'dimension', 'default'})","The dimension along which to integrate.By default, use the last dimension.",torch.trapz.yaml,4
1588,435,0.0014347202295552368,3,"frozenset({'use', 'along', 'dimension', 'default'})","The dimension along which to integrate.By default, use the last dimension.",torch.trapz2.yaml,4
1589,435,0.0014347202295552368,3,"frozenset({'use', 'along', 'dimension', 'default'})","The dimension along which to repeat values.By default, use the flattened input array, and return a flat outputarray.",torch.repeat_interleave.yaml,4
1590,2,0.0014347202295552368,3,"frozenset({'sequences', 'decreasing', 'length'})","if `True`, the input is expected to contain sequences sorted by length in a decreasing order.",torch.nn.utils.rnn.pack_padded_sequence.yaml,3
1591,2,0.0014347202295552368,3,"frozenset({'sequences', 'decreasing', 'length'})","if `True`, checks that the input contains sequences sorted by length in a decreasing order.",torch.nn.utils.rnn.pack_sequence.yaml,3
1592,2,0.0014347202295552368,3,"frozenset({'sequences', 'decreasing', 'length'})",A list of sequences of decreasing length.,torch.nn.utils.rnn.pack_sequence.yaml,3
1593,297,0.0014347202295552368,3,"frozenset({'args', 'SOME_DTYPE'})","the inputs to the model, e.g., such that `model(*args)` is a valid invocation of the model.",torch.onnx.export.yaml,2
1594,297,0.0014347202295552368,3,"frozenset({'args', 'SOME_DTYPE'})"," Any non-Tensor arguments will be hard-coded into the exported model; any Tensor arguments will become inputs of the exported model, in the order they occur in args.",torch.onnx.export.yaml,2
1595,297,0.0014347202295552368,3,"frozenset({'args', 'SOME_DTYPE'})",the corresponding args for callable model.,torch.hub.load.yaml,2
1596,302,0.0014347202295552368,3,"frozenset({'single', 'kh', 'kw', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple (kT, kH, kW)",torch.nn.functional.avg_pool3d.yaml,5
1597,302,0.0014347202295552368,3,"frozenset({'single', 'kh', 'kw', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple (kH, kW)",torch.nn.quantized.functional.avg_pool2d.yaml,5
1598,302,0.0014347202295552368,3,"frozenset({'single', 'kh', 'kw', 'number', 'SOME_STRUCTURE'})","Can be a single number or a tuple (kH, kW)",torch.nn.functional.avg_pool2d.yaml,5
1599,303,0.0014347202295552368,3,"frozenset({'input', 'triangular'})","the input triangular coefficient matrix of size (*, m, m)  where *  is zero or more batch dimensions",torch.triangular_solve.yaml,2
1600,303,0.0014347202295552368,3,"frozenset({'input', 'triangular'})","input matrix u  of size (*, m, m) , where *  is zero of more batch dimensions composed of upper or lower triangular Cholesky factor",torch.cholesky_solve.yaml,2
1601,303,0.0014347202295552368,3,"frozenset({'input', 'triangular'})","the input 2-D tensor u , a upper or lower triangular Cholesky factor",torch.cholesky_inverse.yaml,2
1602,295,0.0014347202295552368,3,"frozenset({'single', 'returns', 'element', 'python', 'tensor', 'takes', 'function', 'inputs'})",a Python function that takes Tensor inputs and returns a Tensor with a single element.,torch.autograd.functional.hvp.yaml,8
1603,295,0.0014347202295552368,3,"frozenset({'single', 'returns', 'element', 'python', 'tensor', 'takes', 'function', 'inputs'})",a Python function that takes Tensor inputs and returns a Tensor with a single element.,torch.autograd.functional.vhp.yaml,8
1604,295,0.0014347202295552368,3,"frozenset({'single', 'returns', 'element', 'python', 'tensor', 'takes', 'function', 'inputs'})",a Python function that takes Tensor inputs and returns a Tensor with a single element.,torch.autograd.functional.hessian.yaml,8
1605,305,0.0014347202295552368,3,"frozenset({'input', 'r', 'tensor'})",input tensor of shape B  times R  times M .,torch.cdist.yaml,3
1606,305,0.0014347202295552368,3,"frozenset({'input', 'r', 'tensor'})","tuple of Q and R tensors satisfying `input = torch.matmul(Q, R)`.",torch.qr.yaml,3
1607,305,0.0014347202295552368,3,"frozenset({'input', 'r', 'tensor'})","If `True`, gradient w.r.t. `input` will be a sparse tensor.",torch.gather.yaml,3
1608,306,0.0014347202295552368,3,"frozenset({'true', 'r'})","If `True`, gradient w.r.t. `weight` will be a sparse tensor.",torch.nn.functional.embedding.yaml,2
1609,306,0.0014347202295552368,3,"frozenset({'true', 'r'})","The dimensions of Q and R are (*, m, k)  and (*, k, n)  respectively, where k =  min(m, n)  if `some:` is `True` and k = m  otherwise.",torch.qr.yaml,2
1610,306,0.0014347202295552368,3,"frozenset({'true', 'r'})","If `True`, gradient w.r.t. `input` will be a sparse tensor.",torch.gather.yaml,2
1611,287,0.0014347202295552368,3,"frozenset({'r', 'w', 'tensor'})","If `True`, gradient w.r.t. `weight` will be a sparse tensor.",torch.nn.functional.embedding.yaml,3
1612,287,0.0014347202295552368,3,"frozenset({'r', 'w', 'tensor'})","The ""vector"" in the Jacobian-vector product, usually gradients w.r.t. each element of corresponding tensors.",torch.autograd.backward.yaml,3
1613,287,0.0014347202295552368,3,"frozenset({'r', 'w', 'tensor'})","If `True`, gradient w.r.t. `input` will be a sparse tensor.",torch.gather.yaml,3
1614,309,0.0014347202295552368,3,"frozenset({'tolerance', 'absolute'})",absolute tolerance,torch.autograd.gradgradcheck.yaml,2
1615,309,0.0014347202295552368,3,"frozenset({'tolerance', 'absolute'})",absolute tolerance,torch.autograd.gradcheck.yaml,2
1616,309,0.0014347202295552368,3,"frozenset({'tolerance', 'absolute'})",absolute tolerance.,torch.allclose.yaml,2
1617,284,0.0014347202295552368,3,"frozenset({'matrix', 'dense'})",a dense matrix to be added,torch.sparse.addmm.yaml,2
1618,284,0.0014347202295552368,3,"frozenset({'matrix', 'dense'})",a dense matrix be multiplied,torch.sparse.addmm.yaml,2
1619,284,0.0014347202295552368,3,"frozenset({'matrix', 'dense'})",the second dense matrix to be multiplied,torch.sparse.mm.yaml,2
1620,281,0.0014347202295552368,3,"frozenset({'values', 'output', 'interpolation'})",interpolation mode to calculate output values `'bilinear'` | `'nearest'`.,torch.nn.functional.grid_sample.yaml,3
1621,281,0.0014347202295552368,3,"frozenset({'values', 'output', 'interpolation'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.quantized.functional.interpolate.yaml,3
1622,281,0.0014347202295552368,3,"frozenset({'values', 'output', 'interpolation'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.functional.interpolate.yaml,3
1623,279,0.0014347202295552368,3,"frozenset({'input', 'gradient'})",Specifies a target value that is ignored and does not contribute to the input gradient.,torch.nn.functional.nll_loss.yaml,2
1624,279,0.0014347202295552368,3,"frozenset({'input', 'gradient'})",Specifies a target value that is ignored and does not contribute to the input gradient.,torch.nn.functional.cross_entropy.yaml,2
1625,279,0.0014347202295552368,3,"frozenset({'input', 'gradient'})","If `True`, gradient w.r.t. `input` will be a sparse tensor.",torch.gather.yaml,2
1626,278,0.0014347202295552368,3,"frozenset({'r', 'w', 'gradient'})","If `True`, gradient w.r.t. `weight` will be a sparse tensor.",torch.nn.functional.embedding.yaml,3
1627,278,0.0014347202295552368,3,"frozenset({'r', 'w', 'gradient'})",Inputs w.r.t. which the gradient will be returned (and not accumulated into `.grad`).,torch.autograd.grad.yaml,3
1628,278,0.0014347202295552368,3,"frozenset({'r', 'w', 'gradient'})","If `True`, gradient w.r.t. `input` will be a sparse tensor.",torch.gather.yaml,3
1629,314,0.0014347202295552368,3,"frozenset({'broadcast', 'process', 'tensor'})",Tensor to be broadcast from current process.,torch.distributed.all_gather.yaml,3
1630,314,0.0014347202295552368,3,"frozenset({'broadcast', 'process', 'tensor'})","If `src` is the rank, then the specified `src_tensor` element of `tensor_list` (`tensor_list[src_tensor]`) will be broadcast to all other tensors (on different GPUs) in the src process and all tensors in `tensor_list` of other non-src processes.",torch.distributed.broadcast_multigpu.yaml,3
1631,314,0.0014347202295552368,3,"frozenset({'broadcast', 'process', 'tensor'})",List of tensors(on different GPUs) to be broadcast from current process.,torch.distributed.all_gather_multigpu.yaml,3
1632,315,0.0014347202295552368,3,"frozenset({'broadcast', 'SOME_STRUCTURE'})",an iterable of devices among which to broadcast.,torch.cuda.comm.broadcast_coalesced.yaml,2
1633,315,0.0014347202295552368,3,"frozenset({'broadcast', 'SOME_STRUCTURE'})",List of tensors(on different GPUs) to be broadcast from current process.,torch.distributed.all_gather_multigpu.yaml,2
1634,315,0.0014347202295552368,3,"frozenset({'broadcast', 'SOME_STRUCTURE'})",an iterable of devices among which to broadcast.,torch.cuda.comm.broadcast.yaml,2
1635,277,0.0014347202295552368,3,"frozenset({'true', 'gradient'})","if `grad_outputs` is `None` and `gen_non_contig_grad_outputs` is `True`, the randomly generated gradient outputs are made to be noncontiguous",torch.autograd.gradgradcheck.yaml,2
1636,277,0.0014347202295552368,3,"frozenset({'true', 'gradient'})","If `True`, gradient w.r.t. `weight` will be a sparse tensor.",torch.nn.functional.embedding.yaml,2
1637,277,0.0014347202295552368,3,"frozenset({'true', 'gradient'})","If `True`, gradient w.r.t. `input` will be a sparse tensor.",torch.gather.yaml,2
1638,272,0.0014347202295552368,3,"frozenset({'input', 'output', 'scale_factor', 'interpolation'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.quantized.functional.interpolate.yaml,4
1639,272,0.0014347202295552368,3,"frozenset({'input', 'output', 'scale_factor', 'interpolation'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.functional.interpolate.yaml,4
1640,272,0.0014347202295552368,3,"frozenset({'input', 'output', 'scale_factor', 'interpolation'})"," If recompute_scale_factor is ``True` or not specified, a new scale_factor will be computed based on the output and input sizes for use in the interpolation computation (i.e. the computation will be identical to if the computed output_size were passed-in explicitly).",torch.nn.functional.interpolate.yaml,4
1641,320,0.0014347202295552368,3,"frozenset({'input', 'iw', 'ih', 'tensor', 'quantized', '_channels', 'minibatch'})","quantized input tensor (minibatch , in _channels , iH , iW) ",torch.nn.quantized.functional.avg_pool2d.yaml,7
1642,320,0.0014347202295552368,3,"frozenset({'input', 'iw', 'ih', 'tensor', 'quantized', '_channels', 'minibatch'})","quantized input tensor of shape (minibatch , in _channels , iH , iW) ",torch.nn.quantized.functional.conv2d.yaml,7
1643,320,0.0014347202295552368,3,"frozenset({'input', 'iw', 'ih', 'tensor', 'quantized', '_channels', 'minibatch'})","quantized input tensor of shape (minibatch , in _channels , iD , iH , iW) ",torch.nn.quantized.functional.conv3d.yaml,7
1644,322,0.0014347202295552368,3,"frozenset({'d', 'n', 'case', 'c'})","input of shape (N, C, H_in, W_in)  (4-D case) or (N, C, D_in, H_in, W_in)  (5-D case)",torch.nn.functional.grid_sample.yaml,4
1645,322,0.0014347202295552368,3,"frozenset({'d', 'n', 'case', 'c'})","(N, C)  where C = number of classes or (N, C, H, W)  in case of 2D Loss, or (N, C, d_1, d_2, ..., d_K)  where K  >= 1  in the case of K-dimensional loss.",torch.nn.functional.nll_loss.yaml,4
1646,322,0.0014347202295552368,3,"frozenset({'d', 'n', 'case', 'c'})","(N, C)  where C = number of classes or (N, C, H, W)  in case of 2D Loss, or (N, C, d_1, d_2, ..., d_K)  where K  >= 1  in the case of K-dimensional loss.",torch.nn.functional.cross_entropy.yaml,4
1647,323,0.0014347202295552368,3,"frozenset({'SOME_DTYPE', 'case'})"," By default, `fork_rng()` operates on all devices, but will emit a warning if your machine has a lot of devices, since this function will run very slowly in that case.",torch.random.fork_rng.yaml,2
1648,323,0.0014347202295552368,3,"frozenset({'SOME_DTYPE', 'case'})"," By default, `fork_rng()` operates on all devices, but will emit a warning if your machine has a lot of devices, since this function will run very slowly in that case.",torch.random.fork_rng2.yaml,2
1649,323,0.0014347202295552368,3,"frozenset({'SOME_DTYPE', 'case'})","In this case, the exported model will first take all of its parameters as arguments, the ordering as specified by `model.state_dict().values()`",torch.onnx.export.yaml,2
1650,270,0.0014347202295552368,3,"frozenset({'input', 'symmetric'})","the input tensor A  of size (*, n, n)  where * is zero or more batch dimensions consisting of symmetric positive-definite matrices.",torch.cholesky.yaml,2
1651,270,0.0014347202295552368,3,"frozenset({'input', 'symmetric'})","the input tensor of size (*, n, n)  where * is zero or more batch dimensions consisting of symmetric matrices.",torch.symeig.yaml,2
1652,270,0.0014347202295552368,3,"frozenset({'input', 'symmetric'})",indicates whether `input` is symmetric.,torch.matrix_rank.yaml,2
1653,269,0.0014347202295552368,3,"frozenset({'run', 'torch', 'SOME_DTYPE'})",A Python function or `torch.nn.Module` that will be run with `example_inputs`.,torch.jit.trace.yaml,3
1654,269,0.0014347202295552368,3,"frozenset({'run', 'torch', 'SOME_DTYPE'})","When a module is passed to `torch.jit.trace`, only the `forward` method is run and traced (see `torch.jit.trace` for details).",torch.jit.trace.yaml,3
1655,269,0.0014347202295552368,3,"frozenset({'run', 'torch', 'SOME_DTYPE'})",A `torch.nn.Sequential` or the list of modules or functions (comprising the model) to run sequentially.,torch.utils.checkpoint.checkpoint_sequential.yaml,3
1656,268,0.0014347202295552368,3,"frozenset({'function', 'run', 'SOME_DTYPE'})"," By default, `fork_rng()` operates on all devices, but will emit a warning if your machine has a lot of devices, since this function will run very slowly in that case.",torch.random.fork_rng.yaml,3
1657,268,0.0014347202295552368,3,"frozenset({'function', 'run', 'SOME_DTYPE'})"," By default, `fork_rng()` operates on all devices, but will emit a warning if your machine has a lot of devices, since this function will run very slowly in that case.",torch.random.fork_rng2.yaml,3
1658,268,0.0014347202295552368,3,"frozenset({'function', 'run', 'SOME_DTYPE'})",A Python function or `torch.nn.Module` that will be run with `example_inputs`.,torch.jit.trace.yaml,3
1659,327,0.0014347202295552368,3,"frozenset({'quantization', 'type'})","dictionary that maps from name or type of submodule to quantization configuration, qconfig applies to all submodules of a given module unless qconfig for the submodules are specified (when the submodule already has qconfig attribute)",torch.quantization.propagate_qconfig_.yaml,2
1660,327,0.0014347202295552368,3,"frozenset({'quantization', 'type'})",quantization data type to use.,torch.nn.quantized.functional.conv2d.yaml,2
1661,327,0.0014347202295552368,3,"frozenset({'quantization', 'type'})",quantization data type to use.,torch.nn.quantized.functional.conv3d.yaml,2
1662,223,0.0014347202295552368,3,"frozenset({'tensor_list', 'rank', 'tensor'})",Source tensor rank within `tensor_list`,torch.distributed.broadcast_multigpu.yaml,3
1663,223,0.0014347202295552368,3,"frozenset({'tensor_list', 'rank', 'tensor'})","If `src` is the rank, then the specified `src_tensor` element of `tensor_list` (`tensor_list[src_tensor]`) will be broadcast to all other tensors (on different GPUs) in the src process and all tensors in `tensor_list` of other non-src processes.",torch.distributed.broadcast_multigpu.yaml,3
1664,223,0.0014347202295552368,3,"frozenset({'tensor_list', 'rank', 'tensor'})",Destination tensor rank within `tensor_list`,torch.distributed.reduce_multigpu.yaml,3
1665,360,0.0014347202295552368,3,"frozenset({'batch', 'first', 'matrices', 'multiplied'})",the first batch of matrices to be multiplied,torch.baddbmm.yaml,4
1666,360,0.0014347202295552368,3,"frozenset({'batch', 'first', 'matrices', 'multiplied'})",the first batch of matrices to be multiplied,torch.addbmm.yaml,4
1667,360,0.0014347202295552368,3,"frozenset({'batch', 'first', 'matrices', 'multiplied'})",the first batch of matrices to be multiplied,torch.bmm.yaml,4
1668,361,0.0014347202295552368,3,"frozenset({'batch', 'second', 'matrices', 'multiplied'})",the second batch of matrices to be multiplied,torch.baddbmm.yaml,4
1669,361,0.0014347202295552368,3,"frozenset({'batch', 'second', 'matrices', 'multiplied'})",the second batch of matrices to be multiplied,torch.addbmm.yaml,4
1670,361,0.0014347202295552368,3,"frozenset({'batch', 'second', 'matrices', 'multiplied'})",the second batch of matrices to be multiplied,torch.bmm.yaml,4
1671,362,0.0014347202295552368,3,"frozenset({'input', 'size', 'm', 'k'})","the input tensor of size (*, m, n)  where k <= n <= m.",torch.lobpcg.yaml,4
1672,362,0.0014347202295552368,3,"frozenset({'input', 'size', 'm', 'k'})","input matrix b  of size (*, m, k) , where *  is zero or more batch dimensions",torch.cholesky_solve.yaml,4
1673,362,0.0014347202295552368,3,"frozenset({'input', 'size', 'm', 'k'})","input matrix B  of size (*, m, k)  , where *  is zero or more batch dimensions.",torch.solve.yaml,4
1674,393,0.0014347202295552368,3,"frozenset({'apply', 'dimension'})",dimension on which apply per-channel quantization,torch.quantize_per_channel.yaml,2
1675,393,0.0014347202295552368,3,"frozenset({'apply', 'dimension'})",the dimension to apply unique.,torch.unique.yaml,2
1676,393,0.0014347202295552368,3,"frozenset({'apply', 'dimension'})",the dimension to apply unique.,torch.unique_consecutive.yaml,2
1677,394,0.0014347202295552368,3,"frozenset({'split', 'dimension'})",dimension on which to split the input.,torch.nn.functional.glu.yaml,2
1678,394,0.0014347202295552368,3,"frozenset({'split', 'dimension'})",dimension along which to split the tensor.,torch.split.yaml,2
1679,394,0.0014347202295552368,3,"frozenset({'split', 'dimension'})",dimension along which to split the tensor,torch.chunk.yaml,2
1680,398,0.0014347202295552368,3,"frozenset({'operation', 'true', 'set', 'place'})","If set to `True`, will do this operation in-place.",torch.nn.functional.dropout.yaml,4
1681,398,0.0014347202295552368,3,"frozenset({'operation', 'true', 'set', 'place'})","If set to `True`, will do this operation in-place.",torch.nn.functional.dropout2d.yaml,4
1682,398,0.0014347202295552368,3,"frozenset({'operation', 'true', 'set', 'place'})","If set to `True`, will do this operation in-place.",torch.nn.functional.dropout3d.yaml,4
1683,399,0.0014347202295552368,3,"frozenset({'values', 'padding'})",padding mode for outside grid values `'zeros'` | `'border'` | `'reflection'`.,torch.nn.functional.grid_sample.yaml,2
1684,399,0.0014347202295552368,3,"frozenset({'values', 'padding'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.quantized.functional.interpolate.yaml,2
1685,399,0.0014347202295552368,3,"frozenset({'values', 'padding'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.functional.interpolate.yaml,2
1686,400,0.0014347202295552368,3,"frozenset({'padding', 'value'})",fill value for `'constant'` padding.,torch.nn.functional.pad.yaml,2
1687,400,0.0014347202295552368,3,"frozenset({'padding', 'value'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.quantized.functional.interpolate.yaml,2
1688,400,0.0014347202295552368,3,"frozenset({'padding', 'value'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.functional.interpolate.yaml,2
1689,401,0.0014347202295552368,3,"frozenset({'function', 'outputs'})",The gradients with respect to the function's outputs.,torch.autograd.gradgradcheck.yaml,2
1690,401,0.0014347202295552368,3,"frozenset({'function', 'outputs'})",outputs of the differentiated function.,torch.autograd.grad.yaml,2
1691,401,0.0014347202295552368,3,"frozenset({'function', 'outputs'})",Function that takes in a list of modules and outputs a list of fused modules of the same length.,torch.quantization.fuse_modules.yaml,2
1692,402,0.0014347202295552368,3,"frozenset({'outputs', 'SOME_DTYPE'})","dimension corresponding to number of outputs, the default is `0`, except for modules that are instances of ConvTranspose{1,2,3}d, when it is `1`",torch.nn.utils.spectral_norm.yaml,2
1693,402,0.0014347202295552368,3,"frozenset({'outputs', 'SOME_DTYPE'})",Model's example outputs being exported.,torch.onnx.export.yaml,2
1694,402,0.0014347202295552368,3,"frozenset({'outputs', 'SOME_DTYPE'})",Function that takes in a list of modules and outputs a list of fused modules of the same length.,torch.quantization.fuse_modules.yaml,2
1695,403,0.0014347202295552368,3,"frozenset({'two', 'dimension', 'dimensions', 'tensor'})","If the value is None, matrix norm will be calculated when the input tensor only has two dimensions, vector norm will be calculated when the input tensor only has one dimension.",torch.norm.yaml,4
1696,403,0.0014347202295552368,3,"frozenset({'two', 'dimension', 'dimensions', 'tensor'})","If the input tensor has more than two dimensions, the vector norm will be applied to last dimension.",torch.norm.yaml,4
1697,403,0.0014347202295552368,3,"frozenset({'two', 'dimension', 'dimensions', 'tensor'})","The indices are the coordinates of the non-zero values in the matrix, and thus should be two-dimensional where the first dimension is the number of tensor dimensions and the second dimension is the number of non-zero values.",torch.sparse_coo_tensor.yaml,4
1698,412,0.0014347202295552368,3,"frozenset({'added', 'tensor'})",the tensor to be added,torch.addcdiv.yaml,2
1699,412,0.0014347202295552368,3,"frozenset({'added', 'tensor'})",the tensor to be added,torch.baddbmm.yaml,2
1700,412,0.0014347202295552368,3,"frozenset({'added', 'tensor'})",the tensor to be added,torch.addcmul.yaml,2
1701,415,0.0014347202295552368,3,"frozenset({'quantized', 'SOME_DTYPE'})",dictionary that maps float modules to quantized modules to be replaced.,torch.quantization.prepare_qat.yaml,2
1702,415,0.0014347202295552368,3,"frozenset({'quantized', 'SOME_DTYPE'})",correspondence between original module types and quantized counterparts,torch.quantization.quantize.yaml,2
1703,415,0.0014347202295552368,3,"frozenset({'quantized', 'SOME_DTYPE'})","a dictionary that maps from float module type to quantized module type, can be overwrritten to allow swapping user defined Modules",torch.quantization.convert.yaml,2
1704,416,0.0014347202295552368,3,"frozenset({'quantized', 'type'})","a dictionary that maps from float module type to quantized module type, can be overwrritten to allow swapping user defined Modules",torch.quantization.convert.yaml,2
1705,416,0.0014347202295552368,3,"frozenset({'quantized', 'type'})",Quantized input of type torch.quint8,torch.nn.quantized.functional.linear.yaml,2
1706,416,0.0014347202295552368,3,"frozenset({'quantized', 'type'})",Quantized weight of type torch.qint8,torch.nn.quantized.functional.linear.yaml,2
1707,418,0.0014347202295552368,3,"frozenset({'norm', 'tensor'})","If the value is None, matrix norm will be calculated when the input tensor only has two dimensions, vector norm will be calculated when the input tensor only has one dimension.",torch.norm.yaml,2
1708,418,0.0014347202295552368,3,"frozenset({'norm', 'tensor'})","If the input tensor has more than two dimensions, the vector norm will be applied to last dimension.",torch.norm.yaml,2
1709,418,0.0014347202295552368,3,"frozenset({'norm', 'tensor'})",the maximum norm to keep each sub-tensor under,torch.renorm.yaml,2
1710,419,0.0014347202295552368,3,"frozenset({'dimension', 'norm'})","If the value is None, matrix norm will be calculated when the input tensor only has two dimensions, vector norm will be calculated when the input tensor only has one dimension.",torch.norm.yaml,2
1711,419,0.0014347202295552368,3,"frozenset({'dimension', 'norm'})","If the input tensor has more than two dimensions, the vector norm will be applied to last dimension.",torch.norm.yaml,2
1712,419,0.0014347202295552368,3,"frozenset({'dimension', 'norm'})",dimension over which to compute the norm,torch.nn.utils.weight_norm.yaml,2
1713,421,0.0014347202295552368,3,"frozenset({'shape', 'non', 'tensor'})",non-quantized bias tensor of shape (out _channels) .,torch.nn.quantized.functional.conv2d.yaml,3
1714,421,0.0014347202295552368,3,"frozenset({'shape', 'non', 'tensor'})","Non-empty tensors provided must have the same shape, except in the cat dimension.",torch.cat.yaml,3
1715,421,0.0014347202295552368,3,"frozenset({'shape', 'non', 'tensor'})",non-quantized bias tensor of shape (out _channels) .,torch.nn.quantized.functional.conv3d.yaml,3
1716,298,0.0014347202295552368,3,"frozenset({'function', 'nn'})","The `nn.Module`, function, or class type to compile.",torch.jit.script.yaml,2
1717,298,0.0014347202295552368,3,"frozenset({'function', 'nn'})",the non-linear function (nn.functional name),torch.nn.init.calculate_gain.yaml,2
1718,298,0.0014347202295552368,3,"frozenset({'function', 'nn'})",A Python function or `torch.nn.Module` that will be run with `example_inputs`.,torch.jit.trace.yaml,2
1719,424,0.0014347202295552368,3,"frozenset({'gradients', 'tensor'})",an iterable of Tensors or a single Tensor that will have gradients normalized,torch.nn.utils.clip_grad_norm_.yaml,2
1720,424,0.0014347202295552368,3,"frozenset({'gradients', 'tensor'})",an iterable of Tensors or a single Tensor that will have gradients normalized,torch.nn.utils.clip_grad_value_.yaml,2
1721,424,0.0014347202295552368,3,"frozenset({'gradients', 'tensor'})","The ""vector"" in the Jacobian-vector product, usually gradients w.r.t. each element of corresponding tensors.",torch.autograd.backward.yaml,2
1722,425,0.0014347202295552368,3,"frozenset({'specified', 'rank', 'tensor'})","List of appropriately-sized tensors to use for gathered data (default is None, must be specified on the destination rank)",torch.distributed.gather.yaml,3
1723,425,0.0014347202295552368,3,"frozenset({'specified', 'rank', 'tensor'})","If `src` is the rank, then the specified `src_tensor` element of `tensor_list` (`tensor_list[src_tensor]`) will be broadcast to all other tensors (on different GPUs) in the src process and all tensors in `tensor_list` of other non-src processes.",torch.distributed.broadcast_multigpu.yaml,3
1724,425,0.0014347202295552368,3,"frozenset({'specified', 'rank', 'tensor'})","List of tensors to scatter (default is None, must be specified on the source rank)",torch.distributed.scatter.yaml,3
1725,426,0.0014347202295552368,3,"frozenset({'rank', 'process'})",Rank of the current process.,torch.distributed.init_process_group.yaml,2
1726,426,0.0014347202295552368,3,"frozenset({'rank', 'process'})","If `src` is the rank, then the specified `src_tensor` element of `tensor_list` (`tensor_list[src_tensor]`) will be broadcast to all other tensors (on different GPUs) in the src process and all tensors in `tensor_list` of other non-src processes.",torch.distributed.broadcast_multigpu.yaml,2
1727,426,0.0014347202295552368,3,"frozenset({'rank', 'process'})","Data to be sent if `src` is the rank of current process, and tensor to be used to save received data otherwise.",torch.distributed.broadcast.yaml,2
1728,428,0.0014347202295552368,3,"frozenset({'one', 'tensor'})",There should be one index letter per tensor dimension.,torch.einsum.yaml,2
1729,428,0.0014347202295552368,3,"frozenset({'one', 'tensor'})","If the value is None, matrix norm will be calculated when the input tensor only has two dimensions, vector norm will be calculated when the input tensor only has one dimension.",torch.norm.yaml,2
1730,428,0.0014347202295552368,3,"frozenset({'one', 'tensor'})","If set to -1, the number of classes will be inferred as one greater than the largest class value in the input tensor.",torch.nn.functional.one_hot.yaml,2
1731,429,0.0014347202295552368,3,"frozenset({'single', 'element', 'number', 'one', 'SOME_STRUCTURE'})","Can be a single number or a one-element tuple (dW,).",torch.nn.functional.conv1d.yaml,5
1732,429,0.0014347202295552368,3,"frozenset({'single', 'element', 'number', 'one', 'SOME_STRUCTURE'})","Can be a single number or a one-element tuple (padW,).",torch.nn.functional.conv1d.yaml,5
1733,429,0.0014347202295552368,3,"frozenset({'single', 'element', 'number', 'one', 'SOME_STRUCTURE'})","Can be a single number or a one-element tuple (sW,).",torch.nn.functional.conv1d.yaml,5
1734,430,0.0014347202295552368,3,"frozenset({'indices', 'containing', 'tensor'})",the output tensor containing indices,torch.nonzero.yaml,3
1735,430,0.0014347202295552368,3,"frozenset({'indices', 'containing', 'tensor'})",Tensor containing indices into the embedding matrix,torch.nn.functional.embedding.yaml,3
1736,430,0.0014347202295552368,3,"frozenset({'indices', 'containing', 'tensor'})",the 1-D tensor containing the indices to index,torch.index_select.yaml,3
1737,431,0.0014347202295552368,3,"frozenset({'elements', 'indices'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique.yaml,2
1738,431,0.0014347202295552368,3,"frozenset({'elements', 'indices'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique_consecutive.yaml,2
1739,431,0.0014347202295552368,3,"frozenset({'elements', 'indices'})",the indices of elements to gather,torch.gather.yaml,2
1740,433,0.0014347202295552368,3,"frozenset({'torch', 'e'})",The logarithmized probabilities of the outputs (e.g. obtained with `torch.nn.functional.log_softmax()`).,torch.nn.functional.ctc_loss.yaml,2
1741,433,0.0014347202295552368,3,"frozenset({'torch', 'e'})","Default: `'cuda'` (i.e., `torch.device('cuda')`, the current CUDA device).",torch.cuda.get_rng_state.yaml,2
1742,433,0.0014347202295552368,3,"frozenset({'torch', 'e'})","Default: `'cuda'` (i.e., `torch.device('cuda')`, the current CUDA device).",torch.cuda.set_rng_state.yaml,2
1743,391,0.0014347202295552368,3,"frozenset({'input', 'tensor', 'weight'})",a manual rescaling weight if provided it's repeated to match input tensor shape,torch.nn.functional.binary_cross_entropy.yaml,3
1744,391,0.0014347202295552368,3,"frozenset({'input', 'tensor', 'weight'})","optional, weight for each value in the input tensor.",torch.bincount.yaml,3
1745,391,0.0014347202295552368,3,"frozenset({'input', 'tensor', 'weight'})",a manual rescaling weight if provided it's repeated to match input tensor shape,torch.nn.functional.binary_cross_entropy_with_logits.yaml,3
1746,188,0.0014347202295552368,3,"frozenset({'aligned', 'false'})",Default: `False` Infinite losses mainly occur when the inputs are too short to be aligned to the targets.,torch.nn.functional.ctc_loss.yaml,2
1747,188,0.0014347202295552368,3,"frozenset({'aligned', 'false'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.quantized.functional.interpolate.yaml,2
1748,188,0.0014347202295552368,3,"frozenset({'aligned', 'false'})","If set to `False`, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when `scale_factor` is kept the same.",torch.nn.functional.interpolate.yaml,2
1749,195,0.0014347202295552368,3,"frozenset({'norm', 'calculate'})","p value for the p-norm distance to calculate between each vector pair  in [0,  infty] .",torch.nn.functional.pdist.yaml,2
1750,195,0.0014347202295552368,3,"frozenset({'norm', 'calculate'})",number of power iterations to calculate spectral norm,torch.nn.utils.spectral_norm.yaml,2
1751,195,0.0014347202295552368,3,"frozenset({'norm', 'calculate'})","p value for the p-norm distance to calculate between each vector pair  in [0,  infty] .",torch.cdist.yaml,2
1752,373,0.0014347202295552368,3,"frozenset({'source', 'tensor'})",Source tensor rank within `tensor_list`,torch.distributed.broadcast_multigpu.yaml,2
1753,373,0.0014347202295552368,3,"frozenset({'source', 'tensor'})","List of tensors to scatter (default is None, must be specified on the source rank)",torch.distributed.scatter.yaml,2
1754,373,0.0014347202295552368,3,"frozenset({'source', 'tensor'})",the source tensor,torch.gather.yaml,2
1755,363,0.0014347202295552368,3,"frozenset({'value', 'n', 'k'})",Default value for n is k.,torch.lobpcg.yaml,3
1756,363,0.0014347202295552368,3,"frozenset({'value', 'n', 'k'})","(N)  where each value is 0  <= targets[i]  <= C-1 , or (N, d_1, d_2, ..., d_K)  where K  >= 1  for K-dimensional loss.",torch.nn.functional.nll_loss.yaml,3
1757,363,0.0014347202295552368,3,"frozenset({'value', 'n', 'k'})","(N)  where each value is 0  <= targets[i]  <= C-1 , or (N, d_1, d_2, ..., d_K)  where K  >= 1  for K-dimensional loss.",torch.nn.functional.cross_entropy.yaml,3
1758,364,0.0014347202295552368,3,"frozenset({'number', 'n', 'c'})","(T, N, C)  where C = number of characters in alphabet including blank, T = input length, and N = batch size.",torch.nn.functional.ctc_loss.yaml,3
1759,364,0.0014347202295552368,3,"frozenset({'number', 'n', 'c'})","(N, C)  where C = number of classes or (N, C, H, W)  in case of 2D Loss, or (N, C, d_1, d_2, ..., d_K)  where K  >= 1  in the case of K-dimensional loss.",torch.nn.functional.nll_loss.yaml,3
1760,364,0.0014347202295552368,3,"frozenset({'number', 'n', 'c'})","(N, C)  where C = number of classes or (N, C, H, W)  in case of 2D Loss, or (N, C, d_1, d_2, ..., d_K)  where K  >= 1  in the case of K-dimensional loss.",torch.nn.functional.cross_entropy.yaml,3
1761,365,0.0014347202295552368,3,"frozenset({'tensor', 'c'})",the output tensor for c,torch.cholesky_solve.yaml,2
1762,365,0.0014347202295552368,3,"frozenset({'tensor', 'c'})","If given, has to be a Tensor of size C",torch.nn.functional.nll_loss.yaml,2
1763,365,0.0014347202295552368,3,"frozenset({'tensor', 'c'})","If given, has to be a Tensor of size C",torch.nn.functional.cross_entropy.yaml,2
1764,210,0.0014347202295552368,3,"frozenset({'sorted', 'order'})","if `True`, the input is expected to contain sequences sorted by length in a decreasing order.",torch.nn.utils.rnn.pack_padded_sequence.yaml,2
1765,210,0.0014347202295552368,3,"frozenset({'sorted', 'order'})",controls whether to return the elements in sorted order,torch.topk.yaml,2
1766,210,0.0014347202295552368,3,"frozenset({'sorted', 'order'})","if `True`, checks that the input contains sequences sorted by length in a decreasing order.",torch.nn.utils.rnn.pack_sequence.yaml,2
1767,367,0.0014347202295552368,3,"frozenset({'pooling', 'indices', 'whether', 'return'})",whether to return pooling indices.,torch.nn.functional.adaptive_max_pool3d.yaml,4
1768,367,0.0014347202295552368,3,"frozenset({'pooling', 'indices', 'whether', 'return'})",whether to return pooling indices.,torch.nn.functional.adaptive_max_pool1d.yaml,4
1769,367,0.0014347202295552368,3,"frozenset({'pooling', 'indices', 'whether', 'return'})",whether to return pooling indices.,torch.nn.functional.adaptive_max_pool2d.yaml,4
1770,368,0.0014347202295552368,3,"frozenset({'pooling', 'operation', 'stride'})",stride of the pooling operation.,torch.nn.functional.avg_pool3d.yaml,3
1771,368,0.0014347202295552368,3,"frozenset({'pooling', 'operation', 'stride'})",stride of the pooling operation.,torch.nn.quantized.functional.avg_pool2d.yaml,3
1772,368,0.0014347202295552368,3,"frozenset({'pooling', 'operation', 'stride'})",stride of the pooling operation.,torch.nn.functional.avg_pool2d.yaml,3
1773,369,0.0014347202295552368,3,"frozenset({'also', 'input'})","This option parallels the `align_corners` option in `interpolate()`, and so whichever option is used here should also be used there to resize the input image before grid sampling.",torch.nn.functional.grid_sample.yaml,2
1774,369,0.0014347202295552368,3,"frozenset({'also', 'input'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique.yaml,2
1775,369,0.0014347202295552368,3,"frozenset({'also', 'input'})",Whether to also return the indices for where elements in the original input ended up in the returned unique list.,torch.unique_consecutive.yaml,2
1776,370,0.0014347202295552368,3,"frozenset({'also', 'SOME_DTYPE'})","This field should be given as a lowercase string (e.g., `""gloo""`), which can also be accessed via `Backend` attributes (e.g., `Backend.GLOO`).",torch.distributed.init_process_group.yaml,2
1777,370,0.0014347202295552368,3,"frozenset({'also', 'SOME_DTYPE'})","This field should be given as a lowercase string (e.g., `""gloo""`), which can also be accessed via `Backend` attributes (e.g., `Backend.GLOO`).",torch.distributed.new_group.yaml,2
1778,370,0.0014347202295552368,3,"frozenset({'also', 'SOME_DTYPE'})",Can also be a list of strings if there is only a single list of modules to fuse.,torch.quantization.fuse_modules.yaml,2
1779,209,0.0014347202295552368,3,"frozenset({'input', 'sorted'})","if `True`, the input is expected to contain sequences sorted by length in a decreasing order.",torch.nn.utils.rnn.pack_padded_sequence.yaml,2
1780,209,0.0014347202295552368,3,"frozenset({'input', 'sorted'})","If `False`, the input will get sorted unconditionally.",torch.nn.utils.rnn.pack_padded_sequence.yaml,2
1781,209,0.0014347202295552368,3,"frozenset({'input', 'sorted'})","if `True`, checks that the input contains sequences sorted by length in a decreasing order.",torch.nn.utils.rnn.pack_sequence.yaml,2
1782,207,0.0014347202295552368,3,"frozenset({'tensor', 'collective'})",It should contain correctly-sized tensors to be used for output of the collective.,torch.distributed.all_gather.yaml,2
1783,207,0.0014347202295552368,3,"frozenset({'tensor', 'collective'})",Tensors that participate in the collective operation.,torch.distributed.broadcast_multigpu.yaml,2
1784,207,0.0014347202295552368,3,"frozenset({'tensor', 'collective'})",Input and output GPU tensors of the collective.,torch.distributed.reduce_multigpu.yaml,2
1785,206,0.0014347202295552368,3,"frozenset({'input', 'output', 'collective'})",Input and output of the collective.,torch.distributed.all_reduce.yaml,3
1786,206,0.0014347202295552368,3,"frozenset({'input', 'output', 'collective'})",Input and output of the collective.,torch.distributed.reduce.yaml,3
1787,206,0.0014347202295552368,3,"frozenset({'input', 'output', 'collective'})",Input and output GPU tensors of the collective.,torch.distributed.reduce_multigpu.yaml,3
1788,385,0.0014347202295552368,3,"frozenset({'shape', 'provided', 'tensor'})",a manual rescaling weight if provided it's repeated to match input tensor shape,torch.nn.functional.binary_cross_entropy.yaml,3
1789,385,0.0014347202295552368,3,"frozenset({'shape', 'provided', 'tensor'})","Non-empty tensors provided must have the same shape, except in the cat dimension.",torch.cat.yaml,3
1790,385,0.0014347202295552368,3,"frozenset({'shape', 'provided', 'tensor'})",a manual rescaling weight if provided it's repeated to match input tensor shape,torch.nn.functional.binary_cross_entropy_with_logits.yaml,3
1791,204,0.0014347202295552368,3,"frozenset({'function', 'op', 'argument', 'negative'})",This function is a no-op if this argument is a negative integer.,torch.cuda.get_device_name.yaml,4
1792,204,0.0014347202295552368,3,"frozenset({'function', 'op', 'argument', 'negative'})",This function is a no-op if this argument is negative.,torch.cuda.set_device.yaml,4
1793,204,0.0014347202295552368,3,"frozenset({'function', 'op', 'argument', 'negative'})",This function is a no-op if this argument is a negative integer.,torch.cuda.get_device_capability.yaml,4
1794,203,0.0014347202295552368,3,"frozenset({'SOME_DTYPE', 'negative'})",non-negative scalar temperature,torch.nn.functional.gumbel_softmax.yaml,2
1795,203,0.0014347202295552368,3,"frozenset({'SOME_DTYPE', 'negative'})",This function is a no-op if this argument is a negative integer.,torch.cuda.get_device_name.yaml,2
1796,203,0.0014347202295552368,3,"frozenset({'SOME_DTYPE', 'negative'})",This function is a no-op if this argument is a negative integer.,torch.cuda.get_device_capability.yaml,2
1797,377,0.0014347202295552368,3,"frozenset({'zeros', 'default'})",Default: `'zeros'`,torch.nn.functional.grid_sample.yaml,2
1798,377,0.0014347202295552368,3,"frozenset({'zeros', 'default'})","Default: ""zeros""",torch.nn.quantized.functional.conv2d.yaml,2
1799,377,0.0014347202295552368,3,"frozenset({'zeros', 'default'})","Default: ""zeros""",torch.nn.quantized.functional.conv3d.yaml,2
1800,378,0.0014347202295552368,3,"frozenset({'input', 'order'})","if `True`, the input is expected to contain sequences sorted by length in a decreasing order.",torch.nn.utils.rnn.pack_padded_sequence.yaml,2
1801,378,0.0014347202295552368,3,"frozenset({'input', 'order'})","names to assign to the input nodes of the graph, in order",torch.onnx.export.yaml,2
1802,378,0.0014347202295552368,3,"frozenset({'input', 'order'})","if `True`, checks that the input contains sequences sorted by length in a decreasing order.",torch.nn.utils.rnn.pack_sequence.yaml,2
1803,379,0.0014347202295552368,3,"frozenset({'order', 'controls'})",controls whether to return the elements in sorted order,torch.topk.yaml,2
1804,379,0.0014347202295552368,3,"frozenset({'order', 'controls'})",controls the sorting order (ascending or descending),torch.argsort.yaml,2
1805,379,0.0014347202295552368,3,"frozenset({'order', 'controls'})",controls the sorting order (ascending or descending),torch.sort.yaml,2
1806,201,0.0014347202295552368,3,"frozenset({'input', 'center', 'true', 'tensor'})","If set to `True`, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels.",torch.nn.quantized.functional.interpolate.yaml,4
1807,201,0.0014347202295552368,3,"frozenset({'input', 'center', 'true', 'tensor'})","If set to `True`, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels.",torch.nn.functional.interpolate.yaml,4
1808,201,0.0014347202295552368,3,"frozenset({'input', 'center', 'true', 'tensor'})","if True, center the input tensor, otherwise, assume that the input is centered.",torch.pca_lowrank.yaml,4
1809,200,0.0014347202295552368,3,"frozenset({'input', 'center', 'set', 'corner', 'pixels', 'points', 'true'})","If set to `True`, the extrema (`-1` and `1`) are considered as referring to the center points of the input's corner pixels.",torch.nn.functional.grid_sample.yaml,7
1810,200,0.0014347202295552368,3,"frozenset({'input', 'center', 'set', 'corner', 'pixels', 'points', 'true'})","If set to `True`, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels.",torch.nn.quantized.functional.interpolate.yaml,7
1811,200,0.0014347202295552368,3,"frozenset({'input', 'center', 'set', 'corner', 'pixels', 'points', 'true'})","If set to `True`, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels.",torch.nn.functional.interpolate.yaml,7
1812,382,0.0014347202295552368,3,"frozenset({'none', 'given', 'uses', 'default', 'current', 'current_device', 'SOME_DTYPE'})","It uses the current device, given by `current_device()`, if `device` is `None` (default).",torch.cuda.get_device_name.yaml,7
1813,382,0.0014347202295552368,3,"frozenset({'none', 'given', 'uses', 'default', 'current', 'current_device', 'SOME_DTYPE'})","It uses the current device, given by `current_device()`, if `device` is `None` (default).",torch.cuda.get_device_capability.yaml,7
1814,382,0.0014347202295552368,3,"frozenset({'none', 'given', 'uses', 'default', 'current', 'current_device', 'SOME_DTYPE'})","It uses the current device, given by `current_device()`, if `device` is `None` (default).",torch.cuda.synchronize.yaml,7
1815,196,0.0014347202295552368,3,"frozenset({'p', 'calculate', 'distance'})","p value for the p-norm distance to calculate between each vector pair  in [0,  infty] .",torch.nn.functional.pdist.yaml,3
1816,196,0.0014347202295552368,3,"frozenset({'p', 'calculate', 'distance'})",'use_mm_for_euclid_dist_if_necessary' - will use matrix multiplication approach to calculate euclidean distance (p = 2) if P > 25 or R > 25 'use_mm_for_euclid_dist' - will always use matrix multiplication approach to calculate euclidean distance (p = 2) 'donot_use_mm_for_euclid_dist' - will never use matrix multiplication approach to calculate euclidean distance (p = 2) Default: use_mm_for_euclid_dist_if_necessary.,torch.cdist.yaml,3
1817,196,0.0014347202295552368,3,"frozenset({'p', 'calculate', 'distance'})","p value for the p-norm distance to calculate between each vector pair  in [0,  infty] .",torch.cdist.yaml,3
1818,384,0.0014347202295552368,3,"frozenset({'provided', 'default'})","If set to `None` (default), this value is automatically determined based on whether `cuda_sources` is provided.",torch.utils.cpp_extension.load_inline.yaml,2
1819,384,0.0014347202295552368,3,"frozenset({'provided', 'default'})","Default: if not provided, 0.",torch.triu_indices.yaml,2
1820,384,0.0014347202295552368,3,"frozenset({'provided', 'default'})","Default: if not provided, 0.",torch.tril_indices.yaml,2
1821,1,0.0014347202295552368,3,"frozenset({'distributed', 'function', 'len', 'calling', 'processes'})",You also need to make sure that `len(tensor_list)` is the same for all the distributed processes calling this function.,torch.distributed.broadcast_multigpu.yaml,5
1822,1,0.0014347202295552368,3,"frozenset({'distributed', 'function', 'len', 'calling', 'processes'})",Note that `len(input_tensor_list)` needs to be the same for all the distributed processes calling this function.,torch.distributed.all_gather_multigpu.yaml,5
1823,1,0.0014347202295552368,3,"frozenset({'distributed', 'function', 'len', 'calling', 'processes'})",You also need to make sure that `len(tensor_list)` is the same for all the distributed processes calling this function.,torch.distributed.reduce_multigpu.yaml,5
