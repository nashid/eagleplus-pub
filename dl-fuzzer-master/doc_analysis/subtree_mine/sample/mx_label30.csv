API,Arg,Descp,Normalized_descp,dtype,tensor_t,structure,shape,ndim,range,enum
mxnet.gluon.nn.Dropout,axes,DF: (),,,,,,,,
mxnet.gluon.utils.split_data,data,A batch of data.,A batch of data,,,,,,,
mxnet.gluon.utils.split_and_load,data,A batch of data.,A batch of data,,,,,,,
mxnet.contrib.quantization.quantize_model,excluded_sym_names,A list of strings representing the names of the symbols that users want to excluding from being quantized.,A D_STRUCTURE of D_TYPE representing the names of the symbols that users want to excluding from being quantized,D_TYPE,,D_STRUCTURE,,,,
mxnet.contrib.quantization.quantize_model,label_names,DD: a list of strs,a D_STRUCTURE of strs,D_TYPE,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantize,data,A ndarray/symbol of type float32,A D_STRUCTURE symbol of type D_TYPE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_flatten,data,A ndarray/symbol of type float32,A D_STRUCTURE symbol of type D_TYPE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantize_v2,data,A ndarray/symbol of type float32,A D_STRUCTURE symbol of type D_TYPE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.dequantize,data,A ndarray/symbol of type uint8,A D_STRUCTURE symbol of type D_TYPE,D_TYPE,,D_STRUCTURE,,,,
mxnet.contrib.quantization.quantize_model,calib_data,A data iterator initialized by the calibration dataset.,A data iterator initialized by the calibration dataset,,,,,,,
mxnet.test_utils.verify_generator,generator,A function that is assumed to generate i.i.d samples from a specific distribution.generator(N) should generate N random samples.,A function that is assumed to generate i i d samples from a specific distribution generator BSTR should generate N random samples,,,,,,,
mxnet.contrib.quantization.quantize_model,logger,A logging object for printing information during the process of quantization.,A logging object for printing information during the process of quantization,,,,,,,
mxnet.ndarray.contrib.while_loop,max_iterations,DD: a python int.,a python D_TYPE,D_TYPE,,,,,,
mxnet.contrib.autograd.grad,func,DD: a python function,a python function,,,,,,,
mxnet.ndarray.op.lamb_update_phase1,epsilon,A small constant for numerical stability.,A small constant for numerical stability,numeric,,,,0,,
mxnet.ndarray.rmsprop_update,epsilon,A small constant for numerical stability.,A small constant for numerical stability,numeric,,,,0,,
mxnet.ndarray.op.L2Normalization,eps,A small constant for numerical stability.,A small constant for numerical stability,numeric,,,,0,,
mxnet.ndarray.op.InstanceNorm,beta,"A vector of length 'channel', which is added to the product of the normalized input and the weight.",A D_STRUCTURE of length QSTR which is added to the product of the normalized input and the weight,,,D_STRUCTURE,[BSTR],1,,
mxnet.ndarray.InstanceNorm,beta,"A vector of length 'channel', which is added to the product of the normalized input and the weight.",A D_STRUCTURE of length QSTR which is added to the product of the normalized input and the weight,,,D_STRUCTURE,[BSTR],1,,
mxnet.ndarray.InstanceNorm,gamma,"A vector of length 'channel', which multiplies the normalized input.",A D_STRUCTURE of length QSTR which multiplies the normalized input,,,D_STRUCTURE,[BSTR],1,,
mxnet.test_utils.get_zip_data,data_dir,Absolute or relative path of the directory name to store zip files,Absolute or relative path of the directory name to store zip files,string,,,,0,,
mxnet.ndarray.contrib.allclose,atol,Absolute tolerance.,Absolute tolerance,,,,,,"[0,inf)",
mxnet.ndarray.LeakyReLU,act_type,Activation function to be applied.,Activation function to be applied,,,,,,,
mxnet.gluon.nn.Conv3DTranspose,activation,"Activation function to use. See `Activation()`. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",Activation function to use,,,,,,,
mxnet.io.ImageRecordIter,contrast,"Add a random value in `[-contrast, contrast]` to the contrast of image.",Add a random value in BSTR to the contrast of image,,,,,0,BSTR,
mxnet.io.ImageRecordIter,random_h,"Add a random value in `[-random_h, random_h]` to the H channel in HSL color space.",Add a random value in BSTR to the H channel in HSL color space,,,,,0,BSTR,
mxnet.ndarray.contrib.Proposal,output_score,Add score to outputs,Add score to outputs,,,,,,,
mxnet.metric.create,**kwargs,Additional arguments to metric constructor. Only used when metric is str,Additional arguments to PARAM constructor,,,,,,,
mxnet.metric.create,*args,Additional arguments to metric constructor. Only used when metric is str.,Additional arguments to PARAM constructor,,,,,,,
mxnet.image.CreateDetAugmenter,max_attempts,"Number of attempts at generating a cropped/padded region of the image of the specified constraints. After max_attempts failures, return the original image.",After max_attempts failures return the original image,int,,,,0,"[0,inf)",
mxnet.ndarray.op.sample_generalized_negative_binomial,alpha,Alpha (dispersion) parameters of the distributions.,Alpha BSTR parameters of the distributions,,,,,,,
mxnet.ndarray.random.gamma_like,alpha,Alpha parameter (shape) of the gamma distribution.,Alpha parameter BSTR of the gamma distribution,,,,,,,
mxnet.ndarray.split,squeeze_axis,"If true, Removes the axis with length 1 from the shapes of the output arrays. Note that setting squeeze_axis to `true` removes axis with length 1 only along the axis which it is split. Also squeeze_axis can be set to `true` only if `input.shape[axis] == num_outputs`.",Also squeeze_axis can be set to CONSTANT_BOOL only if input shape BSTR PARAM,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,activation,"Type of activation function used in n_t. If argument type is string, it's equivalent to nn.Activation(act_type=str). See `Activation()` for available choices. Alternatively, other activation blocks such as nn.LeakyReLU can be used.",Alternatively other activation blocks such as nn LeakyReLU can be used,,,,,,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,activation,"Type of activation function. If argument type is string, it's equivalent to nn.Activation(act_type=str). See `Activation()` for available choices. Alternatively, other activation blocks such as nn.LeakyReLU can be used.",Alternatively other activation blocks such as nn LeakyReLU can be used,,,,,,,
mxnet.ndarray.random.multinomial,data,"An n dimensional array whose last dimension has length k, where k is the number of possible outcomes of each multinomial distribution. For example, data with shape (m, n, k) specifies m*n multinomial distributions each with k possible outcomes.",An n dimensional D_STRUCTURE whose last dimension has length k where k is the number of possible outcomes of each multinomial distribution,,,D_STRUCTURE,,,,
mxnet.ndarray.op.InstanceNorm,data,"An n-dimensional input array (n > 2) of the form [batch, channel, spatial_dim1, spatial_dim2, ...].",An n dimensional input D_STRUCTURE n REXPR of the form BSTR,,,D_STRUCTURE,,REXPR,,
mxnet.ndarray.array,source_array,"An object exposing the array interface, an object whose __array__ method returns an array, or any (nested) sequence.",An object exposing the D_STRUCTURE interface an object whose array method returns an D_STRUCTURE or any BSTR D_STRUCTURE,,,,,,,
mxnet.ndarray.ones,ctx,An optional device context. Defaults to the current default context (`mxnet.context.current_context()`).,An optional device context,,,,,,,
mxnet.ndarray.zeros,ctx,An optional device context (default is the current default context),An optional device context BSTR,,,,,,,
mxnet.ndarray.empty,ctx,An optional device context (default is the current default context).,An optional device context BSTR,,,,,,,
mxnet.ndarray.empty,stype,An optional storage type (default is default).,An optional storage type BSTR,,,,,,,
mxnet.io.ImageRecordIter,max_shear_ratio,"Apply a shear transformation (namely `(x,y)->(x+my,y)`) with `m` randomly chose from `[-max_shear_ratio, max_shear_ratio]`",Apply a shear transformation namely BSTR REXPR with QSTR randomly chose from BSTR,,,,,,,
mxnet.gluon.nn.Conv2DTranspose,groups,"Controls the connections between inputs and outputs. At groups=1, all inputs are convolved to all outputs. At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated.",At groups CONSTANT_NUM all inputs are convolved to all outputs,,,,,,,CONSTANT_NUM
mxnet.gluon.nn.Conv2DTranspose,groups,"Controls the connections between inputs and outputs. At groups=1, all inputs are convolved to all outputs. At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated.",At groups CONSTANT_NUM the operation becomes equivalent to having two conv layers side by side each seeing half the input PARAM and producing half the output PARAM and both subsequently concatenated,,,,,,,CONSTANT_NUM
mxnet.io.ImageDetRecordIter,max_pad_scale,Augmentation Param: Maximum padding scale.,Augmentation Param Maximum padding PARAM,numeric,,,,,,
mxnet.io.ImageDetRecordIter,max_random_hue,Augmentation Param: Maximum random value of H channel in HSL color space.,Augmentation Param Maximum random value of H channel in HSL color space,numeric,,,,,,
mxnet.io.ImageDetRecordIter,max_random_saturation,Augmentation Param: Maximum random value of S channel in HSL color space.,Augmentation Param Maximum random value of S channel in HSL color space,numeric,,,,,,
mxnet.io.ImageDetRecordIter,max_crop_sample_coverages,Augmentation Param: Maximum ratio of intersect/crop_area between crop box and ground-truths.,Augmentation Param Maximum ratio of intersect crop_area between crop box and ground truths,numeric,,,,,,
mxnet.io.ImageDetRecordIter,mean_img,Augmentation Param: Mean Image to be subtracted.,Augmentation Param Mean Image to be subtracted,numeric,,,,,,
mxnet.io.ImageDetRecordIter,min_crop_overlaps,Augmentation Param: Minimum crop IOU between crop_box and ground-truths.,Augmentation Param Minimum crop IOU between crop_box and ground truths,numeric,,,,,,
mxnet.io.ImageDetRecordIter,min_crop_object_coverages,Augmentation Param: Minimum ratio of intersect/gt_area between crop box and ground-truths.,Augmentation Param Minimum ratio of intersect gt_area between crop box and ground truths,numeric,,,,,,
mxnet.io.ImageDetRecordIter,random_contrast_prob,Augmentation Param: Probability to apply random contrast.,Augmentation Param Probability to apply random contrast,,,,,,"[0,1]",
mxnet.io.ImageRecordIter,std_a,Augmentation Param: Standard deviation on Alpha channel.,Augmentation Param Standard deviation on Alpha channel,numeric,,,,,,
mxnet.io.ImageDetRecordIter,std_b,Augmentation Param: Standard deviation on B channel.,Augmentation Param Standard deviation on B channel,numeric,,,,,,
mxnet.io.ImageDetRecordIter,std_r,Augmentation Param: Standard deviation on R channel.,Augmentation Param Standard deviation on R channel,numeric,,,,,,
mxnet.ndarray.broadcast_like,rhs_axes,Axes to copy from the second input array,Axes to copy from the second input D_STRUCTURE,int,,,,,,
mxnet.io.CSVIter,batch_size,Batch size.,Batch size,int,,,,,"[0,inf)",
mxnet.contrib.ndarray.Proposal,bbox_pred,BBox Predicted deltas from anchors for proposals,BBox Predicted deltas from anchors for proposals,,,,,,,
mxnet.ndarray.op.random_gamma,beta,Beta parameter (scale) of the gamma distribution.,Beta parameter BSTR of the gamma distribution,,,,,,,
mxnet.ndarray.sparse.FullyConnected,bias,Bias parameter.,Bias parameter,,,,,,,
mxnet.contrib.ndarray.DeformableConvolution,bias,Bias parameter.,Bias parameter,,,,,,,
mxnet.image.imdecode,buf,Binary image data as string or numpy ndarray.,Binary image data as D_TYPE or numpy D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.space_to_depth,block_size,Blocks of [block_size. block_size] are moved,block_size are moved,,,,,,,
mxnet.ndarray.space_to_depth,block_size,Blocks of [block_size. block_size] are moved,Blocks of block_size,,,,,,,
mxnet.ndarray.contrib.RROIAlign,rois,"Bounding box coordinates, a 2D array",Bounding box coordinates a CONSTANT_NUM D D_STRUCTURE,,,D_STRUCTURE,,CONSTANT_NUM,,
mxnet.image.CreateAugmenter,brightness,Brightness jittering range (percent),Brightness jittering range BSTR,,,,,,,
mxnet.image.CreateDetAugmenter,brightness,Brightness jittering range (percent),Brightness jittering range BSTR,,,,,,,
mxnet.image.CreateAugmenter,rand_gray,"[0, 1], probability to convert to grayscale for all channels, the number of channels will not be reduced to 1",BSTR probability to convert to grayscale for all channels the number of channels will not be reduced to CONSTANT_NUM,numeric,,,,CONSTANT_NUM,"[0,1];BSTR",
mxnet.ndarray.contrib.box_encode,matches,"(B, N) value range [0, M)",BSTR value range BSTR,,,,BSTR,,BSTR,
mxnet.ndarray.load_frombuffer,buf,Buffer containing contents of a file as a string or bytes.,Buffer containing contents of a file as a D_TYPE or bytes,D_TYPE,,,,,,
mxnet.image.CreateAugmenter,inter_method,"Interpolation method for all resizing operations Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). ",But when the image is zoomed it is similar to the Nearest Neighbors method,,,,,,,
mxnet.gluon.contrib.rnn.LSTMPCell,i2h_bias_initializer,"Initializer for the bias vector. By default, bias for the forget gate is initialized to 1 while all other biases are initialized to zero.",By default bias for the forget gate is initialized to CONSTANT_NUM while all other biases are initialized to zero,,,,,,,
mxnet.ndarray.op.repeat,axis,"The axis along which to repeat values. The negative numbers are interpreted counting from the backward. By default, use the flattened input array, and return a flat output array.",By default use the flattened input D_STRUCTURE and return a flat output D_STRUCTURE,,,,,,,
mxnet.ndarray.slice_like,axes,List of axes on which input data will be sliced according to the corresponding size of the second input. By default will slice on all axes. Negative axes are supported.,By default will slice on all axes,,,,,,,
mxnet.ndarray.moveaxis,source,Original position of the axes to move. Can be negative but must be unique.,Can be negative but must be unique,,,,,,,
mxnet.gluon.rnn.BidirectionalCell,r_cell,Cell for backward unrolling,Cell for backward unrolling,,,,,,,
mxnet.io.ImageRecordIter,max_random_area,"Change the area (namely width * height) to a random value in `[min_random_area, max_random_area]`. Ignored if `random_resized_crop` is False.",Change the area BSTR to a random value in BSTR,,,,,,,
mxnet.io.ImageRecordIter,min_random_area,"Change the area (namely width * height) to a random value in `[min_random_area, max_random_area]`. Ignored if `random_resized_crop` is False.",Change the area BSTR to a random value in BSTR,,,,,,,
mxnet.io.ImageRecordIter,max_aspect_ratio,"Change the aspect (namely width/height) to a random value. If min_aspect_ratio is None then the aspect ratio ins sampled from [1 - max_aspect_ratio, 1 + max_aspect_ratio], else it is in `[min_aspect_ratio, max_aspect_ratio]`",Change the aspect BSTR to a random value,,,,,,,
mxnet.ndarray.SVMOutput,label,Class label for the input data.,Class label for the input PARAM,,,,,,,
mxnet.ndarray.op.MakeLoss,valid_thresh,clip each element in the array to 0 when it is less than `valid_thresh`. This is used when `normalization` is set to `'valid'`.,clip each element in the D_STRUCTURE to CONSTANT_NUM when it is less than QSTR,,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase1,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",Clip gradient to the range of BSTR If clip_gradient REXPR gradient clipping is turned off,numeric,,,,0,,
mxnet.ndarray.op.signum_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",Clip gradient to the range of BSTR If clip_gradient REXPR gradient clipping is turned off,numeric,,,,0,,
mxnet.ndarray.ftml_update,clip_grad,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",Clip gradient to the range of BSTR If clip_gradient REXPR gradient clipping is turned off,numeric,,,,0,,
mxnet.ndarray.mp_sgd_mom_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",Clip gradient to the range of BSTR If clip_gradient REXPR gradient clipping is turned off,numeric,,,,0,,
mxnet.ndarray.op.multi_mp_sgd_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",Clip gradient to the range of BSTR If clip_gradient REXPR gradient clipping is turned off,numeric,,,,0,,
mxnet.contrib.ndarray.group_adagrad_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",Clip gradient to the range of BSTR If clip_gradient REXPR gradient clipping is turned off,numeric,,,,0,,
mxnet.ndarray.multi_sgd_mom_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",Clip gradient to the range of BSTR If clip_gradient REXPR gradient clipping is turned off,numeric,,,,0,,
mxnet.ndarray.contrib.MultiBoxDetection,clip,Clip out-of-boundary boxes.,Clip PARAM of boundary boxes,,,,,,,
mxnet.ndarray.contrib.quadratic,b,Coefficient of the linear term in the quadratic function.,Coefficient of the linear term in the quadratic function,numeric,,,,,,
mxnet.ndarray.Embedding,sparse_grad,"Compute row sparse gradient in the backward calculation. If set to True, the grad's storage type is row_sparse.",Compute row sparse gradient in the backward calculation,,,,,,,
mxnet.ndarray.op.UpSampling,multi_input_mode,"How to handle multiple input. concat means concatenate upsampled images along the channel dimension. sum means add all images together, only available for nearest neighbor upsampling.",concat means concatenate upsampled images along the channel dimension,,,,,,,
mxnet.ndarray.op.Softmax,smooth_alpha,Constant for computing a label smoothed version of cross-entropyfor the backwards pass.  This constant gets subtracted from theone-hot encoding of the gold label and distributed uniformly toall other labels.,Constant for computing a PARAM smoothed version of cross entropyfor the backwards pass,,,,,,,
mxnet.image.CreateAugmenter,inter_method,"Interpolation method for all resizing operations Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). ",CONSTANT_NUM Area based BSTR,int,,,,0,,QSTR
mxnet.image.CreateAugmenter,inter_method,"Interpolation method for all resizing operations Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). ",CONSTANT_NUM Bicubic interpolation over 4x4 pixel neighborhood,int,,,,0,,QSTR
mxnet.image.CreateAugmenter,inter_method,"Interpolation method for all resizing operations Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). ",CONSTANT_NUM Bilinear interpolation,int,,,,0,,QSTR
mxnet.gluon.nn.Conv2D,dilation,"DF: (1,1)",CONSTANT_NUM CONSTANT_NUM,int,,,,1,,
mxnet.gluon.contrib.rnn.Conv2DRNNCell,h2h_dilate,"DF: (1,1)",CONSTANT_NUM CONSTANT_NUM,int,,,,1,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,h2h_dilate,"DF: (1,1)",CONSTANT_NUM CONSTANT_NUM,int,,,,1,,
mxnet.gluon.nn.Conv2D,strides,"DF: (1,1)",CONSTANT_NUM CONSTANT_NUM,int,,,,1,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,i2h_pad,"DF: (0,0,0)",CONSTANT_NUM CONSTANT_NUM CONSTANT_NUM,int,,,,1,,
mxnet.gluon.contrib.rnn.Conv3DLSTMCell,i2h_pad,"DF: (0,0,0)",CONSTANT_NUM CONSTANT_NUM CONSTANT_NUM,int,,,,1,,
mxnet.gluon.nn.Conv3D,padding,"DF: (0,0,0)",CONSTANT_NUM CONSTANT_NUM CONSTANT_NUM,int,,,,1,,
mxnet.gluon.nn.Conv3DTranspose,padding,"DF: (0,0,0)",CONSTANT_NUM CONSTANT_NUM CONSTANT_NUM,int,,,,1,,
mxnet.gluon.nn.Conv3DTranspose,dilation,"DF: (1,1,1)",CONSTANT_NUM CONSTANT_NUM CONSTANT_NUM,int,,,,1,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,h2h_dilate,"DF: (1,1,1)",CONSTANT_NUM CONSTANT_NUM CONSTANT_NUM,int,,,,1,,
mxnet.gluon.nn.Conv3D,dilation,"DF: (1,1,1)",CONSTANT_NUM CONSTANT_NUM CONSTANT_NUM,int,,,,1,,
mxnet.gluon.nn.Conv3DTranspose,strides,"DF: (1,1,1)",CONSTANT_NUM CONSTANT_NUM CONSTANT_NUM,int,,,,1,,
mxnet.gluon.nn.AvgPool3D,pool_size,"DF: (2,2,2)",CONSTANT_NUM CONSTANT_NUM CONSTANT_NUM,int,,,,1,,
mxnet.ndarray.linalg_extracttrian,offset,"Offset of the diagonal versus the main diagonal. 0 corresponds to the main diagonal, a negative/positive value to diagonals below/above the main diagonal.",CONSTANT_NUM corresponds to the main diagonal a negative positive value to diagonals below above the main diagonal,int,,,,0,,
mxnet.ndarray.linalg.maketrian,offset,"Offset of the diagonal versus the main diagonal. 0 corresponds to the main diagonal, a negative/positive value to diagonals below/above the main diagonal.",CONSTANT_NUM corresponds to the main diagonal a negative positive value to diagonals below above the main diagonal,int,,,,0,,
mxnet.ndarray.op.linalg_maketrian,offset,"Offset of the diagonal versus the main diagonal. 0 corresponds to the main diagonal, a negative/positive value to diagonals below/above the main diagonal.",CONSTANT_NUM corresponds to the main diagonal a negative positive value to diagonals below above the main diagonal,int,,,,0,,
mxnet.image.CreateAugmenter,inter_method,"Interpolation method for all resizing operations Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). ",CONSTANT_NUM Cubic for enlarge area for shrink bilinear for others CONSTANT_NUM Random select from interpolation method metioned above,int,,,,0,,QSTR
mxnet.image.imread,flag,"DD: {0, 1}, default 1",CONSTANT_NUM default CONSTANT_NUM,int,,,,0,,QSTR
mxnet.image.imread,flag,1 for three channel color output. 0 for grayscale output.,CONSTANT_NUM for grayscale output,int,,,,0,,QSTR
mxnet.image.imread,flag,1 for three channel color output. 0 for grayscale output.,CONSTANT_NUM for three channel color output,int,,,,0,,QSTR
mxnet.image.CreateAugmenter,inter_method,"Interpolation method for all resizing operations Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). ",CONSTANT_NUM Lanczos interpolation over 8x8 pixel neighborhood,int,,,,0,,QSTR
mxnet.gluon.nn.MaxPool2D,strides,"Factor by which to downscale. E.g. 2 will halve the input size. If None, it will default to pool_size.",CONSTANT_NUM will halve the input size,int,,,,,,
mxnet.gluon.nn.AvgPool2D,strides,"Factor by which to downscale. E.g. 2 will halve the input size. If None, it will default to pool_size.",CONSTANT_NUM will halve the input size,int,,,,,,
mxnet.gluon.rnn.LSTMCell,params,Container for weight sharing between cells. Created if None.,Container for weight sharing between cells,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,params,Container for weight sharing between cells. Created if None.,Container for weight sharing between cells,,,,,,,
mxnet.gluon.rnn.RNNCell,params,Container for weight sharing between cells. Created if None.,Container for weight sharing between cells,,,,,,,
mxnet.gluon.rnn.GRUCell,params,Container for weight sharing between cells. Created if None.,Container for weight sharing between cells,,,,,,,
mxnet.gluon.model_zoo.vision.vgg19,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
mxnet.gluon.model_zoo.vision.get_model,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
mxnet.gluon.model_zoo.vision.get_vgg,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
mxnet.gluon.model_zoo.vision.resnet50_v1,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
mxnet.gluon.model_zoo.vision.vgg16,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
mxnet.gluon.model_zoo.vision.mobilenet0_25,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
mxnet.ndarray.op.random_randint,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls.",Context of output in format cpu gpu cpu_pinned BSTR,,,,,,,
mxnet.ndarray.op.random_generalized_negative_binomial,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls.",Context of output in format cpu gpu cpu_pinned BSTR,,,,,,,
mxnet.ndarray.random_uniform,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls.",Context of output in format cpu gpu cpu_pinned BSTR,,,,,,,
mxnet.ndarray.linspace,ctx,"DD: Context, optional",Context optional,,,,,,,
mxnet.ndarray.ones,ctx,"DD: Context, optional",Context optional,,,,,,,
mxnet.ndarray.zeros,ctx,"DD: Context, optional",Context optional,,,,,,,
mxnet.test_utils.check_symbolic_backward,ctx,"DD: Context, optional",Context optional,,,,,,,
mxnet.ndarray.full,ctx,"DD: Context, optional",Context optional,,,,,,,
mxnet.ndarray.empty,ctx,"DD: Context, optional",Context optional,,,,,,,
mxnet.gluon.nn.Conv2DTranspose,groups,"Controls the connections between inputs and outputs. At groups=1, all inputs are convolved to all outputs. At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated.",Controls the connections between inputs and outputs,,,,,,,
mxnet.gluon.nn.Conv3DTranspose,dilation,Controls the spacing between the kernel points; also known as the a trous algorithm.,Controls the spacing between the kernel points also known as the a trous algorithm,,,,,,,
mxnet.ndarray.contrib.quantized_conv,dilate,"Convolution dilate: (w,), (h, w) or (d, h, w). Defaults to 1 for each dimension.",Convolution dilate BSTR,,,,BSTR,,,
mxnet.contrib.ndarray.quantized_conv,dilate,"Convolution dilate: (w,), (h, w) or (d, h, w). Defaults to 1 for each dimension.",Convolution dilate BSTR,,,,BSTR,,,
mxnet.ndarray.op.Convolution,dilate,"Convolution dilate: (w,), (h, w) or (d, h, w). Defaults to 1 for each dimension.",Convolution dilate BSTR,,,,BSTR,,,
mxnet.gluon.nn.Conv1DTranspose,layout,"Dimension ordering of data and weight. Only supports 'NCW' layout for now. 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Convolution is applied on the 'W' dimension.",Convolution is applied on the QSTR dimension,,,,,,,
mxnet.gluon.nn.Conv1D,layout,"Dimension ordering of data and weight. Only supports 'NCW' layout for now. 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Convolution is applied on the 'W' dimension.",Convolution is applied on the QSTR dimension,,,,,,,
mxnet.gluon.nn.Conv2DTranspose,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",Convolution is applied on the QSTR dimensions,,,,,,,
mxnet.ndarray.contrib.DeformableConvolution,kernel,"Convolution kernel size: (h, w) or (d, h, w)",Convolution kernel size BSTR,int,,,,,"[0,inf)",
mxnet.contrib.ndarray.DeformableConvolution,kernel,"Convolution kernel size: (h, w) or (d, h, w)",Convolution kernel size BSTR,int,,,,,"[0,inf)",
mxnet.contrib.ndarray.DeformableConvolution,stride,"Convolution stride: (h, w) or (d, h, w). Defaults to 1 for each dimension.",Convolution stride BSTR,int,,,,,"[0,inf)",
mxnet.gluon.model_zoo.vision.get_vgg,ctx,DF: cpu(0),cpu CONSTANT_NUM,,,,,,,
mxnet.contrib.quantization.quantize_model,ctx,DF: cpu(0),cpu CONSTANT_NUM,,,,,,,
mxnet.contrib.quantization.quantize_net,ctx,DF: cpu(0),cpu CONSTANT_NUM,,,,,,,
mxnet.gluon.rnn.LSTMCell,params,Container for weight sharing between cells. Created if None.,Created if None,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,params,Container for weight sharing between cells. Created if None.,Created if None,,,,,,,
mxnet.gluon.rnn.RNNCell,params,Container for weight sharing between cells. Created if None.,Created if None,,,,,,,
mxnet.gluon.rnn.GRUCell,params,Container for weight sharing between cells. Created if None.,Created if None,,,,,,,
mxnet.io.ImageRecordIter,min_crop_size,"Crop both width and height into a random size in `[min_crop_size, max_crop_size].``Ignored if ``random_resized_crop` is True.",Crop both width and height into a random size in BSTR Ignored if PARAM is CONSTANT_BOOL,,,,,,,
mxnet.contrib.quantization.quantize_model,ctx,"Defines the device that users want to run forward propagation on the calibration dataset for collecting layer output statistics. Currently, only supports single context.",Currently only supports single context,,,,,,,
mxnet.contrib.quantization.quantize_net,ctx,"Defines the device that users want to run forward propagation on the calibration dataset for collecting layer output statistics. Currently, only supports single context.",Currently only supports single context,,,,,,,
mxnet.ndarray.norm,ord,Order of the norm. Currently ord=1 and ord=2 is supported.,Currently ord CONSTANT_NUM and ord CONSTANT_NUM is supported,,,,,,,CONSTANT_NUM
mxnet.ndarray.sparse.row_sparse_array,arg1,"DD: NDArray, numpy.ndarray, RowSparseNDArray, tuple of int or tuple of array_like",D_STRUCTURE numpy D_STRUCTURE RowSparseNDArray D_STRUCTURE of D_TYPE or D_STRUCTURE of D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.slice_like,axes,List of axes on which input data will be sliced according to the corresponding size of the second input. By default will slice on all axes. Negative axes are supported.,D_STRUCTURE of axes on which input PARAM will be sliced according to the corresponding size of the second input,int,,D_STRUCTURE,,,,
mxnet.test_utils.download_model,meta_info,DD: dict of dict,D_STRUCTURE of D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.autograd.grad,variables,DD: NDArray or list of NDArray,D_STRUCTURE of D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.stack,*data,List of arrays to stack,D_STRUCTURE of D_STRUCTURE to stack,,,D_STRUCTURE,,,,
mxnet.contrib.quantization.quantize_model,excluded_sym_names,DD: list of strings,D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,input_shape,DD: tuple of int,D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_makediag,A,Tensor of diagonal entries,D_STRUCTURE of diagonal entries,,D_STRUCTURE,,,,,
mxnet.ndarray.linalg.makediag,A,Tensor of diagonal entries,D_STRUCTURE of diagonal entries,,D_STRUCTURE,,,,,
mxnet.ndarray.op.linalg_makediag,A,Tensor of diagonal entries,D_STRUCTURE of diagonal entries,,D_STRUCTURE,,,,,
mxnet.ndarray.linalg.syrk,A,Tensor of input matrices,D_STRUCTURE of input matrices,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.op.linalg_gemm,B,Tensor of input matrices,D_STRUCTURE of input matrices,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.linalg.gemm2,A,Tensor of input matrices,D_STRUCTURE of input matrices,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.linalg_potrf,A,Tensor of input matrices to be decomposed,D_STRUCTURE of input matrices to be decomposed,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.linalg.potri,A,Tensor of lower triangular matrices,D_STRUCTURE of lower triangular matrices,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.image.normalize,mean,Sequence of means for each channel. Default value is 0.,D_STRUCTURE of means for each channel,numeric,,D_STRUCTURE,,,,
mxnet.contrib.quantization.quantize_model,aux_params,Dictionary of name to NDArray.,D_STRUCTURE of name to D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.test_utils.check_symbolic_backward,expected,DD: list of np.ndarray or dict of str to np.ndarray,D_STRUCTURE of np D_STRUCTURE of D_TYPE to np D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_trsm,A,Tensor of lower triangular matrices,D_STRUCTURE of PARAM triangular matrices,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.linalg_trmm,A,Tensor of lower triangular matrices,D_STRUCTURE of PARAM triangular matrices,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.contrib.MultiBoxPrior,steps,"DD: tuple of <float>, optional, default=[-1,-1]",D_STRUCTURE of REXPR optional default BSTR,REXPR,,D_STRUCTURE,,1,,
mxnet.contrib.ndarray.MultiBoxPrior,steps,"DD: tuple of <float>, optional, default=[-1,-1]",D_STRUCTURE of REXPR optional default BSTR,REXPR,,D_STRUCTURE,,1,,
mxnet.ndarray.image.normalize,mean,"DD: tuple of <float>, optional, default=[0,0,0,0]",D_STRUCTURE of REXPR optional default BSTR,REXPR,,D_STRUCTURE,,1,,
mxnet.ndarray.contrib.MultiBoxPrior,offsets,"DD: tuple of <float>, optional, default=[0.5,0.5]",D_STRUCTURE of REXPR optional default BSTR,REXPR,,D_STRUCTURE,,1,,
mxnet.ndarray.contrib.MultiProposal,ratios,"DD: tuple of <float>, optional, default=[0.5,1,2]",D_STRUCTURE of REXPR optional default BSTR,REXPR,,D_STRUCTURE,,1,,
mxnet.io.ImageDetRecordIter,min_crop_overlaps,"DD: tuple of <float>, optional, default=[0]",D_STRUCTURE of REXPR optional default BSTR,REXPR,,D_STRUCTURE,,1,,
mxnet.io.ImageDetRecordIter,min_crop_object_coverages,"DD: tuple of <float>, optional, default=[0]",D_STRUCTURE of REXPR optional default BSTR,REXPR,,D_STRUCTURE,,1,,
mxnet.io.ImageDetRecordIter,max_crop_sample_coverages,"DD: tuple of <float>, optional, default=[1]",D_STRUCTURE of REXPR optional default BSTR,REXPR,,D_STRUCTURE,,1,,
mxnet.contrib.ndarray.Proposal,scales,"DD: tuple of <float>, optional, default=[4,8,16,32]",D_STRUCTURE of REXPR optional default BSTR,REXPR,,D_STRUCTURE,,1,,
mxnet.ndarray.multi_sgd_mom_update,lrs,"DD: tuple of <float>, required",D_STRUCTURE of REXPR required,REXPR,,D_STRUCTURE,,,,
mxnet.ndarray.op.multi_sgd_mom_update,wds,"DD: tuple of <float>, required",D_STRUCTURE of REXPR required,REXPR,,D_STRUCTURE,,,,
mxnet.ndarray.op.multi_sgd_update,lrs,"DD: tuple of <float>, required",D_STRUCTURE of REXPR required,REXPR,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.dgl_graph_compact,graph_sizes,"DD: tuple of <long>, required",D_STRUCTURE of REXPR required,REXPR,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.det,A,Tensor of square matrix,D_STRUCTURE of square matrix,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.op.linalg_slogdet,A,Tensor of square matrix,D_STRUCTURE of square matrix,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.linalg.slogdet,A,Tensor of square matrix,D_STRUCTURE of square matrix,numeric,D_STRUCTURE,,,,,
mxnet.visualization.plot_network,shape,"DD: dict, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.MultiBoxPrior,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.reshape_like,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.trunc,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_axes,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_fully_connected,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.multi_lars,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_hypot,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.backward_hawkesll,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.SwapAxis,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.rint,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.calibrate_entropy,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.index_array,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.multi_sum_sq,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.sign_ste,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.ctc_loss,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.AdaptiveAvgPooling2D,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.elemwise_sub,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.one_hot,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sigmoid,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.DeformableConvolution,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.interleaved_matmul_selfatt_valatt,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.image.random_flip_left_right,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.rmsprop_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.argsort,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.min_axis,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.shape_array,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.cos,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_lesser_equal,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.box_non_maximum_suppression,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.argmax_channel,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.GroupNorm,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_syrk,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.sgd_mom_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_makediag,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.SoftmaxOutput,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.RROIAlign,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.smooth_l1,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.expm1,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.det,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.random_uniform,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.backward_index_copy,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.slice_like,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.cosh,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.FullyConnected,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.ctc_loss,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_pdf_negative_binomial,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_randint,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.Deconvolution,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.SyncBatchNorm,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_act,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.random.shuffle,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.transpose,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_minus,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.BilinearSampler,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_concat,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_pdf_poisson,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sign,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.degrees,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.random_normal,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.image.resize,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.RNN,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.adagrad_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.ROIAlign,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.L2Normalization,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sort,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.preloaded_multi_mp_sgd_mom_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.SoftmaxOutput,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.backward_gradientmultiplier,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.cos,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.multi_sgd_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.round_ste,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_add,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sample_multinomial,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.reshape_like,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.bipartite_matching,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.LinearRegressionOutput,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sinh,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.random_gamma,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.flatten,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.arcsinh,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quadratic,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.shape_array,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.topk,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_det,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_sub,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.choose_element_0index,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.size_array,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.tan,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.ravel_multi_index,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.gemm2,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.MultiProposal,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.preloaded_multi_sgd_mom_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.random.negative_binomial,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_pdf_normal,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.backward_quadratic,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.concat,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_div,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.round,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_to,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_batch_norm,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.SVMOutput,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.adam_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.broadcast_minus,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.gammaln,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.square,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.edge_id,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.ElementWiseSum,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.clip,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.random.generalized_negative_binomial,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.log1p,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.LRN,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.slogdet,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_lesser,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.argmin,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.exp,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.rmspropalex_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.adam_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.lamb_update_phase1,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.random_pdf_gamma,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sigmoid,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sample_generalized_negative_binomial,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_extractdiag,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.nag_mom_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.identity,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.random.shuffle,out,Array to store the result.,D_STRUCTURE to store the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.AdaptiveAvgPooling2D,output_size,"int (output size) or a tuple of int for output (height, width).",D_TYPE BSTR,D_TYPE,,,,,,
mxnet.ndarray.op.Correlation,max_displacement,"DD: int (non-negative), optional, default=1",D_TYPE BSTR optional default CONSTANT_NUM,D_TYPE,,,,0,"[0,inf)",
mxnet.ndarray.op.Convolution,num_group,"DD: int (non-negative), optional, default=1",D_TYPE BSTR optional default CONSTANT_NUM,D_TYPE,,,,0,"[0,inf)",
mxnet.contrib.ndarray.quantized_conv,num_group,"DD: int (non-negative), optional, default=1",D_TYPE BSTR optional default CONSTANT_NUM,D_TYPE,,,,0,"[0,inf)",
mxnet.ndarray.Correlation,stride2,"DD: int (non-negative), optional, default=1",D_TYPE BSTR optional default CONSTANT_NUM,D_TYPE,,,,0,"[0,inf)",
mxnet.ndarray.op.Correlation,stride1,"DD: int (non-negative), optional, default=1",D_TYPE BSTR optional default CONSTANT_NUM,D_TYPE,,,,0,"[0,inf)",
mxnet.io.CSVIter,batch_size,"DD: int (non-negative), required",D_TYPE BSTR required,D_TYPE,,,,,"[0,inf)",
mxnet.ndarray.Deconvolution,num_filter,"DD: int (non-negative), required",D_TYPE BSTR required,D_TYPE,,,,CONSTANT_NUM,"[0,inf)",
mxnet.recordio.unpack_img,s,String buffer from `MXRecordIO.read`.,D_TYPE buffer from MXRecordIO read,D_TYPE,,,,,,
mxnet.image.imdecode,buf,DD: str/bytes/bytearray or numpy.ndarray,D_TYPE bytes bytearray or numpy D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.gluon.nn.MaxPool2D,strides,"DD: int, list/tuple of 2 ints, or None.",D_TYPE D_STRUCTURE of CONSTANT_NUM D_TYPE or None,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
mxnet.gluon.nn.AvgPool2D,strides,"DD: int, list/tuple of 2 ints, or None.",D_TYPE D_STRUCTURE of CONSTANT_NUM D_TYPE or None,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
mxnet.gluon.nn.MaxPool3D,ceil_mode,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.squeezenet1_1,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.resnet152_v2,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.mobilenet0_5,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.vgg19_bn,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.get_mobilenet,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.mobilenet0_25,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.squeezenet1_0,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.inception_v3,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.rnn.LSTM,bidirectional,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.resnet34_v1,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.vgg16,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.vgg11,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.get_resnet,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.utils.download,verify_ssl,"DD: bool, default True",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.nn.GroupNorm,center,"DD: bool, default True",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.utils.split_and_load,even_split,"DD: bool, default True",D_TYPE default CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.contrib.rnn.VariationalDropoutCell,drop_states,"DD: float, default 0.",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.nn.LayerNorm,axis,"DD: int, default -1",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.contrib.nn.Concurrent,axis,"DD: int, default -1",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.nn.InstanceNorm,in_channels,"DD: int, default 0",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.nn.Conv3D,in_channels,"DD: int, default 0",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.nn.LayerNorm,in_channels,"DD: int, default 0",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.utils.split_data,batch_axis,"DD: int, default 0",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.contrib.nn.SyncBatchNorm,in_channels,"DD: int, default 0",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.nn.Conv1DTranspose,in_channels,"DD: int, default 0",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.nn.InstanceNorm,axis,"DD: int, default 1",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.nn.BatchNorm,axis,"DD: int, default 1",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.utils.download,retries,"DD: integer, default 5",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.image.CreateAugmenter,inter_method,"DD: int, default=2(Area-based",D_TYPE default CONSTANT_NUM Area based,D_TYPE,,,,0,,
mxnet.gluon.model_zoo.vision.vgg19_bn,root,"DD: str, default '$MXNET_HOME/models'",D_TYPE default MXNET_HOME models,D_TYPE,,,,0,,
mxnet.gluon.model_zoo.vision.squeezenet1_1,root,"DD: str, default '$MXNET_HOME/models'",D_TYPE default MXNET_HOME models,D_TYPE,,,,0,,
mxnet.gluon.model_zoo.vision.resnet18_v1,root,"DD: str, default '$MXNET_HOME/models'",D_TYPE default MXNET_HOME models,D_TYPE,,,,0,,
mxnet.gluon.model_zoo.vision.vgg16_bn,root,"DD: str, default '$MXNET_HOME/models'",D_TYPE default MXNET_HOME models,D_TYPE,,,,0,,
mxnet.gluon.model_zoo.vision.resnet34_v1,root,"DD: str, default '$MXNET_HOME/models'",D_TYPE default MXNET_HOME models,D_TYPE,,,,0,,
mxnet.gluon.model_zoo.vision.get_mobilenet_v2,root,"DD: str, default $MXNET_HOME/models",D_TYPE default MXNET_HOME models,D_TYPE,,,,0,,
mxnet.gluon.rnn.LSTM,dtype,"DD: str, default 'float32'",D_TYPE default QSTR,D_TYPE,,,,0,,
mxnet.gluon.nn.GlobalAvgPool2D,layout,"DD: str, default 'NCHW'",D_TYPE default QSTR,D_TYPE,,,,0,,
mxnet.gluon.nn.Conv2DTranspose,layout,"DD: str, default 'NCHW'",D_TYPE default QSTR,D_TYPE,,,,0,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,conv_layout,"DD: str, default 'NCW'",D_TYPE default QSTR,D_TYPE,,,,0,,
mxnet.gluon.nn.Conv1DTranspose,layout,"DD: str, default 'NCW'",D_TYPE default QSTR,D_TYPE,,,,0,,
mxnet.gluon.nn.GlobalMaxPool1D,layout,"DD: str, default 'NCW'",D_TYPE default QSTR,D_TYPE,,,,0,,
mxnet.gluon.contrib.rnn.Conv1DLSTMCell,conv_layout,"DD: str, default 'NCW'",D_TYPE default QSTR,D_TYPE,,,,0,,
mxnet.gluon.nn.Conv1D,layout,"DD: str, default 'NCW'",D_TYPE default QSTR,D_TYPE,,,,0,,
mxnet.gluon.nn.AvgPool1D,layout,"DD: str, default 'NCW'",D_TYPE default QSTR,D_TYPE,,,,0,,
mxnet.ndarray.arange,infer_range,"DD: boolean, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.test_utils.numeric_grad,eps,"DD: float, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.ndarray.split_v2,axis,"DD: int, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.ndarray.arange,repeat,"DD: int, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.test_utils.check_speed,N,"DD: int, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.ndarray.random.multinomial,dtype,"DD: str or numpy.dtype, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.ndarray.linspace,dtype,"DD: str or numpy.dtype, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.log.get_logger,name,"DD: str, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.test_utils.check_speed,typ,"DD: str, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.test_utils.download,dirname,"DD: str, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.ndarray.empty,stype,"DD: str, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.ndarray.op.random_randint,ctx,"DD: string, optional, default=''",D_TYPE optional default,D_TYPE,,,,,,
mxnet.io.ImageDetRecordIter,mean_img,"DD: string, optional, default=''",D_TYPE optional default,D_TYPE,,,,,,
mxnet.ndarray.op.random_generalized_negative_binomial,ctx,"DD: string, optional, default=''",D_TYPE optional default,D_TYPE,,,,,,
mxnet.ndarray.random_uniform,ctx,"DD: string, optional, default=''",D_TYPE optional default,D_TYPE,,,,,,
mxnet.ndarray.op.ftml_update,epsilon,"DD: double, optional, default=9.9999999392252903e-09",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.IdentityAttachKLSparseReg,penalty,"DD: float, optional, default=0.00100000005",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.contrib.SyncBatchNorm,eps,"DD: float, optional, default=0.00100000005",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.image.random_lighting,alpha_std,"DD: float, optional, default=0.0500000007",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.hard_sigmoid,alpha,"DD: float, optional, default=0.200000003",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.op.hard_sigmoid,alpha,"DD: float, optional, default=0.200000003",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.contrib.MultiBoxTarget,overlap_threshold,"DD: float, optional, default=0.5",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.contrib.MultiBoxDetection,nms_threshold,"DD: float, optional, default=0.5",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.contrib.MultiBoxTarget,negative_mining_thresh,"DD: float, optional, default=0.5",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.contrib.ndarray.box_nms,overlap_thresh,"DD: float, optional, default=0.5",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.contrib.ndarray.MultiBoxDetection,nms_threshold,"DD: float, optional, default=0.5",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.contrib.ndarray.Proposal,threshold,"DD: float, optional, default=0.699999988",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.contrib.SyncBatchNorm,momentum,"DD: float, optional, default=0.899999976",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.op.BatchNorm,momentum,"DD: float, optional, default=0.899999976",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.mp_lamb_update_phase1,beta1,"DD: float, optional, default=0.899999976",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.sparse.adam_update,beta2,"DD: float, optional, default=0.999000013",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.op.ftml_update,beta2,"DD: float, optional, default=0.999000013",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.op.L2Normalization,eps,"DD: float, optional, default=1.00000001e-10",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.contrib.ndarray.group_adagrad_update,epsilon,"DD: float, optional, default=9.99999975e-06",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.rmsprop_update,epsilon,"DD: float, optional, default=9.99999994e-09",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.contrib.allclose,atol,"DD: float, optional, default=9.99999994e-09",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.op.lamb_update_phase1,epsilon,"DD: float, optional, default=9.99999997e-07",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.linalg_trmm,transpose,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.random_pdf_uniform,is_log,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.CTCLoss,use_label_lengths,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.Softmax,use_ignore,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.norm,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.FullyConnected,no_bias,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.max_axis,exclude,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.Convolution,no_bias,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.moments,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.batch_dot,transpose_a,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.mean,exclude,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.ROIAlign,position_sensitive,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.linalg_trsm,transpose,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.Convolution,cudnn_off,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.Softmax,multi_output,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.split,squeeze_axis,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg.gemm2,transpose_a,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.Embedding,sparse_grad,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.box_non_maximum_suppression,force_suppress,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.Pooling,global_pool,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.Softmax,out_grad,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.SyncBatchNorm,output_mean_var,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.sparse.mean,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.Softmax,out_grad,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.quantized_conv,cudnn_off,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.DeformableConvolution,no_bias,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.Proposal,output_score,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.moments,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.SoftmaxOutput,use_ignore,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.nansum,exclude,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.FullyConnected,no_bias,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.SoftmaxOutput,out_grad,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.dot,transpose_b,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.argmax,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg.trmm,transpose,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.CTCLoss,use_label_lengths,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.box_nms,force_suppress,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.SequenceReverse,use_sequence_length,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.random_pdf_gamma,is_log,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg_trmm,rightside,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.amp_multicast,cast_narrow,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.ctc_loss,use_data_lengths,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.sparse.dot,transpose_a,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.batch_dot,transpose_b,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.CTCLoss,use_label_lengths,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.Deconvolution,cudnn_off,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.GroupNorm,output_mean_var,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.LayerNorm,output_mean_var,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.random_pdf_poisson,is_log,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.DeformableConvolution,no_bias,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.mean,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg.trsm,transpose,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.Proposal,iou_loss,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.sum,exclude,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.quantized_conv,no_bias,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.quantized_pooling,global_pool,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.multi_all_finite,init_output,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.mp_sgd_update,lazy_update,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.MultiBoxDetection,clip,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.sparse.sgd_mom_update,lazy_update,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.SyncBatchNorm,fix_gamma,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.allclose,equal_nan,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.multi_all_finite,init_output,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.sparse.adam_update,lazy_update,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg_extracttrian,lower,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.Deconvolution,no_bias,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.argsort,is_ascend,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.linalg_gemm,alpha,"DD: double, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.arange_like,step,"DD: double, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg.trsm,alpha,"DD: double, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg_syrk,alpha,"DD: double, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg_gemm2,alpha,"DD: double, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg.gemm2,alpha,"DD: double, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.Softmax,ignore_label,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.mp_lamb_update_phase1,clip_gradient,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.signum_update,clip_gradient,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.MultiBoxTarget,negative_mining_ratio,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.mp_lamb_update_phase2,lower_bound,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.ftml_update,clip_grad,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.mp_sgd_mom_update,clip_gradient,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.multi_mp_sgd_update,clip_gradient,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.group_adagrad_update,clip_gradient,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.multi_sgd_mom_update,clip_gradient,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.box_decode,clip,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.nag_mom_update,wd,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,mean_r,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.RNN,p,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.ftml_update,wd,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.signum_update,wd_lh,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.signum_update,wd_lh,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,contrast,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.preloaded_multi_mp_sgd_mom_update,momentum,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,std_b,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,max_aspect_ratio,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,mean_b,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.sgd_mom_update,momentum,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.MakeLoss,valid_thresh,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.quadratic,b,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.DeformablePSROIPooling,trans_std,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.sgd_mom_update,momentum,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.nag_mom_update,wd,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.random_normal,loc,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,random_contrast_prob,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.random_uniform,low,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.preloaded_multi_mp_sgd_mom_update,momentum,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.sgd_update,wd,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.Softmax,smooth_alpha,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.sparse.adagrad_update,wd,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,std_r,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,max_shear_ratio,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.random_negative_binomial,p,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.multi_sgd_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.preloaded_multi_sgd_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,max_random_area,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.multi_sgd_mom_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.sgd_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.random.generalized_negative_binomial_like,mu,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.preloaded_multi_sgd_mom_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.signum_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.SoftmaxOutput,grad_scale,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.SVMOutput,margin,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.random_exponential,lam,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.LogisticRegressionOutput,grad_scale,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.mp_nag_mom_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.sparse.LogisticRegressionOutput,grad_scale,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.random.exponential_like,lam,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.adam_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,max_pad_scale,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.MAERegressionOutput,grad_scale,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.multi_lars,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.ftrl_update,beta,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.multi_mp_sgd_mom_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.multi_sgd_mom_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.random_generalized_negative_binomial,mu,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.sparse.ftrl_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.SoftmaxOutput,grad_scale,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.group_adagrad_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,min_random_area,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,scale,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.mp_sgd_mom_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.rmspropalex_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.sparse.adagrad_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,std_a,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.random_gamma,beta,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.random.gamma_like,alpha,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.LRN,knorm,"DD: float, optional, default=2",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.softmax,axis,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,label_width,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.box_nms,background_id,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,min_crop_size,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.MultiBoxDetection,nms_topk,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.diag,axis1,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.SwapAxis,dim1,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,random_h,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,label_pad_width,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg_extracttrian,offset,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.take,axis,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.SequenceReverse,axis,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,max_random_saturation,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.DeformablePSROIPooling,part_size,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.SequenceMask,axis,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.swapaxes,dim1,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.SwapAxis,dim2,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.swapaxes,dim1,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg.maketrian,offset,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,max_random_hue,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,shuffle_chunk_seed,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.linalg_maketrian,offset,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.GroupNorm,num_groups,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.SyncBatchNorm,ndev,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.multi_sgd_update,num_weights,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.arange_like,repeat,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.preloaded_multi_mp_sgd_mom_update,num_weights,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.concat,dim,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.quantized_batch_norm,axis,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,num_parts,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.DeformablePSROIPooling,sample_per_part,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.preloaded_multi_mp_sgd_update,num_weights,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.multi_mp_sgd_update,num_weights,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.DeformableConvolution,num_deformable_group,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.LibSVMIter,num_parts,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.fft,compute_size,"DD: int, optional, default='128'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.ifft,compute_size,"DD: int, optional, default='128'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.Proposal,feature_stride,"DD: int, optional, default='16'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.MultiProposal,rpn_min_size,"DD: int, optional, default='16'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.Proposal,rpn_min_size,"DD: int, optional, default='16'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.norm,ord,"DD: int, optional, default='2'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.Proposal,rpn_post_nms_top_n,"DD: int, optional, default='300'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.MultiProposal,rpn_post_nms_top_n,"DD: int, optional, default='300'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.Proposal,rpn_pre_nms_top_n,"DD: int, optional, default='6000'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.image.center_crop,interp,"DD: int, optional, default=2",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,path_imgrec,"DD: string, optional, default='./data/imgrec.rec'",D_TYPE optional default data imgrec rec,D_TYPE,,,,0,,
mxnet.io.LibSVMIter,label_libsvm,"DD: string, optional, default='NULL'",D_TYPE optional default QSTR,D_TYPE,,,,0,,
mxnet.io.MNISTIter,label,"DD: string, optional, default='./train-labels-idx1-ubyte'",D_TYPE optional default train labels idx1 ubyte,D_TYPE,,,,0,,
mxnet.gluon.nn.Conv3D,padding,"DD: int or a tuple/list of 3 int,",D_TYPE or a D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],0;1,,
mxnet.gluon.contrib.nn.PixelShuffle2D,factor,DD: int or 2-tuple of int,D_TYPE or CONSTANT_NUM D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],0;1,,
mxnet.ndarray.random.randn,loc,DD: float or NDArray,D_TYPE or D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.gluon.nn.AvgPool3D,pool_size,"DD: int or list/tuple of 3 ints,",D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],0;1,,
mxnet.gluon.nn.Conv1D,dilation,DD: int or tuple/list of 1 int,D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],0;1,,
mxnet.gluon.nn.Conv1D,strides,"DD: int or tuple/list of 1 int,",D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],0;1,,
mxnet.gluon.nn.Conv2D,dilation,DD: int or tuple/list of 2 int,D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],0;1,,
mxnet.gluon.nn.Conv2D,strides,"DD: int or tuple/list of 2 int,",D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],0;1,,
mxnet.gluon.nn.Conv3DTranspose,dilation,DD: int or tuple/list of 3 int,D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],0;1,,
mxnet.ndarray.moveaxis,source,DD: int or sequence of int,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
mxnet.gluon.contrib.rnn.Conv3DRNNCell,h2h_kernel,DD: int or tuple of int,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.ndarray.full,shape,DD: int or tuple of int,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.ndarray.utils.zeros,shape,DD: int or tuple of int,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,i2h_kernel,DD: int or tuple of int,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.gluon.contrib.rnn.Conv3DLSTMCell,i2h_kernel,DD: int or tuple of int,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.ndarray.utils.empty,shape,DD: int or tuple of int,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.gluon.contrib.rnn.Conv1DLSTMCell,i2h_kernel,DD: int or tuple of int,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.ndarray.zeros,shape,DD: int or tuple of int,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.ndarray.split_v2,indices_or_sections,DD: int or tuple of ints,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,i2h_pad,"DD: int or tuple of int, default (0, 0, 0",D_TYPE or D_STRUCTURE of D_TYPE default CONSTANT_NUM,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.gluon.contrib.rnn.Conv3DLSTMCell,i2h_pad,"DD: int or tuple of int, default (0, 0, 0",D_TYPE or D_STRUCTURE of D_TYPE default CONSTANT_NUM,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.gluon.contrib.rnn.Conv2DRNNCell,h2h_dilate,"DD: int or tuple of int, default (1, 1",D_TYPE or D_STRUCTURE of D_TYPE default CONSTANT_NUM,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,h2h_dilate,"DD: int or tuple of int, default (1, 1",D_TYPE or D_STRUCTURE of D_TYPE default CONSTANT_NUM,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,h2h_dilate,"DD: int or tuple of int, default (1, 1, 1",D_TYPE or D_STRUCTURE of D_TYPE default CONSTANT_NUM,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.ndarray.random.negative_binomial,shape,"DD: int or tuple of ints, optional",D_TYPE or D_STRUCTURE of D_TYPE optional,D_TYPE,,D_STRUCTURE,,0;1,,
mxnet.ndarray.histogram,bins,DD: int or sequence of scalars,D_TYPE or D_STRUCTURE of scalars,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.random.gamma,beta,"DD: float or NDArray, optional",D_TYPE or D_STRUCTURE optional,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.random.generalized_negative_binomial,mu,"DD: float or NDArray, optional",D_TYPE or D_STRUCTURE optional,D_TYPE,,D_STRUCTURE,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,activation,"DD: str or gluon.Block, default 'tanh'",D_TYPE or gluon Block default QSTR,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,activation,"DD: str or gluon.Block, default 'tanh'",D_TYPE or gluon Block default QSTR,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,i2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.rnn.LSTMCell,i2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv3DRNNCell,i2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.rnn.GRUCell,i2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.rnn.LSTM,h2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.rnn.RNN,i2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.LSTMPCell,i2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.rnn.RNN,i2h_bias_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.nn.Conv1D,weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,h2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.rnn.RNNCell,h2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.nn.Conv3D,bias_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv2DLSTMCell,h2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.nn.Conv2D,weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv1DLSTMCell,i2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,h2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.contrib.nn.SyncBatchNorm,running_variance_initializer,"DD: str or Initializer, default ‘ones’",D_TYPE or Initializer default ones,D_TYPE,,,,,,
mxnet.gluon.contrib.nn.SyncBatchNorm,gamma_initializer,"DD: str or Initializer, default ‘ones’",D_TYPE or Initializer default ones,D_TYPE,,,,,,
mxnet.gluon.nn.BatchNorm,gamma_initializer,"DD: str or Initializer, default ‘ones’",D_TYPE or Initializer default ones,D_TYPE,,,,,,
mxnet.gluon.nn.LayerNorm,gamma_initializer,"DD: str or Initializer, default ‘ones’",D_TYPE or Initializer default ones,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.LSTMPCell,i2h_bias_initializer,"DD: str or Initializer, default 'lstmbias'",D_TYPE or Initializer default QSTR,D_TYPE,,,,,,
mxnet.gluon.nn.InstanceNorm,beta_initializer,"DD: str or Initializer, default ‘zeros’",D_TYPE or Initializer default zeros,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv3DLSTMCell,h2h_bias_initializer,"DD: str or Initializer, default zeros",D_TYPE or Initializer default zeros,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv1DGRUCell,i2h_bias_initializer,"DD: str or Initializer, default zeros",D_TYPE or Initializer default zeros,D_TYPE,,,,,,
mxnet.ndarray.pick,axis,"int or None. The axis to picking the elements. Negative values means indexing from right to left. If is None, the elements in the index w.r.t the flattened input will be picked.",D_TYPE or None,D_TYPE,,,,,,
mxnet.ndarray.softmin,use_length,"DD: boolean or None, optional, default=0",D_TYPE or None optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.pick,axis,"DD: int or None, optional, default='-1'",D_TYPE or None optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.Pooling,count_include_pad,"DD: boolean or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.ndarray.BilinearSampler,cudnn_off,"DD: boolean or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.contrib.ndarray.quantized_pooling,count_include_pad,"DD: boolean or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.ndarray.op.BilinearSampler,cudnn_off,"DD: boolean or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.ndarray.contrib.quantized_pooling,count_include_pad,"DD: boolean or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.ndarray.RNN,lstm_state_clip_max,"DD: double or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.ndarray.softmin,temperature,"DD: double or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.ndarray.contrib.BilinearResize2D,scale_width,"DD: float or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.ndarray.contrib.BilinearResize2D,scale_height,"DD: float or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.ndarray.contrib.quantize_v2,min_calib_range,"DD: float or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.contrib.ndarray.quantize_v2,min_calib_range,"DD: float or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.ndarray.contrib.quantized_batch_norm,max_calib_range,"DD: float or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.ndarray.op.repeat,axis,"DD: int or None, optional, default='None'",D_TYPE or None optional default QSTR,D_TYPE,,,,,,
mxnet.ndarray.op.RNN,projection_size,"DD: int or None, optional, default='None'",D_TYPE or None optional default QSTR,D_TYPE,,,,,,
mxnet.ndarray.reshape_like,rhs_begin,"DD: int or None, optional, default='None'",D_TYPE or None optional default QSTR,D_TYPE,,,,,,
mxnet.ndarray.op.reshape_like,lhs_begin,"DD: int or None, optional, default='None'",D_TYPE or None optional default QSTR,D_TYPE,,,,,,
mxnet.ndarray.slice_axis,end,"DD: int or None, required",D_TYPE or None required,D_TYPE,,,,,,
mxnet.ndarray.rmspropalex_update,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.sparse.adam_update,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.multi_lars,eps,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.rmsprop_update,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase2,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.image.random_color_jitter,contrast,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.image.random_color_jitter,saturation,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase1,wd,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.clip,a_max,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.multi_lars,eta,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.contrib.bipartite_matching,threshold,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.clip,a_min,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.image.random_hue,max_factor,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.contrib.PSROIPooling,spatial_scale,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.rmspropalex_update,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.mp_sgd_mom_update,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.contrib.interleaved_matmul_selfatt_qk,heads,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,group_size,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.repeat,repeats,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.multi_sum_sq,num_arrays,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.one_hot,depth,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.image.imresize,h,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.sparse.FullyConnected,num_hidden,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.space_to_depth,block_size,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.contrib.ndarray.DeformablePSROIPooling,group_size,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.contrib.ndarray.PSROIPooling,output_dim,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.image.copyMakeBorder,top,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.contrib.ndarray.interleaved_matmul_selfatt_valatt,heads,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.contrib.SparseEmbedding,output_dim,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.contrib.ndarray.interleaved_matmul_encdec_valatt,heads,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,pooled_size,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.UpSampling,scale,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase1,t,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.FullyConnected,num_hidden,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.contrib.ndarray.PSROIPooling,pooled_size,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.slice_axis,begin,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.io.LibSVMIter,data_libsvm,"DD: string, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.squeeze,data,data to squeeze,data to squeeze,,,,,,,
mxnet.contrib.onnx.export_model,input_type,DD: data type,data type,numpy.dtype,,,,,,
mxnet.gluon.nn.InstanceNorm,axis,"The axis that will be excluded in the normalization process. This is typically the channels (C) axis. For instance, after a Conv2D layer with layout='NCHW', set axis=1 in InstanceNorm. If layout='NHWC', then set axis=3. Data will be normalized along axes excluding the first axis and the axis given.",Data will be normalized along axes excluding the first axis and the axis given,,,,,,,
mxnet.io.ImageDetRecordIter,label_width,"Dataset Param: How many labels for an image, -1 for variable label size.",Dataset Param How many labels for an image CONSTANT_NUM for variable label size,,,,,,,
mxnet.io.MNISTIter,label,Dataset Param: Mnist label path.,Dataset Param Mnist label path,,,,,,,
mxnet.io.ImageDetRecordIter,path_imgrec,Dataset Param: Path to image record file.,Dataset Param Path to image record file,,,,,,,
mxnet.contrib.quantization.quantize_model,label_names,"DF: (softmax_label,)",DEFAULT BSTR,,,,,,,
mxnet.gluon.nn.MaxPool3D,ceil_mode,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.callback.log_train_metric,auto_reset,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.get_mobilenet,pretrained,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.contrib.onnx.export_model,verbose,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.inception_v3,pretrained,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.profiler.dumps,ascending,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.rnn.LSTM,bidirectional,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.nn.Embedding,sparse_grad,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.get_resnet,pretrained,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.model_zoo.vision.alexnet,pretrained,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.test_utils.download,overwrite,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.test_utils.assert_almost_equal,equal_nan,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.metric.np,allow_extra_outputs,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.image.CreateAugmenter,rand_mirror,DF: False,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.util.np_shape,active,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.utils.download,verify_ssl,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.nn.GroupNorm,center,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.utils.split_and_load,even_split,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.nn.Conv2DTranspose,use_bias,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.utils.split_data,even_split,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.nn.BatchNorm,scale,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.util.set_np,shape,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.nn.AvgPool1D,count_include_pad,DF: True,DEFAULT CONSTANT_BOOL,bool,,,,0,,
mxnet.gluon.contrib.rnn.VariationalDropoutCell,drop_states,DF: 0.0,DEFAULT CONSTANT_FLOAT,float,,,,0,,
mxnet.test_utils.numeric_grad,eps,DF: 0.0001,DEFAULT CONSTANT_FLOAT,float,,,,0,,
mxnet.image.CreateDetAugmenter,min_object_covered,DF: 0.1,DEFAULT CONSTANT_FLOAT,float,,,,0,,
mxnet.test_utils.verify_generator,success_rate,DF: 0.2,DEFAULT CONSTANT_FLOAT,float,,,,0,,
mxnet.image.CreateDetAugmenter,min_eject_coverage,DF: 0.3,DEFAULT CONSTANT_FLOAT,float,,,,0,,
mxnet.ndarray.arange,step,DF: 1.0,DEFAULT CONSTANT_FLOAT,float,,,,0,,
mxnet.gluon.nn.ELU,alpha,DF: 1.0,DEFAULT CONSTANT_FLOAT,float,,,,0,,
mxnet.gluon.nn.LayerNorm,epsilon,DF: 1e-05,DEFAULT CONSTANT_FLOAT,float,,,,0,,
mxnet.gluon.nn.LayerNorm,axis,DF: -1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.contrib.nn.Concurrent,axis,DF: -1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.contrib.rnn.Conv1DGRUCell,h2h_dilate,"DF: (1,)",DEFAULT CONSTANT_NUM,int,,,,1,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,i2h_dilate,"DF: (1,)",DEFAULT CONSTANT_NUM,int,,,,1,,
mxnet.gluon.nn.InstanceNorm,in_channels,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.nn.Conv3D,in_channels,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.image.CreateAugmenter,hue,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.split_v2,axis,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.nn.LayerNorm,in_channels,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.image.CreateAugmenter,rand_gray,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.image.CreateAugmenter,brightness,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.utils.split_data,batch_axis,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.image.CreateDetAugmenter,resize,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.image.CreateDetAugmenter,pca_noise,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.contrib.nn.SyncBatchNorm,in_channels,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.nn.Conv1DTranspose,in_channels,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.image.CreateDetAugmenter,brightness,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.context.cpu,device_id,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.random.uniform,low,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.image.CreateDetAugmenter,rand_pad,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.nn.Conv2DTranspose,in_channels,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.rnn.RNN,input_size,DF: 0,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.nn.Conv2DTranspose,groups,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.nn.Conv1D,dilation,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.nn.InstanceNorm,axis,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.nn.BatchNorm,axis,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.arange,repeat,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.random.gamma,beta,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.random.generalized_negative_binomial,mu,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.nn.Conv1D,strides,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.nn.GroupNorm,num_groups,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.random.uniform,high,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.random.gamma,alpha,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.callback.do_checkpoint,period,DF: 1,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.histogram,bins,DF: 10,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.test_utils.chi_square_check,nsamples,DF: 1000000,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.test_utils.verify_generator,nsamples,DF: 1000000,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.image.CreateAugmenter,inter_method,DF: 2,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.image.center_crop,interp,DF: 2,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.nn.AvgPool1D,pool_size,DF: 2,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.test_utils.check_speed,N,DF: 20,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.test_utils.verify_generator,nrepeat,DF: 5,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.gluon.utils.download,retries,DF: 5,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.image.CreateDetAugmenter,max_attempts,DF: 50,DEFAULT CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.linspace,ctx,Device context. Default context is the current default context.,Default context is the current default context,,,,,,,
mxnet.gluon.rnn.LSTM,dtype,DF: float32,DEFAULT D_TYPE,numpy.dtype,,,,0,,
mxnet.ndarray.random.multinomial,dtype,DF: int32,DEFAULT D_TYPE,numpy.dtype,,,,0,,
mxnet.contrib.quantization.quantize_model,calib_mode,DF: entropy,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.MaxPool3D,layout,DF: NCDHW,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.GlobalAvgPool2D,layout,DF: NCHW,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.Conv2DTranspose,layout,DF: NCHW,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.Conv2D,layout,DF: NCHW,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.MaxPool2D,layout,DF: NCHW,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,conv_layout,DF: NCW,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.Conv1DTranspose,layout,DF: NCW,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.GlobalMaxPool1D,layout,DF: NCW,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.contrib.rnn.Conv1DLSTMCell,conv_layout,DF: NCW,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.Conv1D,layout,DF: NCW,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.AvgPool1D,layout,DF: NCW,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.MaxPool1D,layout,DF: NCW,DEFAULT DF_STR,string,,,,0,,
mxnet.contrib.quantization.quantize_net,calib_mode,DF: none,DEFAULT DF_STR,,,,,,,
mxnet.gluon.contrib.nn.SyncBatchNorm,running_variance_initializer,DF: ones,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.contrib.nn.SyncBatchNorm,gamma_initializer,DF: ones,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.BatchNorm,gamma_initializer,DF: ones,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.LayerNorm,gamma_initializer,DF: ones,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.rnn.RNN,activation,DF: relu,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,activation,DF: tanh,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,activation,DF: tanh,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.rnn.RNN,layout,DF: TNC,DEFAULT DF_STR,string,,,,0,,
mxnet.profiler.dumps,sort_by,DF: total,DEFAULT DF_STR,string,,,,0,,
mxnet.test_utils.check_speed,typ,DF: whole,DEFAULT DF_STR,string,,,,0,,
mxnet.test_utils.check_symbolic_backward,grad_req,DF: write,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.contrib.rnn.Conv3DLSTMCell,h2h_bias_initializer,DF: zeros,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.contrib.rnn.LSTMPCell,i2h_bias_initializer,DF: zeros,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.rnn.RNN,i2h_bias_initializer,DF: zeros,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.contrib.rnn.Conv1DGRUCell,i2h_bias_initializer,DF: zeros,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.InstanceNorm,beta_initializer,DF: zeros,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.Conv3D,bias_initializer,DF: zeros,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,i2h_bias_initializer,DF: zeros,DEFAULT DF_STR,string,,,,0,,
mxnet.gluon.nn.Dense,bias_initializer,DF: zeros,DEFAULT DF_STR,string,,,,0,,
mxnet.ndarray.random.gamma,beta,The scale of the gamma distribution. Should be greater than zero. Default is equal to 1.,Default is equal to CONSTANT_NUM,int,,,,0,,
mxnet.recordio.pack_img,img_fmt,DF: .jpg,DEFAULT jpg,,,,,,,
mxnet.ndarray.SVMOutput,margin,The loss function penalizes outputs that lie outside this margin. Default margin is 1.,Default margin is CONSTANT_NUM,,,,,,,
mxnet.contrib.ndarray.MultiBoxPrior,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.reshape_like,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.trunc,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.sample_negative_binomial,p,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_conv,max_bias,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_axes,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.adam_update,var,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.lamb_update_phase2,r1,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.nn.MaxPool2D,strides,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.Embedding,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.RROIAlign,rois,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_fully_connected,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.sort,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.sample_normal,mu,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.multi_lars,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_hypot,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.multi_sgd_update,rescale_grad,DF: None,DEFAULT None,,,,,,,
mxnet.image.CreateAugmenter,mean,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.identity,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.ROIAlign,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.max,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.FullyConnected,bias,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.vgg19_bn,root,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.image.random_hue,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.index_copy,new_tensor,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_hypot,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.LeakyReLU,gamma,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.preloaded_multi_sgd_update,rescale_grad,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.backward_hawkesll,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.BilinearSampler,grid,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.random_pdf_uniform,high,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,max_random_area,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_axis,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.signsgd_update,grad,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.broadcast_minus,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_pooling,min_data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantize,data,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,path_imgrec,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,i2h_weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.rnn.LSTMCell,i2h_weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_lesser,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DRNNCell,i2h_weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.SwapAxis,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.mp_nag_mom_update,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random_pdf_poisson,sample,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,mean_r,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.max,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.rint,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.box_encode,matches,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.multi_sgd_mom_update,rescale_grad,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.calibrate_entropy,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.rnn.GRUCell,i2h_weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.index_array,out,DF: None,DEFAULT None,,,,,,,
mxnet.test_utils.download_model,meta_info,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.multi_sum_sq,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_conv,min_weight,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.rnn.LSTM,h2h_weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.SequenceLast,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.sample_generalized_negative_binomial,alpha,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.ROIAlign,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.multi_sgd_update,num_weights,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.sign_ste,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg.syrk,A,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.ctc_loss,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.adam_update,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.AdaptiveAvgPooling2D,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.degrees,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.elemwise_sub,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.index_copy,index_vector,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.elemwise_div,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.arccos,data,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.rnn.RNN,i2h_weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.gather_nd,indices,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.make_loss,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.one_hot,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sigmoid,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.DeformableConvolution,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.interleaved_matmul_selfatt_valatt,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_logical_and,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_minus,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.contrib.rnn.LSTMPCell,i2h_weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.MultiProposal,cls_prob,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random.randn,loc,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_logical_and,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.Proposal,bbox_pred,DF: None,DEFAULT None,,,,,,,
mxnet.log.get_logger,name,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.random_pdf_generalized_negative_binomial,mu,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.count_sketch,data,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.vgg19,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_conv,max_weight,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.squeezenet1_1,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.image.random_flip_left_right,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.rmsprop_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_equal,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.gamma,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.preloaded_multi_sgd_mom_update,rescale_grad,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.stop_gradient,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.sgd_update,weight,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.resnet152_v2,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sample_uniform,high,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.argsort,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.preloaded_multi_mp_sgd_mom_update,num_weights,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_not_equal,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.size_array,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.min_axis,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.dgl_adjacency,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linspace,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.argmax_channel,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.sum,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random_pdf_uniform,low,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,shuffle_chunk_size,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.shape_array,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.quantization.quantize_model,calib_data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.cos,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.flatten,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.cbrt,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_lesser_equal,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.image.flip_top_bottom,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.pick,data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.box_non_maximum_suppression,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.argmax_channel,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.GroupNorm,out,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,random_h,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,label_pad_width,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg_syrk,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.random_pdf_negative_binomial,sample,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg.det,A,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.FullyConnected,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.DeformableConvolution,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.FullyConnected,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.SequenceLast,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sgd_update,grad,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,label_width,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.bipartite_matching,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.argmin,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.degrees,data,DF: None,DEFAULT None,,,,,,,
mxnet.io.LibSVMIter,label_libsvm,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.sgd_mom_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.linalg_makediag,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.SoftmaxOutput,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.while_loop,max_iterations,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.Deconvolution,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.RROIAlign,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.smooth_l1,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.expm1,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_batch_norm,min_data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.tan,data,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,mean_img,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg.det,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.squeeze,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random_uniform,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg_potrf,A,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.allclose,a,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.get_model,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.linalg_trsm,A,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.backward_index_copy,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.rnn.LSTMCell,params,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.mobilenet0_5,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.vgg19_bn,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.slice_like,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg.potri,A,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.image.resize,data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_conv,min_data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.cosh,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.hawkesll,lda,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.LinearRegressionOutput,label,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.FullyConnected,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.mp_nag_mom_update,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.signsgd_update,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.ctc_loss,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.nn.Conv3DTranspose,activation,DF: None,DEFAULT None,,,,,,,
mxnet.visualization.plot_network,shape,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.multi_all_finite,init_output,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.L2Normalization,data,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,max_random_saturation,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.dequantize,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.arctan,data,DF: None,DEFAULT None,,,,,,,
mxnet.io.MNISTIter,label,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,contrast,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.concat,dim,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.LRN,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.random_pdf_negative_binomial,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_mul,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.MultiProposal,im_info,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase2,weight32,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.random_randint,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_plus,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.RNN,state,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.batch_dot,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.arccosh,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.Deconvolution,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_minimum,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_greater,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,min_crop_size,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.preloaded_multi_mp_sgd_mom_update,momentum,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.argsort,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.BlockGrad,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.InstanceNorm,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.SyncBatchNorm,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.dot,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,std_b,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_act,out,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,max_pad_scale,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,max_aspect_ratio,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random.shuffle,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.make_loss,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.SoftmaxOutput,label,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.cos,data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.edge_id,v,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.quantization.quantize_model,excluded_sym_names,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.gamma,data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.hawkesll,alpha,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.SequenceLast,sequence_length,DF: None,DEFAULT None,,,,,,,
mxnet.profiler.set_config,aggregate_stats,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,mean_b,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.ones,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.expm1,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_conv,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.count_sketch,s,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.transpose,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.random_pdf_normal,mu,DF: None,DEFAULT None,,,,,,,
mxnet.test_utils.assert_almost_equal,rtol,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.Softmax,label,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.mp_lamb_update_phase1,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.negative,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_minus,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.ceil,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.BilinearSampler,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_concat,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.lamb_update_phase2,g,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.arccosh,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.depth_to_space,data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_pooling,max_data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.random_pdf_poisson,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.sign,out,DF: None,DEFAULT None,,,,,,,
mxnet.image.CreateDetAugmenter,mean,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.arange,infer_range,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_fully_connected,max_data,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.mobilenet0_25,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.degrees,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.SwapAxis,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.RNN,parameters,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random_normal,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.signsgd_update,grad,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.image.resize,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.nn.AvgPool2D,strides,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_conv,min_data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.multi_mp_sgd_mom_update,rescale_grad,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.SyncBatchNorm,moving_var,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.InstanceNorm,beta,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.RNN,out,DF: None,DEFAULT None,,,,,,,
mxnet.io.CSVIter,prefetch_buffer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.multi_sgd_mom_update,rescale_grad,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.edge_id,u,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.adagrad_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.floor,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.ROIAlign,out,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,num_parts,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.L2Normalization,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random_pdf_generalized_negative_binomial,sample,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.DeformableConvolution,bias,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.squeezenet1_1,root,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.rint,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sort,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_not_equal,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.preloaded_multi_mp_sgd_mom_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.nn.Conv1D,weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.SoftmaxOutput,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.resnet18_v1,root,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.Deconvolution,data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.backward_gradientmultiplier,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.cos,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.negative,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.multi_sgd_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.count_sketch,s,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.slice_axis,data,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.squeezenet1_0,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.adam_update,grad,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.round_ste,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_add,out,DF: None,DEFAULT None,,,,,,,
mxnet.test_utils.simple_forward,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sample_multinomial,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.SpatialTransformer,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.RNN,state_cell,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.reshape_like,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.bipartite_matching,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.amp_multicast,cast_narrow,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_conv,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.LinearRegressionOutput,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.ctc_loss,data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_pooling,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.allclose,b,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.sinh,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.resnet50_v1,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random_gamma,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_minimum,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random.randn,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.flatten,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_greater,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.erfinv,data,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,params,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.arcsinh,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,h2h_weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quadratic,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.shape_array,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.elemwise_add,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.vgg16,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.rnn.RNNCell,h2h_weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.topk,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.sgd_update,grad,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.Pooling,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.linalg_det,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.gammaln,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_logical_or,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.rint,data,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.mobilenet0_25,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_logical_xor,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.fft,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg_makediag,A,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_sub,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.choose_element_0index,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.dot,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.size_array,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.take,indices,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.tan,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.multi_all_finite,init_output,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.ctc_loss,data_lengths,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,min_random_area,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.rnn.RNNCell,params,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.ravel_multi_index,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg.makediag,A,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.log1p,data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.getnnz,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.rmspropalex_update,grad,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg.gemm2,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.linalg_slogdet,A,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,random_contrast_prob,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.reshape_like,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.MultiProposal,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.zeros,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,max_crop_sample_coverages,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.preloaded_multi_sgd_mom_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.linalg_makediag,A,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_conv,max_data,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.resnet34_v1,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.test_utils.check_symbolic_backward,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,scale,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random.negative_binomial,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.BatchNorm,moving_mean,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.radians,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.random_pdf_normal,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.backward_quadratic,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.interleaved_matmul_selfatt_valatt,queries_keys_values,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_lesser,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.concat,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.cumsum,a,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_div,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.backward_gradientmultiplier,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.full,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.vgg16_bn,root,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.round,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_to,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DLSTMCell,h2h_weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.preloaded_multi_mp_sgd_update,num_weights,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.preloaded_multi_mp_sgd_mom_update,momentum,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.log1p,data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_batch_norm,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_like,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quadratic,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.broadcast_plus,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.LogisticRegressionOutput,label,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.nn.Conv2D,weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.SVMOutput,label,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sample_exponential,lam,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sum_axis,data,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,min_crop_overlaps,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_plus,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_mul,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.GroupNorm,gamma,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.InstanceNorm,beta,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.SVMOutput,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.max_axis,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.multi_mp_sgd_update,num_weights,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.adam_update,grad,DF: None,DEFAULT None,,,,,,,
mxnet.test_utils.download,dirname,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.adam_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.hawkesll,marks,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.ftml_update,v,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,min_crop_object_coverages,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.broadcast_minus,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.multi_lars,lrs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.rsqrt,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.SwapAxis,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.multi_mp_sgd_update,clip_gradient,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sort,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.index_array,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.ctc_loss,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.gammaln,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.ftrl_update,grad,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.RNN,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.linalg_gemm,B,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_equal,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.square,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.image.random_color_jitter,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.empty,stype,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sinh,data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.edge_id,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.Embedding,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.sgd_mom_update,mom,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.vgg16,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg_trmm,A,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.empty,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.round_ste,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.UpSampling,multi_input_mode,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.ElementWiseSum,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_logical_xor,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_flatten,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.ceil,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.clip,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random.generalized_negative_binomial,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,trans,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,std_a,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.rnn.GRUCell,params,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg.gemm2,A,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.ones_like,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.log1p,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.InstanceNorm,gamma,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.LRN,out,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,std_r,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.split,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg.slogdet,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.index_copy,old_tensor,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,max_random_hue,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_flatten,max_data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_lesser,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_power,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_mod,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.vgg11,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg.slogdet,A,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.argmin,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.exp,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.rmspropalex_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.div_sqrt_dim,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantize_v2,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.adam_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.multi_sgd_mom_update,clip_gradient,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,shuffle_chunk_seed,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.resnet34_v1,root,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.lamb_update_phase1,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random_pdf_gamma,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.sign_ste,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.BilinearResize2D,data,DF: None,DEFAULT None,,,,,,,
mxnet.autograd.grad,retain_graph,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.contrib.rnn.Conv1DLSTMCell,i2h_weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quadratic,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_mod,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.sigmoid,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,h2h_weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sample_generalized_negative_binomial,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_fully_connected,min_bias,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.slice,data,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,max_shear_ratio,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.count_sketch,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg_extractdiag,out,DF: None,DEFAULT None,,,,,,,
mxnet.image.imread,flag,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.nag_mom_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.box_non_maximum_suppression,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.identity,out,DF: None,DEFAULT None,,,,,,,
mxnet.io.LibSVMIter,num_parts,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.hawkesll,max_time,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.Convolution,weight,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,num_parts,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.where,condition,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg_inverse,A,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.reshape_like,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.elemwise_sub,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.mp_lamb_update_phase2,r1,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.hawkesll,valid_length,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase2,r2,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_greater_equal,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.zeros2,dtype,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.arccos,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg_trsm,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.SoftmaxOutput,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_fully_connected,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.MultiBoxDetection,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_to,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.fft,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sign,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg_trsm,B,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.arctanh,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_greater,out,DF: None,DEFAULT None,,,,,,,
mxnet.io.MNISTIter,image,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.MAERegressionOutput,label,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.multi_mp_sgd_mom_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.hawkesll,beta,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.mp_lamb_update_phase1,grad,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,resize_mode,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.ones_like,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.arccos,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.Dropout,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.autograd.grad,argnum,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.bipartite_matching,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.linalg_gemm2,A,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.diag,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.mp_sgd_mom_update,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.multi_sgd_update,clip_gradient,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random.generalized_negative_binomial,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.arcsinh,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.cosh,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.SoftmaxOutput,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.row_sparse_array,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.space_to_depth,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random.randn,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.random_pdf_uniform,sample,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.ROIAlign,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.ftml_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.pick,index,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.vgg19,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sum,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.rmsprop_update,weight,DF: None,DEFAULT None,,,,,,,
mxnet.io.MNISTIter,batch_size,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.rcbrt,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.floor,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.vgg16_bn,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_conv,max_weight,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,saturation,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.BilinearResize2D,like,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.LayerNorm,beta,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.get_model,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random_pdf_gamma,alpha,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.CTCLoss,label_lengths,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.round_ste,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.box_encode,matches,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.rmspropalex_update,g,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_plus,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.BatchNorm,moving_mean,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.mp_nag_mom_update,weight32,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.calibrate_entropy,hist_edges,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random_pdf_dirichlet,sample,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.arctan,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.CTCLoss,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_mul,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.mp_lamb_update_phase1,weight32,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sample_generalized_negative_binomial,mu,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.contrib.rnn.Conv1DLSTMCell,prefix,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.argmin,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.elemwise_add,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_conv,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.group_adagrad_update,grad,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.amp_cast,data,DF: None,DEFAULT None,,,,,,,
mxnet.image.imresize,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.zeros,dtype,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.signum_update,grad,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.densenet161,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.ROIPooling,rois,DF: None,DEFAULT None,,,,,,,
mxnet.image.imresize,interp,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.ftrl_update,grad,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.backward_gradientmultiplier,data,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.rnn.GRUCell,prefix,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.swapaxes,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.FullyConnected,bias,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.fix,out,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.hawkesll,state,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.concat,out,DF: None,DEFAULT None,,,,,,,
mxnet.profiler.set_config,continuous_dump,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.densenet121,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.nn.Dense,activation,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.image.random_lighting,data,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,seed_aug,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.slice_axis,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.MakeLoss,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.ROIPooling,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.choose_element_0index,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.log,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.image.to_tensor,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.unravel_index,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.transpose,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.rmspropalex_update,delta,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.linalg_gelqf,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.transpose,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.expm1,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random.uniform,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,scale,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.PSROIPooling,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.BatchNorm,beta,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg_trsm,A,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_act,data,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DLSTMCell,params,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.elemwise_add,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantize,min_range,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.all_finite,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_fully_connected,max_bias,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.nn.Conv3DTranspose,weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.CTCLoss,label,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random.normal,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random.randint,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.retain,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.shuffle,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DRNNCell,params,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.log,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.log2,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.zeros,stype,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.SparseEmbedding,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_equal,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.allclose,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.softmax_cross_entropy,label,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sqrt,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_conv,bias,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.cast_storage,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.elemwise_add,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.utils.download,sha1_hash,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,rois,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.fft,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.ctc_loss,data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.getnnz,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.signum_update,weight,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_fully_connected,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.Activation,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.batch_dot,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.SequenceReverse,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_conv,max_bias,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.elemwise_add,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random_pdf_exponential,sample,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.vgg11_bn,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sample_negative_binomial,p,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.ftml_update,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.backward_hawkesll,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.exp,out,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,mean_g,DF: None,DEFAULT None,,,,,,,
mxnet.image.imdecode,flag,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random.randn,scale,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.shuffle,data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_batch_norm,max_data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.sample_poisson,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.resnet152_v1,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.CTCLoss,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,params,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.DeformableConvolution,weight,DF: None,DEFAULT None,,,,,,,
mxnet.test_utils.check_symbolic_forward,aux_states,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.preloaded_multi_mp_sgd_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg_potri,A,DF: None,DEFAULT None,,,,,,,
mxnet.io.CSVIter,dtype,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.signum_update,grad,DF: None,DEFAULT None,,,,,,,
mxnet.test_utils.numeric_grad,aux_states,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.MAERegressionOutput,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.ElementWiseSum,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.multi_sgd_mom_update,momentum,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.CTCLoss,label_lengths,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantize,max_range,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_conv,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.CTCLoss,data_lengths,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.contrib.quantized_batch_norm,out,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,random_illumination_prob,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_sub,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.quantized_batch_norm,beta,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.pad,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.mp_sgd_update,weight32,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.Activation,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.LayerNorm,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.square,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.arccosh,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.Deconvolution,bias,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.array,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,max_random_contrast,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.ones,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_to,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.nag_mom_update,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.gather_nd,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.nanprod,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.take,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sin,data,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.resnet152_v2,root,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageRecordIter,verbose,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.elemwise_div,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.UpSampling,num_filter,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.lamb_update_phase2,g,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.vgg13,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_axes,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.resnet50_v2,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sqrt,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.log,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.linalg_trmm,A,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.broadcast_add,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.random.normal_like,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.elemwise_sub,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_logical_and,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.nansum,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.ceil,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.radians,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.SequenceMask,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.sample_multinomial,data,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.linalg_det,A,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sinh,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.LogisticRegressionOutput,label,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.AdaptiveAvgPooling2D,out,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.contrib.rnn.Conv1DGRUCell,prefix,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,prefetch_buffer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_not_equal,lhs,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75,pretrained,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.model_zoo.vision.densenet121,ctx,DF: None,DEFAULT None,,,,,,,
mxnet.io.LibSVMIter,dtype,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.RNN,data,DF: None,DEFAULT None,,,,,,,
mxnet.io.ImageDetRecordIter,aug_seq,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase1,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.depth_to_space,data,DF: None,DEFAULT None,,,,,,,
mxnet.contrib.ndarray.MultiBoxDetection,loc_pred,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.scatter_nd,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.random_poisson,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sparse.cosh,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.broadcast_logical_or,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg_gelqf,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.Embedding,weight,DF: None,DEFAULT None,,,,,,,
mxnet.gluon.rnn.RNNCell,i2h_weight_initializer,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.elemwise_mul,rhs,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.multi_mp_sgd_mom_update,momentum,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.linalg.potrf,A,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.erfinv,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.cast_storage,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.sgd_mom_update,weight,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.ctc_loss,label,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.exp,data,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.sample_exponential,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.op.log1p,out,DF: None,DEFAULT None,,,,,,,
mxnet.ndarray.diag,axis1,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Softmax,ignore_label,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.GroupNorm,num_groups,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg_trmm,transpose,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_normal,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.SyncBatchNorm,ndev,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_negative_binomial,p,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.rmspropalex_update,lr,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_pdf_uniform,is_log,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.reverse,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.Proposal,threshold,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase1,clip_gradient,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.broadcast_axis,size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.nag_mom_update,wd,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.CTCLoss,use_label_lengths,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.dot,forward_stype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.softmin,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.pick,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.nansum,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.lamb_update_phase1,epsilon,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.interleaved_matmul_selfatt_qk,heads,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.IdentityAttachKLSparseReg,penalty,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.quantized_conv,dilate,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Softmax,use_ignore,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.DeformableConvolution,kernel,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.norm,keepdims,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.adam_update,lr,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.SwapAxis,dim1,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,group_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.FullyConnected,no_bias,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.MultiBoxPrior,steps,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.image.random_lighting,alpha_std,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.box_nms,out_format,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.signum_update,clip_gradient,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.ravel_multi_index,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Correlation,max_displacement,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sample_gamma,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.Proposal,rpn_pre_nms_top_n,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.MultiProposal,ratios,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.sgd_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.quantized_conv,dilate,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.sample_poisson,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.repeat,repeats,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.max_axis,exclude,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Pooling,count_include_pad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Convolution,no_bias,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.arange_like,repeat,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_poisson,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.RNN,p,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.repeat,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Softmax,normalization,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Convolution,workspace,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.one_hot,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.MultiBoxTarget,negative_mining_ratio,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random.generalized_negative_binomial_like,mu,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.moments,keepdims,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.batch_dot,transpose_a,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.mean,exclude,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.norm,out_dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.RNN,projection_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.signum_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.linalg_gemm,alpha,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.mp_lamb_update_phase2,lower_bound,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_randint,ctx,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.multi_lars,eps,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.norm,ord,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.BilinearResize2D,scale_width,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.ROIAlign,position_sensitive,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.linalg_trsm,transpose,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.SoftmaxOutput,grad_scale,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.MakeLoss,normalization,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.BilinearResize2D,scale_height,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Convolution,cudnn_off,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.max_axis,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Softmax,multi_output,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Embedding,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.SVMOutput,margin,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_exponential,lam,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.rmsprop_update,lr,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.BilinearSampler,cudnn_off,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.broadcast_axes,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.softmax,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.split,squeeze_axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.SyncBatchNorm,eps,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.LogisticRegressionOutput,grad_scale,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.DeformableConvolution,stride,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.reverse,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.adam_update,beta2,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.ftml_update,clip_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.ftml_update,wd,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.mp_nag_mom_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.tile,reps,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.BilinearResize2D,mode,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Convolution,num_group,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg.gemm2,transpose_a,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.LogisticRegressionOutput,grad_scale,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Embedding,sparse_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.amp_cast,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.one_hot,depth,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.box_non_maximum_suppression,force_suppress,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.signum_update,wd_lh,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Pooling,global_pool,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.box_nms,background_id,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Softmax,out_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.MultiBoxTarget,overlap_threshold,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.SyncBatchNorm,output_mean_var,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.arange_like,step,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.mean,keepdims,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Softmax,out_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.signum_update,wd_lh,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.quantized_conv,cudnn_off,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg_extracttrian,offset,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.DeformableConvolution,no_bias,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.Proposal,output_score,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.moments,keepdims,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.DeformableConvolution,kernel,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.SoftmaxOutput,use_ignore,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.take,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.reshape_like,rhs_begin,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.quantize_v2,min_calib_range,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.softmin,use_length,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.scatter_nd,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random.exponential_like,lam,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.box_nms,in_format,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.SequenceReverse,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.FullyConnected,num_hidden,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.RNN,lstm_state_clip_max,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.squeeze,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.Proposal,feature_stride,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.MultiProposal,rpn_min_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.CTCLoss,blank_label,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.nansum,exclude,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.fft,compute_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase2,lr,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.smooth_l1,scalar,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.ftml_update,epsilon,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.adam_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.DeformablePSROIPooling,part_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_negative_binomial,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.RNN,mode,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.SequenceMask,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.quantized_conv,num_group,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.FullyConnected,no_bias,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.SoftmaxOutput,out_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Dropout,mode,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_randint,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.mp_sgd_update,lazy_update,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.dot,transpose_b,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.MAERegressionOutput,grad_scale,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.MultiBoxDetection,nms_threshold,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.quantized_pooling,count_include_pad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.space_to_depth,block_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.ftml_update,beta2,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.quantized_batch_norm,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.Proposal,scales,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.DeformablePSROIPooling,group_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.argmax,keepdims,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.image.random_color_jitter,contrast,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.image.random_color_jitter,saturation,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.hard_sigmoid,alpha,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Pooling,layout,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.PSROIPooling,output_dim,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.softmax,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.reshape_like,lhs_begin,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.quantized_conv,cudnn_tune,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.multi_lars,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.pad,pad_width,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.sgd_mom_update,momentum,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.softmax,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.rmsprop_update,epsilon,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.SyncBatchNorm,momentum,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.min,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase1,wd,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.L2Normalization,eps,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.swapaxes,dim1,DF: _Null,DEFAULT Null,,,,,,,
mxnet.image.copyMakeBorder,top,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.ftrl_update,beta,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Deconvolution,num_filter,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg.trmm,transpose,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.clip,a_max,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.CTCLoss,use_label_lengths,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_uniform,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.MakeLoss,valid_thresh,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.MultiBoxTarget,negative_mining_thresh,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Correlation,stride2,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.BilinearSampler,cudnn_off,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.image.normalize,mean,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.Proposal,rpn_post_nms_top_n,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.BatchNorm,momentum,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_generalized_negative_binomial,mu,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.MultiBoxPrior,steps,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_generalized_negative_binomial,ctx,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.MultiBoxDetection,clip,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random.negative_binomial,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.quadratic,b,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.box_nms,force_suppress,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,trans_std,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.SequenceReverse,use_sequence_length,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.interleaved_matmul_selfatt_valatt,heads,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.ROIPooling,pooled_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg.trsm,alpha,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_pdf_gamma,is_log,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Pooling,pad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg_trmm,rightside,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.allclose,atol,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sgd_mom_update,momentum,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.multi_lars,eta,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.nag_mom_update,wd,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.quantized_pooling,pool_type,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg_syrk,alpha,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Pooling,pooling_convention,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.SwapAxis,dim2,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.sgd_mom_update,lazy_update,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.SyncBatchNorm,fix_gamma,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.ctc_loss,use_data_lengths,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.quantize_v2,min_calib_range,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.dot,transpose_a,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.log_softmax,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.broadcast_like,rhs_axes,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.DeformablePSROIPooling,sample_per_part,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.group_adagrad_update,epsilon,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.sample_generalized_negative_binomial,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.swapaxes,dim1,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.Proposal,rpn_min_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.batch_dot,forward_stype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.max_axis,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.batch_dot,transpose_b,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_normal,loc,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.SparseEmbedding,output_dim,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.box_non_maximum_suppression,in_format,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.pad,mode,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Convolution,dilate,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_gamma,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.ftrl_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.bipartite_matching,threshold,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.MultiBoxDetection,nms_topk,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Pooling,stride,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.SoftmaxOutput,grad_scale,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.interleaved_matmul_encdec_valatt,heads,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.softmin,temperature,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.group_adagrad_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.allclose,equal_nan,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.CTCLoss,use_label_lengths,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Correlation,stride1,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.box_nms,overlap_thresh,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.quantized_pooling,stride,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sample_poisson,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Deconvolution,cudnn_tune,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_uniform,low,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.clip,a_min,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.image.random_hue,max_factor,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.broadcast_axis,size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Deconvolution,cudnn_off,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.log_softmax,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,pooled_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg.maketrian,offset,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.quantized_batch_norm,max_calib_range,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.GroupNorm,output_mean_var,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.mp_sgd_mom_update,clip_gradient,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.quantized_pooling,count_include_pad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.quantized_pooling,layout,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.sgd_update,wd,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.ifft,compute_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.LayerNorm,output_mean_var,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Softmax,smooth_alpha,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_pdf_poisson,is_log,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.mp_sgd_mom_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase1,t,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.hard_sigmoid,alpha,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.PSROIPooling,spatial_scale,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.AdaptiveAvgPooling2D,output_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.DeformableConvolution,num_deformable_group,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_normal,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.DeformableConvolution,no_bias,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.mean,keepdims,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.rmspropalex_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg.trsm,transpose,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.Proposal,iou_loss,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.adagrad_update,wd,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sum,exclude,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.group_adagrad_update,clip_gradient,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.MultiProposal,rpn_post_nms_top_n,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg_gemm2,alpha,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.adagrad_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.adam_update,lazy_update,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.quantize,out_type,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.FullyConnected,num_hidden,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.PSROIPooling,pooled_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_gamma,beta,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random.gamma_like,alpha,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg.gemm2,alpha,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_uniform,ctx,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.slice_axis,end,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg_extracttrian,lower,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.quantized_conv,no_bias,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.slice_like,axes,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.LRN,knorm,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.GridGenerator,target_shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.box_decode,clip,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.rmspropalex_update,lr,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Deconvolution,no_bias,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Deconvolution,workspace,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.mp_lamb_update_phase1,beta1,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.argsort,is_ascend,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.quantized_pooling,global_pool,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.MultiBoxDetection,nms_threshold,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.MakeLoss,normalization,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.mp_sgd_mom_update,lr,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.LeakyReLU,act_type,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.linalg_maketrian,offset,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.GridGenerator,target_shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.MultiBoxPrior,offsets,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.slice_axis,begin,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_pdf_generalized_negative_binomial,is_log,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random.negative_binomial_like,p,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.signsgd_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Activation,act_type,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Convolution,cudnn_off,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.rmsprop_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sgd_mom_update,lr,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.softmin,use_length,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.bipartite_matching,topk,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.split,num_outputs,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.linalg_trmm,transpose,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.sgd_mom_update,lazy_update,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Dropout,mode,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.ftrl_update,wd,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random.normal_like,loc,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.ROIAlign,pooled_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg_trsm,rightside,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.SoftmaxOutput,ignore_label,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.box_nms,topk,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.max_axis,keepdims,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.SyncBatchNorm,use_global_stats,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.quantized_batch_norm,use_global_stats,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.max,keepdims,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.nansum,exclude,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.linalg_trsm,rightside,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sample_multinomial,get_prob,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.adam_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.multi_lars,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Pooling,pooling_convention,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.diag,axis2,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.BatchNorm,max_calib_range,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.box_nms,id_index,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.diag,axis2,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.repeat,repeats,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_pdf_gamma,is_log,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg_gemm,transpose_a,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sparse.mean,exclude,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.dequantize,out_type,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.signsgd_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.PSROIPooling,group_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.interleaved_matmul_encdec_qk,heads,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.ftrl_update,beta,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Pooling,kernel,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.transpose,axes,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.ftml_update,rescale_grad,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_uniform,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.take,mode,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.MultiBoxPrior,ratios,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.min_axis,keepdims,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.sample_exponential,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.Deconvolution,cudnn_tune,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.arange_like,ctx,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.RROIAlign,pooled_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_generalized_negative_binomial,alpha,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.rmspropalex_update,epsilon,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.reshape,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.image.copyMakeBorder,right,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.sum_axis,exclude,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.quantized_batch_norm,eps,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random.gamma,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.LeakyReLU,slope,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Deconvolution,target_shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.SwapAxis,dim2,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_normal,scale,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.linalg_trsm,lower,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.ctc_loss,blank_label,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.BatchNorm,fix_gamma,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.ftrl_update,lr,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random.gamma,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.dot,forward_stype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.nanprod,keepdims,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.quantized_fully_connected,flatten,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.arange_like,step,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.MakeLoss,grad_scale,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_generalized_negative_binomial,mu,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.SequenceLast,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.BatchNorm,use_global_stats,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.SequenceMask,value,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.SparseEmbedding,input_dim,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.quantized_batch_norm,output_mean_var,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.ROIAlign,sample_ratio,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.gradientmultiplier,scalar,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.nanprod,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_uniform,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linalg.extracttrian,offset,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.ctc_loss,blank_label,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sample_exponential,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.max,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.Softmax,preserve_shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.GroupNorm,output_mean_var,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_generalized_negative_binomial,ctx,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.ftml_update,lr,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.argmin,keepdims,DF: _Null,DEFAULT Null,,,,,,,
mxnet.image.copyMakeBorder,bot,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.RNN,state_outputs,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.box_nms,id_index,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.CTCLoss,blank_label,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random.generalized_negative_binomial,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.LRN,nsize,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_negative_binomial,k,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.mp_nag_mom_update,wd,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.random_negative_binomial,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.mp_sgd_update,lazy_update,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.MultiProposal,feature_stride,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.linalg_trmm,rightside,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.box_nms,background_id,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.calibrate_entropy,num_quantized_bins,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.quantized_pooling,pooling_convention,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.nansum,keepdims,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.rmspropalex_update,epsilon,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.SequenceMask,use_sequence_length,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.BatchNorm,eps,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.SoftmaxOutput,preserve_shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.requantize,max_calib_range,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.split,squeeze_axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.sample_gamma,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.ROIPooling,pooled_size,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.quantized_fully_connected,no_bias,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.linalg_gemm,transpose_a,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.BilinearResize2D,scale_width,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.box_decode,std2,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.pick,mode,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.adam_update,lr,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.RNN,lstm_state_clip_nan,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.MultiProposal,threshold,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.ROIPooling,spatial_scale,DF: _Null,DEFAULT Null,,,,,,,
mxnet.image.copyMakeBorder,left,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.contrib.BilinearResize2D,mode,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.backward_gradientmultiplier,scalar,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.cumsum,axis,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.ROIAlign,sample_ratio,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.sample_uniform,shape,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.op.GroupNorm,num_groups,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.topk,dtype,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.mp_lamb_update_phase2,lr,DF: _Null,DEFAULT Null,,,,,,,
mxnet.contrib.ndarray.MultiProposal,rpn_pre_nms_top_n,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.random_normal,loc,DF: _Null,DEFAULT Null,,,,,,,
mxnet.ndarray.linspace,dtype,DF: <classnumpy.float32>,DEFAULT REXPR,,,,,,,
mxnet.contrib.onnx.export_model,input_type,DF: <classnumpy.float32>,DEFAULT REXPR,,,,,,,
mxnet.ndarray.arange,dtype,DF: <classnumpy.float32>,DEFAULT REXPR,,,,,,,
mxnet.gluon.nn.PReLU,alpha_initializer,DF: <mxnet.initializer.Constantobject>,DEFAULT REXPR,,,,,,,
mxnet.test_utils.assert_almost_equal,rtol,The relative threshold. Default threshold will be used if set to `None`.,Default threshold will be used if set to QSTR,,,,,,,
mxnet.ndarray.image.normalize,mean,Sequence of means for each channel. Default value is 0.,Default value is CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.op.Pooling,count_include_pad,"Only used for AvgPool, specify whether to count padding elements for averagecalculation. For example, with a 5*5 kernel on a 3*3 corner of a image,the sum of the 9 valid elements will be divided by 25 if this is set to true,or it will be divided by 9 if this is set to false. Defaults to true.",Defaults to CONSTANT_BOOL,bool,,,,0,,
mxnet.contrib.ndarray.quantized_pooling,count_include_pad,"Only used for AvgPool, specify whether to count padding elements for averagecalculation. For example, with a 5*5 kernel on a 3*3 corner of a image,the sum of the 9 valid elements will be divided by 25 if this is set to true,or it will be divided by 9 if this is set to false. Defaults to true.",Defaults to CONSTANT_BOOL,bool,,,,0,,
mxnet.ndarray.contrib.quantized_pooling,count_include_pad,"Only used for AvgPool, specify whether to count padding elements for averagecalculation. For example, with a 5*5 kernel on a 3*3 corner of a image,the sum of the 9 valid elements will be divided by 25 if this is set to true,or it will be divided by 9 if this is set to false. Defaults to true.",Defaults to CONSTANT_BOOL,bool,,,,0,,
mxnet.ndarray.op.reshape_like,lhs_begin,Defaults to 0. The beginning index along which the lhs dimensions are to be reshaped. Supports negative indices.,Defaults to CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.reshape_like,rhs_begin,Defaults to 0. The beginning index along which the rhs dimensions are to be used for reshaping. Supports negative indices.,Defaults to CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.contrib.quantized_conv,dilate,"Convolution dilate: (w,), (h, w) or (d, h, w). Defaults to 1 for each dimension.",Defaults to CONSTANT_NUM for each dimension,,,,,,,
mxnet.contrib.ndarray.quantized_conv,dilate,"Convolution dilate: (w,), (h, w) or (d, h, w). Defaults to 1 for each dimension.",Defaults to CONSTANT_NUM for each dimension,,,,,,,
mxnet.ndarray.op.Convolution,dilate,"Convolution dilate: (w,), (h, w) or (d, h, w). Defaults to 1 for each dimension.",Defaults to CONSTANT_NUM for each dimension,,,,,,,
mxnet.contrib.ndarray.DeformableConvolution,stride,"Convolution stride: (h, w) or (d, h, w). Defaults to 1 for each dimension.",Defaults to CONSTANT_NUM for each dimension,,,,,,,
mxnet.ndarray.op.Pooling,stride,"Stride: for pooling (y, x) or (d, y, x). Defaults to 1 for each dimension.",Defaults to CONSTANT_NUM for each dimension,,,,,,,
mxnet.contrib.ndarray.quantized_pooling,stride,"Stride: for pooling (y, x) or (d, y, x). Defaults to 1 for each dimension.",Defaults to CONSTANT_NUM for each dimension,,,,,,,
mxnet.ndarray.sample_gamma,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,numpy.dtype,,,,0,,
mxnet.ndarray.op.random_uniform,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,numpy.dtype,,,,0,,
mxnet.ndarray.op.sample_generalized_negative_binomial,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,numpy.dtype,,,,0,,
mxnet.ndarray.random_gamma,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,numpy.dtype,,,,0,,
mxnet.ndarray.random_normal,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,numpy.dtype,,,,0,,
mxnet.ndarray.op.Pooling,pad,"Pad for pooling: (y, x) or (d, y, x). Defaults to no padding.",Defaults to no padding,,,,,,,
mxnet.ndarray.ones,ctx,An optional device context. Defaults to the current default context (`mxnet.context.current_context()`).,Defaults to the current default context mxnet context current_context,,,,,,,
mxnet.ndarray.op.softmin,dtype,DType of the output in case this can't be inferred. Defaults to the same as input's dtype if not defined (dtype=None).,Defaults to the same as input dtype if not defined dtype None,,,,,,,
mxnet.ndarray.op.softmax,dtype,DType of the output in case this can't be inferred. Defaults to the same as input's dtype if not defined (dtype=None).,Defaults to the same as input dtype if not defined dtype None,,,,,,,
mxnet.ndarray.softmax,dtype,DType of the output in case this can't be inferred. Defaults to the same as input's dtype if not defined (dtype=None).,Defaults to the same as input dtype if not defined dtype None,,,,,,,
mxnet.ndarray.log_softmax,dtype,DType of the output in case this can't be inferred. Defaults to the same as input's dtype if not defined (dtype=None).,Defaults to the same as input dtype if not defined dtype None,,,,,,,
mxnet.ndarray.op.log_softmax,dtype,DType of the output in case this can't be inferred. Defaults to the same as input's dtype if not defined (dtype=None).,Defaults to the same as input dtype if not defined dtype None,,,,,,,
mxnet.autograd.grad,retain_graph,"Whether to keep computation graph to differentiate again, instead of clearing history and release memory. Defaults to the same value as create_graph.",Defaults to the same value as PARAM,,,,,,,
mxnet.contrib.quantization.quantize_model,ctx,"Defines the device that users want to run forward propagation on the calibration dataset for collecting layer output statistics. Currently, only supports single context.",Defines the device that users want to run forward propagation on the calibration dataset for collecting layer output statistics,,,,,,,
mxnet.contrib.quantization.quantize_net,ctx,"Defines the device that users want to run forward propagation on the calibration dataset for collecting layer output statistics. Currently, only supports single context.",Defines the device that users want to run forward propagation on the calibration dataset for collecting layer output statistics,,,,,,,
mxnet.ndarray.op.one_hot,depth,Depth of the one hot dimension.,Depth of the one hot dimension,numeric,,,,,,
mxnet.ndarray.linspace,ctx,Device context. Default context is the current default context.,Device context,,,,,,,
mxnet.ndarray.full,ctx,Device context (default is the current default context).,Device context BSTR,,,,,,,
mxnet.ndarray.contrib.SparseEmbedding,output_dim,Dimension of the embedding vectors.,Dimension of the embedding D_STRUCTURE,int,,,,,,
mxnet.gluon.nn.GlobalAvgPool2D,layout,"Dimension ordering of data and out ('NCHW' or 'NHWC'). 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively.",Dimension ordering of data and out QSTR,int,,,,,,
mxnet.gluon.nn.AvgPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. padding is applied on 'W' dimension.",Dimension ordering of data and out QSTR,int,,,,,,
mxnet.gluon.nn.GlobalMaxPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Pooling is applied on the W dimension.",Dimension ordering of data and out QSTR,int,,,,,,
mxnet.gluon.nn.Conv2DTranspose,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",Dimension ordering of data and weight,int,,,,,,
mxnet.gluon.nn.Conv1DTranspose,layout,"Dimension ordering of data and weight. Only supports 'NCW' layout for now. 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Convolution is applied on the 'W' dimension.",Dimension ordering of data and weight,int,,,,,,
mxnet.gluon.nn.Conv1D,layout,"Dimension ordering of data and weight. Only supports 'NCW' layout for now. 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Convolution is applied on the 'W' dimension.",Dimension ordering of data and weight,int,,,,,,
mxnet.ndarray.op.RNN,p,"drop rate of the dropout on the outputs of each RNN layer, except the last layer.",drop rate of the dropout on the outputs of each RNN layer except the last layer,numeric,,,,,"[0,1]",
mxnet.ndarray.one_hot,dtype,DType of the output,DType of the output,numpy.dtype,,,,,,
mxnet.ndarray.sample_gamma,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,DType of the output in case this can t be inferred,numpy.dtype,,,,,,
mxnet.ndarray.op.random_uniform,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,DType of the output in case this can t be inferred,numpy.dtype,,,,,,
mxnet.ndarray.op.sample_generalized_negative_binomial,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,DType of the output in case this can t be inferred,numpy.dtype,,,,,,
mxnet.ndarray.random_gamma,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,DType of the output in case this can t be inferred,numpy.dtype,,,,,,
mxnet.ndarray.random_normal,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,DType of the output in case this can t be inferred,numpy.dtype,,,,,,
mxnet.ndarray.op.softmin,dtype,DType of the output in case this can't be inferred. Defaults to the same as input's dtype if not defined (dtype=None).,DType of the output in case this can t be inferred,numpy.dtype,,,,,,
mxnet.ndarray.op.softmax,dtype,DType of the output in case this can't be inferred. Defaults to the same as input's dtype if not defined (dtype=None).,DType of the output in case this can t be inferred,numpy.dtype,,,,,,
mxnet.ndarray.softmax,dtype,DType of the output in case this can't be inferred. Defaults to the same as input's dtype if not defined (dtype=None).,DType of the output in case this can t be inferred,numpy.dtype,,,,,,
mxnet.ndarray.log_softmax,dtype,DType of the output in case this can't be inferred. Defaults to the same as input's dtype if not defined (dtype=None).,DType of the output in case this can t be inferred,numpy.dtype,,,,,,
mxnet.ndarray.op.log_softmax,dtype,DType of the output in case this can't be inferred. Defaults to the same as input's dtype if not defined (dtype=None).,DType of the output in case this can t be inferred,numpy.dtype,,,,,,
mxnet.gluon.nn.MaxPool2D,strides,"Factor by which to downscale. E.g. 2 will halve the input size. If None, it will default to pool_size.",E g,,,,,,,
mxnet.gluon.nn.AvgPool2D,strides,"Factor by which to downscale. E.g. 2 will halve the input size. If None, it will default to pool_size.",E g,,,,,,,
mxnet.contrib.ndarray.arange_like,repeat,"The repeating time of all elements. E.g repeat=3, the element a will be repeated three times -> a, a, a.",E g repeat CONSTANT_NUM the element a will be repeated three times REXPR a a,,,,,,,
mxnet.ndarray.tile,reps,"The number of times for repeating the tensor a. Each dim size of reps must be a positive integer. If reps has length d, the result will have dimension of max(d, a.ndim); If a.ndim < d, a is promoted to be d-dimensional by prepending new axes. If a.ndim > d, reps is promoted to a.ndim by pre-pending 1's to it.",Each dim size of reps must be a positive D_TYPE,,,,,,,
mxnet.ndarray.op.Pooling,layout,"Set layout for input and output. Empty for default layout: NCW for 1d, NCHW for 2d and NCDHW for 3d.",Empty for default layout NCW for CONSTANT_NUM d NCHW for CONSTANT_NUM d and NCDHW for CONSTANT_NUM d,,,,,,,NCW;NCHW;NCDHW
mxnet.ndarray.contrib.quantized_pooling,layout,"Set layout for input and output. Empty for default layout: NCW for 1d, NCHW for 2d and NCDHW for 3d.",Empty for default layout NCW for CONSTANT_NUM d NCHW for CONSTANT_NUM d and NCDHW for CONSTANT_NUM d,,,,,,,NCW;NCHW;NCDHW
mxnet.contrib.ndarray.group_adagrad_update,epsilon,Epsilon for numerical stability,Epsilon for numerical stability,,,,,,,
mxnet.test_utils.numeric_grad,eps,Epsilon for the finite-difference method.,Epsilon for the finite difference method,,,,,,,
mxnet.ndarray.contrib.SyncBatchNorm,eps,Epsilon to prevent div 0,Epsilon to prevent div CONSTANT_NUM,,,,,,,
mxnet.ndarray.op.ftml_update,epsilon,Epsilon to prevent div 0.,Epsilon to prevent div CONSTANT_NUM,,,,,,,
mxnet.ndarray.contrib.PSROIPooling,spatial_scale,Ratio of input feature map height (or w) to raw image height (or w). Equals the reciprocal of total stride in convolutional layers,Equals the reciprocal of total stride in convolutional layers,,,,,,,
mxnet.test_utils.check_symbolic_backward,expected,expected gradient values   if type is list of np.ndarrayContains arrays corresponding to exe.grad_arrays,expected gradient values if type is D_STRUCTURE of np ndarrayContains D_STRUCTURE corresponding to exe grad_arrays,numeric,,,,,,
mxnet.gluon.nn.MaxPool2D,strides,"Factor by which to downscale. E.g. 2 will halve the input size. If None, it will default to pool_size.",Factor by which to downscale,numeric,,,,,,
mxnet.gluon.nn.AvgPool2D,strides,"Factor by which to downscale. E.g. 2 will halve the input size. If None, it will default to pool_size.",Factor by which to downscale,numeric,,,,,,
mxnet.ndarray.op.sample_negative_binomial,p,Failure probabilities in each experiment.,Failure probabilities in each experiment,numeric,,,,,"[0,1]",
mxnet.ndarray.random_negative_binomial,p,Failure probability in each experiment.,Failure probability in each experiment,numeric,,,,,"[0,1]",
mxnet.ndarray.modulo,lhs,First array in modulo.,First D_STRUCTURE in modulo,,,D_STRUCTURE,,,,
mxnet.ndarray.maximum,lhs,First array to be compared.,First D_STRUCTURE to be compared,,,D_STRUCTURE,,,,
mxnet.ndarray.elemwise_add,lhs,first input,first input,,,,,,,
mxnet.ndarray.reshape_like,lhs,First input.,First input,,,,,,,
mxnet.ndarray.logical_xor,lhs,First input of the function.,First input of the function,,,,,,,
mxnet.ndarray.op.broadcast_logical_and,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.broadcast_minus,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.broadcast_logical_and,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.op.broadcast_minimum,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.op.broadcast_greater,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.op.broadcast_logical_or,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.op.broadcast_logical_xor,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.broadcast_plus,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.op.broadcast_mul,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.broadcast_equal,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.broadcast_logical_xor,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.broadcast_mod,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,group_size,fix group size,fix group size,int,,,,,"[0,inf)",
mxnet.contrib.ndarray.DeformablePSROIPooling,group_size,fix group size,fix group size,int,,,,,"[0,inf)",
mxnet.contrib.ndarray.PSROIPooling,output_dim,fix output dim,fix output dim,int,,,,,,
mxnet.ndarray.contrib.SyncBatchNorm,fix_gamma,Fix gamma while training,Fix PARAM while training,,,,,CONSTANT_NUM,,
mxnet.contrib.ndarray.DeformablePSROIPooling,part_size,fix part size,fix part size,int,,,,,"[0,inf)",
mxnet.ndarray.contrib.DeformablePSROIPooling,pooled_size,fix pooled size,fix pooled size,int,,,,,"[0,inf)",
mxnet.contrib.ndarray.PSROIPooling,pooled_size,fix pooled size,fix pooled size,int,,,,,"[0,inf)",
mxnet.contrib.ndarray.DeformablePSROIPooling,sample_per_part,fix samples per part,fix samples per part,,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,trans_std,fix transition std,fix transition std,,,,,,,
mxnet.ndarray.split_v2,indices_or_sections,"If indices_or_sections is an integer, N, the array will be divided into N equal arrays along axis.  If such a split is not possible, an error is raised. If indices_or_sections is a 1-D array of sorted integers, the entries indicate where along axis the array is split.  For example, `[2, 3]` would, for `axis=0`, result in - ary[:2] - ary[2:3] - ary[3:] If an index exceeds the dimension of the array along axis, an empty sub-array is returned correspondingly.",For example BSTR would for PARAM CONSTANT_NUM result in PARAM CONSTANT_NUM PARAM CONSTANT_NUM CONSTANT_NUM PARAM CONSTANT_NUM If an index exceeds the dimension of the D_STRUCTURE along PARAM an empty sub D_STRUCTURE is returned correspondingly,,,,,,,
mxnet.ndarray.random.multinomial,data,"An n dimensional array whose last dimension has length k, where k is the number of possible outcomes of each multinomial distribution. For example, data with shape (m, n, k) specifies m*n multinomial distributions each with k possible outcomes.",For example data with PARAM BSTR specifies m n multinomial distributions each with k possible outcomes,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,input_shape,"Input tensor shape at each time step for each sample, excluding dimension of the batch size and sequence length. Must be consistent with conv_layout. For example, for layout 'NCHW' the shape should be (C, H, W).",For example for layout QSTR the shape should be BSTR,,,,,,,
mxnet.ndarray.op.Pooling,count_include_pad,"Only used for AvgPool, specify whether to count padding elements for averagecalculation. For example, with a 5*5 kernel on a 3*3 corner of a image,the sum of the 9 valid elements will be divided by 25 if this is set to true,or it will be divided by 9 if this is set to false. Defaults to true.",For example with a CONSTANT_NUM CONSTANT_NUM PARAM on a CONSTANT_NUM CONSTANT_NUM corner of a image the sum of the CONSTANT_NUM valid elements will be divided by CONSTANT_NUM if this is set to CONSTANT_BOOL or it will be divided by CONSTANT_NUM if this is set to CONSTANT_BOOL,,,,,,,
mxnet.contrib.ndarray.quantized_pooling,count_include_pad,"Only used for AvgPool, specify whether to count padding elements for averagecalculation. For example, with a 5*5 kernel on a 3*3 corner of a image,the sum of the 9 valid elements will be divided by 25 if this is set to true,or it will be divided by 9 if this is set to false. Defaults to true.",For example with a CONSTANT_NUM CONSTANT_NUM PARAM on a CONSTANT_NUM CONSTANT_NUM corner of a image the sum of the CONSTANT_NUM valid elements will be divided by CONSTANT_NUM if this is set to CONSTANT_BOOL or it will be divided by CONSTANT_NUM if this is set to CONSTANT_BOOL,,,,,,,
mxnet.ndarray.contrib.quantized_pooling,count_include_pad,"Only used for AvgPool, specify whether to count padding elements for averagecalculation. For example, with a 5*5 kernel on a 3*3 corner of a image,the sum of the 9 valid elements will be divided by 25 if this is set to true,or it will be divided by 9 if this is set to false. Defaults to true.",For example with a CONSTANT_NUM CONSTANT_NUM PARAM on a CONSTANT_NUM CONSTANT_NUM corner of a image the sum of the CONSTANT_NUM valid elements will be divided by CONSTANT_NUM if this is set to CONSTANT_BOOL or it will be divided by CONSTANT_NUM if this is set to CONSTANT_BOOL,,,,,,,
mxnet.gluon.nn.BatchNorm,axis,"The axis that should be normalized. This is typically the channels (C) axis. For instance, after a Conv2D layer with layout='NCHW', set axis=1 in BatchNorm. If layout='NHWC', then set axis=3.",For instance after a Conv2D layer with layout QSTR set axis CONSTANT_NUM in BatchNorm,,,,,,,
mxnet.gluon.nn.InstanceNorm,axis,"The axis that will be excluded in the normalization process. This is typically the channels (C) axis. For instance, after a Conv2D layer with layout='NCHW', set axis=1 in InstanceNorm. If layout='NHWC', then set axis=3. Data will be normalized along axes excluding the first axis and the axis given.",For instance after a Conv2D layer with layout QSTR set axis CONSTANT_NUM in InstanceNorm,,,,,,,
mxnet.ndarray.op.GroupNorm,gamma,gamma array,gamma D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.ftml_update,beta2,Generally close to 1.,Generally close to CONSTANT_NUM,int,,,,,,
mxnet.ndarray.op.multi_mp_sgd_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",grad max BSTR,,,,,,,
mxnet.ndarray.multi_sgd_mom_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",grad max BSTR,,,,,,,
mxnet.ndarray.op.multi_lars,rescale_grad,Gradient rescaling factor,Gradient rescaling factor,,,,,,,
mxnet.ndarray.SoftmaxOutput,label,Ground truth label.,Ground truth label,,,,,,,
mxnet.ndarray.Softmax,label,Ground truth label.,Ground truth label,,,,,,,
mxnet.operator.get_operator_arguments,op_name,Handle for the operator,Handle for the operator,,,,,,,
mxnet.profiler.set_config,aggregate_stats,whether to maintain aggregate stats in memory for console dump.  Has some negative performance impact.,Has some negative performance impact,,,,,,,
mxnet.image.imresize,h,Height of resized image.,Height of resized image,numeric,,,,,"[0,inf)",
mxnet.gluon.model_zoo.vision.get_mobilenet_v2,root,DF: /home/jenkins_slave/.mxnet/models,home jenkins_slave mxnet models,,,,,,,
mxnet.gluon.model_zoo.vision.inception_v3,root,DF: /home/jenkins_slave/.mxnet/models,home jenkins_slave mxnet models,,,,,,,
mxnet.ndarray.image.random_color_jitter,contrast,How much to jitter contrast.,How much to jitter contrast,,,,,,,
mxnet.ndarray.image.random_color_jitter,saturation,How much to jitter saturation.,How much to jitter saturation,,,,,,,
mxnet.ndarray.op.UpSampling,multi_input_mode,"How to handle multiple input. concat means concatenate upsampled images along the channel dimension. sum means add all images together, only available for nearest neighbor upsampling.",How to handle multiple input,,,,,,,
mxnet.image.CreateAugmenter,hue,Hue jittering range (percent),Hue jittering range BSTR,numeric,,,,,"[0,1]",
mxnet.ndarray.tile,reps,"The number of times for repeating the tensor a. Each dim size of reps must be a positive integer. If reps has length d, the result will have dimension of max(d, a.ndim); If a.ndim < d, a is promoted to be d-dimensional by prepending new axes. If a.ndim > d, reps is promoted to a.ndim by pre-pending 1's to it.",If a ndim REXPR reps is promoted to a ndim by pre pending CONSTANT_NUMs to it,,,,,,,
mxnet.ndarray.squeeze,axis,"Selects a subset of the single-dimensional entries in the shape. If an axis is selected with shape entry greater than one, an error is raised.",If an axis is selected with shape entry greater than one an error is raised,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,activation,"Type of activation function used in n_t. If argument type is string, it's equivalent to nn.Activation(act_type=str). See `Activation()` for available choices. Alternatively, other activation blocks such as nn.LeakyReLU can be used.",If argument type is D_TYPE it equivalent to nn Activation act_type D_TYPE,,,,,,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,activation,"Type of activation function. If argument type is string, it's equivalent to nn.Activation(act_type=str). See `Activation()` for available choices. Alternatively, other activation blocks such as nn.LeakyReLU can be used.",If argument type is D_TYPE it equivalent to nn Activation act_type D_TYPE,,,,,,,
mxnet.ndarray.op.nansum,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is a D_STRUCTURE of D_TYPE a reduction is performed on all the axes specified in the D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.max_axis,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is a D_STRUCTURE of D_TYPE a reduction is performed on all the axes specified in the D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.min,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is a D_STRUCTURE of D_TYPE a reduction is performed on all the axes specified in the D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.op.max_axis,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is a D_STRUCTURE of D_TYPE a reduction is performed on all the axes specified in the D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.op.nansum,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is D_TYPE a reduction is performed on a particular axis,D_TYPE,,,,,,
mxnet.ndarray.max_axis,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is D_TYPE a reduction is performed on a particular axis,D_TYPE,,,,,,
mxnet.ndarray.min,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is D_TYPE a reduction is performed on a particular axis,D_TYPE,,,,,,
mxnet.ndarray.op.max_axis,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is D_TYPE a reduction is performed on a particular axis,D_TYPE,,,,,,
mxnet.ndarray.histogram,bins,"If bins is an int, it defines the number of equal-width bins in the given range (10, by default). If bins is a sequence, it defines the bin edges, including the rightmost edge, allowing for non-uniform bin widths.",If bins is a D_STRUCTURE it defines the bin edges including the rightmost edge allowing for non uniform bin widths,,,D_STRUCTURE,,,,
mxnet.ndarray.histogram,bins,"If bins is an int, it defines the number of equal-width bins in the given range (10, by default). If bins is a sequence, it defines the bin edges, including the rightmost edge, allowing for non-uniform bin widths.",If bins is an D_TYPE it defines the number of equal width bins in the given PARAM BSTR,D_TYPE,,,,0,"[0,inf)",
mxnet.contrib.quantization.quantize_net,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",If calib_mode QSTR BSTR the thresholds for quantization will be derived such that the KL divergence between the distributions of D_TYPE layer outputs and quantized layer outputs is minimized based upon the calibration dataset,D_TYPE,,,,,,QSTR
mxnet.contrib.quantization.quantize_net,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",If calib_mode QSTR no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators,D_TYPE,,,,,,QSTR
mxnet.contrib.quantization.quantize_net,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",If calib_mode QSTR the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization,D_TYPE,,,,,,QSTR
mxnet.gluon.nn.GroupNorm,center,"If True, add offset of beta to normalized tensor. If False, beta is ignored.",If CONSTANT_BOOL add offset of beta to normalized D_STRUCTURE,bool,,,,0,,
mxnet.gluon.rnn.LSTM,bidirectional,"If True, becomes a bidirectional RNN.",If CONSTANT_BOOL becomes a bidirectional RNN,bool,,,,0,,
mxnet.gluon.nn.GroupNorm,center,"If True, add offset of beta to normalized tensor. If False, beta is ignored.",If CONSTANT_BOOL beta is ignored,bool,,,,0,,
mxnet.gluon.nn.Embedding,sparse_grad,"If True, gradient w.r.t. weight will be a 'row_sparse' NDArray.",If CONSTANT_BOOL gradient w r t,bool,,,,0,,
mxnet.ndarray.mp_sgd_update,lazy_update,"If true, lazy updates are applied if gradient's stype is row_sparse.",If CONSTANT_BOOL lazy updates are applied if gradient stype is row_sparse,bool,,,,0,,
mxnet.ndarray.sparse.adam_update,lazy_update,"If true, lazy updates are applied if gradient's stype is row_sparse and all of w, m and v have the same stype",If CONSTANT_BOOL lazy updates are applied if gradient stype is row_sparse and all of w m and v have the same stype,bool,,,,0,,
mxnet.ndarray.sparse.sgd_mom_update,lazy_update,"If true, lazy updates are applied if gradient's stype is row_sparse and both weight and momentum have the same stype",If CONSTANT_BOOL lazy updates are applied if gradient stype is row_sparse and both PARAM and PARAM have the same stype,bool,,,,0,,
mxnet.ndarray.contrib.allclose,equal_nan,"Whether to compare NaN's as equal. If True, NaN's in A will be considered equal to NaN's in B in the output array.",If CONSTANT_BOOL NaN in A will be considered equal to NaN in B in the output D_STRUCTURE,bool,,,,0,,
mxnet.ndarray.split,squeeze_axis,"If true, Removes the axis with length 1 from the shapes of the output arrays. Note that setting squeeze_axis to `true` removes axis with length 1 only along the axis which it is split. Also squeeze_axis can be set to `true` only if `input.shape[axis] == num_outputs`.",If CONSTANT_BOOL Removes the PARAM with length CONSTANT_NUM from the shapes of the output D_STRUCTURE,bool,,,,0,,
mxnet.ndarray.op.CTCLoss,use_label_lengths,"Whether the label lenghts are decided by label_lengths, or derived from padding_mask. If false, the lengths are derived from the first occurrence of the value of padding_mask. The value of padding_mask is `0` when first CTC label is reserved for blank, and `-1` when last label is reserved for blank. See blank_label.",If CONSTANT_BOOL the lengths are derived from the first occurrence of the value of padding_mask,bool,,,,0,,
mxnet.ndarray.CTCLoss,use_label_lengths,"Whether the label lenghts are decided by label_lengths, or derived from padding_mask. If false, the lengths are derived from the first occurrence of the value of padding_mask. The value of padding_mask is `0` when first CTC label is reserved for blank, and `-1` when last label is reserved for blank. See blank_label.",If CONSTANT_BOOL the lengths are derived from the first occurrence of the value of padding_mask,bool,,,,0,,
mxnet.ndarray.contrib.CTCLoss,use_label_lengths,"Whether the label lenghts are decided by label_lengths, or derived from padding_mask. If false, the lengths are derived from the first occurrence of the value of padding_mask. The value of padding_mask is `0` when first CTC label is reserved for blank, and `-1` when last label is reserved for blank. See blank_label.",If CONSTANT_BOOL the lengths are derived from the first occurrence of the value of padding_mask,bool,,,,0,,
mxnet.contrib.ndarray.ctc_loss,use_data_lengths,"Whether the data lenghts are decided by data_lengths. If false, the lengths are equal to the max sequence length.",If CONSTANT_BOOL the lengths are equal to the max D_STRUCTURE length,bool,,,,0,,
mxnet.ndarray.op.batch_dot,transpose_a,If true then transpose the first input before dot.,If CONSTANT_BOOL then transpose the first input before dot,bool,,,,0,,
mxnet.ndarray.sparse.dot,transpose_a,If true then transpose the first input before dot.,If CONSTANT_BOOL then transpose the first input before dot,bool,,,,0,,
mxnet.ndarray.op.dot,transpose_b,If true then transpose the second input before dot.,If CONSTANT_BOOL then transpose the second input before dot,bool,,,,0,,
mxnet.ndarray.batch_dot,transpose_b,If true then transpose the second input before dot.,If CONSTANT_BOOL then transpose the second input before dot,bool,,,,0,,
mxnet.contrib.onnx.export_model,verbose,If true will print logs of the model conversion,If CONSTANT_BOOL will print logs of the model conversion,bool,,,,0,,
mxnet.ndarray.split_v2,indices_or_sections,"If indices_or_sections is an integer, N, the array will be divided into N equal arrays along axis.  If such a split is not possible, an error is raised. If indices_or_sections is a 1-D array of sorted integers, the entries indicate where along axis the array is split.  For example, `[2, 3]` would, for `axis=0`, result in - ary[:2] - ary[2:3] - ary[3:] If an index exceeds the dimension of the array along axis, an empty sub-array is returned correspondingly.",If indices_or_sections is a CONSTANT_NUM D D_STRUCTURE of sorted D_TYPE the entries indicate where along PARAM the D_STRUCTURE is split,,,D_STRUCTURE,,CONSTANT_NUM,,
mxnet.ndarray.split_v2,indices_or_sections,"If indices_or_sections is an integer, N, the array will be divided into N equal arrays along axis.  If such a split is not possible, an error is raised. If indices_or_sections is a 1-D array of sorted integers, the entries indicate where along axis the array is split.  For example, `[2, 3]` would, for `axis=0`, result in - ary[:2] - ary[2:3] - ary[3:] If an index exceeds the dimension of the array along axis, an empty sub-array is returned correspondingly.",If indices_or_sections is an D_TYPE N the D_STRUCTURE will be divided into N equal D_STRUCTURE along PARAM,D_TYPE,,,,0,,
mxnet.ndarray.pick,axis,"int or None. The axis to picking the elements. Negative values means indexing from right to left. If is None, the elements in the index w.r.t the flattened input will be picked.",If is None the elements in the PARAM w r t the flattened input will be picked,,,,,,,
mxnet.ndarray.random.negative_binomial,shape,"The number of samples to draw. If shape is, e.g., (m, n) and k and p are scalars, output shape will be (m, n). If k and p are NDArrays with shape, e.g., (x, y), then output will have shape (x, y, m, n), where m*n samples are drawn for each [k, p) pair.",If k and p are NDArrays with shape e g BSTR where m n samples are drawn for each BSTR pair,,,,,,,
mxnet.ndarray.contrib.box_decode,clip,"If larger than 0, bounding box target will be clipped to this value.",If larger than CONSTANT_NUM bounding box target will be clipped to this value,,,,,,,
mxnet.gluon.nn.BatchNorm,axis,"The axis that should be normalized. This is typically the channels (C) axis. For instance, after a Conv2D layer with layout='NCHW', set axis=1 in BatchNorm. If layout='NHWC', then set axis=3.",If layout QSTR then set axis CONSTANT_NUM,,,,,,,
mxnet.gluon.nn.InstanceNorm,axis,"The axis that will be excluded in the normalization process. This is typically the channels (C) axis. For instance, after a Conv2D layer with layout='NCHW', set axis=1 in InstanceNorm. If layout='NHWC', then set axis=3. Data will be normalized along axes excluding the first axis and the axis given.",If layout QSTR then set axis CONSTANT_NUM,,,,,,,
mxnet.ndarray.mp_lamb_update_phase2,lower_bound,"Lower limit of norm of weight. If lower_bound <= 0, Lower limit is not set",If lower_bound REXPR Lower limit is not set,,,,,,,
mxnet.gluon.nn.MaxPool2D,strides,"Factor by which to downscale. E.g. 2 will halve the input size. If None, it will default to pool_size.",If None it will default to PARAM,,,,,,,
mxnet.gluon.nn.AvgPool2D,strides,"Factor by which to downscale. E.g. 2 will halve the input size. If None, it will default to pool_size.",If None it will default to PARAM,,,,,,,
mxnet.test_utils.download,dirname,"output directory name. If None, then guess from fname or use the current directory",If None then guess from PARAM or use the current directory,,,,,,,
mxnet.gluon.nn.InstanceNorm,in_channels,"Number of channels (feature maps) in input data. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",If not specified initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data,,,,,,,
mxnet.gluon.nn.LayerNorm,in_channels,"Number of channels (feature maps) in input data. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",If not specified initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data,,,,,,,
mxnet.gluon.contrib.nn.SyncBatchNorm,in_channels,"Number of channels (feature maps) in input data. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",If not specified initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data,,,,,,,
mxnet.gluon.nn.Conv3D,in_channels,"The number of input channels to this layer. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",If not specified initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data,,,,,,,
mxnet.gluon.nn.Conv1DTranspose,in_channels,"The number of input channels to this layer. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",If not specified initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data,,,,,,,
mxnet.io.LibSVMIter,label_libsvm,"The input LibSVM label file or a directory path. If NULL, all labels will be read from `data_libsvm`.",If NULL all labels will be read from PARAM,,,,,,,
mxnet.gluon.nn.Conv3D,padding,"If padding is non-zero, then the input is implicitly zero-padded on both sides for padding number of points",If padding is non zero then the input is implicitly zero padded on both sides for padding number of points,,,,,,,
mxnet.ndarray.op.nansum,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If PARAM is CONSTANT_BOOL reduction will be performed on the axes that are NOT in axis instead,,,,,,,
mxnet.ndarray.max_axis,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If PARAM is CONSTANT_BOOL reduction will be performed on the axes that are NOT in axis instead,,,,,,,
mxnet.ndarray.min,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If PARAM is CONSTANT_BOOL reduction will be performed on the axes that are NOT in axis instead,,,,,,,
mxnet.ndarray.op.max_axis,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If PARAM is CONSTANT_BOOL reduction will be performed on the axes that are NOT in axis instead,,,,,,,
mxnet.io.ImageRecordIter,max_aspect_ratio,"Change the aspect (namely width/height) to a random value. If min_aspect_ratio is None then the aspect ratio ins sampled from [1 - max_aspect_ratio, 1 + max_aspect_ratio], else it is in `[min_aspect_ratio, max_aspect_ratio]`",If PARAM is None then the aspect ratio ins sampled from BSTR else it is in BSTR,,,,,,,
mxnet.ndarray.power,exp,"The exponent array. If `base.shape != exp.shape`, they must be broadcastable to a common shape.",If PARAM shape exp shape they must be broadcastable to a common shape,,,,,,,
mxnet.ndarray.sparse.add,rhs,"Second array to be added. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",If PARAM shape rhs shape they must be broadcastable to a common shape,,,,,,,
mxnet.ndarray.greater_equal,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",If PARAM shape rhs shape they must be broadcastable to a common shape,,,,,,,
mxnet.ndarray.multiply,rhs,"Second array to be multiplied. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",If PARAM shape rhs shape they must be broadcastable to a common shape,,,,,,,
mxnet.ndarray.logical_xor,rhs,"Second input of the function. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",If PARAM shape rhs shape they must be broadcastable to a common shape,,,,,,,
mxnet.ndarray.contrib.quantized_batch_norm,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to by quantized batch norm op to calculate primitive scale.Note: this calib_range is to calib bn output.",If present it will be used to by quantized batch norm op to calculate primitive scale Note this calib_range is to calib bn output,,,,,,,
mxnet.ndarray.contrib.quantize_v2,min_calib_range,"The minimum scalar value in the form of float32. If present, it will be used to quantize the fp32 data into int8 or uint8.",If present it will be used to quantize the D_TYPE PARAM into D_TYPE,,,,,,,
mxnet.contrib.ndarray.quantize_v2,min_calib_range,"The minimum scalar value in the form of float32. If present, it will be used to quantize the fp32 data into int8 or uint8.",If present it will be used to quantize the D_TYPE PARAM into D_TYPE,,,,,,,
mxnet.contrib.ndarray.CTCLoss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",If QSTR last PARAM value alphabet_size CONSTANT_NUM is reserved for blank PARAM instead and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and alphabet_size CONSTANT_NUM and the padding mask is CONSTANT_NUM,,,,,,,QSTR
mxnet.test_utils.simple_forward,ctx,"If `None`, will take the default context.",If QSTR will take the default context,,,,,,,
mxnet.ndarray.tile,reps,"The number of times for repeating the tensor a. Each dim size of reps must be a positive integer. If reps has length d, the result will have dimension of max(d, a.ndim); If a.ndim < d, a is promoted to be d-dimensional by prepending new axes. If a.ndim > d, reps is promoted to a.ndim by pre-pending 1's to it.",If reps has length d the result will have dimension of max BSTR If a ndim REXPR a is promoted to be d dimensional by prepending new axes,,,,,,,
mxnet.ndarray.op.random_pdf_uniform,is_log,"If set, compute the density of the log-probability instead of the probability.",If set compute the density of the log probability instead of the probability,,,,,,,
mxnet.ndarray.op.random_pdf_gamma,is_log,"If set, compute the density of the log-probability instead of the probability.",If set compute the density of the log probability instead of the probability,,,,,,,
mxnet.ndarray.random_pdf_poisson,is_log,"If set, compute the density of the log-probability instead of the probability.",If set compute the density of the log probability instead of the probability,,,,,,,
mxnet.ndarray.Embedding,sparse_grad,"Compute row sparse gradient in the backward calculation. If set to True, the grad's storage type is row_sparse.",If set to CONSTANT_BOOL the grad storage type is row_sparse,bool,,,,0,,
mxnet.ndarray.op.Softmax,use_ignore,"If set to `true`, the ignore_label value will not contribute to the backward gradient.",If set to CONSTANT_BOOL the PARAM value will not contribute to the backward gradient,bool,,,,0,,
mxnet.ndarray.SoftmaxOutput,use_ignore,"If set to `true`, the ignore_label value will not contribute to the backward gradient.",If set to CONSTANT_BOOL the PARAM value will not contribute to the backward gradient,bool,,,,0,,
mxnet.ndarray.Softmax,multi_output,"If set to `true`, the softmax function will be computed along axis `1`. This is applied when the shape of input array differs from the shape of label array.",If set to CONSTANT_BOOL the softmax function will be computed along axis CONSTANT_NUM,bool,,,,0,,
mxnet.ndarray.SequenceReverse,use_sequence_length,"If set to true, this layer takes in an extra input parameter sequence_length to specify variable length sequence",If set to CONSTANT_BOOL this layer takes in an extra input parameter PARAM to specify variable length D_STRUCTURE,bool,,,,0,,
mxnet.ndarray.random.negative_binomial,shape,"The number of samples to draw. If shape is, e.g., (m, n) and k and p are scalars, output shape will be (m, n). If k and p are NDArrays with shape, e.g., (x, y), then output will have shape (x, y, m, n), where m*n samples are drawn for each [k, p) pair.",If shape is e g BSTR,,,,BSTR,,,
mxnet.visualization.plot_network,shape,"Specifies the shape of the input tensors. If specified, the visualization will include the shape of the tensors between the nodes. shape is a dictionary mapping input symbol names (str) to the corresponding tensor shape (tuple).",If specified the visualization will include the shape of the D_STRUCTURE between the nodes,,,,,,,
mxnet.ndarray.split_v2,indices_or_sections,"If indices_or_sections is an integer, N, the array will be divided into N equal arrays along axis.  If such a split is not possible, an error is raised. If indices_or_sections is a 1-D array of sorted integers, the entries indicate where along axis the array is split.  For example, `[2, 3]` would, for `axis=0`, result in - ary[:2] - ary[2:3] - ary[3:] If an index exceeds the dimension of the array along axis, an empty sub-array is returned correspondingly.",If such a split is not possible an error is raised,,,,,,,
mxnet.ndarray.op.MakeLoss,normalization,"If this is set to null, the output gradient will not be normalized. If this is set to batch, the output gradient will be divided by the batch size. If this is set to valid, the output gradient will be divided by the number of valid input elements.",If this is set to batch the output gradient will be divided by the batch size,,,,,,,
mxnet.ndarray.MakeLoss,normalization,"If this is set to null, the output gradient will not be normalized. If this is set to batch, the output gradient will be divided by the batch size. If this is set to valid, the output gradient will be divided by the number of valid input elements.",If this is set to batch the output gradient will be divided by the batch size,,,,,,,
mxnet.ndarray.sparse.mean,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
mxnet.ndarray.mean,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
mxnet.ndarray.norm,keepdims,"If this is set to True, the reduced axis is left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced PARAM is left in the result as dimension with size one,bool,,,,0,,
mxnet.ndarray.argmax,keepdims,"If this is set to True, the reduced axis is left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced PARAM is left in the result as dimension with size one,bool,,,,0,,
mxnet.ndarray.op.MakeLoss,normalization,"If this is set to null, the output gradient will not be normalized. If this is set to batch, the output gradient will be divided by the batch size. If this is set to valid, the output gradient will be divided by the number of valid input elements.",If this is set to null the output gradient will not be normalized,,,,,,,
mxnet.ndarray.MakeLoss,normalization,"If this is set to null, the output gradient will not be normalized. If this is set to batch, the output gradient will be divided by the batch size. If this is set to valid, the output gradient will be divided by the number of valid input elements.",If this is set to null the output gradient will not be normalized,,,,,,,
mxnet.ndarray.op.MakeLoss,normalization,"If this is set to null, the output gradient will not be normalized. If this is set to batch, the output gradient will be divided by the batch size. If this is set to valid, the output gradient will be divided by the number of valid input elements.",If this is set to valid the output gradient will be divided by the number of valid input elements,,,,,,,
mxnet.ndarray.MakeLoss,normalization,"If this is set to null, the output gradient will not be normalized. If this is set to batch, the output gradient will be divided by the batch size. If this is set to valid, the output gradient will be divided by the number of valid input elements.",If this is set to valid the output gradient will be divided by the number of valid input elements,,,,,,,
mxnet.ndarray.GridGenerator,target_shape,"Specifies the output shape (H, W). This is required if transformation type is affine. If transformation type is warp, this parameter is ignored.",If transformation type is warp this parameter is ignored,,,,,,,
mxnet.ndarray.op.GridGenerator,target_shape,"Specifies the output shape (H, W). This is required if transformation type is affine. If transformation type is warp, this parameter is ignored.",If transformation type is warp this parameter is ignored,,,,,,,
mxnet.test_utils.check_symbolic_backward,out_grads,NumPys arrays corresponding to sym.outputs for incomming gradient.   if type is list of np.ndarrayContains arrays corresponding to `exe.outputs`.,if type is D_STRUCTURE of np ndarrayContains D_STRUCTURE corresponding to exe outputs,,,,,,,
mxnet.gluon.nn.Conv3DTranspose,activation,"Activation function to use. See `Activation()`. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",If you don t specify anything no activation is applied ie,,,,,,,
mxnet.ndarray.contrib.bipartite_matching,threshold,"Ignore matching when score < thresh, if is_ascend=false, or ignore score > thresh, if is_ascend=true.",Ignore matching when score REXPR if PARAM CONSTANT_BOOL or ignore score REXPR if PARAM CONSTANT_BOOL,,,,,,,
mxnet.ndarray.Pooling,global_pool,"Ignore kernel size, do global pooling based on current input feature map.",Ignore PARAM size do global pooling based on current input feature map,,,,,,,
mxnet.ndarray.contrib.quantized_pooling,global_pool,"Ignore kernel size, do global pooling based on current input feature map.",Ignore PARAM size do global pooling based on current input feature map,,,,,,,
mxnet.io.ImageRecordIter,max_random_area,"Change the area (namely width * height) to a random value in `[min_random_area, max_random_area]`. Ignored if `random_resized_crop` is False.",Ignored if PARAM is CONSTANT_BOOL,,,,,,,
mxnet.io.ImageRecordIter,min_random_area,"Change the area (namely width * height) to a random value in `[min_random_area, max_random_area]`. Ignored if `random_resized_crop` is False.",Ignored if PARAM is CONSTANT_BOOL,,,,,,,
mxnet.ndarray.diag,axis1,The first axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,Ignored when the input is a CONSTANT_NUM D D_STRUCTURE,,,,,,,
mxnet.ndarray.contrib.MultiProposal,im_info,Image size and scale.,Image size and scale,int,,,,,,
mxnet.image.CreateDetAugmenter,min_object_covered,"The cropped area of the image must contain at least this fraction of any bounding box supplied. The value of this parameter should be non-negative. In the case of 0, the cropped area does not need to overlap any of the bounding boxes supplied.",In the case of CONSTANT_NUM the cropped area does not need to overlap any of the bounding boxes supplied,,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase1,t,Index update count.,Index update count,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.index_copy,index_vector,Index vector,Index D_STRUCTURE,int,,D_STRUCTURE,,,,
mxnet.util.np_shape,active,Indicates whether to activate NumPy-shape semantics.,Indicates whether to activate NumPy shape semantics,bool,,,,0,,
mxnet.ndarray.arange,infer_range,"Infer the stop position from the start, step, repeat, and output tensor size. Deprecated. Only False is supported.",Infer the PARAM position from the PARAM PARAM PARAM and output D_STRUCTURE size,,,,,,,
mxnet.ndarray.op.RNN,state_cell,initial cell state for LSTM networks (only for LSTM),initial cell PARAM for LSTM networks BSTR,,,,,,,
mxnet.ndarray.RNN,state,initial hidden state of the RNN,initial hidden state of the RNN,,,,,,,
mxnet.ndarray.op.multi_all_finite,init_output,Initialize output to 1.,Initialize output to CONSTANT_NUM,,,,,,,
mxnet.ndarray.multi_all_finite,init_output,Initialize output to 1.,Initialize output to CONSTANT_NUM,,,,,,,
mxnet.gluon.nn.InstanceNorm,beta_initializer,Initializer for the beta weight.,Initializer for the beta weight,,,,,,,
mxnet.gluon.rnn.RNN,i2h_bias_initializer,Initializer for the bias vector.,Initializer for the bias D_STRUCTURE,,,,,,,
mxnet.gluon.nn.Conv3D,bias_initializer,Initializer for the bias vector.,Initializer for the bias D_STRUCTURE,,,,,,,
mxnet.gluon.contrib.rnn.LSTMPCell,i2h_bias_initializer,"Initializer for the bias vector. By default, bias for the forget gate is initialized to 1 while all other biases are initialized to zero.",Initializer for the bias D_STRUCTURE,,,,,,,
mxnet.gluon.contrib.nn.SyncBatchNorm,gamma_initializer,Initializer for the gamma weight.,Initializer for the gamma weight,,,,,,,
mxnet.gluon.nn.BatchNorm,gamma_initializer,Initializer for the gamma weight.,Initializer for the gamma weight,,,,,,,
mxnet.gluon.nn.LayerNorm,gamma_initializer,Initializer for the gamma weight.,Initializer for the gamma weight,,,,,,,
mxnet.gluon.contrib.rnn.Conv1DGRUCell,i2h_bias_initializer,Initializer for the input convolution bias vectors.,Initializer for the input convolution bias D_STRUCTURE,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,i2h_weight_initializer,"Initializer for the input weights matrix, used for the input convolutions.",Initializer for the input weights matrix used for the input convolutions,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DRNNCell,i2h_weight_initializer,"Initializer for the input weights matrix, used for the input convolutions.",Initializer for the input weights matrix used for the input convolutions,,,,,,,
mxnet.gluon.contrib.rnn.Conv1DLSTMCell,i2h_weight_initializer,"Initializer for the input weights matrix, used for the input convolutions.",Initializer for the input weights matrix used for the input convolutions,,,,,,,
mxnet.gluon.rnn.LSTMCell,i2h_weight_initializer,"Initializer for the input weights matrix, used for the linear transformation of the inputs.",Initializer for the input weights matrix used for the linear transformation of the inputs,,,,,,,
mxnet.gluon.rnn.GRUCell,i2h_weight_initializer,"Initializer for the input weights matrix, used for the linear transformation of the inputs.",Initializer for the input weights matrix used for the linear transformation of the inputs,,,,,,,
mxnet.gluon.rnn.RNN,i2h_weight_initializer,"Initializer for the input weights matrix, used for the linear transformation of the inputs.",Initializer for the input weights matrix used for the linear transformation of the inputs,,,,,,,
mxnet.gluon.contrib.rnn.LSTMPCell,i2h_weight_initializer,"Initializer for the input weights matrix, used for the linear transformation of the inputs.",Initializer for the input weights matrix used for the linear transformation of the inputs,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DLSTMCell,h2h_bias_initializer,Initializer for the recurrent convolution bias vectors.,Initializer for the recurrent convolution bias D_STRUCTURE,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,h2h_weight_initializer,"Initializer for the recurrent weights matrix, used for the input convolutions.",Initializer for the recurrent weights matrix used for the input convolutions,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DLSTMCell,h2h_weight_initializer,"Initializer for the recurrent weights matrix, used for the input convolutions.",Initializer for the recurrent weights matrix used for the input convolutions,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,h2h_weight_initializer,"Initializer for the recurrent weights matrix, used for the input convolutions.",Initializer for the recurrent weights matrix used for the input convolutions,,,,,,,
mxnet.gluon.rnn.LSTM,h2h_weight_initializer,"Initializer for the recurrent weights matrix, used for the linear transformation of the recurrent state.",Initializer for the recurrent weights matrix used for the linear transformation of the recurrent state,,,,,,,
mxnet.gluon.rnn.RNNCell,h2h_weight_initializer,"Initializer for the recurrent weights matrix, used for the linear transformation of the recurrent state.",Initializer for the recurrent weights matrix used for the linear transformation of the recurrent state,,,,,,,
mxnet.gluon.contrib.nn.SyncBatchNorm,running_variance_initializer,Initializer for the running variance.,Initializer for the running variance,,,,,,,
mxnet.gluon.nn.Conv1D,weight_initializer,Initializer for the weight weights matrix.,Initializer for the weight weights matrix,,,,,,,
mxnet.gluon.nn.Conv2D,weight_initializer,Initializer for the weight weights matrix.,Initializer for the weight weights matrix,,,,,,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,i2h_kernel,Input convolution kernel sizes.,Input convolution kernel sizes,int,,,,,"[0,inf)",
mxnet.gluon.contrib.rnn.Conv3DLSTMCell,i2h_kernel,Input convolution kernel sizes.,Input convolution kernel sizes,int,,,,,"[0,inf)",
mxnet.gluon.contrib.rnn.Conv1DLSTMCell,i2h_kernel,Input convolution kernel sizes.,Input convolution kernel sizes,int,,,,,"[0,inf)",
mxnet.ndarray.size_array,data,Input Array.,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.flatten,data,Input array.,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.SwapAxis,data,Input array.,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.SwapAxis,data,Input array.,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.dgl_adjacency,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.depth_to_space,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.ctc_loss,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.cumsum,a,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quadratic,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.ctc_loss,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quadratic,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.allclose,a,Input array a,Input D_STRUCTURE a,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.allclose,b,Input array b,Input D_STRUCTURE b,,,D_STRUCTURE,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,input_shape,"Input tensor shape at each time step for each sample, excluding dimension of the batch size and sequence length. Must be consistent with conv_layout. For example, for layout 'NCHW' the shape should be (C, H, W).",Input D_STRUCTURE shape at each time step for each sample excluding dimension of the batch size and D_STRUCTURE length,,D_STRUCTURE,,,,,
mxnet.ndarray.L2Normalization,data,Input array to normalize.,Input D_STRUCTURE to normalize,,,D_STRUCTURE,,,,
mxnet.ndarray.op.Deconvolution,data,Input tensor to the deconvolution operation.,Input D_STRUCTURE to the deconvolution operation,,D_STRUCTURE,,,,,
mxnet.ndarray.contrib.index_array,data,Input data,Input data,,,,,,,
mxnet.ndarray.contrib.BilinearResize2D,data,Input data,Input data,,,,,,,
mxnet.ndarray.op.FullyConnected,data,Input data.,Input data,,,,,,,
mxnet.contrib.ndarray.quantized_conv,data,Input data.,Input data,,,,,,,
mxnet.contrib.ndarray.quantized_pooling,data,Input data.,Input data,,,,,,,
mxnet.ndarray.Custom,*data,Input data for the custom operator.,Input data for the custom operator,,,,,,,
mxnet.ndarray.op.LRN,data,Input data to LRN,Input data to LRN,,,,,,,
mxnet.ndarray.op.RNN,data,Input data to RNN,Input data to RNN,,,,,,,
mxnet.contrib.ndarray.count_sketch,data,Input data to the CountSketchOp.,Input data to the CountSketchOp,,,,,,,
mxnet.ndarray.contrib.count_sketch,data,Input data to the CountSketchOp.,Input data to the CountSketchOp,,,,,,,
mxnet.ndarray.contrib.fft,data,Input data to the FFTOp.,Input data to the FFTOp,,,,,,,
mxnet.ndarray.op.Pooling,data,Input data to the pooling operator.,Input data to the pooling operator,,,,,,,
mxnet.ndarray.contrib.ROIAlign,data,"Input data to the pooling operator, a 4D Feature maps",Input data to the pooling operator a CONSTANT_NUM D Feature maps,,,,,,,
mxnet.contrib.ndarray.ROIAlign,data,"Input data to the pooling operator, a 4D Feature maps",Input data to the pooling operator a CONSTANT_NUM D Feature maps,,,,,,,
mxnet.ndarray.op.SpatialTransformer,data,Input data to the SpatialTransformerOp.,Input data to the SpatialTransformerOp,,,,,,,
mxnet.contrib.onnx.export_model,input_type,Input data type e.g. np.float32,Input data type e g,,,,,,,
mxnet.ndarray.op.BilinearSampler,grid,"Input grid to the BilinearsamplerOp.grid has two channels: x_src, y_src",Input grid to the BilinearsamplerOp grid has two channels x_src y_src,,,,,,,
mxnet.image.random_size_crop,src,Input image,Input image,numeric,,,,,,
mxnet.ndarray.sparse.LinearRegressionOutput,label,Input label to the function.,Input label to the function,,,,,,,
mxnet.ndarray.sparse.LogisticRegressionOutput,label,Input label to the function.,Input label to the function,,,,,,,
mxnet.ndarray.op.LeakyReLU,gamma,Input data to activation function.,Input PARAM to activation function,,,,,,,
mxnet.autograd.grad,variables,Input variables to compute gradients for.,Input variables to compute gradients for,,,,,,,
mxnet.ndarray.ftml_update,v,Internal state `v_t`,Internal state QSTR,,,,,,,
mxnet.image.center_crop,interp,Interpolation method. See resize_short for details.,Interpolation method,,,,,,,
mxnet.image.CreateAugmenter,inter_method,"Interpolation method for all resizing operations Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). ",Interpolation method for all resizing operations Possible values CONSTANT_NUM Nearest Neighbors Interpolation,,,,,,,
mxnet.test_utils.var_check,generator,The generator function. It's expected to generate N i.i.d samples by calling generator(N).,It expected to generate N i i d samples by calling generator BSTR,,,,,,,
mxnet.ndarray.pad,pad_width,"Widths of the padding regions applied to the edges of each axis. It is a tuple of integer padding widths for each axis of the format `(before_1, after_1, ... , before_N, after_N)`. It should be of length `2*N` where `N` is the number of dimensions of the array.This is equivalent to pad_width in numpy.pad, but flattened.",It is a D_STRUCTURE of D_TYPE padding widths for each axis of the format BSTR,,,,,,,
mxnet.image.CreateAugmenter,inter_method,"Interpolation method for all resizing operations Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). ",It may be a preferred method for image decimation as it gives moire free results,,,,,,,
mxnet.ndarray.pad,pad_width,"Widths of the padding regions applied to the edges of each axis. It is a tuple of integer padding widths for each axis of the format `(before_1, after_1, ... , before_N, after_N)`. It should be of length `2*N` where `N` is the number of dimensions of the array.This is equivalent to pad_width in numpy.pad, but flattened.",It should be of length CONSTANT_NUM N QSTR N is the number of dimensions of the D_STRUCTURE This is equivalent to pad_width in numpy pad but flattened,,,,,1,,
mxnet.ndarray.contrib.MultiBoxDetection,nms_topk,"Keep maximum top k detections before nms, -1 for no limit.",Keep maximum top k detections before nms CONSTANT_NUM for no limit,,,,,,,
mxnet.contrib.quantization.quantize_model,label_names,Label names required for creating a Module object to run forward propagation on the calibration dataset.,Label names required for creating a Module object to run forward propagation on the calibration dataset,string,,,,,,
mxnet.ndarray.sample_exponential,lam,Lambda (rate) parameters of the distributions.,Lambda BSTR parameters of the distributions,,,,,,,
mxnet.ndarray.random_exponential,lam,Lambda parameter (rate) of the exponential distribution.,Lambda parameter BSTR of the exponential distribution,numeric,,,,,,
mxnet.ndarray.random.exponential_like,lam,Lambda parameter (rate) of the exponential distribution.,Lambda parameter BSTR of the exponential distribution,numeric,,,,,,
mxnet.ndarray.multi_lars,eps,LARS eps,LARS eps,,,,,,,
mxnet.ndarray.op.multi_lars,eta,LARS eta,LARS eta,,,,,,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,conv_layout,"Layout for all convolution inputs, outputs and weights. Options are 'NCW' and 'NWC'.",Layout for all convolution inputs outputs and weights,,,,,,,
mxnet.gluon.contrib.rnn.Conv1DLSTMCell,conv_layout,"Layout for all convolution inputs, outputs and weights. Options are 'NCW' and 'NWC'.",Layout for all convolution inputs outputs and weights,,,,,,,
mxnet.ndarray.rmspropalex_update,lr,Learning rate,Learning rate,numeric,,,,,"[0,1]",
mxnet.ndarray.sparse.adam_update,lr,Learning rate,Learning rate,numeric,,,,,"[0,1]",
mxnet.ndarray.op.rmsprop_update,lr,Learning rate,Learning rate,numeric,,,,,"[0,1]",
mxnet.ndarray.op.mp_lamb_update_phase2,lr,Learning rate,Learning rate,numeric,,,,,"[0,1]",
mxnet.ndarray.op.rmspropalex_update,lr,Learning rate,Learning rate,numeric,,,,,"[0,1]",
mxnet.ndarray.mp_sgd_mom_update,lr,Learning rate,Learning rate,numeric,,,,,"[0,1]",
mxnet.ndarray.multi_sgd_mom_update,lrs,Learning rates.,Learning rates,numeric,,,,,"[0,1]",
mxnet.ndarray.op.multi_sgd_update,lrs,Learning rates.,Learning rates,numeric,,,,,"[0,1]",
mxnet.ndarray.op.multi_lars,lrs,Learning rates to scale by LARS coefficient,Learning rates to scale by LARS coefficient,numeric,,,,,"[0,1]",
mxnet.ndarray.contrib.ctc_loss,data_lengths,Lengths of data for each of the samples. Only required when use_data_lengths is true.,Lengths of PARAM for each of the samples,int,,,,,"[0,inf)",
mxnet.ndarray.image.random_lighting,alpha_std,Level of the lighting noise.,Level of the lighting noise,D_TYPE,,,,CONSTANT_NUM,,
mxnet.gluon.model_zoo.vision.vgg19_bn,root,Location for keeping the model parameters.,Location for keeping the model parameters,,,,,,,
mxnet.gluon.model_zoo.vision.squeezenet1_1,root,Location for keeping the model parameters.,Location for keeping the model parameters,,,,,,,
mxnet.gluon.model_zoo.vision.resnet18_v1,root,Location for keeping the model parameters.,Location for keeping the model parameters,,,,,,,
mxnet.gluon.model_zoo.vision.vgg16_bn,root,Location for keeping the model parameters.,Location for keeping the model parameters,,,,,,,
mxnet.gluon.model_zoo.vision.resnet34_v1,root,Location for keeping the model parameters.,Location for keeping the model parameters,,,,,,,
mxnet.gluon.model_zoo.vision.get_mobilenet_v2,root,Location for keeping the model parameters.,Location for keeping the model parameters,,,,,,,
mxnet.io.ImageDetRecordIter,shuffle_chunk_size,"DD: long (non-negative), optional, default=0",long BSTR optional default CONSTANT_NUM,int64,,,,,,
mxnet.ndarray.op.Convolution,workspace,"DD: long (non-negative), optional, default=1024",long BSTR optional default CONSTANT_NUM,int64,,,,,,
mxnet.io.CSVIter,prefetch_buffer,"DD: long (non-negative), optional, default=4",long BSTR optional default CONSTANT_NUM,int64,,,,,,
mxnet.ndarray.op.Deconvolution,workspace,"DD: long (non-negative), optional, default=512",long BSTR optional default CONSTANT_NUM,int64,,,,,,
mxnet.ndarray.op.random_uniform,low,Lower bound of the distribution.,Lower bound of the distribution,,,,,,,
mxnet.ndarray.random_pdf_uniform,low,Lower bounds of the distributions.,Lower bounds of the distributions,,,,,,,
mxnet.ndarray.mp_lamb_update_phase2,lower_bound,"Lower limit of norm of weight. If lower_bound <= 0, Lower limit is not set",Lower limit of norm of PARAM,,,,,,,
mxnet.test_utils.download_model,meta_info,"Mapping from model_name to dict of the following structure: {'symbol': url, 'params': url}",Mapping from PARAM to D_STRUCTURE of the following structure QSTR url QSTR url,,,D_STRUCTURE,,,,
mxnet.ndarray.op.Correlation,max_displacement,Max displacement of Correlation,Max displacement of Correlation,,,,,,,
mxnet.ndarray.contrib.MultiBoxTarget,negative_mining_ratio,"Max negative to positive samples ratio, use -1 to disable mining",Max negative to positive samples ratio use CONSTANT_NUM to disable mining,numeric,,,,,,
mxnet.ndarray.RNN,lstm_state_clip_max,Maximum clip value of LSTM states. This option must be used together with lstm_state_clip_min.,Maximum clip value of LSTM states,,,,,,,
mxnet.gluon.contrib.nn.SparseEmbedding,input_dim,"Size of the vocabulary, i.e. maximum integer index + 1.",maximum D_TYPE index CONSTANT_NUM,D_TYPE,,,,,,
mxnet.ndarray.image.random_hue,max_factor,Maximum factor.,Maximum factor,numeric,,,,,,
mxnet.io.CSVIter,prefetch_buffer,Maximum number of batches to prefetch.,Maximum number of batches to prefetch,int,,,,0,"[0,inf)",
mxnet.ndarray.contrib.while_loop,max_iterations,Maximum number of iterations.,Maximum number of iterations,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.fft,compute_size,Maximum size of sub-batch to be forwarded at one time,Maximum size of sub batch to be forwarded at one time,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.ifft,compute_size,Maximum size of sub-batch to be forwarded at one time,Maximum size of sub batch to be forwarded at one time,int,,,,0,"[0,inf)",
mxnet.ndarray.op.Convolution,workspace,"Maximum temporary workspace allowed (MB) in convolution.This parameter has two usages. When CUDNN is not used, it determines the effective batch size of the convolution kernel. When CUDNN is used, it controls the maximum temporary storage used for tuning the best CUDNN kernel when limited_workspace strategy is used.",Maximum temporary workspace allowed BSTR in convolution This parameter has two usages,,,,,,,
mxnet.ndarray.op.Deconvolution,workspace,"Maximum temporary workspace allowed (MB) in deconvolution.This parameter has two usages. When CUDNN is not used, it determines the effective batch size of the deconvolution kernel. When CUDNN is used, it controls the maximum temporary storage used for tuning the best CUDNN kernel when limited_workspace strategy is used.",Maximum temporary workspace allowed BSTR in deconvolution This parameter has two usages,,,,,,,
mxnet.ndarray.op.clip,a_max,Maximum value,Maximum value,numeric,,,,,,
mxnet.contrib.ndarray.quantized_conv,max_bias,Maximum value of bias.,Maximum value of PARAM,numeric,,,,,,
mxnet.contrib.ndarray.quantized_pooling,max_data,Maximum value of data.,Maximum value of PARAM,numeric,,,,,,
mxnet.contrib.ndarray.quantized_fully_connected,max_data,Maximum value of data.,Maximum value of PARAM,numeric,,,,,,
mxnet.contrib.ndarray.quantized_conv,max_data,Maximum value of data.,Maximum value of PARAM,numeric,,,,,,
mxnet.contrib.ndarray.quantized_conv,max_weight,Maximum value of weight.,Maximum value of PARAM,numeric,,,,,,
mxnet.ndarray.random.randn,loc,Mean (centre) of the distribution.,Mean BSTR of the distribution,numeric,,,,,,
mxnet.ndarray.op.random_normal,loc,Mean of the distribution.,Mean of the distribution,numeric,,,,,,
mxnet.ndarray.random.generalized_negative_binomial_like,mu,Mean of the negative binomial distribution.,Mean of the negative binomial distribution,numeric,,,,,,
mxnet.ndarray.random_generalized_negative_binomial,mu,Mean of the negative binomial distribution.,Mean of the negative binomial distribution,numeric,,,,,,
mxnet.ndarray.random.generalized_negative_binomial,mu,Mean of the negative binomial distribution.,Mean of the negative binomial distribution,numeric,,,,,,
mxnet.image.CreateAugmenter,mean,"Mean pixel values for [r, g, b]",Mean pixel values for BSTR,numeric,,,,,,
mxnet.image.CreateDetAugmenter,mean,"Mean pixel values for [r, g, b]",Mean pixel values for BSTR,numeric,,,,,,
mxnet.ndarray.op.sample_normal,mu,Means of the distributions.,Means of the distributions,numeric,,,,,,
mxnet.ndarray.op.random_pdf_generalized_negative_binomial,mu,Means of the distributions.,Means of the distributions,numeric,,,,,,
mxnet.ndarray.op.random_pdf_normal,mu,Means of the distributions.,Means of the distributions,numeric,,,,,,
mxnet.ndarray.contrib.MultiProposal,rpn_min_size,Minimum height or width in proposal,Minimum height or width in proposal,numeric,,,,,,
mxnet.contrib.ndarray.Proposal,rpn_min_size,Minimum height or width in proposal,Minimum height or width in proposal,numeric,,,,,,
mxnet.ndarray.op.clip,a_min,Minimum value,Minimum value,numeric,,,,,,
mxnet.ndarray.contrib.quantized_fully_connected,min_bias,Minimum value of bias.,Minimum value of PARAM,numeric,,,,,,
mxnet.ndarray.contrib.quantized_pooling,min_data,Minimum value of data.,Minimum value of PARAM,numeric,,,,,,
mxnet.contrib.ndarray.quantized_batch_norm,min_data,Minimum value of data.,Minimum value of PARAM,numeric,,,,,,
mxnet.contrib.ndarray.quantized_conv,min_data,Minimum value of data.,Minimum value of PARAM,numeric,,,,,,
mxnet.ndarray.contrib.quantized_conv,min_data,Minimum value of data.,Minimum value of PARAM,numeric,,,,,,
mxnet.contrib.ndarray.quantized_conv,min_weight,Minimum value of weight.,Minimum value of PARAM,numeric,,,,,,
mxnet.contrib.onnx.export_model,onnx_file_path,DF: model.onnx,model onnx,,,,,,,
mxnet.ndarray.contrib.SyncBatchNorm,momentum,Momentum for moving average,Momentum for moving average,,,,,,,
mxnet.ndarray.op.BatchNorm,momentum,Momentum for moving average,Momentum for moving average,,,,,,,
mxnet.ndarray.adam_update,var,Moving variance,Moving variance,,,,,,,
mxnet.ndarray.Softmax,out_grad,Multiplies gradient with output gradient element-wise.,Multiplies gradient with output gradient element wise,,,,,,,
mxnet.ndarray.op.Softmax,out_grad,Multiplies gradient with output gradient element-wise.,Multiplies gradient with output gradient element wise,,,,,,,
mxnet.ndarray.SoftmaxOutput,out_grad,Multiplies gradient with output gradient element-wise.,Multiplies gradient with output gradient element wise,,,,,,,
mxnet.io.ImageRecordIter,scale,Multiply the image with a scale value.,Multiply the image with a scale value,,,,,,,
mxnet.ndarray.linalg_trmm,rightside,Multiply triangular matrix from the right to non-triangular one.,Multiply triangular matrix from the right to non triangular one,,,,,,,
mxnet.ndarray.linalg.gemm2,transpose_a,Multiply with transposed of first input (A).,Multiply with transposed of first input BSTR,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,input_shape,"Input tensor shape at each time step for each sample, excluding dimension of the batch size and sequence length. Must be consistent with conv_layout. For example, for layout 'NCHW' the shape should be (C, H, W).",Must be consistent with PARAM,,,,,,,
mxnet.ndarray.SequenceLast,data,"n-dimensional input array of the form [max_sequence_length, batch_size, other_feature_dims] where n>2",n dimensional input D_STRUCTURE of the form BSTR where n REXPR,,,D_STRUCTURE,BSTR,,,
mxnet.ndarray.op.SequenceLast,data,"n-dimensional input array of the form [max_sequence_length, batch_size, other_feature_dims] where n>2",n dimensional input D_STRUCTURE of the form BSTR where n REXPR,,,D_STRUCTURE,BSTR,,,
mxnet.log.get_logger,name,Name of the logger.,Name of the logger,string,,,,0,,
mxnet.ndarray.slice_like,axes,List of axes on which input data will be sliced according to the corresponding size of the second input. By default will slice on all axes. Negative axes are supported.,Negative axes are supported,,,,,,,
mxnet.ndarray.pick,axis,"int or None. The axis to picking the elements. Negative values means indexing from right to left. If is None, the elements in the index w.r.t the flattened input will be picked.",Negative values means indexing from right to left,,,,,,,
mxnet.ndarray.op.nansum,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",Negative values means indexing from right to left,,,,,,,
mxnet.ndarray.max_axis,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",Negative values means indexing from right to left,,,,,,,
mxnet.ndarray.min,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",Negative values means indexing from right to left,,,,,,,
mxnet.ndarray.op.max_axis,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",Negative values means indexing from right to left,,,,,,,
mxnet.ndarray.contrib.index_copy,new_tensor,New tensor to be copied,New D_STRUCTURE to be copied,,,D_STRUCTURE,,,,
mxnet.registry.get_create_func,nickname,nickname of base_class for logging,nickname of PARAM for logging,string,,,,0,,
mxnet.registry.get_register_func,nickname,nickname of base_class for logging,nickname of PARAM for logging,string,,,,0,,
mxnet.contrib.ndarray.Proposal,threshold,"NMS value, below which to suppress.",NMS value below which to suppress,,,,,,,
mxnet.ndarray.contrib.MultiBoxDetection,nms_threshold,Non-maximum suppression threshold.,Non maximum suppression PARAM,,,,,,,
mxnet.contrib.ndarray.MultiBoxDetection,nms_threshold,Non-maximum suppression threshold.,Non maximum suppression PARAM,,,,,,,
mxnet.test_utils.check_symbolic_backward,out_grads,DD: None or list of np.ndarray or dict of str to np.ndarray,None or D_STRUCTURE of np D_STRUCTURE of D_TYPE to np D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.test_utils.assert_almost_equal,rtol,DD: None or float,None or D_TYPE,D_TYPE,,,,,,
mxnet.ndarray.sparse.dot,forward_stype,"DD: {None, 'csr', 'default', 'row_sparse'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.batch_dot,forward_stype,"DD: {None, 'csr', 'default', 'row_sparse'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.contrib.ndarray.quantized_conv,cudnn_tune,"DD: {None, 'fastest', 'limited_workspace', 'off'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.Deconvolution,cudnn_tune,"DD: {None, 'fastest', 'limited_workspace', 'off'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.norm,out_dtype,"DD: {None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.softmin,dtype,"DD: {None, 'float16', 'float32', 'float64'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.softmax,dtype,"DD: {None, 'float16', 'float32', 'float64'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.softmax,dtype,"DD: {None, 'float16', 'float32', 'float64'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.log_softmax,dtype,"DD: {None, 'float16', 'float32', 'float64'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.log_softmax,dtype,"DD: {None, 'float16', 'float32', 'float64'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.Pooling,layout,"DD: {None, 'NCDHW', 'NCHW', 'NCW', 'NDHWC', 'NHWC', 'NWC'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.contrib.quantized_pooling,layout,"DD: {None, 'NCDHW', 'NCHW', 'NCW', 'NDHWC', 'NHWC', 'NWC'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.Softmax,normalization,Normalizes the gradient.,Normalizes the gradient,,,,,,,
mxnet.ndarray.split,squeeze_axis,"If true, Removes the axis with length 1 from the shapes of the output arrays. Note that setting squeeze_axis to `true` removes axis with length 1 only along the axis which it is split. Also squeeze_axis can be set to `true` only if `input.shape[axis] == num_outputs`.",Note that setting squeeze_axis to CONSTANT_BOOL removes PARAM with length CONSTANT_NUM only along the PARAM which it is split,,,,,,,
mxnet.ndarray.random.multinomial,dtype,Data type of the sample output array. The default is int32. Note that the data type of the log likelihood array is the same with that of data.,Note that the PARAM type of the log likelihood D_STRUCTURE is the same with that of PARAM,,,,,,,
mxnet.image.CreateAugmenter,inter_method,"Interpolation method for all resizing operations Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). ",Note When shrinking an image it will generally look best with AREA based interpolation whereas when enlarging an image it will generally look best with Bicubic BSTR,,,,,,,
mxnet.image.CreateAugmenter,mean,DD: np.ndarray or None,np D_STRUCTURE or None,,,D_STRUCTURE,,,,
mxnet.image.CreateDetAugmenter,mean,DD: np.ndarray or None,np D_STRUCTURE or None,,,D_STRUCTURE,,,,
mxnet.image.CreateDetAugmenter,max_attempts,"Number of attempts at generating a cropped/padded region of the image of the specified constraints. After max_attempts failures, return the original image.",Number of attempts at generating a cropped padded region of the image of the specified constraints,int,,,,0,"[0,inf)",
mxnet.gluon.nn.InstanceNorm,in_channels,"Number of channels (feature maps) in input data. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",Number of channels BSTR in input data,int,,,,0,"[0,inf)",
mxnet.gluon.nn.LayerNorm,in_channels,"Number of channels (feature maps) in input data. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",Number of channels BSTR in input data,int,,,,0,"[0,inf)",
mxnet.gluon.contrib.nn.SyncBatchNorm,in_channels,"Number of channels (feature maps) in input data. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",Number of channels BSTR in input data,int,,,,0,"[0,inf)",
mxnet.ndarray.contrib.DeformableConvolution,num_deformable_group,Number of deformable group partitions.,Number of deformable group partitions,int,,,,0,"[0,inf)",
mxnet.gluon.utils.split_data,num_slice,Number of desired slices.,Number of desired slices,int,,,,0,"[0,inf)",
mxnet.ndarray.op.Convolution,num_group,Number of group partitions.,Number of group partitions,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.quantized_conv,num_group,Number of group partitions.,Number of group partitions,int,,,,0,"[0,inf)",
mxnet.ndarray.sparse.FullyConnected,num_hidden,Number of hidden nodes of the output.,Number of hidden nodes of the output,int,,,,0,"[0,inf)",
mxnet.ndarray.FullyConnected,num_hidden,Number of hidden nodes of the output.,Number of hidden nodes of the output,int,,,,0,"[0,inf)",
mxnet.ndarray.op.multi_sum_sq,num_arrays,number of input arrays.,number of input D_STRUCTURE,int,,,,0,"[0,inf)",
mxnet.gluon.contrib.rnn.Conv1DGRUCell,hidden_channels,Number of output channels.,Number of output channels,int,,,,0,"[0,inf)",
mxnet.gluon.contrib.rnn.Conv3DRNNCell,hidden_channels,Number of output channels.,Number of output channels,int,,,,0,"[0,inf)",
mxnet.ndarray.Deconvolution,num_filter,Number of output filters.,Number of output filters,int,,,,0,"[0,inf)",
mxnet.ndarray.eye,N,Number of rows in the output.,Number of rows in the output,int,,,,0,"[0,inf)",
mxnet.ndarray.arange,repeat,Number of times to repeat each element. The default repeat count is 1.,Number of times to repeat each element,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.Proposal,rpn_post_nms_top_n,Number of top scoring boxes to keep after applying NMS to RPN proposals,Number of top scoring boxes to keep after applying NMS to RPN proposals,int,,,,0,"[0,inf)",
mxnet.ndarray.contrib.MultiProposal,rpn_post_nms_top_n,Number of top scoring boxes to keep after applying NMS to RPN proposals,Number of top scoring boxes to keep after applying NMS to RPN proposals,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.Proposal,rpn_pre_nms_top_n,Number of top scoring boxes to keep before applying NMS to RPN proposals,Number of top scoring boxes to keep before applying NMS to RPN proposals,int,,,,0,"[0,inf)",
mxnet.gluon.rnn.LSTMCell,hidden_size,Number of units in output symbol.,Number of units in output symbol,int,,,,0,"[0,inf)",
mxnet.ndarray.op.multi_sgd_update,num_weights,Number of updated weights.,Number of updated weights,int,,,,0,"[0,inf)",
mxnet.ndarray.preloaded_multi_mp_sgd_mom_update,num_weights,Number of updated weights.,Number of updated weights,int,,,,0,"[0,inf)",
mxnet.ndarray.preloaded_multi_mp_sgd_update,num_weights,Number of updated weights.,Number of updated weights,int,,,,0,"[0,inf)",
mxnet.ndarray.multi_mp_sgd_update,num_weights,Number of updated weights.,Number of updated weights,int,,,,0,"[0,inf)",
mxnet.ndarray.arange,step,"DD: number, optional",number optional,int,,,,0,"[0,inf)",
mxnet.gluon.model_zoo.vision.get_resnet,num_layers,"Numbers of layers. Options are 18, 34, 50, 101, 152.",Numbers of layers,int,,,,0,"[0,inf)",
mxnet.test_utils.check_symbolic_backward,out_grads,NumPys arrays corresponding to sym.outputs for incomming gradient.   if type is list of np.ndarrayContains arrays corresponding to `exe.outputs`.,NumPys D_STRUCTURE corresponding to PARAM outputs for incomming gradient,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_extracttrian,offset,"Offset of the diagonal versus the main diagonal. 0 corresponds to the main diagonal, a negative/positive value to diagonals below/above the main diagonal.",Offset of the diagonal versus the main diagonal,,,,,,,
mxnet.ndarray.linalg.maketrian,offset,"Offset of the diagonal versus the main diagonal. 0 corresponds to the main diagonal, a negative/positive value to diagonals below/above the main diagonal.",Offset of the diagonal versus the main diagonal,,,,,,,
mxnet.ndarray.op.linalg_maketrian,offset,"Offset of the diagonal versus the main diagonal. 0 corresponds to the main diagonal, a negative/positive value to diagonals below/above the main diagonal.",Offset of the diagonal versus the main diagonal,,,,,,,
mxnet.contrib.ndarray.index_copy,old_tensor,Old tensor,Old D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.image.CreateAugmenter,inter_method,"Interpolation method for all resizing operations Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). ",ONE_WORD BSTR,,,,,,,
mxnet.test_utils.simple_forward,ctx,DD: Context,ONE_WORD Context,,,,,,,
mxnet.contrib.quantization.quantize_model,ctx,DD: Context,ONE_WORD Context,,,,,,,
mxnet.contrib.quantization.quantize_net,ctx,DD: Context,ONE_WORD Context,,,,,,,
mxnet.ndarray.op.multi_all_finite,*data,Arrays,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.array,source_array,DD: array_like,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.quantization.quantize_model,aux_params,DD: dict,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.metric.create,**kwargs,DD: dict,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.metric.create,*args,DD: list,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.test_utils.verify_generator,probs,DD: list or tuple,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sample_negative_binomial,p,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_conv,max_bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.gluon.utils.split_data,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.adam_update,var,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.lamb_update_phase2,r1,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.Embedding,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.RROIAlign,rois,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sort,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sample_normal,mu,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_hypot,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.identity,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.ROIAlign,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.max,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.FullyConnected,bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.image.random_hue,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.index_copy,new_tensor,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.LeakyReLU,gamma,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.BilinearSampler,grid,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_pdf_uniform,high,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.random.multinomial,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_axis,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.signsgd_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.broadcast_minus,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_pooling,min_data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantize,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_lesser,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.mp_nag_mom_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.random_pdf_poisson,sample,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.max,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.box_encode,matches,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_conv,min_weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.SequenceLast,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sample_generalized_negative_binomial,alpha,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.ROIAlign,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.syrk,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.adam_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.degrees,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.index_copy,index_vector,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.elemwise_div,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.arccos,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.gather_nd,indices,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.make_loss,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_logical_and,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_minus,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.MultiProposal,cls_prob,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_logical_and,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.Proposal,bbox_pred,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_pdf_generalized_negative_binomial,mu,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.count_sketch,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_conv,max_weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_equal,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.gamma,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.stop_gradient,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sgd_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sample_uniform,high,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_not_equal,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.size_array,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.dgl_adjacency,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.argmax_channel,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sum,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.random_pdf_uniform,low,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.flatten,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.cbrt,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.image.flip_top_bottom,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.pick,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_pdf_negative_binomial,sample,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.det,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.FullyConnected,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.DeformableConvolution,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.FullyConnected,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.SequenceLast,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sgd_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.bipartite_matching,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.argmin,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.degrees,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.Deconvolution,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_batch_norm,min_data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.tan,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.squeeze,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_potrf,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.allclose,a,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_trsm,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.potri,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.image.resize,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_conv,min_data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.hawkesll,lda,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.image.random_size_crop,src,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.LinearRegressionOutput,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.mp_nag_mom_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.signsgd_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.image.resize_short,src,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.L2Normalization,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.dequantize,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.arctan,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.LRN,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_mul,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.MultiProposal,im_info,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.mp_lamb_update_phase2,weight32,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_plus,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.RNN,state,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.batch_dot,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.arccosh,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_minimum,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_greater,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.argsort,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.BlockGrad,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.InstanceNorm,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.dot,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.make_loss,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.SoftmaxOutput,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.cos,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.edge_id,v,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.gamma,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.hawkesll,alpha,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.SequenceLast,sequence_length,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.expm1,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_conv,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.count_sketch,s,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_pdf_normal,mu,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.Softmax,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.mp_lamb_update_phase1,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.negative,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.ceil,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.lamb_update_phase2,g,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.arccosh,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.depth_to_space,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_pooling,max_data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_fully_connected,max_data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.SwapAxis,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.RNN,parameters,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.signsgd_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_conv,min_data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.SyncBatchNorm,moving_var,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.InstanceNorm,beta,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.edge_id,u,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.floor,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.random_pdf_generalized_negative_binomial,sample,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.DeformableConvolution,bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.rint,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_not_equal,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.Deconvolution,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.negative,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.count_sketch,s,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.slice_axis,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.adam_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.SpatialTransformer,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.RNN,state_cell,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_conv,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.ctc_loss,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_pooling,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.allclose,b,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_minimum,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.random.randn,out,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_greater,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.erfinv,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.elemwise_add,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sgd_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.Pooling,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.gammaln,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_logical_or,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.image.imresize,src,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.rint,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_logical_xor,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.fft,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_makediag,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.dot,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.take,indices,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.ctc_loss,data_lengths,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.makediag,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.log1p,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.getnnz,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.rmspropalex_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_slogdet,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.reshape_like,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_makediag,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_conv,max_data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.BatchNorm,moving_mean,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.radians,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.interleaved_matmul_selfatt_valatt,queries_keys_values,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_lesser,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.cumsum,a,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.backward_gradientmultiplier,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.log1p,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_like,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quadratic,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.broadcast_plus,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.LogisticRegressionOutput,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.SVMOutput,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sample_exponential,lam,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sum_axis,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_plus,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_mul,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.GroupNorm,gamma,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.InstanceNorm,beta,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.max_axis,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.adam_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.hawkesll,marks,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.ftml_update,v,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.multi_lars,lrs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.rsqrt,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.SwapAxis,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sort,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.index_array,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.ctc_loss,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.ftrl_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.RNN,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_gemm,B,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_equal,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.image.random_color_jitter,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sinh,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.Embedding,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.sgd_mom_update,mom,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_trmm,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.round_ste,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_logical_xor,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_flatten,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.ceil,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.gemm2,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.ones_like,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.InstanceNorm,gamma,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.split,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.index_copy,old_tensor,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_flatten,max_data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_power,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_mod,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.slogdet,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.div_sqrt_dim,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantize_v2,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.sign_ste,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.BilinearResize2D,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quadratic,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_mod,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_fully_connected,min_bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.slice,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.count_sketch,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.box_non_maximum_suppression,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.gluon.utils.split_and_load,data,DD: NDArray or ndarray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.Custom,*data,DD: NDArray[],ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.multi_sgd_mom_update,*data,DD: NDArray[],ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.preloaded_multi_mp_sgd_mom_update,*data,DD: NDArray[],ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.preloaded_multi_sgd_mom_update,*data,DD: NDArray[],ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.stack,*data,DD: NDArray[],ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.multi_sgd_mom_update,*data,DD: NDArray[],ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.multi_all_finite,*data,DD: NDArray[],ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.util.np_shape,active,DD: bool,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.callback.log_train_metric,auto_reset,DD: bool,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.nn.Embedding,sparse_grad,DD: bool,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.autograd.grad,retain_graph,DD: bool,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.contrib.onnx.export_model,verbose,DD: Boolean,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.profiler.dumps,ascending,DD: boolean,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.profiler.set_config,aggregate_stats,"DD: boolean,",ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.image.CreateDetAugmenter,min_object_covered,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.image.CreateAugmenter,hue,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.ndarray.op.smooth_l1,scalar,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.image.CreateAugmenter,rand_gray,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.image.CreateAugmenter,brightness,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.image.CreateDetAugmenter,pca_noise,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.nn.ELU,alpha,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.image.CreateDetAugmenter,brightness,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.image.CreateDetAugmenter,min_eject_coverage,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.test_utils.verify_generator,nrepeat,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.model_zoo.vision.get_resnet,num_layers,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.nn.Conv2DTranspose,groups,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.rnn.LSTMCell,hidden_size,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.utils.split_data,num_slice,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.image.CreateDetAugmenter,max_attempts,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.rnn.GRU,hidden_size,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.nn.Conv1D,channels,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.test_utils.chi_square_check,nsamples,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv1DGRUCell,hidden_channels,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.contrib.nn.SparseEmbedding,input_dim,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv3DRNNCell,hidden_channels,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.image.CreateDetAugmenter,resize,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.ndarray.eye,N,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.recordio.unpack_img,s,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.model.load_checkpoint,prefix,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.test_utils.get_zip_data,url,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.contrib.quantization.quantize_net,calib_mode,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.nn.Conv3DTranspose,activation,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.test_utils.get_zip_data,data_dir,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.registry.get_create_func,nickname,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.registry.get_register_func,nickname,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.contrib.onnx.import_model,model_file,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.ndarray.load_frombuffer,buf,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.operator.get_operator_arguments,op_name,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.util.np_ufunc_legal_option,value,DD: string,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.util.np_ufunc_legal_option,key,DD: string,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.contrib.onnx.export_model,input_type,Input data type e.g. np.float32,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.contrib.quantization.quantize_model,calib_data,DD: DataIter,ONE_WORD DataIter,,,,,,,
mxnet.ndarray.arange,infer_range,"Infer the stop position from the start, step, repeat, and output tensor size. Deprecated. Only False is supported.",ONE_WORD Deprecated,,,,,,,
mxnet.test_utils.var_check,generator,DD: function,ONE_WORD function,,,,,,,
mxnet.test_utils.verify_generator,generator,DD: function,ONE_WORD function,,,,,,,
mxnet.ndarray.op.signsgd_update,grad,Gradient,ONE_WORD Gradient,,,,,,,
mxnet.ndarray.sgd_update,grad,Gradient,ONE_WORD Gradient,,,,,,,
mxnet.ndarray.signsgd_update,grad,Gradient,ONE_WORD Gradient,,,,,,,
mxnet.ndarray.adam_update,grad,Gradient,ONE_WORD Gradient,,,,,,,
mxnet.ndarray.op.sgd_update,grad,Gradient,ONE_WORD Gradient,,,,,,,
mxnet.ndarray.rmspropalex_update,grad,Gradient,ONE_WORD Gradient,,,,,,,
mxnet.ndarray.sparse.adam_update,grad,Gradient,ONE_WORD Gradient,,,,,,,
mxnet.ndarray.sparse.ftrl_update,grad,Gradient,ONE_WORD Gradient,,,,,,,
mxnet.ndarray.gather_nd,indices,indices,ONE_WORD index,int,,,,,,
mxnet.contrib.ndarray.getnnz,data,Input,ONE_WORD Input,,,,,,,
mxnet.ndarray.linspace,start,DD: number,ONE_WORD number,numeric,,,,,,
mxnet.contrib.quantization.quantize_model,logger,DD: Object,ONE_WORD Object,,,,,,,
mxnet.ndarray.sparse.sgd_mom_update,mom,Momentum,ONE_WORD PARAM,,,,,,,
mxnet.ndarray.op.lamb_update_phase2,r1,r1,ONE_WORD r1,,,,,,,
mxnet.gluon.rnn.BidirectionalCell,r_cell,DD: RecurrentCell,ONE_WORD RecurrentCell,,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,trans,DD: Symbol,ONE_WORD Symbol,,,,,,,
mxnet.ndarray.op.mp_nag_mom_update,weight,Weight,ONE_WORD Weight,numeric,,,,,,
mxnet.ndarray.op.adam_update,weight,Weight,ONE_WORD Weight,numeric,,,,,,
mxnet.ndarray.op.sgd_update,weight,Weight,ONE_WORD Weight,numeric,,,,,,
mxnet.ndarray.mp_nag_mom_update,weight,Weight,ONE_WORD Weight,numeric,,,,,,
mxnet.ndarray.op.signsgd_update,weight,Weight,ONE_WORD Weight,numeric,,,,,,
mxnet.ndarray.mp_lamb_update_phase1,weight,Weight,ONE_WORD Weight,numeric,,,,,,
mxnet.ndarray.contrib.quantized_conv,weight,weight.,ONE_WORD weight,numeric,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase2,weight32,Weight32,ONE_WORD Weight32,numeric,,,,,,
mxnet.ndarray.arange,infer_range,"Infer the stop position from the start, step, repeat, and output tensor size. Deprecated. Only False is supported.",Only CONSTANT_BOOL is supported,bool,,,,0,,CONSTANT_BOOL
mxnet.ndarray.op.SequenceReverse,axis,The sequence axis. Only 0 is currently supported.,Only CONSTANT_NUM is currently supported,,,,,,,CONSTANT_NUM
mxnet.gluon.contrib.rnn.Conv3DRNNCell,h2h_kernel,Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.,Only odd numbered sizes are supported,,,,,,,
mxnet.ndarray.linalg_extracttrian,lower,"Refer to the lower triangular matrix if lower=true, refer to the upper otherwise. Only relevant when offset=0",Only relevant when PARAM CONSTANT_NUM,,,,,,,
mxnet.ndarray.contrib.ctc_loss,data_lengths,Lengths of data for each of the samples. Only required when use_data_lengths is true.,Only required when PARAM is CONSTANT_BOOL,,,,,,,
mxnet.gluon.nn.Conv2DTranspose,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",Only supports QSTR layout for now,,,,,,,QSTR
mxnet.gluon.nn.Conv1DTranspose,layout,"Dimension ordering of data and weight. Only supports 'NCW' layout for now. 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Convolution is applied on the 'W' dimension.",Only supports QSTR layout for now,,,,,,,QSTR
mxnet.gluon.nn.Conv1D,layout,"Dimension ordering of data and weight. Only supports 'NCW' layout for now. 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Convolution is applied on the 'W' dimension.",Only supports QSTR layout for now,,,,,,,QSTR
mxnet.ndarray.op.Pooling,count_include_pad,"Only used for AvgPool, specify whether to count padding elements for averagecalculation. For example, with a 5*5 kernel on a 3*3 corner of a image,the sum of the 9 valid elements will be divided by 25 if this is set to true,or it will be divided by 9 if this is set to false. Defaults to true.",Only used for AvgPool specify whether to count padding elements for averagecalculation,,,,,,,
mxnet.contrib.ndarray.quantized_pooling,count_include_pad,"Only used for AvgPool, specify whether to count padding elements for averagecalculation. For example, with a 5*5 kernel on a 3*3 corner of a image,the sum of the 9 valid elements will be divided by 25 if this is set to true,or it will be divided by 9 if this is set to false. Defaults to true.",Only used for AvgPool specify whether to count padding elements for averagecalculation,,,,,,,
mxnet.ndarray.contrib.quantized_pooling,count_include_pad,"Only used for AvgPool, specify whether to count padding elements for averagecalculation. For example, with a 5*5 kernel on a 3*3 corner of a image,the sum of the 9 valid elements will be divided by 25 if this is set to true,or it will be divided by 9 if this is set to false. Defaults to true.",Only used for AvgPool specify whether to count padding elements for averagecalculation,,,,,,,
mxnet.ndarray.op.random_randint,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls.",Only used for imperative calls,,,,,,,
mxnet.ndarray.op.random_generalized_negative_binomial,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls.",Only used for imperative calls,,,,,,,
mxnet.ndarray.random_uniform,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls.",Only used for imperative calls,,,,,,,
mxnet.metric.create,**kwargs,Additional arguments to metric constructor. Only used when metric is str,Only used when PARAM is D_TYPE,,,,,,,
mxnet.metric.create,*args,Additional arguments to metric constructor. Only used when metric is str.,Only used when PARAM is D_TYPE,,,,,,,
mxnet.ndarray.op.SequenceMask,axis,The sequence axis. Only values of 0 and 1 are currently supported.,Only values of CONSTANT_NUM are currently supported,,,,,,,CONSTANT_NUM
mxnet.contrib.onnx.import_model,model_file,ONNX model file name,ONNX model file name,string,,,,0,,
mxnet.contrib.ndarray.box_nms,background_id,"Optional, id of the background class which will be ignored in nms.",Optional id of the background class which will be ignored in nms,int,,,,0,"[0,inf)",
mxnet.ndarray.contrib.box_non_maximum_suppression,force_suppress,"Optional, if set false and id_index is provided, nms will only apply to boxes belongs to the same category",Optional if set CONSTANT_BOOL and PARAM is provided nms will only apply to boxes belongs to the same category,bool,,,,0,,
mxnet.ndarray.contrib.box_nms,force_suppress,"Optional, if set false and id_index is provided, nms will only apply to boxes belongs to the same category",Optional if set CONSTANT_BOOL and PARAM is provided nms will only apply to boxes belongs to the same category,bool,,,,0,,
mxnet.gluon.model_zoo.vision.get_resnet,num_layers,"Numbers of layers. Options are 18, 34, 50, 101, 152.",Options are CONSTANT_NUM,,,,,,,CONSTANT_NUM
mxnet.gluon.contrib.rnn.Conv1DRNNCell,conv_layout,"Layout for all convolution inputs, outputs and weights. Options are 'NCW' and 'NWC'.",Options are QSTR,,,,,,,QSTR
mxnet.gluon.contrib.rnn.Conv1DLSTMCell,conv_layout,"Layout for all convolution inputs, outputs and weights. Options are 'NCW' and 'NWC'.",Options are QSTR,,,,,,,QSTR
mxnet.ndarray.norm,ord,Order of the norm. Currently ord=1 and ord=2 is supported.,Order of the norm,,,,,,,
mxnet.ndarray.moveaxis,source,Original position of the axes to move. Can be negative but must be unique.,Original position of the axes to move,,,,,,,
mxnet.ndarray.contrib.SyncBatchNorm,output_mean_var,"Output All,normal mean and var",Output All normal mean and var,,,,,,,
mxnet.test_utils.download,dirname,"output directory name. If None, then guess from fname or use the current directory",output directory name,string,,,,0,,
mxnet.ndarray.op.lamb_update_phase2,g,Output of lamb_update_phase 1,Output of lamb_update_phase CONSTANT_NUM,,,,,,,
mxnet.ndarray.op.amp_cast,dtype,Output data type.,Output PARAM type,numpy.dtype,,,,,,
mxnet.ndarray.contrib.quantize,out_type,Output data type.,Output PARAM type,numpy.dtype,,,,,,
mxnet.ndarray.op.GroupNorm,output_mean_var,Output the mean and std calculated along the given axis.,Output the mean and std calculated along the given axis,,,,,,,
mxnet.ndarray.op.LayerNorm,output_mean_var,Output the mean and std calculated along the given axis.,Output the mean and std calculated along the given PARAM,,,,,,,
mxnet.contrib.ndarray.box_nms,overlap_thresh,Overlapping(IoU) threshold to suppress object with smaller score.,Overlapping BSTR threshold to suppress object with smaller score,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,i2h_pad,Pad for input convolution.,Pad for input convolution,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DLSTMCell,i2h_pad,Pad for input convolution.,Pad for input convolution,,,,,,,
mxnet.ndarray.op.Pooling,pad,"Pad for pooling: (y, x) or (d, y, x). Defaults to no padding.",Pad for pooling BSTR,,,,BSTR,,,
mxnet.io.ImageDetRecordIter,label_pad_width,"pad output label width if set larger than 0, -1 for auto estimate",pad output label width if set larger than CONSTANT_NUM for auto estimate,,,,,,,
mxnet.ndarray.op.pad,mode,"Padding type to use. ""constant"" pads with CONSTANT_NUMue ""edge"" pads using the edge values of the input array ""reflect"" pads by reflecting values with respect to the edges.",Padding type to use,,,,,,,
mxnet.ndarray.sparse.adagrad_update,wd,weight decay,PARAM decay,numeric,,,,,,
mxnet.ndarray.op.nag_mom_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,PARAM decay augments the objective function with a regularization term that penalizes large weights,numeric,,,,,,
mxnet.ndarray.ftml_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,PARAM decay augments the objective function with a regularization term that penalizes large weights,numeric,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase1,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,PARAM decay augments the objective function with a regularization term that penalizes large weights,numeric,,,,,,
mxnet.ndarray.nag_mom_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,PARAM decay augments the objective function with a regularization term that penalizes large weights,numeric,,,,,,
mxnet.ndarray.op.sgd_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,PARAM decay augments the objective function with a regularization term that penalizes large weights,numeric,,,,,,
mxnet.ndarray.contrib.MultiBoxTarget,overlap_threshold,Anchor-GT overlap threshold to be regarded as a positive match.,PARAM GT overlap threshold to be regarded as a positive match,,,,,,,
mxnet.gluon.nn.AvgPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. padding is applied on 'W' dimension.",PARAM is applied on QSTR dimension,,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase1,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",PARAM max BSTR,,,,,,,
mxnet.ndarray.op.signum_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",PARAM max BSTR,,,,,,,
mxnet.ndarray.ftml_update,clip_grad,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",PARAM max BSTR,,,,,,,
mxnet.ndarray.mp_sgd_mom_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",PARAM max BSTR,,,,,,,
mxnet.contrib.ndarray.group_adagrad_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",PARAM max BSTR,,,,,,,
mxnet.contrib.ndarray.BilinearResize2D,mode,"DD: {'like', 'odd_scale', 'size', 'to_even_down', 'to_even_up', 'to_odd_down', 'to_odd_up'},optional, default='size'",PARAM QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.Embedding,dtype,Data type of weight.,PARAM type of PARAM,numpy.dtype,,,,0,,
mxnet.ndarray.random.multinomial,dtype,Data type of the sample output array. The default is int32. Note that the data type of the log likelihood array is the same with that of data.,PARAM type of the sample output D_STRUCTURE,numpy.dtype,,,,0,,
mxnet.gluon.rnn.RNNCell,params,DD: Parameter or None,Parameter or None,,,,,,,
mxnet.gluon.rnn.LSTMCell,params,"DD: Parameter or None, default None",Parameter or None default None,,,,,,,
mxnet.gluon.rnn.GRUCell,params,"DD: Parameter or None, default None",Parameter or None default None,,,,,,,
mxnet.io.LibSVMIter,num_parts,partition the data into multiple parts,partition the data into multiple parts,,,,,,,
mxnet.image.CreateDetAugmenter,pca_noise,Pca noise level (percent),Pca noise level BSTR,,,,,,,
mxnet.ndarray.op.ftrl_update,beta,Per-Coordinate Learning Rate beta.,Per Coordinate Learning Rate beta,,,,,,,
mxnet.ndarray.Pooling,pooling_convention,Pooling convention to be applied.,Pooling convention to be applied,,,,,,,
mxnet.gluon.nn.GlobalMaxPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Pooling is applied on the W dimension.",Pooling is applied on the W dimension,,,,,,,
mxnet.contrib.ndarray.quantized_pooling,pool_type,Pooling type to be applied.,Pooling type to be applied,,,,,,,
mxnet.model.load_checkpoint,prefix,Prefix of model name.,Prefix of model name,string,,,,0,,
mxnet.ndarray.contrib.MultiBoxPrior,offsets,"Priorbox center offsets, y and x respectively",Priorbox center offsets y and x respectively,,,,,,,
mxnet.ndarray.contrib.MultiBoxPrior,steps,"Priorbox step across y and x, -1 for auto calculation.",Priorbox step across y and x CONSTANT_NUM for auto calculation,,,,,,,
mxnet.contrib.ndarray.MultiBoxPrior,steps,"Priorbox step across y and x, -1 for auto calculation.",Priorbox step across y and x CONSTANT_NUM for auto calculation,,,,,,,
mxnet.ndarray.moments,keepdims,produce moments with the same dimensionality as the input.,produce moments with the same dimensionality as the input,,,,,,,
mxnet.ndarray.op.moments,keepdims,produce moments with the same dimensionality as the input.,produce moments with the same dimensionality as the input,,,,,,,
mxnet.contrib.ndarray.ROIAlign,position_sensitive,"Whether to perform position-sensitive RoI pooling. PSRoIPooling is first proposaled by R-FCN and it can reduce the input channels by ph*pw times, where (ph, pw) is the pooled_size",PSRoIPooling is first proposaled by R FCN and it can reduce the input channels by ph pw times where BSTR is the PARAM,,,,,,,
mxnet.gluon.nn.Conv3DTranspose,activation,"Activation function to use. See `Activation()`. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",QSTR activation a BSTR x,,,,,,,
mxnet.ndarray.contrib.box_nms,in_format,"The input box encoding type. ""corner"" means boxes are encoded as [xmin, ymin, xmax, ymax], ""center"" means boxes are encodes as [x, y, width, height].",QSTR means boxes are encoded as BSTR QSTR means boxes are encodes as BSTR,,,,,,,QSTR
mxnet.contrib.ndarray.box_non_maximum_suppression,in_format,"The input box encoding type. ""corner"" means boxes are encoded as [xmin, ymin, xmax, ymax], ""center"" means boxes are encodes as [x, y, width, height].",QSTR means boxes are encoded as BSTR QSTR means boxes are encodes as BSTR,,,,,,,QSTR
mxnet.contrib.ndarray.box_nms,out_format,"The output box encoding type. ""corner"" means boxes are encoded as [xmin, ymin, xmax, ymax], ""center"" means boxes are encodes as [x, y, width, height].",QSTR means boxes are encoded as BSTR QSTR means boxes are encodes as BSTR,,,,,,,QSTR
mxnet.ndarray.op.Dropout,mode,"DD: {'always', 'training'},optional, default='training'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.contrib.ndarray.quantized_pooling,pool_type,"DD: {'avg', 'lp', 'max', 'sum'},optional, default='max'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.Softmax,normalization,"DD: {'batch', 'null', 'valid'},optional, default='null'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.MakeLoss,normalization,"DD: {'batch', 'null', 'valid'},optional, default='null'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.MakeLoss,normalization,"DD: {'batch', 'null', 'valid'},optional, default='null'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.contrib.ndarray.box_nms,out_format,"DD: {'center', 'corner'},optional, default='corner'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.contrib.box_nms,in_format,"DD: {'center', 'corner'},optional, default='corner'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.contrib.ndarray.box_non_maximum_suppression,in_format,"DD: {'center', 'corner'},optional, default='corner'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.UpSampling,multi_input_mode,"DD: {'concat', 'sum'},optional, default='concat'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.LeakyReLU,act_type,"DD: {'elu', 'gelu', 'leaky', 'prelu', 'rrelu', 'selu'},optional, default='leaky'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.contrib.ndarray.CTCLoss,blank_label,"DD: {'first', 'last'},optional, default='first'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.one_hot,dtype,"DD: {'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='float32'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.Embedding,dtype,"DD: {'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='float32'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.Pooling,pooling_convention,"DD: {'full', 'same', 'valid'},optional, default='valid'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.contrib.quantize,out_type,"DD: {'int8', 'uint8'},optional, default='uint8'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.sample_gamma,dtype,"DD: {'None', 'float16', 'float32', 'float64'},optional, default='None'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.random_uniform,dtype,"DD: {'None', 'float16', 'float32', 'float64'},optional, default='None'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.sample_generalized_negative_binomial,dtype,"DD: {'None', 'float16', 'float32', 'float64'},optional, default='None'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.random_gamma,dtype,"DD: {'None', 'float16', 'float32', 'float64'},optional, default='None'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.random_normal,dtype,"DD: {'None', 'float16', 'float32', 'float64'},optional, default='None'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.contrib.ndarray.BilinearResize2D,mode,"resizing mode. ""simple"" - output height equals parameter ""height"" if ""scale_height"" parameter is not defined or input height multiplied by ""scale_height"" otherwise. Same for width;""odd_scale"" - if original height or width is odd, then result height is calculated like result_h = (original_h - 1) * scale + 1; for scale > 1 the result shape would be like if we did deconvolution with kernel = (1, 1) and stride = (height_scale, width_scale); and for scale < 1 shape would be like we did convolution with kernel = (1, 1) and stride = (int(1 / height_scale), int( 1/ width_scale);""like"" - resize first input to the height and width of second input; ""to_even_down"" - resize input to nearest lower even height and width (if original height is odd then result height = original height - 1);""to_even_up"" - resize input to nearest bigger even height and width (if original height is odd then result height = original height + 1);""to_odd_down"" - resize input to nearest odd height and width (if original height is odd then result height = original height - 1);""to_odd_up"" - resize input to nearest odd height and width (if original height is odd then result height = original height + 1);",QSTR output PARAM equals parameter PARAM if PARAM parameter is not defined or input PARAM multiplied by PARAM otherwise,,,,,,,
mxnet.ndarray.op.pad,mode,"Padding type to use. ""constant"" pads with CONSTANT_NUMue ""edge"" pads using the edge values of the input array ""reflect"" pads by reflecting values with respect to the edges.",QSTR pads with PARAM QSTR pads using the edge values of the input D_STRUCTURE QSTR pads by reflecting values with respect to the edges,,,,,,,
mxnet.ndarray.op.pad,mode,"DD: {'constant', 'edge', 'reflect'}, required",QSTR required,,,,,,,QSTR
mxnet.ndarray.op.amp_cast,dtype,"DD: {'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'}, required",QSTR required,,,,,,,QSTR
mxnet.ndarray.op.RNN,mode,"DD: {'gru', 'lstm', 'rnn_relu', 'rnn_tanh'}, required",QSTR required,,,,,,,QSTR
mxnet.gluon.nn.AvgPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. padding is applied on 'W' dimension.",QSTR stands for batch channel and width BSTR dimensions respectively,,,,,,,
mxnet.gluon.nn.GlobalMaxPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Pooling is applied on the W dimension.",QSTR stands for batch channel and width BSTR dimensions respectively,,,,,,,
mxnet.gluon.nn.Conv1DTranspose,layout,"Dimension ordering of data and weight. Only supports 'NCW' layout for now. 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Convolution is applied on the 'W' dimension.",QSTR stands for batch channel and width BSTR dimensions respectively,,,,,,,
mxnet.gluon.nn.Conv1D,layout,"Dimension ordering of data and weight. Only supports 'NCW' layout for now. 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Convolution is applied on the 'W' dimension.",QSTR stands for batch channel and width BSTR dimensions respectively,,,,,,,
mxnet.gluon.nn.GlobalAvgPool2D,layout,"Dimension ordering of data and out ('NCHW' or 'NHWC'). 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively.",QSTR stands for batch channel height and width dimensions respectively,,,,,,,
mxnet.gluon.nn.Conv2DTranspose,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",QSTR stands for batch channel height and width dimensions respectively,,,,,,,
mxnet.test_utils.check_speed,typ,"""whole"" or ""forward""   ""whole""Test the forward_backward speed.   ",QSTR Test the forward_backward speed,,,,,,,QSTR
mxnet.ndarray.contrib.interleaved_matmul_selfatt_valatt,queries_keys_values,"Queries, keys and values interleaved",Queries keys and values interleaved,,,,,,,
mxnet.ndarray.contrib.PSROIPooling,spatial_scale,Ratio of input feature map height (or w) to raw image height (or w). Equals the reciprocal of total stride in convolutional layers,Ratio of input feature map height BSTR,numeric,,,,,,
mxnet.gluon.contrib.rnn.Conv2DRNNCell,h2h_dilate,Recurrent convolution dilate.,Recurrent convolution dilate,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,h2h_dilate,Recurrent convolution dilate.,Recurrent convolution dilate,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,h2h_dilate,Recurrent convolution dilate.,Recurrent convolution dilate,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DRNNCell,h2h_kernel,Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.,Recurrent convolution kernel sizes,int,,,,,"[0,inf)",
mxnet.ndarray.linalg_extracttrian,lower,"Refer to the lower triangular matrix if lower=true, refer to the upper otherwise. Only relevant when offset=0",Refer to the lower triangular matrix if lower CONSTANT_BOOL refer to the upper otherwise,,,,,,,
mxnet.test_utils.check_speed,N,Repeat times.,Repeat times,int,,,,0,"[0,inf)",
mxnet.ndarray.op.multi_sgd_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to grad rescale_grad grad,,,,,,,
mxnet.ndarray.preloaded_multi_sgd_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to grad rescale_grad grad,,,,,,,
mxnet.ndarray.op.multi_sgd_mom_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to grad rescale_grad grad,,,,,,,
mxnet.ndarray.preloaded_multi_sgd_mom_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to grad rescale_grad grad,,,,,,,
mxnet.ndarray.op.multi_mp_sgd_mom_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to grad rescale_grad grad,,,,,,,
mxnet.ndarray.multi_sgd_mom_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to grad rescale_grad grad,,,,,,,
mxnet.ndarray.op.sgd_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.ndarray.op.signum_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.ndarray.mp_nag_mom_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.ndarray.op.adam_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.ndarray.sparse.ftrl_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.contrib.ndarray.group_adagrad_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.ndarray.mp_sgd_mom_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.ndarray.rmspropalex_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.ndarray.sparse.adagrad_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.callback.log_train_metric,auto_reset,Reset the metric after each log.,Reset the metric after each log,,,,,,,
mxnet.image.CreateDetAugmenter,resize,Resize shorter edge if larger than 0 at the begining,Resize shorter edge if larger than CONSTANT_NUM at the begining,,,,,,,
mxnet.contrib.ndarray.BilinearResize2D,mode,"resizing mode. ""simple"" - output height equals parameter ""height"" if ""scale_height"" parameter is not defined or input height multiplied by ""scale_height"" otherwise. Same for width;""odd_scale"" - if original height or width is odd, then result height is calculated like result_h = (original_h - 1) * scale + 1; for scale > 1 the result shape would be like if we did deconvolution with kernel = (1, 1) and stride = (height_scale, width_scale); and for scale < 1 shape would be like we did convolution with kernel = (1, 1) and stride = (int(1 / height_scale), int( 1/ width_scale);""like"" - resize first input to the height and width of second input; ""to_even_down"" - resize input to nearest lower even height and width (if original height is odd then result height = original height - 1);""to_even_up"" - resize input to nearest bigger even height and width (if original height is odd then result height = original height + 1);""to_odd_down"" - resize input to nearest odd height and width (if original height is odd then result height = original height - 1);""to_odd_up"" - resize input to nearest odd height and width (if original height is odd then result height = original height + 1);",resizing mode,,,,,,,
mxnet.contrib.quantization.quantize_model,logger,DF: <moduleloggingfrom/work/conda_env/lib/python3.8/logging/__init__.py>,REXPR work conda_env lib python3 CONSTANT_NUM logging init py,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,params,"DD: RNNParams, default None",RNNParams default None,,,,,,,
mxnet.ndarray.ROIPooling,pooled_size,"ROI pooling output shape (h,w)",ROI pooling output shape BSTR,,,,,,,
mxnet.test_utils.check_symbolic_backward,ctx,Running context.,Running context,,,,,,,
mxnet.ndarray.op.BatchNorm,moving_mean,running mean of input,running mean of input,numeric,,,,,,
mxnet.contrib.ndarray.SyncBatchNorm,moving_var,running variance of input,running variance of input,numeric,,,,,,
mxnet.contrib.ndarray.BilinearResize2D,mode,"resizing mode. ""simple"" - output height equals parameter ""height"" if ""scale_height"" parameter is not defined or input height multiplied by ""scale_height"" otherwise. Same for width;""odd_scale"" - if original height or width is odd, then result height is calculated like result_h = (original_h - 1) * scale + 1; for scale > 1 the result shape would be like if we did deconvolution with kernel = (1, 1) and stride = (height_scale, width_scale); and for scale < 1 shape would be like we did convolution with kernel = (1, 1) and stride = (int(1 / height_scale), int( 1/ width_scale);""like"" - resize first input to the height and width of second input; ""to_even_down"" - resize input to nearest lower even height and width (if original height is odd then result height = original height - 1);""to_even_up"" - resize input to nearest bigger even height and width (if original height is odd then result height = original height + 1);""to_odd_down"" - resize input to nearest odd height and width (if original height is odd then result height = original height - 1);""to_odd_up"" - resize input to nearest odd height and width (if original height is odd then result height = original height + 1);",Same for PARAM QSTR if original PARAM or PARAM is odd then result PARAM is calculated PARAM result_h BSTR scale CONSTANT_NUM for scale REXPR the result shape would be PARAM if we did deconvolution with kernel BSTR and stride BSTR and for scale REXPR shape would be PARAM we did convolution with kernel BSTR and stride BSTR PARAM resize first input to the PARAM and PARAM of second input QSTR resize input to nearest lower even PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM QSTR resize input to nearest bigger even PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM QSTR resize input to nearest odd PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM QSTR resize input to nearest odd PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM,,,,,,,
mxnet.ndarray.random_pdf_poisson,sample,Samples from the distributions.,Samples from the distributions,,,,,,,
mxnet.ndarray.op.random_pdf_negative_binomial,sample,Samples from the distributions.,Samples from the distributions,,,,,,,
mxnet.ndarray.random_pdf_generalized_negative_binomial,sample,Samples from the distributions.,Samples from the distributions,,,,,,,
mxnet.ndarray.contrib.BilinearResize2D,scale_height,"sampling scale of the height (optional, used in modes ""scale"" and ""odd_scale"")",sampling scale of the PARAM optional used in modes QSTR,,,,,,,
mxnet.ndarray.contrib.BilinearResize2D,scale_width,"sampling scale of the width (optional, used in modes ""scale"" and ""odd_scale"")",sampling scale of the PARAM optional used in modes QSTR,,,,,,,
mxnet.ndarray.op.linalg_gemm,alpha,Scalar factor multiplied with A*B.,Scalar factor multiplied with A B,,,,,0,,
mxnet.ndarray.linalg_gemm2,alpha,Scalar factor multiplied with A*B.,Scalar factor multiplied with A B,,,,,0,,
mxnet.ndarray.linalg.gemm2,alpha,Scalar factor multiplied with A*B.,Scalar factor multiplied with A B,,,,,0,,
mxnet.ndarray.linalg.trsm,alpha,Scalar factor to be applied to the result.,Scalar factor to be applied to the result,,,,,0,,
mxnet.ndarray.linalg_syrk,alpha,Scalar factor to be applied to the result.,Scalar factor to be applied to the result,,,,,0,,
mxnet.ndarray.op.smooth_l1,scalar,scalar input,scalar input,,,,,0,,
mxnet.ndarray.power,exp,DD: scalar or NDArray,scalar or D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.greater_equal,rhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.logical_xor,rhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.modulo,lhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.multiply,rhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.logical_xor,lhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.maximum,lhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.sparse.add,rhs,DD: scalar or mxnet.ndarray.sparse.array,scalar or mxnet D_STRUCTURE sparse D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.op.LogisticRegressionOutput,grad_scale,Scale the gradient by a float factor,Scale the gradient by a D_TYPE factor,,,,,,,
mxnet.ndarray.sparse.LogisticRegressionOutput,grad_scale,Scale the gradient by a float factor,Scale the gradient by a D_TYPE factor,,,,,,,
mxnet.ndarray.MAERegressionOutput,grad_scale,Scale the gradient by a float factor,Scale the gradient by a D_TYPE factor,,,,,,,
mxnet.ndarray.SoftmaxOutput,grad_scale,Scales the gradient by a float factor.,Scales the gradient by a D_TYPE factor,,,,,,,
mxnet.ndarray.op.SoftmaxOutput,grad_scale,Scales the gradient by a float factor.,Scales the gradient by a D_TYPE factor,,,,,,,
mxnet.contrib.ndarray.MultiProposal,cls_prob,Score of how likely proposal is object.,Score of how likely proposal is object,,,,,,,
mxnet.ndarray.sparse.add,rhs,"Second array to be added. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",Second D_STRUCTURE to be added,,,D_STRUCTURE,,,,
mxnet.ndarray.greater_equal,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",Second D_STRUCTURE to be compared,,,D_STRUCTURE,,,,
mxnet.ndarray.multiply,rhs,"Second array to be multiplied. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",Second D_STRUCTURE to be multiplied,,,D_STRUCTURE,,,,
mxnet.ndarray.elemwise_div,rhs,second input,second input,,,,,,,
mxnet.ndarray.broadcast_like,rhs,Second input.,Second input,,,,,,,
mxnet.ndarray.logical_xor,rhs,"Second input of the function. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",Second input of the function,,,,,,,
mxnet.ndarray.broadcast_hypot,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.sparse.broadcast_minus,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.broadcast_lesser,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.broadcast_equal,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.broadcast_not_equal,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.op.broadcast_mul,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.broadcast_plus,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.broadcast_greater,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.op.broadcast_not_equal,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.broadcast_minimum,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.op.broadcast_lesser,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.sparse.broadcast_plus,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.op.broadcast_power,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.broadcast_mod,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.sparse.row_sparse_array,arg1,The argument to help instantiate the row sparse ndarray. See above for further details.,See above for further details,,,,,,,
mxnet.gluon.nn.Conv3DTranspose,activation,"Activation function to use. See `Activation()`. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",See Activation,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,activation,"Type of activation function used in n_t. If argument type is string, it's equivalent to nn.Activation(act_type=str). See `Activation()` for available choices. Alternatively, other activation blocks such as nn.LeakyReLU can be used.",See Activation for available choices,,,,,,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,activation,"Type of activation function. If argument type is string, it's equivalent to nn.Activation(act_type=str). See `Activation()` for available choices. Alternatively, other activation blocks such as nn.LeakyReLU can be used.",See Activation for available choices,,,,,,,
mxnet.ndarray.op.CTCLoss,use_label_lengths,"Whether the label lenghts are decided by label_lengths, or derived from padding_mask. If false, the lengths are derived from the first occurrence of the value of padding_mask. The value of padding_mask is `0` when first CTC label is reserved for blank, and `-1` when last label is reserved for blank. See blank_label.",See PARAM,,,,,,,
mxnet.ndarray.CTCLoss,use_label_lengths,"Whether the label lenghts are decided by label_lengths, or derived from padding_mask. If false, the lengths are derived from the first occurrence of the value of padding_mask. The value of padding_mask is `0` when first CTC label is reserved for blank, and `-1` when last label is reserved for blank. See blank_label.",See PARAM,,,,,,,
mxnet.ndarray.contrib.CTCLoss,use_label_lengths,"Whether the label lenghts are decided by label_lengths, or derived from padding_mask. If false, the lengths are derived from the first occurrence of the value of padding_mask. The value of padding_mask is `0` when first CTC label is reserved for blank, and `-1` when last label is reserved for blank. See blank_label.",See PARAM,,,,,,,
mxnet.image.center_crop,interp,Interpolation method. See resize_short for details.,See resize_short for details,,,,,,,
mxnet.ndarray.squeeze,axis,"Selects a subset of the single-dimensional entries in the shape. If an axis is selected with shape entry greater than one, an error is raised.",Selects a subset of the single dimensional entries in the shape,,,,,,,
mxnet.ndarray.op.Pooling,layout,"Set layout for input and output. Empty for default layout: NCW for 1d, NCHW for 2d and NCDHW for 3d.",Set layout for input and output,,,,,,,
mxnet.ndarray.contrib.quantized_pooling,layout,"Set layout for input and output. Empty for default layout: NCW for 1d, NCHW for 2d and NCDHW for 3d.",Set layout for input and output,,,,,,,
mxnet.ndarray.contrib.interleaved_matmul_selfatt_qk,heads,Set number of heads,Set number of heads,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.interleaved_matmul_selfatt_valatt,heads,Set number of heads,Set number of heads,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.interleaved_matmul_encdec_valatt,heads,Set number of heads,Set number of heads,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.CTCLoss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",Set the PARAM that is reserved for blank PARAM If QSTR CONSTANT_NUM th PARAM is reserved and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and alphabet_size CONSTANT_NUM and the padding mask is CONSTANT_NUM,,,,,,,
mxnet.contrib.ndarray.hawkesll,marks,"Shape (N, T) the marks (process ids)",Shape BSTR,,,,BSTR,,,
mxnet.contrib.ndarray.hawkesll,alpha,"Shape (K,) The infectivity factor (branching ratio) for each process",Shape BSTR for each process,,,,BSTR,,,
mxnet.ndarray.op.broadcast_axis,size,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.contrib.quantized_conv,dilate,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.contrib.ndarray.quantized_conv,dilate,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.op.sample_poisson,shape,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.op.broadcast_axes,axis,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.contrib.ndarray.DeformableConvolution,stride,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.op.Pooling,pad,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.op.Convolution,dilate,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.op.Pooling,stride,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.contrib.ndarray.quantized_pooling,stride,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.sample_poisson,shape,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.broadcast_axis,size,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.contrib.AdaptiveAvgPooling2D,output_size,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.slice_like,axes,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.GridGenerator,target_shape,"DD: Shape(tuple), optional, default=[0,0]",Shape BSTR optional default BSTR,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.op.GridGenerator,target_shape,"DD: Shape(tuple), optional, default=[0,0]",Shape BSTR optional default BSTR,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.random_normal,shape,"DD: Shape(tuple), optional, default=None",Shape BSTR optional default None,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.ravel_multi_index,shape,"DD: Shape(tuple), optional, default=None",Shape BSTR optional default None,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.random_poisson,shape,"DD: Shape(tuple), optional, default=None",Shape BSTR optional default None,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.op.random_negative_binomial,shape,"DD: Shape(tuple), optional, default=None",Shape BSTR optional default None,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.random_randint,shape,"DD: Shape(tuple), optional, default=None",Shape BSTR optional default None,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.op.reverse,axis,"DD: Shape(tuple), required",Shape BSTR required,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.contrib.DeformableConvolution,kernel,"DD: Shape(tuple), required",Shape BSTR required,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.reverse,axis,"DD: Shape(tuple), required",Shape BSTR required,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.tile,reps,"DD: Shape(tuple), required",Shape BSTR required,int,,BSTR,,1,"[0,inf)",
mxnet.contrib.ndarray.DeformableConvolution,kernel,"DD: Shape(tuple), required",Shape BSTR required,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.op.scatter_nd,shape,"DD: Shape(tuple), required",Shape BSTR required,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.pad,pad_width,"DD: Shape(tuple), required",Shape BSTR required,int,,BSTR,,1,"[0,inf)",
mxnet.ndarray.ROIPooling,pooled_size,"DD: Shape(tuple), required",Shape BSTR required,int,,BSTR,,1,"[0,inf)",
mxnet.contrib.ndarray.hawkesll,lda,"Shape (N, K) The intensity for each of the K processes, for each sample",Shape BSTR The intensity for each of the K processes for each sample,,,,BSTR,,,
mxnet.visualization.plot_network,shape,"Specifies the shape of the input tensors. If specified, the visualization will include the shape of the tensors between the nodes. shape is a dictionary mapping input symbol names (str) to the corresponding tensor shape (tuple).",shape is a D_STRUCTURE mapping input PARAM names BSTR,,,,,,,
mxnet.ndarray.op.scatter_nd,shape,Shape of output.,Shape of output,int,,,,1,"[0,inf)",
mxnet.ndarray.ravel_multi_index,shape,Shape of the array into which the multi-indices apply.,Shape of the D_STRUCTURE into which the multi indices apply,int,,,,1,"[0,inf)",
mxnet.ndarray.random_normal,shape,Shape of the output.,Shape of the output,int,,,,1,"[0,inf)",
mxnet.ndarray.random_poisson,shape,Shape of the output.,Shape of the output,int,,,,1,"[0,inf)",
mxnet.ndarray.op.random_negative_binomial,shape,Shape of the output.,Shape of the output,int,,,,1,"[0,inf)",
mxnet.ndarray.random_randint,shape,Shape of the output.,Shape of the output,int,,,,1,"[0,inf)",
mxnet.ndarray.op.nansum,axis,"DD: Shape or None, optional, default=None",Shape or None optional default None,int,,,,1,"[0,inf)",
mxnet.ndarray.max_axis,axis,"DD: Shape or None, optional, default=None",Shape or None optional default None,int,,,,1,"[0,inf)",
mxnet.ndarray.squeeze,axis,"DD: Shape or None, optional, default=None",Shape or None optional default None,int,,,,1,"[0,inf)",
mxnet.ndarray.min,axis,"DD: Shape or None, optional, default=None",Shape or None optional default None,int,,,,1,"[0,inf)",
mxnet.ndarray.broadcast_like,rhs_axes,"DD: Shape or None, optional, default=None",Shape or None optional default None,int,,,,1,"[0,inf)",
mxnet.ndarray.op.max_axis,axis,"DD: Shape or None, optional, default=None",Shape or None optional default None,int,,,,1,"[0,inf)",
mxnet.ndarray.op.sample_poisson,shape,Shape to be sampled from each random distribution.,Shape to be sampled from each random distribution,int,,,,1,"[0,inf)",
mxnet.ndarray.sample_poisson,shape,Shape to be sampled from each random distribution.,Shape to be sampled from each random distribution,int,,,,1,"[0,inf)",
mxnet.ndarray.random.gamma,beta,The scale of the gamma distribution. Should be greater than zero. Default is equal to 1.,Should be greater than zero,,,,,,"[0,inf)",
mxnet.ndarray.op.RNN,projection_size,size of project size,size of project size,int,,,,,"[0,inf)",
mxnet.gluon.nn.AvgPool3D,pool_size,Size of the average pooling windows.,Size of the average pooling windows,int,,,,,"[0,inf)",
mxnet.gluon.contrib.nn.SparseEmbedding,input_dim,"Size of the vocabulary, i.e. maximum integer index + 1.",Size of the vocabulary i e,int,,,,,"[0,inf)",
mxnet.ndarray.hard_sigmoid,alpha,Slope of hard sigmoid,Slope of hard sigmoid,,,,,,,
mxnet.ndarray.op.hard_sigmoid,alpha,Slope of hard sigmoid,Slope of hard sigmoid,,,,,,,
mxnet.image.imresize,src,source image,source image,numeric,,,,,,
mxnet.ndarray.slice_axis,data,Source input,Source input,,,,,,,
mxnet.contrib.ndarray.backward_gradientmultiplier,data,source input,source input,,,,,,,
mxnet.ndarray.slice,data,Source input,Source input,,,,,,,
mxnet.contrib.ndarray.arange_like,step,Spacing between values.,Spacing between values,,,,,,,
mxnet.ndarray.arange,step,Spacing between values. The default step size is 1.,Spacing between values,,,,,,,
mxnet.gluon.nn.Conv1D,dilation,Specifies the dilation rate to use for dilated convolution.,Specifies the dilation rate to use for dilated convolution,,,,,,,
mxnet.gluon.nn.Conv2D,dilation,Specifies the dilation rate to use for dilated convolution.,Specifies the dilation rate to use for dilated convolution,,,,,,,
mxnet.ndarray.GridGenerator,target_shape,"Specifies the output shape (H, W). This is required if transformation type is affine. If transformation type is warp, this parameter is ignored.",Specifies the output shape BSTR,int,,,BSTR,1,"[0,inf)",
mxnet.ndarray.op.GridGenerator,target_shape,"Specifies the output shape (H, W). This is required if transformation type is affine. If transformation type is warp, this parameter is ignored.",Specifies the output shape BSTR,int,,,BSTR,1,"[0,inf)",
mxnet.visualization.plot_network,shape,"Specifies the shape of the input tensors. If specified, the visualization will include the shape of the tensors between the nodes. shape is a dictionary mapping input symbol names (str) to the corresponding tensor shape (tuple).",Specifies the shape of the input D_STRUCTURE,int,,,,1,"[0,inf)",
mxnet.gluon.nn.Conv1D,strides,Specify the strides of the convolution.,Specify the strides of the convolution,int,,,,,"[0,inf)",
mxnet.gluon.nn.Conv2D,strides,Specify the strides of the convolution.,Specify the strides of the convolution,int,,,,,"[0,inf)",
mxnet.contrib.ndarray.quantized_batch_norm,axis,Specify which shape axis the channel is specified,Specify which shape axis the channel is specified,int,,,,0,,
mxnet.ndarray.linspace,start,Start of interval.,Start of interval,numeric,,,,,,
mxnet.ndarray.random.randn,out,Store output to an existing NDArray.,Store output to an existing D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.random.negative_binomial,out,Store output to an existing NDArray.,Store output to an existing D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.random.generalized_negative_binomial,out,Store output to an existing NDArray.,Store output to an existing D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.Pooling,stride,"Stride: for pooling (y, x) or (d, y, x). Defaults to 1 for each dimension.",Stride for pooling BSTR,int,,,,,"[0,inf)",
mxnet.contrib.ndarray.quantized_pooling,stride,"Stride: for pooling (y, x) or (d, y, x). Defaults to 1 for each dimension.",Stride for pooling BSTR,int,,,,,"[0,inf)",
mxnet.ndarray.op.Correlation,stride1,stride1 quantize data1 globally,stride1 quantize PARAM globally,int,,,,,"[0,inf)",
mxnet.ndarray.Correlation,stride2,stride2 quantize data2 within the neighborhood centered around data1,stride2 quantize PARAM within the neighborhood centered around PARAM,int,,,,,"[0,inf)",
mxnet.ndarray.op.UpSampling,multi_input_mode,"How to handle multiple input. concat means concatenate upsampled images along the channel dimension. sum means add all images together, only available for nearest neighbor upsampling.",sum means add all images together only available for nearest neighbor upsampling,,,,,,,
mxnet.ndarray.op.reshape_like,lhs_begin,Defaults to 0. The beginning index along which the lhs dimensions are to be reshaped. Supports negative indices.,Supports negative indices,,,,,,,
mxnet.ndarray.reshape_like,rhs_begin,Defaults to 0. The beginning index along which the rhs dimensions are to be used for reshaping. Supports negative indices.,Supports negative indices,,,,,,,
mxnet.ndarray.op.broadcast_axis,size,Target sizes of the broadcasting axes.,Target sizes of the broadcasting axes,int,,,,,"[0,inf)",
mxnet.ndarray.broadcast_axis,size,Target sizes of the broadcasting axes.,Target sizes of the broadcasting axes,int,,,,,"[0,inf)",
mxnet.ndarray.softmin,temperature,Temperature parameter in softmax,Temperature parameter in softmax,,,,,,,
mxnet.gluon.nn.ELU,alpha,"The alpha parameter as described by Clevert et al, 2016",The alpha parameter as described by Clevert et al CONSTANT_NUM,,,,,,,
mxnet.ndarray.signum_update,wd_lh,The amount of weight decay that does not go into gradient/momentum calculationsotherwise do weight decay algorithmically only.,The amount of PARAM decay that does not go into gradient PARAM calculationsotherwise do PARAM decay algorithmically only,int,,,,0,"[0,inf)",
mxnet.ndarray.op.signum_update,wd_lh,The amount of weight decay that does not go into gradient/momentum calculationsotherwise do weight decay algorithmically only.,The amount of PARAM decay that does not go into gradient PARAM calculationsotherwise do PARAM decay algorithmically only,int,,,,0,"[0,inf)",
mxnet.ndarray.sparse.row_sparse_array,arg1,The argument to help instantiate the row sparse ndarray. See above for further details.,The argument to help instantiate the row sparse D_STRUCTURE,,,,,,,
mxnet.ndarray.op.broadcast_axes,axis,The axes to perform the broadcasting.,The axes to perform the broadcasting,int,,,,,,
mxnet.ndarray.softmax,axis,The axis along which to compute softmax.,The axis along which to compute softmax,int,,,,0,,
mxnet.ndarray.op.repeat,axis,"The axis along which to repeat values. The negative numbers are interpreted counting from the backward. By default, use the flattened input array, and return a flat output array.",The axis along which to repeat values,int,,,,0,,
mxnet.gluon.utils.split_data,batch_axis,The axis along which to slice.,The axis along which to slice,int,,,,0,,
mxnet.ndarray.split_v2,axis,"The axis along which to split, default is 0.",The axis along which to split default is CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.take,axis,"The axis of input array to be taken.For input tensor of rank r, it could be in the range of [-r, r-1]",The axis of input D_STRUCTURE to be taken For input D_STRUCTURE of rank r it could be in the range of BSTR,int,,,,0,,
mxnet.gluon.contrib.nn.Concurrent,axis,The axis on which to concatenate the outputs.,The axis on which to concatenate the outputs,int,,,,0,,
mxnet.ndarray.op.nansum,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The axis or axes along which to perform the reduction,int,,,,0,,
mxnet.ndarray.max_axis,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The axis or axes along which to perform the reduction,int,,,,0,,
mxnet.ndarray.min,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The axis or axes along which to perform the reduction,int,,,,0,,
mxnet.ndarray.op.max_axis,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The axis or axes along which to perform the reduction,int,,,,0,,
mxnet.gluon.nn.LayerNorm,axis,The axis that should be normalized. This is typically the axis of the channels.,The axis that should be normalized,int,,,,0,,
mxnet.gluon.nn.BatchNorm,axis,"The axis that should be normalized. This is typically the channels (C) axis. For instance, after a Conv2D layer with layout='NCHW', set axis=1 in BatchNorm. If layout='NHWC', then set axis=3.",The axis that should be normalized,int,,,,0,,
mxnet.gluon.nn.InstanceNorm,axis,"The axis that will be excluded in the normalization process. This is typically the channels (C) axis. For instance, after a Conv2D layer with layout='NCHW', set axis=1 in InstanceNorm. If layout='NHWC', then set axis=3. Data will be normalized along axes excluding the first axis and the axis given.",The axis that will be excluded in the normalization process,int,,,,0,,
mxnet.ndarray.pick,axis,"int or None. The axis to picking the elements. Negative values means indexing from right to left. If is None, the elements in the index w.r.t the flattened input will be picked.",The axis to picking the elements,int,,,,0,,
mxnet.ndarray.op.reverse,axis,The axis which to reverse elements.,The axis which to reverse elements,int,,,,0,,
mxnet.ndarray.reverse,axis,The axis which to reverse elements.,The axis which to reverse elements,int,,,,0,,
mxnet.ndarray.slice_axis,begin,"The beginning index along the axis to be sliced,  supports negative indexes.",The beginning index along the PARAM to be sliced supports negative indexes,int,,,,0,,
mxnet.ndarray.op.reshape_like,lhs_begin,Defaults to 0. The beginning index along which the lhs dimensions are to be reshaped. Supports negative indices.,The beginning index along which the PARAM dimensions are to be reshaped,int,,,,0,,
mxnet.ndarray.reshape_like,rhs_begin,Defaults to 0. The beginning index along which the rhs dimensions are to be used for reshaping. Supports negative indices.,The beginning index along which the PARAM dimensions are to be used for reshaping,int,,,,0,,
mxnet.gluon.model_zoo.vision.vgg19,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
mxnet.gluon.model_zoo.vision.get_model,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
mxnet.gluon.model_zoo.vision.get_vgg,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
mxnet.gluon.model_zoo.vision.resnet50_v1,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
mxnet.gluon.model_zoo.vision.vgg16,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
mxnet.gluon.model_zoo.vision.mobilenet0_25,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
mxnet.contrib.ndarray.SyncBatchNorm,ndev,The count of GPU devices,The count of GPU devices,int,,,,0,"[0,inf)",
mxnet.image.CreateDetAugmenter,min_object_covered,"The cropped area of the image must contain at least this fraction of any bounding box supplied. The value of this parameter should be non-negative. In the case of 0, the cropped area does not need to overlap any of the bounding boxes supplied.",The cropped area of the image must contain at least this fraction of any bounding box supplied,,,,,,,
mxnet.ndarray.op.SequenceReverse,axis,The sequence axis. Only 0 is currently supported.,The D_STRUCTURE axis,int,,,,0,,
mxnet.ndarray.op.SequenceMask,axis,The sequence axis. Only values of 0 and 1 are currently supported.,The D_STRUCTURE axis,int,,,,0,,
mxnet.ndarray.linspace,dtype,The data type of the NDArray. The default datatype is np.float32.,The data type of the D_STRUCTURE,numpy.dtype,,,,,,
mxnet.ndarray.mp_lamb_update_phase1,beta1,The decay rate for the 1st moment estimates.,The decay rate for the 1st moment estimates,numeric,,,,,"[0,1]",
mxnet.ndarray.sparse.adam_update,beta2,The decay rate for the 2nd moment estimates.,The decay rate for the 2nd moment estimates,numeric,,,,,"[0,1]",
mxnet.ndarray.preloaded_multi_mp_sgd_mom_update,momentum,The decay rate of momentum estimates at each epoch.,The decay rate of momentum estimates at each epoch,numeric,,,,,"[0,1]",
mxnet.ndarray.op.sgd_mom_update,momentum,The decay rate of momentum estimates at each epoch.,The decay rate of momentum estimates at each epoch,numeric,,,,,"[0,1]",
mxnet.ndarray.sgd_mom_update,momentum,The decay rate of momentum estimates at each epoch.,The decay rate of momentum estimates at each epoch,numeric,,,,,"[0,1]",
mxnet.ndarray.op.preloaded_multi_mp_sgd_mom_update,momentum,The decay rate of momentum estimates at each epoch.,The decay rate of momentum estimates at each epoch,numeric,,,,,"[0,1]",
mxnet.ndarray.op.nansum,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The default axis BSTR,,,,,,,
mxnet.ndarray.max_axis,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The default axis BSTR,,,,,,,
mxnet.ndarray.min,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The default axis BSTR,,,,,,,
mxnet.ndarray.op.max_axis,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The default axis BSTR,,,,,,,
mxnet.ndarray.linspace,dtype,The data type of the NDArray. The default datatype is np.float32.,The default datatype is D_TYPE,numpy.dtype,,,,0,,
mxnet.ndarray.random.multinomial,dtype,Data type of the sample output array. The default is int32. Note that the data type of the log likelihood array is the same with that of data.,The default is D_TYPE,numpy.dtype,,,,0,,
mxnet.ndarray.arange,repeat,Number of times to repeat each element. The default repeat count is 1.,The default repeat count is CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.arange,step,Spacing between values. The default step size is 1.,The default step size is CONSTANT_NUM,int,,,,0,,
mxnet.ndarray.sparse.dot,forward_stype,"The desired storage type of the forward output given by user, if thecombination of input storage types and this hint does not matchany implemented ones, the dot operator will perform fallback operationand still produce an output of the desired storage type.",The desired storage type of the forward output given by user if thecombination of input storage types and this hint does not matchany implemented ones the dot operator will perform fallback operationand still produce an output of the desired storage type,,,,,,,
mxnet.ndarray.op.batch_dot,forward_stype,"The desired storage type of the forward output given by user, if thecombination of input storage types and this hint does not matchany implemented ones, the dot operator will perform fallback operationand still produce an output of the desired storage type.",The desired storage type of the forward output given by user if thecombination of input storage types and this hint does not matchany implemented ones the dot operator will perform fallback operationand still produce an output of the desired storage type,,,,,,,
mxnet.ndarray.concat,dim,the dimension to be concated.,the dimension to be concated,int,,,,0,,
mxnet.gluon.nn.Conv1D,channels,"The dimensionality of the output space, i.e. the number of output channels (filters) in the convolution.",The dimensionality of the output space i e,int,,,,,,
mxnet.gluon.contrib.rnn.VariationalDropoutCell,drop_states,The dropout rate for state inputs on the first state channel. Won't apply dropout if it equals 0.,The dropout rate for state inputs on the first state channel,numeric,,,,,"[0,1]",
mxnet.ndarray.sparse.Embedding,weight,The embedding weight matrix.,The embedding weight matrix,numeric,,,,,,
mxnet.ndarray.slice_axis,end,"The ending index along the axis to be sliced,  supports negative indexes.",The ending index along the PARAM to be sliced supports negative indexes,int,,,,0,,
mxnet.ndarray.power,exp,"The exponent array. If `base.shape != exp.shape`, they must be broadcastable to a common shape.",The exponent D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.diag,axis1,The first axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,The first axis of the sub D_STRUCTURE of interest,int,,,,0,,
mxnet.ndarray.SwapAxis,dim1,the first axis to be swapped.,the first axis to be swapped,int,,,,0,,
mxnet.ndarray.op.swapaxes,dim1,the first axis to be swapped.,the first axis to be swapped,int,,,,0,,
mxnet.ndarray.swapaxes,dim1,the first axis to be swapped.,the first axis to be swapped,int,,,,0,,
mxnet.ndarray.op.batch_dot,lhs,The first input,The first input,,,,,,,
mxnet.ndarray.op.dot,lhs,The first input,The first input,,,,,,,
mxnet.contrib.autograd.grad,func,The forward (loss) function.,The forward BSTR function,,,,,,,
mxnet.test_utils.var_check,generator,The generator function. It's expected to generate N i.i.d samples by calling generator(N).,The generator function,,,,,,,
mxnet.test_utils.verify_generator,probs,The ground-truth probability of the random value fall in a specific bucket.,The ground truth probability of the random value fall in a specific bucket,numeric,,,,,"[0,1]",
mxnet.ndarray.take,indices,The indices of the values to be extracted.,The indices of the values to be extracted,int,,,,,,
mxnet.ndarray.op.max,data,The input,The input,,,,,,,
mxnet.ndarray.broadcast_axis,data,The input,The input,,,,,,,
mxnet.ndarray.max,data,The input,The input,,,,,,,
mxnet.ndarray.op.sum,data,The input,The input,,,,,,,
mxnet.ndarray.contrib.bipartite_matching,data,The input,The input,,,,,,,
mxnet.ndarray.op.argmin,data,The input,The input,,,,,,,
mxnet.ndarray.sum_axis,data,The input,The input,,,,,,,
mxnet.ndarray.max_axis,data,The input,The input,,,,,,,
mxnet.ndarray.ones_like,data,The input,The input,,,,,,,
mxnet.ndarray.split,data,The input,The input,,,,,,,
mxnet.ndarray.contrib.box_non_maximum_suppression,data,The input,The input,,,,,,,
mxnet.ndarray.image.random_hue,data,The input.,The input,,,,,,,
mxnet.ndarray.image.flip_top_bottom,data,The input.,The input,,,,,,,
mxnet.ndarray.image.resize,data,The input.,The input,,,,,,,
mxnet.ndarray.image.random_color_jitter,data,The input.,The input,,,,,,,
mxnet.ndarray.contrib.box_nms,in_format,"The input box encoding type. ""corner"" means boxes are encoded as [xmin, ymin, xmax, ymax], ""center"" means boxes are encodes as [x, y, width, height].",The input box encoding type,,,,,,,
mxnet.contrib.ndarray.box_non_maximum_suppression,in_format,"The input box encoding type. ""corner"" means boxes are encoded as [xmin, ymin, xmax, ymax], ""center"" means boxes are encodes as [x, y, width, height].",The input box encoding type,,,,,,,
mxnet.ndarray.op.sort,data,The input array,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.argmax_channel,data,The input array,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.pick,data,The input array,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.argsort,data,The input array,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sort,data,The input array,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.identity,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.degrees,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.arccos,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.make_loss,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.gamma,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.stop_gradient,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.cbrt,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.degrees,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.tan,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.arctan,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.arccosh,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.BlockGrad,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.make_loss,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.cos,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.gamma,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.expm1,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.negative,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.ceil,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.arccosh,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.floor,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.rint,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.negative,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.erfinv,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.gammaln,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.rint,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.log1p,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.radians,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.log1p,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.rsqrt,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sinh,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.round_ste,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.ceil,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.div_sqrt_dim,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.sign_ste,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.Embedding,data,The input array to the embedding operator.,The input D_STRUCTURE to the embedding operator,,,D_STRUCTURE,,,,
mxnet.io.LibSVMIter,label_libsvm,"The input LibSVM label file or a directory path. If NULL, all labels will be read from `data_libsvm`.",The input LibSVM label file or a directory path,,,,,,,
mxnet.io.LibSVMIter,data_libsvm,The input zero-base indexed LibSVM data file or a directory path.,The input zero base indexed LibSVM data file or a directory path,,,,,,,
mxnet.ndarray.op.Softmax,ignore_label,"The instances whose labels == ignore_label will be ignored during backward, if use_ignore is set to `true`).",The instances whose labels ignore_label will be ignored during backward if PARAM is set to CONSTANT_BOOL,,,,,,,
mxnet.util.np_ufunc_legal_option,key,the key of the ufunc argument.,the key of the ufunc argument,,,,,,,
mxnet.ndarray.SVMOutput,margin,The loss function penalizes outputs that lie outside this margin. Default margin is 1.,The loss function penalizes outputs that lie outside this margin,,,,,,,
mxnet.ndarray.contrib.quantized_batch_norm,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to by quantized batch norm op to calculate primitive scale.Note: this calib_range is to calib bn output.",The maximum scalar value in the form of D_TYPE obtained through calibration,D_TYPE,,,,0,,
mxnet.ndarray.contrib.quantized_flatten,max_data,The maximum scalar value possibly produced for the data,The maximum scalar value possibly produced for the PARAM,numeric,,,,0,,
mxnet.io.ImageRecordIter,mean_b,The mean value to be subtracted on the B channel,The mean value to be subtracted on the B channel,numeric,,,,,,
mxnet.io.ImageRecordIter,mean_r,The mean value to be subtracted on the R channel,The mean value to be subtracted on the R channel,numeric,,,,,,
mxnet.image.CreateDetAugmenter,min_eject_coverage,"The minimum coverage of cropped sample w.r.t its original size. With this constraint, objects that have marginal area after crop will be discarded.",The minimum coverage of cropped sample w r t its original size,int,,,,,"[0,inf)",
mxnet.ndarray.contrib.quantize_v2,min_calib_range,"The minimum scalar value in the form of float32. If present, it will be used to quantize the fp32 data into int8 or uint8.",The minimum scalar value in the form of D_TYPE,D_TYPE,,,,0,,
mxnet.contrib.ndarray.quantize_v2,min_calib_range,"The minimum scalar value in the form of float32. If present, it will be used to quantize the fp32 data into int8 or uint8.",The minimum scalar value in the form of D_TYPE,D_TYPE,,,,0,,
mxnet.ndarray.op.repeat,axis,"The axis along which to repeat values. The negative numbers are interpreted counting from the backward. By default, use the flattened input array, and return a flat output array.",The negative numbers are interpreted counting from the backward,,,,,,,
mxnet.gluon.rnn.GRU,hidden_size,The number of features in the hidden state h,The number of features in the hidden state h,int,,,,0,"[0,inf)",
mxnet.gluon.nn.Conv3D,in_channels,"The number of input channels to this layer. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",The number of input PARAM to this layer,int,,,,0,"[0,inf)",
mxnet.gluon.nn.Conv1DTranspose,in_channels,"The number of input channels to this layer. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",The number of input PARAM to this layer,int,,,,0,"[0,inf)",
mxnet.gluon.nn.Conv1D,channels,"The dimensionality of the output space, i.e. the number of output channels (filters) in the convolution.",the number of output channels BSTR in the convolution,int,,,,0,"[0,inf)",
mxnet.ndarray.repeat,repeats,The number of repetitions for each element.,The number of repetitions for each element,int,,,,0,"[0,inf)",
mxnet.ndarray.random.negative_binomial,shape,"The number of samples to draw. If shape is, e.g., (m, n) and k and p are scalars, output shape will be (m, n). If k and p are NDArrays with shape, e.g., (x, y), then output will have shape (x, y, m, n), where m*n samples are drawn for each [k, p) pair.",The number of samples to draw,int,,,,0,"[0,inf)",
mxnet.test_utils.chi_square_check,nsamples,The number of samples to generate for the testing,The number of samples to generate for the testing,int,,,,0,"[0,inf)",
mxnet.ndarray.tile,reps,"The number of times for repeating the tensor a. Each dim size of reps must be a positive integer. If reps has length d, the result will have dimension of max(d, a.ndim); If a.ndim < d, a is promoted to be d-dimensional by prepending new axes. If a.ndim > d, reps is promoted to a.ndim by pre-pending 1's to it.",The number of times for repeating the D_STRUCTURE a,int,,,,0,"[0,inf)",
mxnet.gluon.utils.download,retries,The number of times to attempt the download in case of failure or non 200 return codes,The number of times to attempt the download in case of failure or non CONSTANT_NUM return codes,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.dgl_graph_compact,graph_sizes,the number of vertices in each graph.,the number of vertices in each graph,int,,,,0,"[0,inf)",
mxnet.image.resize_short,src,The original image.,The original image,numeric,,,,,,
mxnet.contrib.ndarray.box_nms,out_format,"The output box encoding type. ""corner"" means boxes are encoded as [xmin, ymin, xmax, ymax], ""center"" means boxes are encodes as [x, y, width, height].",The output box encoding type,,,,,,,
mxnet.contrib.ndarray.MultiBoxPrior,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.reshape_like,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.trunc,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_axes,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_fully_connected,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.multi_lars,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_hypot,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.backward_hawkesll,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.SwapAxis,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.rint,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.calibrate_entropy,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.index_array,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.multi_sum_sq,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.sign_ste,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.ctc_loss,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.AdaptiveAvgPooling2D,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.elemwise_sub,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.one_hot,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sigmoid,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.DeformableConvolution,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.interleaved_matmul_selfatt_valatt,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.image.random_flip_left_right,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.rmsprop_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.argsort,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.min_axis,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.shape_array,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.cos,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_lesser_equal,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.box_non_maximum_suppression,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.argmax_channel,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.GroupNorm,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_syrk,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.sgd_mom_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_makediag,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.SoftmaxOutput,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.RROIAlign,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.smooth_l1,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.expm1,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.det,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.random_uniform,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.backward_index_copy,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.slice_like,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.cosh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.FullyConnected,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.ctc_loss,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_pdf_negative_binomial,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_randint,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.Deconvolution,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.SyncBatchNorm,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_act,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.transpose,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_minus,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.BilinearSampler,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_concat,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_pdf_poisson,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sign,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.degrees,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.random_normal,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.image.resize,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.RNN,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.adagrad_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.ROIAlign,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.L2Normalization,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sort,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.preloaded_multi_mp_sgd_mom_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.SoftmaxOutput,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.backward_gradientmultiplier,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.cos,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.multi_sgd_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.round_ste,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_add,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sample_multinomial,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.reshape_like,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.bipartite_matching,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.LinearRegressionOutput,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sinh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.random_gamma,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.flatten,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.arcsinh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quadratic,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.shape_array,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.topk,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_det,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_sub,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.choose_element_0index,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.size_array,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.tan,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.ravel_multi_index,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.gemm2,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.MultiProposal,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.preloaded_multi_sgd_mom_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_pdf_normal,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.backward_quadratic,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.concat,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_div,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.round,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_to,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_batch_norm,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.SVMOutput,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.adam_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.broadcast_minus,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.gammaln,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.square,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.edge_id,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.ElementWiseSum,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.clip,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.log1p,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.LRN,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.slogdet,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_lesser,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.argmin,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.exp,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.rmspropalex_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.adam_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.lamb_update_phase1,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.random_pdf_gamma,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sigmoid,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sample_generalized_negative_binomial,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_extractdiag,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.nag_mom_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.identity,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.norm,out_dtype,The data type of the output.,The PARAM type of the output,numpy.dtype,,,,,,
mxnet.ndarray.op.LRN,knorm,The parameter \(k\) in the LRN expression.,The parameter k in the LRN expression,,,,,,,
mxnet.ndarray.op.nag_mom_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,The penalty scales with the square of the magnitude of each PARAM,,,,,,,
mxnet.ndarray.ftml_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,The penalty scales with the square of the magnitude of each PARAM,,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase1,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,The penalty scales with the square of the magnitude of each PARAM,,,,,,,
mxnet.ndarray.nag_mom_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,The penalty scales with the square of the magnitude of each PARAM,,,,,,,
mxnet.ndarray.op.sgd_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,The penalty scales with the square of the magnitude of each PARAM,,,,,,,
mxnet.ndarray.op.multi_sgd_mom_update,wds,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,The penalty scales with the square of the magnitude of each weight,,,,,,,
mxnet.contrib.quantization.quantize_net,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",The quantized models generated in this mode are normally CONSTANT_NUM CONSTANT_NUM slower than those with calibrations during inference,,,,,,,
mxnet.io.ImageRecordIter,shuffle_chunk_seed,The random seed for shuffling,The random PARAM for shuffling,,,,,,,
mxnet.test_utils.assert_almost_equal,rtol,The relative threshold. Default threshold will be used if set to `None`.,The relative threshold,,,,,,,
mxnet.contrib.ndarray.arange_like,repeat,"The repeating time of all elements. E.g repeat=3, the element a will be repeated three times -> a, a, a.",The repeating time of all elements,int,,,,,"[0,inf)",
mxnet.ndarray.random.gamma,beta,The scale of the gamma distribution. Should be greater than zero. Default is equal to 1.,The scale of the gamma distribution,,,,,,,
mxnet.ndarray.op.SwapAxis,dim2,the second axis to be swapped.,the second axis to be swapped,int,,,,0,,
mxnet.ndarray.op.dot,rhs,The second input,The second input,,,,,,,
mxnet.ndarray.utils.zeros,shape,The shape of the empty array,The shape of the empty D_STRUCTURE,int,,,,1,"[0,inf)",
mxnet.ndarray.zeros,shape,The shape of the empty array,The shape of the empty D_STRUCTURE,int,,,,1,"[0,inf)",
mxnet.ndarray.utils.empty,shape,The shape of the empty array.,The shape of the empty D_STRUCTURE,int,,,,1,"[0,inf)",
mxnet.ndarray.full,shape,The shape of the new array.,The shape of the new D_STRUCTURE,int,,,,1,"[0,inf)",
mxnet.ndarray.contrib.count_sketch,s,The sign vector,The sign D_STRUCTURE,,,D_STRUCTURE,,1,,
mxnet.contrib.ndarray.count_sketch,s,The sign vector,The sign D_STRUCTURE,,,D_STRUCTURE,,1,,
mxnet.io.ImageDetRecordIter,shuffle_chunk_size,"the size(MB) of the shuffle chunk, used with shuffle=True, it can enable global shuffling",the size BSTR of the PARAM chunk used with PARAM CONSTANT_BOOL it can enable global shuffling,int,,,,,"[0,inf)",
mxnet.ndarray.contrib.Proposal,feature_stride,"The size of the receptive field each unit in the convolution layer of the rpn,for example the product of all stride's prior to this layer.",The size of the receptive field each unit in the convolution layer of the rpn for example the product of all stride prior to this layer,int,,,,,"[0,inf)",
mxnet.test_utils.verify_generator,nrepeat,The times to repeat the test,The times to repeat the test,,,,,,,
mxnet.ndarray.IdentityAttachKLSparseReg,penalty,The tradeoff parameter for the sparseness penalty,The tradeoff parameter for the sparseness penalty,,,,,,,
mxnet.ndarray.op.RNN,mode,the type of RNN to compute,the type of RNN to compute,,,,,,,
mxnet.ndarray.op.CTCLoss,use_label_lengths,"Whether the label lenghts are decided by label_lengths, or derived from padding_mask. If false, the lengths are derived from the first occurrence of the value of padding_mask. The value of padding_mask is `0` when first CTC label is reserved for blank, and `-1` when last label is reserved for blank. See blank_label.",The value of padding_mask is CONSTANT_NUM when first CTC PARAM is reserved for blank and CONSTANT_NUM when last PARAM is reserved for blank,,,,,,,
mxnet.ndarray.CTCLoss,use_label_lengths,"Whether the label lenghts are decided by label_lengths, or derived from padding_mask. If false, the lengths are derived from the first occurrence of the value of padding_mask. The value of padding_mask is `0` when first CTC label is reserved for blank, and `-1` when last label is reserved for blank. See blank_label.",The value of padding_mask is CONSTANT_NUM when first CTC PARAM is reserved for blank and CONSTANT_NUM when last PARAM is reserved for blank,,,,,,,
mxnet.ndarray.contrib.CTCLoss,use_label_lengths,"Whether the label lenghts are decided by label_lengths, or derived from padding_mask. If false, the lengths are derived from the first occurrence of the value of padding_mask. The value of padding_mask is `0` when first CTC label is reserved for blank, and `-1` when last label is reserved for blank. See blank_label.",The value of padding_mask is CONSTANT_NUM when first CTC PARAM is reserved for blank and CONSTANT_NUM when last PARAM is reserved for blank,,,,,,,
mxnet.util.np_ufunc_legal_option,value,the value of the ufunc argument.,the value of the ufunc argument,,,,,,,
mxnet.image.CreateDetAugmenter,min_object_covered,"The cropped area of the image must contain at least this fraction of any bounding box supplied. The value of this parameter should be non-negative. In the case of 0, the cropped area does not need to overlap any of the bounding boxes supplied.",The value of this parameter should be non negative,,,,,,"[0,inf)",
mxnet.ndarray.op.Softmax,smooth_alpha,Constant for computing a label smoothed version of cross-entropyfor the backwards pass.  This constant gets subtracted from theone-hot encoding of the gold label and distributed uniformly toall other labels.,This constant gets subtracted from theone hot encoding of the gold PARAM and distributed uniformly toall other labels,,,,,,,
mxnet.ndarray.Softmax,multi_output,"If set to `true`, the softmax function will be computed along axis `1`. This is applied when the shape of input array differs from the shape of label array.",This is applied when the shape of input D_STRUCTURE differs from the shape of PARAM D_STRUCTURE,,,,,,,
mxnet.ndarray.GridGenerator,target_shape,"Specifies the output shape (H, W). This is required if transformation type is affine. If transformation type is warp, this parameter is ignored.",This is required if transformation type is affine,,,,,,,
mxnet.ndarray.op.GridGenerator,target_shape,"Specifies the output shape (H, W). This is required if transformation type is affine. If transformation type is warp, this parameter is ignored.",This is required if transformation type is affine,,,,,,,
mxnet.gluon.nn.LayerNorm,axis,The axis that should be normalized. This is typically the axis of the channels.,This is typically the axis of the channels,int,,,,0,,
mxnet.gluon.nn.BatchNorm,axis,"The axis that should be normalized. This is typically the channels (C) axis. For instance, after a Conv2D layer with layout='NCHW', set axis=1 in BatchNorm. If layout='NHWC', then set axis=3.",This is typically the channels BSTR axis,int,,,,0,,
mxnet.gluon.nn.InstanceNorm,axis,"The axis that will be excluded in the normalization process. This is typically the channels (C) axis. For instance, after a Conv2D layer with layout='NCHW', set axis=1 in InstanceNorm. If layout='NHWC', then set axis=3. Data will be normalized along axes excluding the first axis and the axis given.",This is typically the channels BSTR axis,int,,,,0,,
mxnet.ndarray.op.MakeLoss,valid_thresh,clip each element in the array to 0 when it is less than `valid_thresh`. This is used when `normalization` is set to `'valid'`.,This is used when PARAM is set to QSTR,,,,,,,
mxnet.ndarray.RNN,lstm_state_clip_max,Maximum clip value of LSTM states. This option must be used together with lstm_state_clip_min.,This option must be used together with PARAM,,,,,,,
mxnet.ndarray.contrib.MultiBoxTarget,negative_mining_thresh,Threshold used for negative mining.,Threshold used for negative mining,,,,,,,
mxnet.image.copyMakeBorder,top,Top margin.,Top margin,,,,,,,
mxnet.ndarray.GroupNorm,num_groups,Total number of groups.,Total number of groups,int,,,,0,"[0,inf)",
mxnet.ndarray.contrib.DeformablePSROIPooling,trans,transition parameter,transition parameter,,,,,,,
mxnet.ndarray.Convolution,cudnn_off,Turn off cudnn for this layer.,Turn off cudnn for this layer,,,,,,,
mxnet.ndarray.contrib.quantized_conv,cudnn_off,Turn off cudnn for this layer.,Turn off cudnn for this layer,,,,,,,
mxnet.ndarray.Deconvolution,cudnn_off,Turn off cudnn for this layer.,Turn off cudnn for this layer,,,,,,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,activation,"Type of activation function. If argument type is string, it's equivalent to nn.Activation(act_type=str). See `Activation()` for available choices. Alternatively, other activation blocks such as nn.LeakyReLU can be used.",Type of activation function,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,activation,"Type of activation function used in n_t. If argument type is string, it's equivalent to nn.Activation(act_type=str). See `Activation()` for available choices. Alternatively, other activation blocks such as nn.LeakyReLU can be used.",Type of activation function used in n_t,,,,,,,
mxnet.gluon.rnn.LSTM,dtype,Type to initialize the parameters and default states to,Type to initialize the parameters and default states to,,,,,,,
mxnet.ndarray.contrib.edge_id,u,u ndarray,u D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.UpSampling,scale,Up sampling scale,Up sampling scale,,,,,,,
mxnet.ndarray.op.random_pdf_uniform,high,Upper bounds of the distributions.,Upper bounds of the distributions,numeric,,,,,,
mxnet.ndarray.sample_uniform,high,Upper bounds of the distributions.,Upper bounds of the distributions,numeric,,,,,,
mxnet.gluon.contrib.nn.PixelShuffle2D,factor,"Upsampling factors, applied to the `H` and `W` dimensions, in that order.",Upsampling factors applied to the QSTR dimensions in that order,,,,,,,
mxnet.test_utils.get_zip_data,url,URL to download data from,URL to download data from,string,,,,,,
mxnet.ndarray.contrib.Proposal,iou_loss,Usage of IoU Loss,Usage of IoU Loss,,,,,,,
mxnet.ndarray.linalg_trmm,transpose,Use transposed of the triangular matrix,Use transposed of the triangular matrix,,,,,,,
mxnet.ndarray.op.linalg_trsm,transpose,Use transposed of the triangular matrix,Use transposed of the triangular matrix,,,,,,,
mxnet.ndarray.linalg.trmm,transpose,Use transposed of the triangular matrix,Use transposed of the triangular matrix,,,,,,,
mxnet.ndarray.linalg.trsm,transpose,Use transposed of the triangular matrix,Use transposed of the triangular matrix,,,,,,,
mxnet.ndarray.contrib.MultiProposal,ratios,Used to generate anchor windows by enumerating ratios,Used to generate anchor windows by enumerating ratios,,,,,,,
mxnet.contrib.ndarray.Proposal,scales,Used to generate anchor windows by enumerating scales,Used to generate anchor windows by enumerating scales,,,,,,,
mxnet.contrib.ndarray.edge_id,v,v ndarray,v D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.RNN,parameters,Vector of all RNN trainable parameters concatenated,D_STRUCTURE of all RNN trainable parameters concatenated,,,D_STRUCTURE,,1,,
mxnet.ndarray.SequenceLast,sequence_length,vector of sequence lengths of the form [batch_size],D_STRUCTURE of D_STRUCTURE lengths of the form BSTR,int,,D_STRUCTURE,,1,"[0,inf)",
mxnet.gluon.utils.download,verify_ssl,Verify SSL certificates.,Verify SSL certificates,,,,,,,
mxnet.io.ImageRecordIter,num_parts,Virtually partition the data into these many parts.,Virtually partition the data into these many parts,,,,,,,
mxnet.ndarray.op.multi_sgd_mom_update,wds,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,Weight decay augments the objective function with a regularization term that penalizes large weights,numeric,,,,,,
mxnet.ndarray.contrib.DeformableConvolution,weight,Weight matrix.,Weight matrix,numeric,,,,,,
mxnet.ndarray.op.FullyConnected,weight,Weight matrix.,Weight matrix,numeric,,,,,,
mxnet.gluon.nn.Embedding,sparse_grad,"If True, gradient w.r.t. weight will be a 'row_sparse' NDArray.",weight will be a QSTR D_STRUCTURE,numeric,,,,,,
mxnet.ndarray.multi_sgd_mom_update,*data,"Weights, gradients and momentum",Weights gradients and PARAM,numeric,,,,,,
mxnet.ndarray.op.multi_sgd_mom_update,*data,"Weights, gradients and momentum",Weights gradients and PARAM,numeric,,,,,,
mxnet.ndarray.preloaded_multi_mp_sgd_mom_update,*data,"Weights, gradients, momentums, learning rates and weight decays",Weights gradients momentums learning rates and weight decays,numeric,,,,,,
mxnet.ndarray.op.preloaded_multi_sgd_mom_update,*data,"Weights, gradients, momentum, learning rates and weight decays",Weights gradients PARAM learning rates and weight decays,numeric,,,,,,
mxnet.ndarray.op.Deconvolution,weight,Weights representing the kernel.,Weights representing the PARAM,numeric,,,,,,
mxnet.gluon.nn.MaxPool3D,ceil_mode,"When True, will use ceil instead of floor to compute the output shape.",When CONSTANT_BOOL will use ceil instead of floor to compute the output shape,bool,,,,0,,
mxnet.ndarray.op.Convolution,workspace,"Maximum temporary workspace allowed (MB) in convolution.This parameter has two usages. When CUDNN is not used, it determines the effective batch size of the convolution kernel. When CUDNN is used, it controls the maximum temporary storage used for tuning the best CUDNN kernel when limited_workspace strategy is used.",When CUDNN is not used it determines the effective batch size of the convolution PARAM,,,,,,,
mxnet.ndarray.op.Deconvolution,workspace,"Maximum temporary workspace allowed (MB) in deconvolution.This parameter has two usages. When CUDNN is not used, it determines the effective batch size of the deconvolution kernel. When CUDNN is used, it controls the maximum temporary storage used for tuning the best CUDNN kernel when limited_workspace strategy is used.",When CUDNN is not used it determines the effective batch size of the deconvolution PARAM,,,,,,,
mxnet.ndarray.op.Convolution,workspace,"Maximum temporary workspace allowed (MB) in convolution.This parameter has two usages. When CUDNN is not used, it determines the effective batch size of the convolution kernel. When CUDNN is used, it controls the maximum temporary storage used for tuning the best CUDNN kernel when limited_workspace strategy is used.",When CUDNN is used it controls the maximum temporary storage used for tuning the best CUDNN PARAM when limited_workspace strategy is used,,,,,,,
mxnet.ndarray.op.Deconvolution,workspace,"Maximum temporary workspace allowed (MB) in deconvolution.This parameter has two usages. When CUDNN is not used, it determines the effective batch size of the deconvolution kernel. When CUDNN is used, it controls the maximum temporary storage used for tuning the best CUDNN kernel when limited_workspace strategy is used.",When CUDNN is used it controls the maximum temporary storage used for tuning the best CUDNN PARAM when limited_workspace strategy is used,,,,,,,
mxnet.contrib.ndarray.ctc_loss,use_data_lengths,"Whether the data lenghts are decided by data_lengths. If false, the lengths are equal to the max sequence length.",Whether the PARAM lenghts are decided by PARAM,bool,,,,0,,
mxnet.ndarray.op.CTCLoss,use_label_lengths,"Whether the label lenghts are decided by label_lengths, or derived from padding_mask. If false, the lengths are derived from the first occurrence of the value of padding_mask. The value of padding_mask is `0` when first CTC label is reserved for blank, and `-1` when last label is reserved for blank. See blank_label.",Whether the PARAM lenghts are decided by PARAM or derived from padding_mask,bool,,,,0,,
mxnet.ndarray.CTCLoss,use_label_lengths,"Whether the label lenghts are decided by label_lengths, or derived from padding_mask. If false, the lengths are derived from the first occurrence of the value of padding_mask. The value of padding_mask is `0` when first CTC label is reserved for blank, and `-1` when last label is reserved for blank. See blank_label.",Whether the PARAM lenghts are decided by PARAM or derived from padding_mask,bool,,,,0,,
mxnet.ndarray.contrib.CTCLoss,use_label_lengths,"Whether the label lenghts are decided by label_lengths, or derived from padding_mask. If false, the lengths are derived from the first occurrence of the value of padding_mask. The value of padding_mask is `0` when first CTC label is reserved for blank, and `-1` when last label is reserved for blank. See blank_label.",Whether the PARAM lenghts are decided by PARAM or derived from padding_mask,bool,,,,0,,
mxnet.ndarray.amp_multicast,cast_narrow,Whether to cast to the narrowest type,Whether to cast to the narrowest type,bool,,,,0,,
mxnet.ndarray.contrib.allclose,equal_nan,"Whether to compare NaN's as equal. If True, NaN's in A will be considered equal to NaN's in B in the output array.",Whether to compare NaN as equal,bool,,,,0,,
mxnet.ndarray.FullyConnected,no_bias,Whether to disable bias parameter.,Whether to disable PARAM parameter,bool,,,,0,,
mxnet.ndarray.op.Convolution,no_bias,Whether to disable bias parameter.,Whether to disable PARAM parameter,bool,,,,0,,
mxnet.contrib.ndarray.DeformableConvolution,no_bias,Whether to disable bias parameter.,Whether to disable PARAM parameter,bool,,,,0,,
mxnet.ndarray.op.FullyConnected,no_bias,Whether to disable bias parameter.,Whether to disable PARAM parameter,bool,,,,0,,
mxnet.ndarray.contrib.DeformableConvolution,no_bias,Whether to disable bias parameter.,Whether to disable PARAM parameter,bool,,,,0,,
mxnet.ndarray.contrib.quantized_conv,no_bias,Whether to disable bias parameter.,Whether to disable PARAM parameter,bool,,,,0,,
mxnet.ndarray.Deconvolution,no_bias,Whether to disable bias parameter.,Whether to disable PARAM parameter,bool,,,,0,,
mxnet.gluon.utils.split_and_load,even_split,Whether to force all slices to have the same number of elements.,Whether to force all slices to have the same number of elements,bool,,,,0,,
mxnet.autograd.grad,retain_graph,"Whether to keep computation graph to differentiate again, instead of clearing history and release memory. Defaults to the same value as create_graph.",Whether to keep computation graph to differentiate again instead of clearing history and release memory,bool,,,,0,,
mxnet.gluon.model_zoo.vision.squeezenet1_1,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.resnet152_v2,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.mobilenet0_5,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.vgg19_bn,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.get_mobilenet,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.mobilenet0_25,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.squeezenet1_0,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.inception_v3,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.resnet34_v1,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.vgg16,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.vgg11,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.get_resnet,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.profiler.set_config,aggregate_stats,whether to maintain aggregate stats in memory for console dump.  Has some negative performance impact.,whether to maintain aggregate stats in memory for console dump,bool,,,,0,,
mxnet.ndarray.op.Dropout,mode,Whether to only turn on dropout during training or to also turn on for inference.,Whether to only turn on dropout during training or to also turn on for inference,bool,,,,0,,
mxnet.contrib.ndarray.ROIAlign,position_sensitive,"Whether to perform position-sensitive RoI pooling. PSRoIPooling is first proposaled by R-FCN and it can reduce the input channels by ph*pw times, where (ph, pw) is the pooled_size",Whether to perform position sensitive RoI pooling,bool,,,,0,,
mxnet.ndarray.op.max_axis,exclude,Whether to perform reduction on axis that are NOT in axis instead.,Whether to perform reduction on PARAM that are NOT in PARAM instead,bool,,,,0,,
mxnet.ndarray.mean,exclude,Whether to perform reduction on axis that are NOT in axis instead.,Whether to perform reduction on PARAM that are NOT in PARAM instead,bool,,,,0,,
mxnet.ndarray.nansum,exclude,Whether to perform reduction on axis that are NOT in axis instead.,Whether to perform reduction on PARAM that are NOT in PARAM instead,bool,,,,0,,
mxnet.ndarray.sum,exclude,Whether to perform reduction on axis that are NOT in axis instead.,Whether to perform reduction on PARAM that are NOT in PARAM instead,bool,,,,0,,
mxnet.contrib.ndarray.quantized_conv,cudnn_tune,Whether to pick convolution algo by running performance test.,Whether to pick convolution algo by running performance test,bool,,,,0,,
mxnet.ndarray.op.Deconvolution,cudnn_tune,Whether to pick convolution algorithm by running performance test.,Whether to pick convolution algorithm by running performance test,bool,,,,0,,
mxnet.profiler.dumps,ascending,whether to sort ascendingly defaults to False,whether to sort ascendingly defaults to CONSTANT_BOOL,bool,,,,0,,
mxnet.ndarray.argsort,is_ascend,Whether to sort in ascending or descending order.,Whether to sort in ascending or descending order,bool,,,,0,,
mxnet.ndarray.BilinearSampler,cudnn_off,whether to turn cudnn off,whether to turn cudnn off,bool,,,,0,,
mxnet.ndarray.op.BilinearSampler,cudnn_off,whether to turn cudnn off,whether to turn cudnn off,bool,,,,0,,
mxnet.ndarray.softmin,use_length,Whether to use the length input as a mask over the data input.,Whether to use the length input as a mask over the PARAM input,bool,,,,0,,
mxnet.ndarray.pad,pad_width,"Widths of the padding regions applied to the edges of each axis. It is a tuple of integer padding widths for each axis of the format `(before_1, after_1, ... , before_N, after_N)`. It should be of length `2*N` where `N` is the number of dimensions of the array.This is equivalent to pad_width in numpy.pad, but flattened.",Widths of the padding regions applied to the edges of each axis,numeric,,,,,"[0,inf)",
mxnet.image.CreateDetAugmenter,min_eject_coverage,"The minimum coverage of cropped sample w.r.t its original size. With this constraint, objects that have marginal area after crop will be discarded.",With this constraint objects that have marginal area after crop will be discarded,,,,,,,
mxnet.gluon.contrib.rnn.VariationalDropoutCell,drop_states,The dropout rate for state inputs on the first state channel. Won't apply dropout if it equals 0.,Won t apply dropout if it equals CONSTANT_NUM,,,,,,,
mxnet.ndarray.contrib.calibrate_entropy,hist_edges,A ndarray/symbol of type float32,A D_STRUCTURE symbol of type D_TYPE,D_TYPE,,D_STRUCTURE,,,,
mxnet.util.set_np,shape,"A boolean value indicating whether the NumPy-shape semantics should be turned on or off. When this flag is set to True, zero-size and zero-dim shapes are all valid shapes in shape inference process, instead of treated as unknown shapes in legacy mode.",A D_TYPE value indicating whether the NumPy shape semantics should be turned on or off,D_TYPE,,,,0,,
mxnet.test_utils.chi_square_check,generator,A function that is assumed to generate i.i.d samples from a specific distribution. generator(N) should generate N random samples.,A function that is assumed to generate i i d samples from a specific distribution,,,,,,,
mxnet.test_utils.np_reduce,numpy_reduce_func,A NumPy reducing function like `np.sum` or `np.max`.,A NumPy reducing function like np sum QSTR np max,,,,,,,
mxnet.ndarray.op.rmspropalex_update,epsilon,A small constant for numerical stability.,A small constant for numerical stability,numeric,,,,0,,
mxnet.ndarray.rmspropalex_update,epsilon,A small constant for numerical stability.,A small constant for numerical stability,numeric,,,,0,,
mxnet.ndarray.Activation,act_type,Activation function to be applied.,Activation function to be applied,,,,,,,QSTR
mxnet.gluon.nn.Dense,activation,"Activation function to use. See help on Activation layer. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",activation function to use,,,,,,,
mxnet.io.ImageRecordIter,saturation,"Add a random value in `[-saturation, saturation]` to the saturation of image.",Add a random value in BSTR to the saturation of image,,,,,,,
mxnet.io.ImageDetRecordIter,aug_seq,"Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. Make sure you don't use normal augmenters for detection tasks.",Additional keyword parameters will be seen by these augmenters,,,,,,,
mxnet.ndarray.random.uniform,low,Lower boundary of the output interval. All values generated will be greater than or equal to low. The default value is 0.,All values generated will be greater than or equal to low,,,,,,,
mxnet.ndarray.random.uniform,high,Upper boundary of the output interval. All values generated will be less than high. The default value is 1.0.,All values generated will be less than high,,,,,,,
mxnet.ndarray.op.random_generalized_negative_binomial,alpha,Alpha (dispersion) parameter of the negative binomial distribution.,alpha BSTR parameter of the negative binomial distribution,,,,,,,
mxnet.ndarray.random_pdf_gamma,alpha,Alpha (shape) parameters of the distributions.,alpha BSTR parameters of the distributions,,,,,,,
mxnet.ndarray.op.split,squeeze_axis,"If true, Removes the axis with length 1 from the shapes of the output arrays. Note that setting squeeze_axis to `true` removes axis with length 1 only along the axis which it is split. Also squeeze_axis can be set to `true` only if `input.shape[axis] == num_outputs`.",Also squeeze_axis can be set to CONSTANT_BOOL only if input shape BSTR PARAM,bool,,,,0,,
mxnet.contrib.autograd.grad,argnum,DD: an int or a list of int,an D_TYPE or a D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.topk,dtype,"DType of the output indices when ret_typ is ""indices"" or ""both"". An error will be raised if the selected data type cannot precisely represent the indices.",An error will be raised if the selected PARAM type cannot precisely represent the indices,,,,,,,
mxnet.ndarray.zeros,dtype,An optional value type (default is float32),An optional value type BSTR,numpy.dtype,,,,0,,
mxnet.ndarray.zeros2,dtype,An optional value type (default is float32),An optional value type BSTR,numpy.dtype,,,,0,,
mxnet.contrib.ndarray.box_nms,topk,"Apply nms to topk boxes with descending scores, -1 to no restriction.",Apply nms to topk boxes with descending scores CONSTANT_NUM to no restriction,,,,,,,
mxnet.io.ImageDetRecordIter,resize_mode,"Augmentation Param: How image data fit in data_shape. force: force reshape to data_shape regardless of aspect ratio; shrink: ensure each side fit in data_shape, preserve aspect ratio; fit: fit image to data_shape, preserve ratio, will upscale if applicable.",Augmentation Param How image data fit in PARAM,,,,,,,
mxnet.io.ImageDetRecordIter,max_random_contrast,Augmentation Param: Maximum random value of delta contrast.,Augmentation Param Maximum random value of delta contrast,numeric,,,,,,
mxnet.io.ImageDetRecordIter,random_illumination_prob,Augmentation Param: Probability to apply random illumination.,Augmentation Param Probability to apply random illumination,float,,,,,"[0,1]",
mxnet.io.ImageDetRecordIter,scale,Augmentation Param: Scale in color space.,Augmentation Param scale in color space,,,,,,,
mxnet.io.ImageDetRecordIter,aug_seq,"Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. Make sure you don't use normal augmenters for detection tasks.",Augmentation Param the augmenter names to represent D_STRUCTURE of augmenters to be applied seperated by comma,string,,,,0,,
mxnet.test_utils.numeric_grad,aux_states,Auxiliary states values used as location to compute gradient Maps the name of aux_states to the corresponding numpy.ndarray. Value of all the auxiliary arguments must be provided.,Auxiliary states values used as PARAM to compute gradient Maps the name of aux_states to the corresponding numpy D_STRUCTURE,,,,,,,
mxnet.ndarray.op.cumsum,axis,Axis along which the cumulative sum is computed. The default (None) is to compute the cumsum over the flattened array.,axis along which the cumulative sum is computed,int,,,,,"[0,inf)",
mxnet.io.MNISTIter,batch_size,Batch Param: Batch Size.,Batch Param Batch Size,int,,,,,"[0,inf)",
mxnet.io.ImageDetRecordIter,batch_size,Batch size.,Batch size,int,,,,,"[0,inf)",
mxnet.ndarray.ROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]], where (x1, y1) and (x2, y2) are top left and bottom right corners of designated region of interest. batch_index indicates the index of corresponding image in the input array",batch_index indicates the index of corresponding image in the input D_STRUCTURE,int,,,,0,,
mxnet.ndarray.contrib.DeformablePSROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]]. (x1, y1) and (x2, y2) are top left and down right corners of designated region of interest. batch_index indicates the index of corresponding image in the input data",batch_index indicates the index of corresponding image in the input PARAM,int,,,,0,,
mxnet.contrib.ndarray.quantized_batch_norm,beta,beta.,ONE_WORD beta,,,,,,,
mxnet.ndarray.BatchNorm,beta,beta array,beta D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.LayerNorm,beta,beta array,beta D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_conv,bias,bias.,ONE_WORD bias,,,,,,,
mxnet.ndarray.op.Deconvolution,bias,Bias added to the result after the deconvolution operation.,bias added to the result after the deconvolution operation,,,,,,,
mxnet.ndarray.FullyConnected,bias,Bias parameter.,bias parameter,,,,,,,
mxnet.image.copyMakeBorder,bot,Bottom margin.,Bottom margin,,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]]. (x1, y1) and (x2, y2) are top left and down right corners of designated region of interest. batch_index indicates the index of corresponding image in the input data",Bounding box coordinates a CONSTANT_NUM D D_STRUCTURE of BSTR,,,D_STRUCTURE,BSTR,CONSTANT_NUM,,
mxnet.ndarray.ROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]], where (x1, y1) and (x2, y2) are top left and bottom right corners of designated region of interest. batch_index indicates the index of corresponding image in the input array",Bounding box coordinates a CONSTANT_NUM D D_STRUCTURE of BSTR where BSTR are top left and bottom right corners of designated region of interest,,,D_STRUCTURE,BSTR,CONSTANT_NUM,,
mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",ONE_WORD BSTR,,,,,,,
mxnet.ndarray.op.LeakyReLU,slope,Init slope for the activation. (For leaky and elu only),ONE_WORD BSTR,,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]]. (x1, y1) and (x2, y2) are top left and down right corners of designated region of interest. batch_index indicates the index of corresponding image in the input data",BSTR are top left and down right corners of designated region of interest,,,,,,,
mxnet.image.CreateDetAugmenter,rand_pad,"[0, 1], probability to apply random padding",BSTR probability to apply random padding,float,,,,0,"[0,1]",
mxnet.contrib.ndarray.box_encode,matches,"(B, N) value range [0, M)",BSTR value range BSTR,,,,BSTR,,BSTR,
mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",But when the image is zoomed it is similar to the Nearest Neighbors method,,,,,,,
mxnet.metric.np,allow_extra_outputs,"Whether prediction output is allowed to have extra outputs. This is useful in cases like RNN where states are also part of output which can then be fed back to the RNN in the next step. By default, extra outputs are not allowed.",By default extra outputs are not allowed,,,,,,,
mxnet.ndarray.transpose,axes,Target axis order. By default the axes will be inverted.,By default the axes will be inverted,,,,,,,
mxnet.profiler.dumps,sort_by,"can take 'total', 'avg', 'min', 'max', or 'count' by which stat to sort the entries in each category defaults to 'total'",can take QSTR by which stat to sort the entries in each category defaults to QSTR,,,,,,,QSTR
mxnet.ndarray.multi_sgd_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",Clip gradient to the range of BSTR If clip_gradient REXPR gradient clipping is turned off,,,,,,BSTR,
mxnet.ndarray.op.where,condition,condition array,condition D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_trsm,lower,"True if the triangular matrix is lower triangular, false if it is upper triangular.",CONSTANT_BOOL if the triangular matrix is lower triangular CONSTANT_BOOL if it is upper triangular,bool,,,,0,,
mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Area based BSTR,,,,,,,CONSTANT_NUM
mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Bicubic interpolation over 4x4 pixel neighborhood,,,,,,,CONSTANT_NUM
mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Bilinear interpolation,,,,,,,CONSTANT_NUM
mxnet.ndarray.linalg.extracttrian,offset,"Offset of the diagonal versus the main diagonal. 0 corresponds to the main diagonal, a negative/positive value to diagonals below/above the main diagonal.",CONSTANT_NUM corresponds to the main diagonal a negative positive value to diagonals below above the main diagonal,,,,,,,CONSTANT_NUM
mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Cubic for enlarge area for shrink bilinear for others CONSTANT_NUM Random select from interpolation method metioned above,,,,,,,CONSTANT_NUM
mxnet.image.imdecode,flag,1 for three channel color output. 0 for grayscale output.,CONSTANT_NUM for grayscale output,,,,,,,CONSTANT_NUM
mxnet.image.imdecode,flag,1 for three channel color output. 0 for grayscale output.,CONSTANT_NUM for three channel color output,,,,,,,CONSTANT_NUM
mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Lanczos interpolation over 8x8 pixel neighborhood,,,,,,,CONSTANT_NUM
mxnet.gluon.contrib.rnn.Conv3DGRUCell,params,Container for weight sharing between cells. Created if None.,Container for weight sharing between cells,numeric,,,,,,
mxnet.gluon.contrib.rnn.Conv3DLSTMCell,params,Container for weight sharing between cells. Created if None.,Container for weight sharing between cells,numeric,,,,,,
mxnet.gluon.contrib.rnn.Conv3DRNNCell,params,Container for weight sharing between cells. Created if None.,Container for weight sharing between cells,numeric,,,,,,
mxnet.gluon.model_zoo.vision.vgg16_bn,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
mxnet.gluon.model_zoo.vision.densenet161,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
mxnet.gluon.model_zoo.vision.resnet152_v1,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
mxnet.gluon.model_zoo.vision.densenet121,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
mxnet.ndarray.random_generalized_negative_binomial,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls.",Context of output in format cpu gpu cpu_pinned BSTR,,,,,,,
mxnet.ndarray.contrib.arange_like,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n).Only used for imperative calls.",Context of output in format cpu gpu cpu_pinned BSTR Only used for imperative calls,,,,,,,
mxnet.ndarray.random.generalized_negative_binomial,ctx,"DD: Context, optional",Context optional,,,,,,,
mxnet.ndarray.sparse.row_sparse_array,ctx,"DD: Context, optional",Context optional,,,,,,,
mxnet.ndarray.random.uniform,ctx,"DD: Context, optional",Context optional,,,,,,,
mxnet.ndarray.random.randint,ctx,"DD: Context, optional",Context optional,,,,,,,
mxnet.ndarray.array,ctx,"DD: Context, optional",Context optional,,,,,,,
mxnet.contrib.onnx.import_to_gluon,ctx,DD: Context or list of Context,Context or D_STRUCTURE of Context,,,D_STRUCTURE,,,,
mxnet.gluon.nn.Conv2D,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",Convolution is applied on the QSTR dimensions,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,params,Container for weight sharing between cells. Created if None.,Created if None,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DLSTMCell,params,Container for weight sharing between cells. Created if None.,Created if None,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DRNNCell,params,Container for weight sharing between cells. Created if None.,Created if None,,,,,,,
mxnet.ndarray.op.all_finite,data,Array,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.MultiBoxPrior,ratios,List of aspect ratios of generated MultiBoxPriores.,D_STRUCTURE of aspect ratios of generated MultiBoxPriores,,,D_STRUCTURE,,,,
mxnet.ndarray.stack,*data,List of arrays to stack,D_STRUCTURE of D_STRUCTURE to stack,,,D_STRUCTURE,,,,
mxnet.image.CreateAugmenter,data_shape,DD: tuple of int,D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
mxnet.gluon.contrib.rnn.Conv2DRNNCell,input_shape,DD: tuple of int,D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
mxnet.gluon.nn.Dropout,axes,"DD: tuple of int, default ",D_STRUCTURE of D_TYPE default,D_TYPE,,D_STRUCTURE,,,,
mxnet.model.save_checkpoint,arg_params,DD: dict of str to NDArray,D_STRUCTURE of D_TYPE to D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.op.unravel_index,data,Array of flat indices,D_STRUCTURE of flat indices,int,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_gemm2,A,Tensor of input matrices,D_STRUCTURE of input matrices,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.linalg.potrf,A,Tensor of input matrices to be decomposed,D_STRUCTURE of input matrices to be decomposed,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.linalg_potri,A,Tensor of lower triangular matrices,D_STRUCTURE of lower triangular matrices,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.linalg_trsm,B,Tensor of matrices,D_STRUCTURE of matrices,numeric,D_STRUCTURE,,,,,
mxnet.contrib.quantization.quantize_graph,arg_params,Dictionary of name to NDArray.,D_STRUCTURE of name to D_STRUCTURE,string,,D_STRUCTURE,,,,
mxnet.contrib.quantization.quantize_graph,aux_params,Dictionary of name to NDArray.,D_STRUCTURE of name to D_STRUCTURE,string,,D_STRUCTURE,,,,
mxnet.test_utils.check_symbolic_forward,aux_states,"DD: list of np.ndarray of dict, optional",D_STRUCTURE of np D_STRUCTURE of D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.test_utils.check_symbolic_forward,expected,DD: list of np.ndarray or dict of str to np.ndarray,D_STRUCTURE of np D_STRUCTURE of D_TYPE to np D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_trsm,A,Tensor of lower triangular matrices,D_STRUCTURE of PARAM triangular matrices,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.op.linalg_trmm,A,Tensor of lower triangular matrices,D_STRUCTURE of PARAM triangular matrices,numeric,D_STRUCTURE,,,,,
mxnet.contrib.ndarray.MultiBoxPrior,ratios,"DD: tuple of <float>, optional, default=[1]",D_STRUCTURE of REXPR optional default BSTR,D_TYPE,,D_STRUCTURE,,1,,
mxnet.ndarray.op.multi_sgd_mom_update,lrs,"DD: tuple of <float>, required",D_STRUCTURE of REXPR required,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.op.multi_mp_sgd_mom_update,lrs,"DD: tuple of <float>, required",D_STRUCTURE of REXPR required,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_inverse,A,Tensor of square matrix,D_STRUCTURE of square matrix,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.op.linalg_det,A,Tensor of square matrix,D_STRUCTURE of square matrix,numeric,D_STRUCTURE,,,,,
mxnet.ndarray.op.broadcast_greater_equal,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.arccos,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_trsm,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_fully_connected,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.MultiBoxDetection,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_to,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.fft,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.arctanh,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_greater,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.multi_mp_sgd_mom_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.ones_like,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.Dropout,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.diag,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.space_to_depth,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.ROIAlign,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.ftml_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.floor,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.round_ste,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_plus,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.arctan,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_mul,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.elemwise_add,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_conv,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.image.imresize,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.fix,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.concat,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.slice_axis,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.MakeLoss,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_gelqf,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.random.normal,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.shuffle,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.SparseEmbedding,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.allclose,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sqrt,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.cast_storage,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.getnnz,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.Activation,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.SequenceReverse,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.backward_hawkesll,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.exp,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sample_poisson,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.CTCLoss,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.preloaded_multi_mp_sgd_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.MAERegressionOutput,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.ElementWiseSum,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_batch_norm,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.pad,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.Activation,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.LayerNorm,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.arccosh,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.ones,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.nag_mom_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.take,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_axes,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.log,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.random.normal_like,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_logical_and,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.nansum,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.ceil,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sinh,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.AdaptiveAvgPooling2D,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.mp_lamb_update_phase1,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_poisson,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.cosh,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_gelqf,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.erfinv,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.cast_storage,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.sample_exponential,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.op.log1p,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
mxnet.ndarray.LRN,nsize,"DD: int (non-negative), required",D_TYPE BSTR required,D_TYPE,,,,,"[0,inf)",
mxnet.io.ImageDetRecordIter,batch_size,"DD: int (non-negative), required",D_TYPE BSTR required,D_TYPE,,,,,"[0,inf)",
mxnet.recordio.unpack,s,String buffer from `MXRecordIO.read`.,D_TYPE buffer from MXRecordIO read,D_TYPE,,,,,,
mxnet.gluon.model_zoo.vision.alexnet,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
mxnet.gluon.model_zoo.vision.vgg19,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
mxnet.gluon.utils.split_data,even_split,"DD: bool, default True",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
mxnet.gluon.nn.BatchNorm,scale,"DD: bool, default True",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
mxnet.gluon.model_zoo.vision.densenet121,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
mxnet.gluon.model_zoo.vision.vgg11_bn,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
mxnet.gluon.nn.AvgPool1D,count_include_pad,"DD: bool, default True",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
mxnet.gluon.model_zoo.vision.vgg13,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
mxnet.gluon.model_zoo.vision.resnet50_v2,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
mxnet.gluon.nn.LayerNorm,epsilon,"DD: float, default 1e-5",D_TYPE default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.gluon.nn.GroupNorm,num_groups,"DD: int, default 1",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.nn.Conv2DTranspose,in_channels,"DD: int, default 0",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.rnn.RNN,input_size,"DD: int, default 0",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.gluon.model_zoo.vision.resnet152_v2,root,"DD: str, default '$MXNET_HOME/models'",D_TYPE default MXNET_HOME models,D_TYPE,,,,,,
mxnet.gluon.model_zoo.vision.inception_v3,root,"DD: str, default $MXNET_HOME/models",D_TYPE default MXNET_HOME models,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv1DLSTMCell,prefix,"DD: str, default `'conv_lstm_`’",D_TYPE default QSTR,D_TYPE,,,,,,
mxnet.gluon.nn.MaxPool3D,layout,"DD: str, default 'NCDHW'",D_TYPE default QSTR,D_TYPE,,,,,,
mxnet.gluon.rnn.RNN,layout,"DD: str, default 'TNC'",D_TYPE default QSTR,D_TYPE,,,,,,
mxnet.gluon.rnn.GRUCell,prefix,"DD: str, default `'gru_'`",D_TYPE default QSTR,D_TYPE,,,,,,
mxnet.gluon.nn.MaxPool1D,layout,"DD: str, default 'NCW'",D_TYPE default QSTR,D_TYPE,,,,,,
mxnet.gluon.nn.Conv2D,layout,"DD: str, default 'NCHW'",D_TYPE default QSTR,D_TYPE,,,,,,
mxnet.gluon.nn.MaxPool2D,layout,"DD: str, default 'NCHW'",D_TYPE default QSTR,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv1DGRUCell,prefix,"DD: str, default `'conv_gru_`’",D_TYPE default QSTR,D_TYPE,,,,,,
mxnet.ndarray.zeros,dtype,"DD: str or numpy.dtype, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.context.cpu,device_id,"DD: int, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.ndarray.zeros2,dtype,"DD: str or numpy.dtype, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.ndarray.arange,dtype,"DD: str or numpy.dtype, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.ndarray.zeros,stype,"DD: string, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.gluon.utils.download,sha1_hash,"DD: str, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.test_utils.download,overwrite,"DD: bool, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.callback.do_checkpoint,period,"DD: int, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.test_utils.assert_almost_equal,equal_nan,"DD: boolean, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.metric.np,allow_extra_outputs,"DD: bool, optional",D_TYPE optional,D_TYPE,,,,,,
mxnet.ndarray.contrib.arange_like,ctx,"DD: string, optional, default=''",D_TYPE optional default,D_TYPE,,,,,,
mxnet.ndarray.random_generalized_negative_binomial,ctx,"DD: string, optional, default=''",D_TYPE optional default,D_TYPE,,,,,,
mxnet.ndarray.rmspropalex_update,epsilon,"DD: float, optional, default=9.99999994e-09",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.contrib.ndarray.quantized_batch_norm,eps,"DD: double, optional, default=0.0010000000474974513",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.op.LeakyReLU,slope,"DD: float, optional, default=0.25",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.op.rmspropalex_update,epsilon,"DD: float, optional, default=9.99999994e-09",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.op.BatchNorm,eps,"DD: double, optional, default=0.0010000000474974513",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.ndarray.contrib.MultiProposal,threshold,"DD: float, optional, default=0.699999988",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,num_parts,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.random_pdf_generalized_negative_binomial,is_log,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.random.negative_binomial_like,p,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.signsgd_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.Convolution,cudnn_off,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.rmsprop_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.bipartite_matching,topk,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.linalg_trmm,transpose,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.sgd_mom_update,lazy_update,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.ftrl_update,wd,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.random.normal_like,loc,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg_trsm,rightside,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.SoftmaxOutput,ignore_label,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.box_nms,topk,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.max_axis,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.SyncBatchNorm,use_global_stats,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.quantized_batch_norm,use_global_stats,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.max,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.nansum,exclude,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.linalg_trsm,rightside,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.multi_sgd_update,clip_gradient,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.sample_multinomial,get_prob,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.sparse.adam_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.multi_lars,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.MNISTIter,batch_size,"DD: int, optional, default='128'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.diag,axis2,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,saturation,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.box_nms,id_index,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.diag,axis2,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.random_pdf_gamma,is_log,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg_gemm,transpose_a,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.sparse.mean,exclude,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.signsgd_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.PSROIPooling,group_size,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.ftrl_update,beta,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.ftml_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.min_axis,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.random_generalized_negative_binomial,alpha,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.image.imresize,interp,"DD: int, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.sum_axis,exclude,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.SwapAxis,dim2,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.random_normal,scale,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.linalg_trsm,lower,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.BatchNorm,fix_gamma,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,scale,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.nanprod,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.quantized_fully_connected,flatten,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.arange_like,step,"DD: double, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.MakeLoss,grad_scale,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.random_generalized_negative_binomial,mu,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.SequenceLast,axis,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.BatchNorm,use_global_stats,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.SequenceMask,value,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.quantized_batch_norm,output_mean_var,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.ROIAlign,sample_ratio,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.linalg.extracttrian,offset,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.Softmax,preserve_shape,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.GroupNorm,output_mean_var,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.argmin,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.RNN,state_outputs,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.box_nms,id_index,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,mean_g,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.image.imdecode,flag,"DD: int, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.random_negative_binomial,k,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.multi_sgd_mom_update,momentum,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.mp_nag_mom_update,wd,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.mp_sgd_update,lazy_update,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.MultiProposal,feature_stride,"DD: int, optional, default='16'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.linalg_trmm,rightside,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.box_nms,background_id,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.calibrate_entropy,num_quantized_bins,"DD: int, optional, default='255'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,random_illumination_prob,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.nansum,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.SequenceMask,use_sequence_length,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,max_random_contrast,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.SoftmaxOutput,preserve_shape,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.split,squeeze_axis,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.quantized_fully_connected,no_bias,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageRecordIter,verbose,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.linalg_gemm,transpose_a,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.UpSampling,num_filter,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.contrib.box_decode,std2,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.RNN,lstm_state_clip_nan,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.ROIAlign,sample_ratio,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.GroupNorm,num_groups,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.op.multi_mp_sgd_mom_update,momentum,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.contrib.ndarray.MultiProposal,rpn_pre_nms_top_n,"DD: int, optional, default='6000'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.ndarray.random_normal,loc,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
mxnet.io.ImageDetRecordIter,aug_seq,"DD: string, optional, default='det_aug_default'",D_TYPE optional default QSTR,D_TYPE,,,,,,
mxnet.io.MNISTIter,image,"DD: string, optional, default='./train-images-idx3-ubyte'",D_TYPE optional default train images idx3 ubyte,D_TYPE,,,,,,
mxnet.gluon.nn.Conv3DTranspose,padding,"DD: int or a tuple/list of 3 int,",D_TYPE or a D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
mxnet.ndarray.random.randn,scale,DD: float or NDArray,D_TYPE or D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.gluon.nn.Conv1DTranspose,kernel_size,DD: int or tuple/list of 1 int,D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
mxnet.gluon.nn.Conv3D,dilation,DD: int or tuple/list of 3 int,D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
mxnet.gluon.nn.Conv3DTranspose,strides,DD: int or tuple/list of 3 int,D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,i2h_kernel,DD: int or tuple of int,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
mxnet.gluon.contrib.rnn.Conv2DLSTMCell,h2h_kernel,DD: int or tuple of int,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
mxnet.gluon.contrib.rnn.Conv1DGRUCell,h2h_dilate,"DD: int or tuple of int, default (1,",D_TYPE or D_STRUCTURE of D_TYPE default CONSTANT_NUM,D_TYPE,,D_STRUCTURE,,,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,i2h_dilate,"DD: int or tuple of int, default (1,",D_TYPE or D_STRUCTURE of D_TYPE default CONSTANT_NUM,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.random.gamma,shape,"DD: int or tuple of ints, optional",D_TYPE or D_STRUCTURE of D_TYPE optional,D_TYPE,,D_STRUCTURE,,,,
mxnet.test_utils.check_symbolic_backward,grad_req,"DD: str or list of str or dict of str to str, optional",D_TYPE or D_STRUCTURE of D_TYPE or D_STRUCTURE of D_TYPE to D_TYPE optional,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.random.uniform,low,"DD: float or NDArray, optional",D_TYPE or D_STRUCTURE optional,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.random.uniform,high,"DD: float or NDArray, optional",D_TYPE or D_STRUCTURE optional,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.random.gamma,alpha,"DD: float or NDArray, optional",D_TYPE or D_STRUCTURE optional,D_TYPE,,D_STRUCTURE,,,,
mxnet.gluon.nn.Conv3DTranspose,weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.nn.Dense,bias_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.rnn.RNNCell,i2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,i2h_bias_initializer,"DD: str or Initializer, default zeros",D_TYPE or Initializer default zeros,D_TYPE,,,,,,
mxnet.ndarray.op.softmin,use_length,"DD: boolean or None, optional, default=0",D_TYPE or None optional default CONSTANT_NUM,D_TYPE,,,,,,
mxnet.ndarray.BatchNorm,max_calib_range,"DD: float or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.ndarray.contrib.requantize,max_calib_range,"DD: float or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.contrib.ndarray.BilinearResize2D,scale_width,"DD: float or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
mxnet.io.ImageRecordIter,seed_aug,"DD: int or None, optional, default='None'",D_TYPE or None optional default QSTR,D_TYPE,,,,,,
mxnet.ndarray.op.cumsum,axis,"DD: int or None, optional, default='None'",D_TYPE or None optional default QSTR,D_TYPE,,,,,,
mxnet.ndarray.sgd_mom_update,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.split,num_outputs,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.repeat,repeats,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.contrib.ndarray.interleaved_matmul_encdec_qk,heads,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.image.copyMakeBorder,right,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.ftrl_update,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.contrib.ndarray.SparseEmbedding,input_dim,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.ftml_update,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.image.copyMakeBorder,bot,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.adam_update,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.ROIPooling,spatial_scale,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.image.copyMakeBorder,left,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.mp_lamb_update_phase2,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
mxnet.ndarray.op.gather_nd,data,data,ONE_WORD data,,,,,,,
mxnet.ndarray.scatter_nd,data,data,ONE_WORD data,,,,,,,
mxnet.ndarray.shuffle,data,Data to be shuffled.,data to be shuffled,,,,,,,
mxnet.ndarray.random.gamma,dtype,Data type of output samples. Default is 'float32',Data type of output samples,numpy.dtype,,,,,,
mxnet.ndarray.random.generalized_negative_binomial,dtype,Data type of output samples. Default is 'float32',Data type of output samples,numpy.dtype,,,,,,
mxnet.io.MNISTIter,image,Dataset Param: Mnist image path.,Dataset Param Mnist image path,,,,,,,
mxnet.test_utils.download,overwrite,"Default is false, which means skipping download if the local file exists. If true, then download the url to overwrite the local file if exists.",Default is CONSTANT_BOOL which means skipping download if the local file exists,bool,,,,0,,
mxnet.ndarray.random.generalized_negative_binomial,ctx,Device context of output. Default is current context. Overridden by mu.context when mu is an NDArray.,Default is current context,,,,,,,
mxnet.ndarray.random.randint,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Default is current context,,,,,,,
mxnet.ndarray.random.randn,ctx,Device context of output. Default is current context. Overridden by loc.context when loc is an NDArray.,Default is current context,,,,,,,
mxnet.ndarray.random.uniform,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Default is current context,,,,,,,
mxnet.ndarray.random.gamma,dtype,Data type of output samples. Default is 'float32',Default is QSTR,,,,,,,
mxnet.ndarray.random.generalized_negative_binomial,dtype,Data type of output samples. Default is 'float32',Default is QSTR,,,,,,,
mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",Default is QSTR,,,,,,,
mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",Default is QSTR,,,,,,,
mxnet.callback.do_checkpoint,period,Interval (number of epochs) between checkpoints. Default period is 1.,Default period is CONSTANT_NUM,,,,,,,
mxnet.ndarray.op.random_negative_binomial,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,,,,,,,
mxnet.ndarray.random_uniform,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,,,,,,,
mxnet.ndarray.sample_exponential,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,,,,,,,
mxnet.ndarray.rmspropalex_update,delta,delta,ONE_WORD delta,,,,,,,
mxnet.ndarray.array,ctx,Device context (default is the current default context).,Device context BSTR,,,,,,,
mxnet.ndarray.sparse.row_sparse_array,ctx,Device context (default is the current default context).,Device context BSTR,,,,,,,
mxnet.ndarray.random.generalized_negative_binomial,ctx,Device context of output. Default is current context. Overridden by mu.context when mu is an NDArray.,Device context of output,,,,,,,
mxnet.ndarray.random.randint,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Device context of output,,,,,,,
mxnet.ndarray.random.randn,ctx,Device context of output. Default is current context. Overridden by loc.context when loc is an NDArray.,Device context of output,,,,,,,
mxnet.ndarray.random.uniform,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Device context of output,,,,,,,
mxnet.context.cpu,device_id,The device id of the device. device_id is not needed for CPU. This is included to make interface compatible with GPU.,device_id is not needed for CPU,int,,,,0,"[0,inf)",
mxnet.gluon.nn.MaxPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Pooling is applied on the W dimension.",Dimension ordering of data and out QSTR,,,,,,,
mxnet.gluon.nn.MaxPool2D,layout,"Dimension ordering of data and out ('NCHW' or 'NHWC'). 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. padding is applied on 'H' and 'W' dimension.",Dimension ordering of data and out QSTR,,,,,,,
mxnet.gluon.nn.MaxPool3D,layout,"Dimension ordering of data and out ('NCDHW' or 'NDHWC'). 'N', 'C', 'H', 'W', 'D' stands for batch, channel, height, width and depth dimensions respectively. padding is applied on 'D', 'H' and 'W' dimension.",Dimension ordering of data and out QSTR,,,,,,,
mxnet.gluon.nn.Conv2D,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",Dimension ordering of data and weight,numeric,,,,,,
mxnet.ndarray.op.sample_multinomial,data,Distribution probabilities. Must sum to one on the last axis.,Distribution probabilities,,,,,,,
mxnet.ndarray.op.random_negative_binomial,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,dtype of the output in case this can t be inferred,numpy.dtype,,,,,,
mxnet.ndarray.random_uniform,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,dtype of the output in case this can t be inferred,numpy.dtype,,,,,,
mxnet.ndarray.sample_exponential,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,dtype of the output in case this can t be inferred,numpy.dtype,,,,,,
mxnet.ndarray.topk,dtype,"DType of the output indices when ret_typ is ""indices"" or ""both"". An error will be raised if the selected data type cannot precisely represent the indices.",dtype of the output indices when PARAM is QSTR,numpy.dtype,,,,,,
mxnet.recordio.pack_img,img_fmt,"Encoding of the image (.jpg for JPEG, .png for PNG).",Encoding of the image BSTR,,,,,,,
mxnet.contrib.ndarray.quantized_batch_norm,eps,Epsilon to prevent div 0. Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn.h when using cudnn (usually 1e-5),Epsilon to prevent div CONSTANT_NUM,numeric,,,,,,
mxnet.ndarray.op.BatchNorm,eps,Epsilon to prevent div 0. Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn.h when using cudnn (usually 1e-5),Epsilon to prevent div CONSTANT_NUM,numeric,,,,,,
mxnet.ndarray.ROIPooling,spatial_scale,Ratio of input feature map height (or w) to raw image height (or w). Equals the reciprocal of total stride in convolutional layers,Equals the reciprocal of total stride in convolutional layers,,,,,,,
mxnet.gluon.utils.download,sha1_hash,Expected sha1 hash in hexadecimal digits. Will ignore existing file when hash is specified but doesn't match.,Expected sha1 hash in hexadecimal digits,,,,,,,
mxnet.ndarray.sample_negative_binomial,p,Failure probabilities in each experiment.,Failure probabilities in each experiment,float,,,,,"[0,1]",
mxnet.ndarray.random.negative_binomial_like,p,Failure probability in each experiment.,Failure probability in each experiment,float,,,,,"[0,1]",
mxnet.ndarray.full,val,Fill value.,Fill value,,,,,,,
mxnet.ndarray.sparse.add,lhs,First array to be added.,First D_STRUCTURE to be added,,,D_STRUCTURE,,,,
mxnet.ndarray.minimum,lhs,First array to be compared.,First D_STRUCTURE to be compared,,,D_STRUCTURE,,,,
mxnet.ndarray.subtract,lhs,First array to be subtracted.,First D_STRUCTURE to be subtracted,,,D_STRUCTURE,,,,
mxnet.ndarray.elemwise_div,lhs,first input,first input,,,,,,,
mxnet.ndarray.op.elemwise_add,lhs,first input,first input,,,,,,,
mxnet.ndarray.op.reshape_like,lhs,First input.,First input,,,,,,,
mxnet.ndarray.sparse.elemwise_add,lhs,first input,first input,,,,,,,
mxnet.ndarray.sparse.elemwise_sub,lhs,first input,first input,,,,,,,
mxnet.ndarray.broadcast_not_equal,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.op.broadcast_add,lhs,First input to the function,First input to the function,,,,,,,
mxnet.ndarray.contrib.PSROIPooling,group_size,fix group size,fix group size,int,,,,,"[0,inf)",
mxnet.ndarray.BatchNorm,fix_gamma,Fix gamma while training,Fix PARAM while training,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DRNNCell,input_shape,"Input tensor shape at each time step for each sample, excluding dimension of the batch size and sequence length. Must be consistent with conv_layout. For example, for layout 'NCHW' the shape should be (C, H, W).",For example for layout QSTR the shape should be BSTR,,,,,,,
mxnet.io.ImageDetRecordIter,resize_mode,"Augmentation Param: How image data fit in data_shape. force: force reshape to data_shape regardless of aspect ratio; shrink: ensure each side fit in data_shape, preserve aspect ratio; fit: fit image to data_shape, preserve ratio, will upscale if applicable.",force force reshape to PARAM regardless of aspect ratio shrink ensure each side fit in PARAM preserve aspect ratio fit fit image to PARAM preserve ratio will upscale if applicable,,,,,,,
mxnet.ndarray.rmspropalex_update,g,g,ONE_WORD g,,,,,,,
mxnet.test_utils.chi_square_check,generator,A function that is assumed to generate i.i.d samples from a specific distribution. generator(N) should generate N random samples.,generator BSTR should generate N random samples,,,,,,,
mxnet.ndarray.multi_sgd_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",grad max BSTR,,,,,,,
mxnet.ndarray.contrib.group_adagrad_update,grad,Gradient,ONE_WORD Gradient,numeric,,,,,,
mxnet.ndarray.ftrl_update,grad,Gradient,ONE_WORD Gradient,numeric,,,,,,
mxnet.ndarray.mp_lamb_update_phase1,grad,Gradient,ONE_WORD Gradient,numeric,,,,,,
mxnet.ndarray.op.signum_update,grad,Gradient,ONE_WORD Gradient,numeric,,,,,,
mxnet.ndarray.signum_update,grad,Gradient,ONE_WORD Gradient,numeric,,,,,,
mxnet.test_utils.check_symbolic_backward,grad_req,"Gradient requirements. 'write', 'add' or 'null'.",Gradient requirements,,,,,,,
mxnet.ndarray.multi_lars,rescale_grad,Gradient rescaling factor,Gradient rescaling factor,,,,,,,
mxnet.ndarray.MakeLoss,grad_scale,Gradient scale as a supplement to unary and binary operators,Gradient scale as a supplement to unary and binary operators,,,,,,,
mxnet.ndarray.contrib.CTCLoss,label,Ground-truth labels for the loss.,Ground truth labels for the loss,,,,,,,
mxnet.ndarray.ctc_loss,label,Ground-truth labels for the loss.,Ground truth labels for the loss,,,,,,,
mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is a D_STRUCTURE of D_TYPE a reduction is performed on all the axes specified in the D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is a D_STRUCTURE of D_TYPE a reduction is performed on all the axes specified in the D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is D_TYPE a reduction is performed on a particular axis,D_TYPE,,,,,,
mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is D_TYPE a reduction is performed on a particular axis,D_TYPE,,,,,,
mxnet.contrib.quantization.quantize_model,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",If calib_mode QSTR BSTR the thresholds for quantization will be derived such that the KL divergence between the distributions of D_TYPE layer outputs and quantized layer outputs is minimized based upon the calibration dataset,,,,,,,QSTR
mxnet.contrib.quantization.quantize_model,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",If calib_mode QSTR no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators,,,,,,,QSTR
mxnet.contrib.quantization.quantize_model,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",If calib_mode QSTR the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization,,,,,,,QSTR
mxnet.ndarray.RNN,lstm_state_clip_nan,"Whether to stop NaN from propagating in state by clipping it to min/max. If clipping range is not specified, this option is ignored.",If clipping range is not specified this option is ignored,,,,,,,
mxnet.gluon.utils.split_data,even_split,"Whether to force all slices to have the same number of elements. If True, an error will be raised when num_slice does not evenly divide data.shape[batch_axis].",If CONSTANT_BOOL an error will be raised when PARAM does not evenly divide PARAM shape BSTR,bool,,,,0,,
mxnet.gluon.nn.BatchNorm,scale,"If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.",If CONSTANT_BOOL gamma is not used,bool,,,,0,,
mxnet.ndarray.op.mp_sgd_update,lazy_update,"If true, lazy updates are applied if gradient's stype is row_sparse.",If CONSTANT_BOOL lazy updates are applied if gradient stype is row_sparse,bool,,,,0,,
mxnet.ndarray.op.sgd_mom_update,lazy_update,"If true, lazy updates are applied if gradient's stype is row_sparse and both weight and momentum have the same stype",If CONSTANT_BOOL lazy updates are applied if gradient stype is row_sparse and both PARAM and PARAM have the same stype,bool,,,,0,,
mxnet.gluon.nn.BatchNorm,scale,"If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.",If CONSTANT_BOOL multiply by gamma,bool,,,,0,,
mxnet.ndarray.op.split,squeeze_axis,"If true, Removes the axis with length 1 from the shapes of the output arrays. Note that setting squeeze_axis to `true` removes axis with length 1 only along the axis which it is split. Also squeeze_axis can be set to `true` only if `input.shape[axis] == num_outputs`.",If CONSTANT_BOOL Removes the PARAM with length CONSTANT_NUM from the shapes of the output D_STRUCTURE,bool,,,,0,,
mxnet.test_utils.download,overwrite,"Default is false, which means skipping download if the local file exists. If true, then download the url to overwrite the local file if exists.",If CONSTANT_BOOL then download the PARAM to overwrite the local file if exists,bool,,,,0,,
mxnet.gluon.nn.Dropout,axes,"The axes on which dropout mask is shared. If empty, regular dropout is applied.",If empty regular dropout is applied,,,,,,,
mxnet.gluon.nn.Conv2DTranspose,in_channels,"The number of input channels to this layer. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",If not specified initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data,,,,,,,
mxnet.gluon.rnn.RNN,input_size,"The number of expected features in the input x. If not specified, it will be inferred from input.",If not specified it will be inferred from input,,,,,,,
mxnet.io.ImageRecordIter,verbose,If or not output verbose information.,If or not output verbose information,,,,,,,
mxnet.gluon.nn.Conv3DTranspose,padding,"If padding is non-zero, then the input is implicitly zero-padded on both sides for padding number of points",If padding is non zero then the input is implicitly zero padded on both sides for padding number of points,,,,,,,
mxnet.ndarray.random.gamma,shape,"The number of samples to draw. If shape is, e.g., (m, n) and alpha and beta are scalars, output shape will be (m, n). If alpha and beta are NDArrays with shape, e.g., (x, y), then output will have shape (x, y, m, n), where m*n samples are drawn for each [alpha, beta) pair.",If PARAM and PARAM are NDArrays with shape e g BSTR where m n samples are drawn for each BSTR pair,,,,,,,
mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If PARAM is CONSTANT_BOOL reduction will be performed on the axes that are NOT in axis instead,,,,,,,
mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If PARAM is CONSTANT_BOOL reduction will be performed on the axes that are NOT in axis instead,,,,,,,
mxnet.ndarray.equal,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",If PARAM shape rhs shape they must be broadcastable to a common shape,,,,,,,
mxnet.ndarray.minimum,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",If PARAM shape rhs shape they must be broadcastable to a common shape,,,,,,,
mxnet.ndarray.sparse.subtract,rhs,"Second array to be subtracted. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.__spec__",If PARAM shape rhs shape they must be broadcastable to a common shape spec,,,,,,,
mxnet.ndarray.BatchNorm,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to by quantized batch norm op to calculate primitive scale.Note: this calib_range is to calib bn output.",If present it will be used to by quantized batch norm op to calculate primitive scale Note this calib_range is to calib bn output,,,,,,,
mxnet.ndarray.contrib.requantize,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to requantize the int32 data into int8.",If present it will be used to requantize the D_TYPE PARAM into D_TYPE,,,,,,,
mxnet.ndarray.ctc_loss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",If QSTR last PARAM value QSTR is reserved for blank PARAM instead and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
mxnet.ndarray.CTCLoss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",If QSTR last PARAM value QSTR is reserved for blank PARAM instead and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
mxnet.ndarray.op.ctc_loss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",If QSTR last PARAM value QSTR is reserved for blank PARAM instead and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
mxnet.ndarray.op.random_pdf_generalized_negative_binomial,is_log,"If set, compute the density of the log-probability instead of the probability.",If set compute the density of the log probability instead of the probability,,,,,,,
mxnet.ndarray.random_pdf_gamma,is_log,"If set, compute the density of the log-probability instead of the probability.",If set compute the density of the log probability instead of the probability,,,,,,,
mxnet.ndarray.op.Softmax,preserve_shape,"If set to `true`, the softmax function will be computed along the last axis (`-1`).",If set to CONSTANT_BOOL the softmax function will be computed along the last axis CONSTANT_NUM,bool,,,,0,,
mxnet.ndarray.op.SoftmaxOutput,preserve_shape,"If set to `true`, the softmax function will be computed along the last axis (`-1`).",If set to CONSTANT_BOOL the softmax function will be computed along the last axis CONSTANT_NUM,bool,,,,0,,
mxnet.ndarray.op.SequenceMask,use_sequence_length,"If set to true, this layer takes in an extra input parameter sequence_length to specify variable length sequence",If set to CONSTANT_BOOL this layer takes in an extra input parameter PARAM to specify variable length D_STRUCTURE,bool,,,,0,,
mxnet.ndarray.random.gamma,shape,"The number of samples to draw. If shape is, e.g., (m, n) and alpha and beta are scalars, output shape will be (m, n). If alpha and beta are NDArrays with shape, e.g., (x, y), then output will have shape (x, y, m, n), where m*n samples are drawn for each [alpha, beta) pair.",If shape is e g BSTR,,,,BSTR,,,
mxnet.ndarray.min_axis,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
mxnet.ndarray.nansum,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
mxnet.ndarray.op.max,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
mxnet.ndarray.op.max_axis,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
mxnet.ndarray.op.nanprod,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
mxnet.ndarray.argmin,keepdims,"If this is set to True, the reduced axis is left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced PARAM is left in the result as dimension with size one,bool,,,,0,,
mxnet.test_utils.check_symbolic_forward,aux_states,if type is list of np.ndarrayContains all the NumPy arrays corresponding to sym.list_auxiliary_states,if type is D_STRUCTURE of np ndarrayContains all the NumPy D_STRUCTURE corresponding to PARAM list_auxiliary_states,,,D_STRUCTURE,,,,
mxnet.gluon.nn.Dense,activation,"Activation function to use. See help on Activation layer. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",If you don t specify anything no activation is applied ie,,,,,,,
mxnet.ndarray.diag,axis2,The second axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,Ignored when the input is a CONSTANT_NUM D D_STRUCTURE,,,,,,,
mxnet.ndarray.op.diag,axis2,The second axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,Ignored when the input is a CONSTANT_NUM D D_STRUCTURE,,,,,,,
mxnet.ndarray.sample_multinomial,get_prob,"Whether to also return the log probability of sampled result. This is usually used for differentiating through stochastic variables, e.g. in reinforcement learning.",in reinforcement learning,,,,,,,
mxnet.ndarray.op.LeakyReLU,slope,Init slope for the activation. (For leaky and elu only),Init slope for the activation,,,,,,,
mxnet.gluon.nn.Dense,bias_initializer,Initializer for the bias vector.,Initializer for the bias D_STRUCTURE,,,,,,,
mxnet.gluon.nn.PReLU,alpha_initializer,Initializer for the embeddings matrix.,Initializer for the embeddings matrix,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DGRUCell,i2h_bias_initializer,Initializer for the input convolution bias vectors.,Initializer for the input convolution bias D_STRUCTURE,,,,,,,
mxnet.gluon.rnn.RNNCell,i2h_weight_initializer,"Initializer for the input weights matrix, used for the linear transformation of the inputs.",Initializer for the input weights matrix used for the linear transformation of the inputs,,,,,,,
mxnet.gluon.nn.Conv3DTranspose,weight_initializer,Initializer for the weight weights matrix.,Initializer for the weight weights matrix,,,,,,,
mxnet.gluon.contrib.rnn.Conv1DRNNCell,i2h_dilate,Input convolution dilate.,Input convolution dilate,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,i2h_kernel,Input convolution kernel sizes.,Input convolution kernel sizes,int,,,,,"[0,inf)",
mxnet.ndarray.depth_to_space,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.image.to_tensor,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.ctc_loss,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.CTCLoss,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.SoftmaxOutput,data,Input array.,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.swapaxes,data,Input array.,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.SoftmaxOutput,data,Input array.,Input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.gluon.contrib.rnn.Conv2DRNNCell,input_shape,"Input tensor shape at each time step for each sample, excluding dimension of the batch size and sequence length. Must be consistent with conv_layout. For example, for layout 'NCHW' the shape should be (C, H, W).",Input D_STRUCTURE shape at each time step for each sample excluding dimension of the batch size and D_STRUCTURE length,int,,,,,"[0,inf)",
mxnet.contrib.ndarray.quantized_act,data,Input data.,Input data,,,,,,,
mxnet.ndarray.to_dlpack_for_write,data,input data.,input data,,,,,,,
mxnet.ndarray.RNN,data,Input data to RNN,Input data to RNN,,,,,,,
mxnet.contrib.ndarray.fft,data,Input data to the FFTOp.,Input data to the FFTOp,,,,,,,
mxnet.ndarray.contrib.PSROIPooling,data,"Input data to the pooling operator, a 4D Feature maps",Input data to the pooling operator a CONSTANT_NUM D Feature maps,,,,,,,
mxnet.ndarray.UpSampling,num_filter,"Input filter. Only used by bilinear sample_type.Since bilinear upsampling uses deconvolution, num_filters is set to the number of channels.",Input filter,,,,,,,
mxnet.ndarray.op.softmax_cross_entropy,label,Input label,Input label,,,,,,,
mxnet.ndarray.LogisticRegressionOutput,label,Input label to the function.,Input label to the function,,,,,,,
mxnet.ndarray.sparse.MAERegressionOutput,label,Input label to the function.,Input label to the function,,,,,,,
mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",Interpolation method default cv2 INTER_LINEAR,,,,,,,
mxnet.callback.do_checkpoint,period,Interval (number of epochs) between checkpoints. Default period is 1.,Interval BSTR between checkpoints,,,,,,,
mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",It may be a preferred method for image decimation as it gives moire free results,,,,,,,
mxnet.contrib.ndarray.gradientmultiplier,scalar,lambda multiplier,lambda multiplier,,,,,,,
mxnet.ndarray.mp_lamb_update_phase2,lr,Learning rate,Learning rate,numeric,,,,0,"[0,1]",
mxnet.ndarray.op.adam_update,lr,Learning rate,Learning rate,numeric,,,,0,"[0,1]",
mxnet.ndarray.op.ftml_update,lr,Learning rate.,Learning rate,numeric,,,,0,"[0,1]",
mxnet.ndarray.op.ftrl_update,lr,Learning rate,Learning rate,numeric,,,,0,"[0,1]",
mxnet.ndarray.sgd_mom_update,lr,Learning rate,Learning rate,numeric,,,,0,"[0,1]",
mxnet.ndarray.op.multi_mp_sgd_mom_update,lrs,Learning rates.,Learning rates,numeric,,,,1,"[0,1]",
mxnet.ndarray.op.multi_sgd_mom_update,lrs,Learning rates.,Learning rates,numeric,,,,1,"[0,1]",
mxnet.image.copyMakeBorder,left,Left margin.,left margin,,,,,,,
mxnet.ndarray.contrib.CTCLoss,label_lengths,Lengths of labels for each of the samples. Only required when use_label_lengths is true.,Lengths of labels for each of the samples,int,,,,,"[0,inf)",
mxnet.ndarray.op.CTCLoss,label_lengths,Lengths of labels for each of the samples. Only required when use_label_lengths is true.,Lengths of labels for each of the samples,int,,,,,"[0,inf)",
mxnet.ndarray.contrib.CTCLoss,data_lengths,Lengths of data for each of the samples. Only required when use_data_lengths is true.,Lengths of PARAM for each of the samples,int,,,,,"[0,inf)",
mxnet.ndarray.op.random_negative_binomial,k,Limit of unsuccessful experiments.,Limit of unsuccessful experiments,,,,,,,
mxnet.ndarray.contrib.bipartite_matching,topk,"Limit the number of matches to topk, set -1 for no limit",Limit the number of matches to topk set CONSTANT_NUM for no limit,,,,,,,
mxnet.contrib.onnx.import_to_gluon,ctx,Loads the model into one or many context(s).,Loads the model into one or many context BSTR,,,,,,,
mxnet.gluon.model_zoo.vision.inception_v3,root,Location for keeping the model parameters.,Location for keeping the model parameters,,,,,,,
mxnet.gluon.model_zoo.vision.resnet152_v2,root,Location for keeping the model parameters.,Location for keeping the model parameters,,,,,,,
mxnet.contrib.ndarray.MultiBoxDetection,loc_pred,Location regression predictions.,Location regression predictions,,,,,,,
mxnet.io.ImageDetRecordIter,prefetch_buffer,"DD: long (non-negative), optional, default=4",long BSTR optional default CONSTANT_NUM,D_TYPE,,,,0,"[0,inf)",
mxnet.ndarray.random.uniform,low,Lower boundary of the output interval. All values generated will be greater than or equal to low. The default value is 0.,Lower boundary of the output interval,,,,,,,
mxnet.io.ImageDetRecordIter,aug_seq,"Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. Make sure you don't use normal augmenters for detection tasks.",Make sure you don t use normal augmenters for detection tasks,,,,,,,
mxnet.io.ImageDetRecordIter,prefetch_buffer,Maximum number of batches to prefetch.,Maximum number of batches to prefetch,int,,,,0,"[0,inf)",
mxnet.ndarray.contrib.quantized_conv,max_bias,Maximum value of bias.,Maximum value of PARAM,numeric,,,,,,
mxnet.ndarray.contrib.quantized_fully_connected,max_bias,Maximum value of bias.,Maximum value of PARAM,numeric,,,,,,
mxnet.contrib.ndarray.quantized_batch_norm,max_data,Maximum value of data.,Maximum value of PARAM,numeric,,,,,,
mxnet.ndarray.contrib.quantized_conv,max_weight,Maximum value of weight.,Maximum value of PARAM,numeric,,,,,,
mxnet.ndarray.random_normal,loc,Mean of the distribution.,Mean of the distribution,numeric,,,,0,,
mxnet.ndarray.random.normal_like,loc,Mean of the distribution.,Mean of the distribution,numeric,,,,0,,
mxnet.ndarray.op.random_generalized_negative_binomial,mu,Mean of the negative binomial distribution.,Mean of the negative binomial distribution,numeric,,,,0,,
mxnet.ndarray.sample_generalized_negative_binomial,mu,Means of the distributions.,Means of the distributions,numeric,,,,1,,
mxnet.model.save_checkpoint,arg_params,"Model parameter, dict of name to NDArray of net's weights.",Model parameter D_STRUCTURE of name to D_STRUCTURE of net weights,string,,D_STRUCTURE,,,,
mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",More details can be found in the documentation of OpenCV please refer to http docs opencv org master da d54 group__imgproc__transform html,,,,,,,
mxnet.ndarray.linalg_trsm,rightside,Multiply triangular matrix from the right to non-triangular one.,Multiply triangular matrix from the right to non triangular one,numeric,,,,,,
mxnet.ndarray.op.linalg_trmm,rightside,Multiply triangular matrix from the right to non-triangular one.,Multiply triangular matrix from the right to non triangular one,numeric,,,,,,
mxnet.ndarray.op.linalg_trsm,rightside,Multiply triangular matrix from the right to non-triangular one.,Multiply triangular matrix from the right to non triangular one,numeric,,,,,,
mxnet.ndarray.linalg_gemm,transpose_a,Multiply with transposed of first input (A).,Multiply with transposed of first input BSTR,,,,,,,
mxnet.ndarray.op.linalg_gemm,transpose_a,Multiply with transposed of first input (A).,Multiply with transposed of first input BSTR,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DRNNCell,input_shape,"Input tensor shape at each time step for each sample, excluding dimension of the batch size and sequence length. Must be consistent with conv_layout. For example, for layout 'NCHW' the shape should be (C, H, W).",Must be consistent with PARAM,,,,,,,
mxnet.contrib.ndarray.quantized_batch_norm,eps,Epsilon to prevent div 0. Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn.h when using cudnn (usually 1e-5),Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn h when using cudnn BSTR,,,,,,,
mxnet.ndarray.op.BatchNorm,eps,Epsilon to prevent div 0. Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn.h when using cudnn (usually 1e-5),Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn h when using cudnn BSTR,,,,,,,
mxnet.gluon.nn.LeakyReLU,alpha,slope coefficient for the negative half axis. Must be >= 0.,Must be REXPR,,,,,,REXPR,
mxnet.ndarray.op.sample_multinomial,data,Distribution probabilities. Must sum to one on the last axis.,Must sum to one on the last axis,,,,,,,
mxnet.ndarray.op.SequenceMask,data,"n-dimensional input array of the form [max_sequence_length, batch_size, other_feature_dims] where n>2",n dimensional input D_STRUCTURE of the form BSTR where n REXPR,,,D_STRUCTURE,,REXPR,,
mxnet.gluon.model_zoo.vision.get_model,name,Name of the model.,name of the model,string,,,,0,,
mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",Negative values means indexing from right to left,,,,,,,
mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",Negative values means indexing from right to left,,,,,,,
mxnet.ndarray.contrib.MultiProposal,threshold,"NMS value, below which to suppress.",NMS value below which to suppress,,,,,,,
mxnet.gluon.nn.BatchNorm,scale,"If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.",nn relu this can be disabled since the scaling will be done by the next layer,,,,,,,
mxnet.test_utils.numeric_grad,aux_states,"DD: None or list of numpy.ndarray or dict of str to numpy.ndarray, optional",None or D_STRUCTURE of numpy D_STRUCTURE of D_TYPE to numpy D_STRUCTURE optional,D_TYPE,,D_STRUCTURE,,,,
mxnet.ndarray.Deconvolution,cudnn_tune,"DD: {None, 'fastest', 'limited_workspace', 'off'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.dot,forward_stype,"DD: {None, 'csr', 'default', 'row_sparse'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.io.CSVIter,dtype,"DD: {None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.io.LibSVMIter,dtype,"DD: {None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.LRN,nsize,normalization window width in elements.,normalization window width in elements,numeric,,,,,"[0,inf)",
mxnet.ndarray.op.split,squeeze_axis,"If true, Removes the axis with length 1 from the shapes of the output arrays. Note that setting squeeze_axis to `true` removes axis with length 1 only along the axis which it is split. Also squeeze_axis can be set to `true` only if `input.shape[axis] == num_outputs`.",Note that setting squeeze_axis to CONSTANT_BOOL removes PARAM with length CONSTANT_NUM only along the PARAM which it is split,,,,,,,
mxnet.ndarray.split,num_outputs,Number of splits. Note that this should evenly divide the length of the axis.,Note that this should evenly divide the length of the PARAM,,,,,,,
mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",Note When shrinking an image it will generally look best with AREA based interpolation whereas when enlarging an image it will generally look best with Bicubic BSTR,,,,,,,
mxnet.gluon.nn.GroupNorm,num_groups,Number of groups to separate the channel axis into.,Number of groups to separate the channel axis into,int,,,,0,"[0,inf)",
mxnet.ndarray.split,num_outputs,Number of splits. Note that this should evenly divide the length of the axis.,Number of splits,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.MultiProposal,rpn_pre_nms_top_n,Number of top scoring boxes to keep before applying NMS to RPN proposals,Number of top scoring boxes to keep before applying NMS to RPN proposals,int,,,,0,"[0,inf)",
mxnet.gluon.contrib.rnn.LSTMPCell,hidden_size,Number of units in cell state symbol.,Number of units in cell state symbol,int,,,,0,"[0,inf)",
mxnet.ndarray.arange,start,"DD: number, optional",number optional,numeric,,,,,,
mxnet.ndarray.linalg.extracttrian,offset,"Offset of the diagonal versus the main diagonal. 0 corresponds to the main diagonal, a negative/positive value to diagonals below/above the main diagonal.",offset of the diagonal versus the main diagonal,,,,,,,
mxnet.ndarray.random.randn,ctx,DD: Context,ONE_WORD Context,,,,,,,
mxnet.contrib.ndarray.hawkesll,max_time,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.Convolution,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.where,condition,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_inverse,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.reshape_like,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.elemwise_sub,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.mp_lamb_update_phase2,r1,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.hawkesll,valid_length,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.mp_lamb_update_phase2,r2,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.add_n,*args,DD: NDArray[],ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.SoftmaxOutput,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sign,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_trsm,B,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.MAERegressionOutput,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.hawkesll,beta,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.mp_lamb_update_phase1,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.arccos,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.bipartite_matching,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_gemm2,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.mp_sgd_mom_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.arcsinh,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.cosh,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.SoftmaxOutput,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_pdf_uniform,sample,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.pick,index,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.to_dlpack_for_write,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sum,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.quantization.quantize_graph,arg_params,DD: dict,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.rmsprop_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.rcbrt,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_conv,max_weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.BilinearResize2D,like,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.LayerNorm,beta,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.random_pdf_gamma,alpha,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.CTCLoss,label_lengths,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.box_encode,matches,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.rmspropalex_update,g,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.BatchNorm,moving_mean,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.mp_nag_mom_update,weight32,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.calibrate_entropy,hist_edges,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.random_pdf_dirichlet,sample,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.CTCLoss,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.mp_lamb_update_phase1,weight32,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sample_generalized_negative_binomial,mu,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.argmin,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.group_adagrad_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.amp_cast,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.signum_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.ROIPooling,rois,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.ftrl_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.backward_gradientmultiplier,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.swapaxes,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.stack,*data,DD: NDArray[],ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.FullyConnected,bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.hawkesll,state,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.image.random_lighting,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.ROIPooling,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.choose_element_0index,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.log,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.image.to_tensor,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.unravel_index,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.transpose,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.rmspropalex_update,delta,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.transpose,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.expm1,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.BatchNorm,beta,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_trsm,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_act,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.elemwise_add,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantize,min_range,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.all_finite,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_fully_connected,max_bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.CTCLoss,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.retain,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.log,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.log2,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_equal,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.softmax_cross_entropy,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_conv,bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.elemwise_add,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.fft,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.ctc_loss,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.signum_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_fully_connected,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.batch_dot,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_conv,max_bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.elemwise_add,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.random_pdf_exponential,sample,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sample_negative_binomial,p,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.ftml_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.shuffle,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_batch_norm,max_data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.DeformableConvolution,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_potri,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.signum_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.CTCLoss,label_lengths,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantize,max_range,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_conv,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.CTCLoss,data_lengths,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_sub,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.quantized_batch_norm,beta,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.mp_sgd_update,weight32,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.square,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.Deconvolution,bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_to,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.gather_nd,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.nanprod,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sin,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.elemwise_div,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.lamb_update_phase2,g,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sqrt,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_trmm,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_add,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.elemwise_sub,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.radians,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.SequenceMask,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sample_multinomial,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_det,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.LogisticRegressionOutput,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_not_equal,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.quantization.quantize_graph,aux_params,DD: dict,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.RNN,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.depth_to_space,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.MultiBoxDetection,loc_pred,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.scatter_nd,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_logical_or,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.Embedding,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.elemwise_mul,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg.potrf,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sgd_mom_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.ctc_loss,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.exp,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.gluon.nn.Conv2DTranspose,use_bias,DD: bool,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.ndarray.utils.save,fname,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.test_utils.verify_generator,success_rate,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.profiler.dumps,sort_by,DD: string,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.nn.LeakyReLU,alpha,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.contrib.onnx.export_model,onnx_file_path,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.model_zoo.vision.get_model,pretrained,DD: bool,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.callback.log_train_metric,period,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.profiler.set_config,continuous_dump,"DD: boolean,",ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.nn.Dense,activation,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.test_utils.verify_generator,nsamples,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.recordio.pack_img,img_fmt,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.image.CreateDetAugmenter,rand_pad,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.contrib.rnn.LSTMPCell,hidden_size,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.contrib.ndarray.gradientmultiplier,scalar,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.nn.AvgPool1D,pool_size,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.recordio.unpack,s,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.util.set_np,shape,DD: bool,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.contrib.quantization.quantize_model,calib_mode,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.model_zoo.vision.get_model,name,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.contrib.ndarray.backward_gradientmultiplier,scalar,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.image.CreateAugmenter,rand_mirror,DD: bool,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.gluon.rnn.LSTM,hidden_size,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
mxnet.test_utils.np_reduce,numpy_reduce_func,DD: function,ONE_WORD function,,,,,,,
mxnet.test_utils.chi_square_check,generator,DD: function,ONE_WORD function,,,,,,,
mxnet.gluon.nn.PReLU,alpha_initializer,DD: Initializer,ONE_WORD Initializer,,,,,,,
mxnet.gluon.contrib.rnn.VariationalDropoutCell,base_cell,DD: RecurrentCell,ONE_WORD RecurrentCell,,,,,,,
mxnet.ndarray.full,val,DD: scalar,ONE_WORD scalar,,,,,0,,
mxnet.test_utils.check_symbolic_forward,sym,DD: Symbol,ONE_WORD Symbol,,,,,,,
mxnet.ndarray.contrib.PSROIPooling,data,DD: Symbol,ONE_WORD Symbol,,,,,,,
mxnet.ndarray.contrib.DeformablePSROIPooling,rois,DD: Symbol,ONE_WORD Symbol,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DLSTMCell,h2h_kernel,Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.,Only odd numbered sizes are supported,,,,,,,
mxnet.ndarray.contrib.CTCLoss,data_lengths,Lengths of data for each of the samples. Only required when use_data_lengths is true.,Only required when PARAM is CONSTANT_BOOL,,,,,,,
mxnet.ndarray.contrib.CTCLoss,label_lengths,Lengths of labels for each of the samples. Only required when use_label_lengths is true.,Only required when PARAM is CONSTANT_BOOL,,,,,,,
mxnet.ndarray.op.CTCLoss,label_lengths,Lengths of labels for each of the samples. Only required when use_label_lengths is true.,Only required when PARAM is CONSTANT_BOOL,,,,,,,
mxnet.gluon.nn.Conv2D,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",Only supports QSTR layout for now,,,,,,,QSTR
mxnet.ndarray.UpSampling,num_filter,"Input filter. Only used by bilinear sample_type.Since bilinear upsampling uses deconvolution, num_filters is set to the number of channels.",Only used by bilinear PARAM Since bilinear upsampling uses deconvolution num_filters is set to the number of channels,,,,,,,
mxnet.ndarray.random_generalized_negative_binomial,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls.",Only used for imperative calls,,,,,,,
mxnet.ndarray.SequenceLast,axis,The sequence axis. Only values of 0 and 1 are currently supported.,Only values of CONSTANT_NUM are currently supported,,,,,,,CONSTANT_NUM
mxnet.ndarray.contrib.box_nms,background_id,"Optional, id of the background class which will be ignored in nms.",Optional id of the background class which will be ignored in nms,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.box_nms,id_index,"Optional, index of the class categories, -1 to disable.",Optional index of the class categories CONSTANT_NUM to disable,int,,,,0,,
mxnet.ndarray.contrib.box_nms,id_index,"Optional, index of the class categories, -1 to disable.",Optional index of the class categories CONSTANT_NUM to disable,int,,,,0,,
mxnet.contrib.ndarray.ROIAlign,sample_ratio,"Optional sampling ratio of ROI align, using adaptive size by default.",Optional sampling ratio of ROI align using adaptive size by default,numeric,,,,,,
mxnet.ndarray.contrib.ROIAlign,sample_ratio,"Optional sampling ratio of ROI align, using adaptive size by default.",Optional sampling ratio of ROI align using adaptive size by default,numeric,,,,,,
mxnet.io.CSVIter,dtype,Output data type. `None` means no change.,Output data type,numpy.dtype,,,,,,
mxnet.io.LibSVMIter,dtype,Output data type. `None` means no change.,Output data type,numpy.dtype,,,,,,
mxnet.ndarray.lamb_update_phase2,g,Output of lamb_update_phase 1,Output of lamb_update_phase CONSTANT_NUM,,,,,,,
mxnet.contrib.ndarray.dequantize,out_type,Output data type.,Output PARAM type,numpy.dtype,,,,,,
mxnet.test_utils.check_symbolic_forward,sym,output symbol,output symbol,,,,,,,
mxnet.ndarray.contrib.quantized_batch_norm,output_mean_var,Output the mean and inverse std,Output the mean and inverse std,numeric,,,,,,
mxnet.ndarray.GroupNorm,output_mean_var,Output the mean and std calculated along the given axis.,Output the mean and std calculated along the given axis,numeric,,,,,,
mxnet.ndarray.random.generalized_negative_binomial,ctx,Device context of output. Default is current context. Overridden by mu.context when mu is an NDArray.,Overridden by PARAM context when PARAM is an D_STRUCTURE,,,,,,,
mxnet.ndarray.random.randint,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Overridden by PARAM context when PARAM is an D_STRUCTURE,,,,,,,
mxnet.ndarray.random.randn,ctx,Device context of output. Default is current context. Overridden by loc.context when loc is an NDArray.,Overridden by PARAM context when PARAM is an D_STRUCTURE,,,,,,,
mxnet.ndarray.random.uniform,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Overridden by PARAM context when PARAM is an D_STRUCTURE,,,,,,,
mxnet.ndarray.mp_nag_mom_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,PARAM decay augments the objective function with a regularization term that penalizes large weights,,,,,,,
mxnet.ndarray.op.ftrl_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,PARAM decay augments the objective function with a regularization term that penalizes large weights,,,,,,,
mxnet.gluon.nn.MaxPool2D,layout,"Dimension ordering of data and out ('NCHW' or 'NHWC'). 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. padding is applied on 'H' and 'W' dimension.",PARAM is applied on QSTR dimension,,,,,,,
mxnet.gluon.nn.MaxPool3D,layout,"Dimension ordering of data and out ('NCDHW' or 'NDHWC'). 'N', 'C', 'H', 'W', 'D' stands for batch, channel, height, width and depth dimensions respectively. padding is applied on 'D', 'H' and 'W' dimension.",PARAM is applied on QSTR dimension,,,,,,,
mxnet.ndarray.contrib.BilinearResize2D,mode,"DD: {'like', 'odd_scale', 'size', 'to_even_down', 'to_even_up', 'to_odd_down', 'to_odd_up'},optional, default='size'",PARAM QSTR optional default QSTR,,,,,,,QSTR
mxnet.io.ImageDetRecordIter,num_parts,partition the data into multiple parts,partition the data into multiple parts,,,,,,,
mxnet.contrib.onnx.export_model,onnx_file_path,Path where to save the generated onnx file,Path where to save the generated onnx file,string,,,,0,,
mxnet.ndarray.ftrl_update,beta,Per-Coordinate Learning Rate beta.,Per Coordinate Learning Rate beta,numeric,,,,,"[0,1]",
mxnet.ndarray.contrib.quantized_pooling,pooling_convention,Pooling convention to be applied.,Pooling convention to be applied,,,,,,,
mxnet.ndarray.op.Pooling,pooling_convention,Pooling convention to be applied.,Pooling convention to be applied,,,,,,,
mxnet.gluon.nn.MaxPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Pooling is applied on the W dimension.",Pooling is applied on the W dimension,,,,,,,
mxnet.ndarray.Pooling,kernel,"Pooling kernel size: (y, x) or (d, y, x)",Pooling kernel size BSTR,numeric,,,BSTR,,"[0,inf)",
mxnet.ndarray.sparse.add_n,*args,Positional input arguments,Positional input arguments,,,,,,,
mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",Possible values CONSTANT_NUM Nearest Neighbors Interpolation,,,,,,,CONSTANT_NUM
mxnet.gluon.rnn.GRUCell,prefix,prefix for name of Block`s (and name of weight if params is `None).,prefix for name of Block and name of weight if PARAM is None,string,,,,0,,
mxnet.gluon.contrib.rnn.Conv1DGRUCell,prefix,Prefix for name of layers (and name of weight if params is None).,prefix for name of layers BSTR,string,,,,0,,
mxnet.gluon.contrib.rnn.Conv1DLSTMCell,prefix,Prefix for name of layers (and name of weight if params is None).,prefix for name of layers BSTR,string,,,,0,,
mxnet.test_utils.check_symbolic_backward,grad_req,"Gradient requirements. 'write', 'add' or 'null'.",ONE_WORD QSTR,,,,,,,QSTR
mxnet.gluon.nn.Dense,activation,"Activation function to use. See help on Activation layer. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",QSTR activation a BSTR x,,,,,,,
mxnet.gluon.rnn.RNN,activation,"DD: {'relu' or 'tanh'}, default 'relu'",QSTR default QSTR,,,,,,,QSTR
mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",QSTR means clip to the range,,,,,,,QSTR
mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",QSTR means clip to the range,,,,,,,QSTR
mxnet.io.CSVIter,dtype,Output data type. `None` means no change.,QSTR means no change,,,,,,,QSTR
mxnet.io.LibSVMIter,dtype,Output data type. `None` means no change.,QSTR means no change,,,,,,,QSTR
mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",QSTR means to raise an error when index PARAM of range,,,,,,,QSTR
mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",QSTR means to wrap around,,,,,,,QSTR
mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",QSTR means to wrap around,,,,,,,QSTR
mxnet.ndarray.random.gamma,dtype,"DD: {'float16', 'float32', 'float64'}, optional",QSTR optional,,,,,,,QSTR
mxnet.ndarray.random.generalized_negative_binomial,dtype,"DD: {'float16', 'float32', 'float64'}, optional",QSTR optional,,,,,,,QSTR
mxnet.ndarray.Dropout,mode,"DD: {'always', 'training'},optional, default='training'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.io.ImageDetRecordIter,resize_mode,"DD: {'fit', 'force', 'shrink'},optional, default='force'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.Pooling,pooling_convention,"DD: {'full', 'same', 'valid'},optional, default='valid'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.contrib.ndarray.dequantize,out_type,"DD: {'float32'},optional, default='float32'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.random_uniform,dtype,"DD: {'None', 'float16', 'float32', 'float64'},optional, default='None'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.take,mode,"DD: {'clip', 'raise', 'wrap'},optional, default='clip'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.ctc_loss,blank_label,"DD: {'first', 'last'},optional, default='first'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.ctc_loss,blank_label,"DD: {'first', 'last'},optional, default='first'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.sample_exponential,dtype,"DD: {'None', 'float16', 'float32', 'float64'},optional, default='None'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.CTCLoss,blank_label,"DD: {'first', 'last'},optional, default='first'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.op.random_negative_binomial,dtype,"DD: {'None', 'float16', 'float32', 'float64'},optional, default='None'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.contrib.quantized_pooling,pooling_convention,"DD: {'full', 'same', 'valid'},optional, default='valid'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.pick,mode,"DD: {'clip', 'wrap'},optional, default='clip'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.topk,dtype,"DD: {'float16', 'float32', 'float64', 'int32', 'int64', 'uint8'},optional, default='float32'",QSTR optional default QSTR,,,,,,,QSTR
mxnet.ndarray.contrib.BilinearResize2D,mode,"resizing mode. ""simple"" - output height equals parameter ""height"" if ""scale_height"" parameter is not defined or input height multiplied by ""scale_height"" otherwise. Same for width;""odd_scale"" - if original height or width is odd, then result height is calculated like result_h = (original_h - 1) * scale + 1; for scale > 1 the result shape would be like if we did deconvolution with kernel = (1, 1) and stride = (height_scale, width_scale); and for scale < 1 shape would be like we did convolution with kernel = (1, 1) and stride = (int(1 / height_scale), int( 1/ width_scale);""like"" - resize first input to the height and width of second input; ""to_even_down"" - resize input to nearest lower even height and width (if original height is odd then result height = original height - 1);""to_even_up"" - resize input to nearest bigger even height and width (if original height is odd then result height = original height + 1);""to_odd_down"" - resize input to nearest odd height and width (if original height is odd then result height = original height - 1);""to_odd_up"" - resize input to nearest odd height and width (if original height is odd then result height = original height + 1);",QSTR output PARAM equals parameter PARAM if PARAM parameter is not defined or input PARAM multiplied by PARAM otherwise,,,,,,,QSTR
mxnet.ndarray.Activation,act_type,"DD: {'relu', 'sigmoid', 'softrelu', 'softsign', 'tanh'}, required",QSTR required,,,,,,,QSTR
mxnet.ndarray.UpSampling,sample_type,"DD: {'bilinear', 'nearest'}, required",QSTR required,,,,,,,QSTR
mxnet.gluon.nn.MaxPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Pooling is applied on the W dimension.",QSTR stands for batch channel and width BSTR dimensions respectively,,,,,,,
mxnet.gluon.nn.Conv2D,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",QSTR stands for batch channel height and width dimensions respectively,,,,,,,
mxnet.gluon.nn.MaxPool2D,layout,"Dimension ordering of data and out ('NCHW' or 'NHWC'). 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. padding is applied on 'H' and 'W' dimension.",QSTR stands for batch channel height and width dimensions respectively,,,,,,,
mxnet.gluon.nn.MaxPool3D,layout,"Dimension ordering of data and out ('NCDHW' or 'NDHWC'). 'N', 'C', 'H', 'W', 'D' stands for batch, channel, height, width and depth dimensions respectively. padding is applied on 'D', 'H' and 'W' dimension.",QSTR stands for batch channel height width and depth dimensions respectively,,,,,,,
mxnet.ndarray.mp_lamb_update_phase2,r1,r1,ONE_WORD r1,,,,,,,
mxnet.ndarray.op.mp_lamb_update_phase2,r2,r2,ONE_WORD r2,,,,,,,
mxnet.io.ImageRecordIter,seed_aug,Random seed for augmentations.,Random PARAM for augmentations,,,,,,,
mxnet.ndarray.ROIPooling,spatial_scale,Ratio of input feature map height (or w) to raw image height (or w). Equals the reciprocal of total stride in convolutional layers,Ratio of input feature map height BSTR,numeric,,,,,,
mxnet.gluon.contrib.rnn.Conv1DGRUCell,h2h_dilate,Recurrent convolution dilate.,Recurrent convolution dilate,,,,,,,
mxnet.gluon.contrib.rnn.Conv2DLSTMCell,h2h_kernel,Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.,Recurrent convolution kernel sizes,int,,,,,"[0,inf)",
mxnet.ndarray.ftml_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.ndarray.op.rmsprop_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.ndarray.op.signsgd_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.ndarray.signsgd_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.ndarray.sparse.adam_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
mxnet.contrib.ndarray.BilinearResize2D,like,Resize data to it's shape,Resize PARAM to it shape,,,,,,,
mxnet.ndarray.contrib.BilinearResize2D,mode,"resizing mode. ""simple"" - output height equals parameter ""height"" if ""scale_height"" parameter is not defined or input height multiplied by ""scale_height"" otherwise. Same for width;""odd_scale"" - if original height or width is odd, then result height is calculated like result_h = (original_h - 1) * scale + 1; for scale > 1 the result shape would be like if we did deconvolution with kernel = (1, 1) and stride = (height_scale, width_scale); and for scale < 1 shape would be like we did convolution with kernel = (1, 1) and stride = (int(1 / height_scale), int( 1/ width_scale);""like"" - resize first input to the height and width of second input; ""to_even_down"" - resize input to nearest lower even height and width (if original height is odd then result height = original height - 1);""to_even_up"" - resize input to nearest bigger even height and width (if original height is odd then result height = original height + 1);""to_odd_down"" - resize input to nearest odd height and width (if original height is odd then result height = original height - 1);""to_odd_up"" - resize input to nearest odd height and width (if original height is odd then result height = original height + 1);",resizing mode,,,,,,,
mxnet.image.copyMakeBorder,right,Right margin.,right margin,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DLSTMCell,params,"DD: RNNParams, default None",RNNParams default None,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DRNNCell,params,"DD: RNNParams, default None",RNNParams default None,,,,,,,
mxnet.gluon.contrib.rnn.Conv3DGRUCell,params,"DD: RNNParams, default None",RNNParams default None,,,,,,,
mxnet.contrib.ndarray.ROIAlign,pooled_size,"ROI Align output roi feature map height and width: (h, w)",ROI Align output roi feature map height and width BSTR,,,,BSTR,,,
mxnet.ndarray.op.ROIPooling,pooled_size,"ROI pooling output shape (h,w)",ROI pooling output shape BSTR,,,,BSTR,,,
mxnet.contrib.ndarray.RROIAlign,pooled_size,"RROI align output shape (h,w)",RROI align output shape BSTR,,,,BSTR,,,
mxnet.ndarray.BatchNorm,moving_mean,running mean of input,running mean of input,numeric,,,,,,
mxnet.ndarray.contrib.BilinearResize2D,mode,"resizing mode. ""simple"" - output height equals parameter ""height"" if ""scale_height"" parameter is not defined or input height multiplied by ""scale_height"" otherwise. Same for width;""odd_scale"" - if original height or width is odd, then result height is calculated like result_h = (original_h - 1) * scale + 1; for scale > 1 the result shape would be like if we did deconvolution with kernel = (1, 1) and stride = (height_scale, width_scale); and for scale < 1 shape would be like we did convolution with kernel = (1, 1) and stride = (int(1 / height_scale), int( 1/ width_scale);""like"" - resize first input to the height and width of second input; ""to_even_down"" - resize input to nearest lower even height and width (if original height is odd then result height = original height - 1);""to_even_up"" - resize input to nearest bigger even height and width (if original height is odd then result height = original height + 1);""to_odd_down"" - resize input to nearest odd height and width (if original height is odd then result height = original height - 1);""to_odd_up"" - resize input to nearest odd height and width (if original height is odd then result height = original height + 1);",Same for PARAM QSTR if original PARAM or PARAM is odd then result PARAM is calculated PARAM result_h BSTR scale CONSTANT_NUM for scale REXPR the result shape would be PARAM if we did deconvolution with kernel BSTR and stride BSTR and for scale REXPR shape would be PARAM we did convolution with kernel BSTR and stride BSTR PARAM resize first input to the PARAM and PARAM of second input QSTR resize input to nearest lower even PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM QSTR resize input to nearest bigger even PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM QSTR resize input to nearest odd PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM QSTR resize input to nearest odd PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM,,,,,,,QSTR
mxnet.ndarray.op.random_pdf_uniform,sample,Samples from the distributions.,Samples from the distributions,,,,,,,
mxnet.ndarray.random_pdf_dirichlet,sample,Samples from the distributions.,Samples from the distributions,,,,,,,
mxnet.ndarray.random_pdf_exponential,sample,Samples from the distributions.,Samples from the distributions,,,,,,,
mxnet.contrib.ndarray.BilinearResize2D,scale_width,"sampling scale of the width (optional, used in modes ""scale"" and ""odd_scale"")",sampling scale of the PARAM optional used in modes QSTR,,,,,,,
mxnet.contrib.ndarray.backward_gradientmultiplier,scalar,scalar input,scalar input,,,,,0,,
mxnet.ndarray.subtract,lhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.minimum,lhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.minimum,rhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.equal,rhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.sparse.subtract,rhs,DD: scalar or mxnet.ndarray.sparse.array,scalar or mxnet D_STRUCTURE sparse D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.sparse.add,lhs,DD: scalar or mxnet.ndarray.sparse.array,scalar or mxnet D_STRUCTURE sparse D_STRUCTURE,,,D_STRUCTURE,,0,,
mxnet.ndarray.equal,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",Second D_STRUCTURE to be compared,,,D_STRUCTURE,,,,
mxnet.ndarray.minimum,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",Second D_STRUCTURE to be compared,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.subtract,rhs,"Second array to be subtracted. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.__spec__",Second D_STRUCTURE to be subtracted,,,D_STRUCTURE,,,,
mxnet.ndarray.elemwise_add,rhs,second input,second input,,,,,,,
mxnet.ndarray.op.elemwise_mul,rhs,second input,second input,,,,,,,
mxnet.ndarray.sparse.elemwise_sub,rhs,second input,second input,,,,,,,
mxnet.ndarray.broadcast_logical_or,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.broadcast_sub,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.ndarray.op.broadcast_equal,rhs,Second input to the function,Second input to the function,,,,,,,
mxnet.gluon.nn.Dense,activation,"Activation function to use. See help on Activation layer. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",See help on activation layer,,,,,,,
mxnet.contrib.ndarray.interleaved_matmul_encdec_qk,heads,Set number of heads,Set number of heads,,,,,,,
mxnet.ndarray.ctc_loss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",Set the PARAM that is reserved for blank PARAM If QSTR CONSTANT_NUM th PARAM is reserved and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
mxnet.ndarray.CTCLoss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",Set the PARAM that is reserved for blank PARAM If QSTR CONSTANT_NUM th PARAM is reserved and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
mxnet.ndarray.op.ctc_loss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",Set the PARAM that is reserved for blank PARAM If QSTR CONSTANT_NUM th PARAM is reserved and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
mxnet.ndarray.Pooling,kernel,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
mxnet.ndarray.transpose,axes,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
mxnet.ndarray.op.sample_exponential,shape,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
mxnet.ndarray.op.reshape,shape,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
mxnet.ndarray.op.Deconvolution,target_shape,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
mxnet.ndarray.op.sample_gamma,shape,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
mxnet.ndarray.sample_uniform,shape,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
mxnet.ndarray.op.random_uniform,shape,"DD: Shape(tuple), optional, default=None",Shape BSTR optional default None,int,,tuple,,1,"[0,inf)",
mxnet.contrib.ndarray.ROIAlign,pooled_size,"DD: Shape(tuple), required",Shape BSTR required,int,,tuple,,1,"[0,inf)",
mxnet.contrib.ndarray.RROIAlign,pooled_size,"DD: Shape(tuple), required",Shape BSTR required,int,,tuple,,1,"[0,inf)",
mxnet.ndarray.op.ROIPooling,pooled_size,"DD: Shape(tuple), required",Shape BSTR required,int,,tuple,,1,"[0,inf)",
mxnet.ndarray.contrib.hawkesll,beta,"Shape (K,) The decay parameter for each process",Shape BSTR The decay parameter for each process,,,,BSTR,,,
mxnet.contrib.ndarray.hawkesll,state,"Shape (N, K) the Hawkes state for each process",Shape BSTR the Hawkes state for each process,,,,BSTR,,,
mxnet.image.CreateAugmenter,data_shape,Shape for output data,Shape for output data,int,,,,1,"[0,inf)",
mxnet.ndarray.op.random_uniform,shape,Shape of the output.,shape of the output,int,,,,1,"[0,inf)",
mxnet.ndarray.op.Deconvolution,target_shape,"Shape of the output tensor: (w,), (h, w) or (d, h, w).",Shape of the output D_STRUCTURE BSTR,int,,,,1,"[0,inf)",
mxnet.ndarray.op.nanprod,axis,"DD: Shape or None, optional, default=None",Shape or None optional default None,int,,,,1,"[0,inf)",
mxnet.ndarray.op.max,axis,"DD: Shape or None, optional, default=None",Shape or None optional default None,int,,,,1,"[0,inf)",
mxnet.ndarray.op.sample_exponential,shape,Shape to be sampled from each random distribution.,shape to be sampled from each random distribution,int,,,,1,"[0,inf)",
mxnet.ndarray.op.sample_gamma,shape,Shape to be sampled from each random distribution.,shape to be sampled from each random distribution,int,,,,1,"[0,inf)",
mxnet.ndarray.sample_uniform,shape,Shape to be sampled from each random distribution.,shape to be sampled from each random distribution,int,,,,1,"[0,inf)",
mxnet.ndarray.random.gamma,alpha,The shape of the gamma distribution. Should be greater than zero.,Should be greater than zero,,,,,,"[0,inf)",
mxnet.gluon.nn.AvgPool1D,pool_size,Size of the average pooling windows.,Size of the average pooling windows,int,,,,,"[0,inf)",
mxnet.gluon.nn.LeakyReLU,alpha,slope coefficient for the negative half axis. Must be >= 0.,slope coefficient for the negative half axis,numeric,,,,,,
mxnet.gluon.nn.LayerNorm,epsilon,Small float added to variance to avoid dividing by zero.,Small D_TYPE added to variance to avoid dividing by zero,D_TYPE,,,,,,
mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",So if all indices mentioned are too large they are replaced by the PARAM that addresses the last element along an PARAM,,,,,,,
mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",So if all PARAM mentioned are too large they are replaced by the index that addresses the last element along an PARAM,,,,,,,
mxnet.ndarray.contrib.backward_gradientmultiplier,data,source input,source input,,,,,,,
mxnet.ndarray.op.transpose,data,Source input,Source input,,,,,,,
mxnet.ndarray.transpose,data,Source input,Source input,,,,,,,
mxnet.ndarray.contrib.arange_like,step,Spacing between values.,Spacing between values,,,,,,,
mxnet.gluon.nn.Conv3D,dilation,Specifies the dilation rate to use for dilated convolution.,Specifies the dilation rate to use for dilated convolution,numeric,,,,,"[0,1]",
mxnet.gluon.nn.Conv1DTranspose,kernel_size,Specifies the dimensions of the convolution window.,Specifies the dimensions of the convolution window,int,,,,1,,
mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",Specify how PARAM of bound indices behave,,,,,,,
mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",Specify how PARAM of bound PARAM bahave,,,,,,,
mxnet.gluon.nn.Conv3DTranspose,strides,Specify the strides of the convolution.,Specify the strides of the convolution,int,,,,,"[0,inf)",
mxnet.ndarray.random.randn,scale,Standard deviation (spread or width) of the distribution.,Standard deviation BSTR of the distribution,numeric,,,,,,
mxnet.ndarray.op.random_normal,scale,Standard deviation of the distribution.,Standard deviation of the distribution,numeric,,,,,,
mxnet.ndarray.arange,start,Start of interval. The default start value is 0.,start of interval,,,,,,,
mxnet.ndarray.random.normal,out,Store output to an existing NDArray.,Store output to an existing D_STRUCTURE,,,,,,,
mxnet.gluon.nn.SymbolBlock,inputs,DD: Symbol or list of Symbol,Symbol or D_STRUCTURE of Symbol,,,D_STRUCTURE,,,,
mxnet.gluon.rnn.RNN,layout,"The format of input and output tensors. T, N and C stand for sequence length, batch size, and feature dimensions respectively.",T N and C stand for D_STRUCTURE length batch size and feature dimensions respectively,,,,,,,
mxnet.ndarray.transpose,axes,Target axis order. By default the axes will be inverted.,Target axis order,int,,,,,"[0,inf)",
mxnet.gluon.rnn.RNN,activation,The activation function to use.,The activation function to use,,,,,,,
mxnet.gluon.nn.Dropout,axes,"The axes on which dropout mask is shared. If empty, regular dropout is applied.",The axes on which dropout mask is shared,int,,,,,,
mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The axis or axes along which to perform the reduction,int,,,,,"[0,inf)",
mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The axis or axes along which to perform the reduction,int,,,,,"[0,inf)",
mxnet.gluon.contrib.rnn.VariationalDropoutCell,base_cell,The cell on which to perform variational dropout.,The cell on which to perform variational dropout,,,,,,,
mxnet.gluon.model_zoo.vision.densenet121,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
mxnet.gluon.model_zoo.vision.densenet161,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
mxnet.gluon.model_zoo.vision.resnet152_v1,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
mxnet.gluon.model_zoo.vision.vgg16_bn,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
mxnet.ndarray.SequenceLast,axis,The sequence axis. Only values of 0 and 1 are currently supported.,The D_STRUCTURE axis,int,,,,,"[0,inf)",
mxnet.ndarray.arange,dtype,The data type of the NDArray. The default datatype is np.float32.,The data type of the D_STRUCTURE,numpy.dtype,,,,,,
mxnet.ndarray.multi_sgd_mom_update,momentum,The decay rate of momentum estimates at each epoch.,The decay rate of momentum estimates at each epoch,numeric,,,,0,"[0,1]",
mxnet.ndarray.op.multi_mp_sgd_mom_update,momentum,The decay rate of momentum estimates at each epoch.,The decay rate of momentum estimates at each epoch,numeric,,,,0,"[0,1]",
mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The default axis BSTR,,,,,,,
mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The default axis BSTR,,,,,,,
mxnet.ndarray.op.cumsum,axis,Axis along which the cumulative sum is computed. The default (None) is to compute the cumsum over the flattened array.,The default BSTR is to compute the cumsum over the flattened D_STRUCTURE,,,,,,,
mxnet.ndarray.arange,dtype,The data type of the NDArray. The default datatype is np.float32.,The default datatype is D_TYPE,,,,,,,
mxnet.ndarray.arange,start,Start of interval. The default start value is 0.,The default start value is CONSTANT_NUM,,,,,,,
mxnet.ndarray.random.uniform,high,Upper boundary of the output interval. All values generated will be less than high. The default value is 1.0.,The default value is CONSTANT_NUM,,,,,,,
mxnet.ndarray.random.uniform,low,Lower boundary of the output interval. All values generated will be greater than or equal to low. The default value is 0.,The default value is CONSTANT_NUM,,,,,,,
mxnet.ndarray.op.dot,forward_stype,"The desired storage type of the forward output given by user, if thecombination of input storage types and this hint does not matchany implemented ones, the dot operator will perform fallback operationand still produce an output of the desired storage type.",The desired storage type of the forward output given by user if thecombination of input storage types and this hint does not matchany implemented ones the dot operator will perform fallback operationand still produce an output of the desired storage type,,,,,,,QSTR
mxnet.test_utils.verify_generator,success_rate,The desired success rate,The desired success rate,numeric,,,,0,"[0,1]",
mxnet.context.cpu,device_id,The device id of the device. device_id is not needed for CPU. This is included to make interface compatible with GPU.,The device id of the device,int,,,,0,"[0,inf)",
mxnet.ndarray.Embedding,weight,The embedding weight matrix.,The embedding weight matrix,numeric,,,,,,
mxnet.test_utils.check_symbolic_forward,expected,The expected output value   if type is list of np.ndarrayContains arrays corresponding to exe.outputs.,The expected output value if type is D_STRUCTURE of np ndarrayContains D_STRUCTURE corresponding to exe outputs,,,D_STRUCTURE,,,,
mxnet.ndarray.utils.save,fname,The filename.,The filename,string,,,,0,,
mxnet.ndarray.batch_dot,lhs,The first input,The first input,,,,,,,
mxnet.test_utils.assert_almost_equal,equal_nan,The flag determining how to treat NAN values in comparison,The flag determining how to treat NAN values in comparison,,,,,,,
mxnet.gluon.rnn.RNN,layout,"The format of input and output tensors. T, N and C stand for sequence length, batch size, and feature dimensions respectively.",The format of input and output D_STRUCTURE,,,,,,,
mxnet.ndarray.pick,index,The index array,The index D_STRUCTURE,int,,D_STRUCTURE,,,,
mxnet.contrib.autograd.grad,argnum,The index of argument to calculate gradient for.,The index of argument to calculate gradient for,int,,,,0,,
mxnet.contrib.ndarray.bipartite_matching,data,The input,The input,,,,,,,
mxnet.ndarray.argmin,data,The input,The input,,,,,,,
mxnet.ndarray.broadcast_to,data,The input,The input,,,,,,,
mxnet.ndarray.image.random_lighting,data,The input.,The input,,,,,,,
mxnet.ndarray.nanprod,data,The input,The input,,,,,,,
mxnet.ndarray.op.amp_cast,data,The input.,The input,,,,,,,
mxnet.ndarray.sum,data,The input,The input,,,,,,,
mxnet.ndarray.choose_element_0index,data,The input array,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.expm1,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.arccos,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.exp,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.log,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.rcbrt,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.op.square,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.radians,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sign,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sin,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.arcsinh,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.cosh,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.log,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.log2,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sqrt,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.retain,data,The input array for sparse_retain operator.,The input D_STRUCTURE for sparse_retain operator,,,D_STRUCTURE,,,,
mxnet.ndarray.op.ROIPooling,data,"The input array to the pooling operator,  a 4D Feature maps",The input D_STRUCTURE to the pooling operator a CONSTANT_NUM D Feature maps,,,D_STRUCTURE,,CONSTANT_NUM,,
mxnet.ndarray.op.SoftmaxOutput,ignore_label,"The instances whose labels == ignore_label will be ignored during backward, if use_ignore is set to `true`).",The instances whose labels ignore_label will be ignored during backward if PARAM is set to CONSTANT_BOOL,,,,,,,
mxnet.contrib.ndarray.hawkesll,max_time,the length of the interval where the processes were sampled,the length of the interval where the processes were sampled,int,,,,,"[0,inf)",
mxnet.ndarray.BatchNorm,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to by quantized batch norm op to calculate primitive scale.Note: this calib_range is to calib bn output.",The maximum scalar value in the form of D_TYPE obtained through calibration,D_TYPE,,,,0,,
mxnet.ndarray.contrib.requantize,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to requantize the int32 data into int8.",The maximum scalar value in the form of D_TYPE obtained through calibration,D_TYPE,,,,0,,
mxnet.ndarray.contrib.quantize,max_range,The maximum scalar value possibly produced for the input,The maximum scalar value possibly produced for the input,numeric,,,,0,,
mxnet.io.ImageRecordIter,mean_g,The mean value to be subtracted on the G channel,The mean value to be subtracted on the G channel,numeric,,,,,,
mxnet.ndarray.contrib.quantize,min_range,The minimum scalar value possibly produced for the input,The minimum scalar value possibly produced for the input,numeric,,,,0,,
mxnet.callback.log_train_metric,period,The number of batch to log the training evaluation metric.,The number of batch to log the training evaluation metric,int,,,,0,"[0,inf)",
mxnet.gluon.rnn.RNN,input_size,"The number of expected features in the input x. If not specified, it will be inferred from input.",The number of expected features in the input x,int,,,,0,"[0,inf)",
mxnet.gluon.rnn.LSTM,hidden_size,The number of features in the hidden state h.,The number of features in the hidden state h,int,,,,0,"[0,inf)",
mxnet.gluon.nn.Conv2DTranspose,in_channels,"The number of input channels to this layer. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",The number of input PARAM to this layer,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.calibrate_entropy,num_quantized_bins,The number of quantized bins.,The number of quantized bins,int,,,,0,"[0,inf)",
mxnet.ndarray.op.repeat,repeats,The number of repetitions for each element.,The number of repetitions for each element,int,,,,0,"[0,inf)",
mxnet.ndarray.random.gamma,shape,"The number of samples to draw. If shape is, e.g., (m, n) and alpha and beta are scalars, output shape will be (m, n). If alpha and beta are NDArrays with shape, e.g., (x, y), then output will have shape (x, y, m, n), where m*n samples are drawn for each [alpha, beta) pair.",The number of samples to draw,int,,,,0,"[0,inf)",
mxnet.test_utils.verify_generator,nsamples,The number of samples to generate for the testing,The number of samples to generate for the testing,int,,,,0,"[0,inf)",
mxnet.contrib.ndarray.hawkesll,valid_length,The number of valid points in the process,The number of valid points in the process,int,,,,0,"[0,inf)",
mxnet.ndarray.ones,out,The output NDArray (default is None).,The output D_STRUCTURE BSTR,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.AdaptiveAvgPooling2D,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.allclose,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.fft,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.getnnz,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.MultiBoxDetection,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.ROIAlign,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.contrib.ndarray.SparseEmbedding,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.image.imresize,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.Activation,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.arccos,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.arctan,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.arctanh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_axes,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_greater,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_logical_and,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_mul,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.broadcast_plus,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.cast_storage,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.backward_hawkesll,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.CTCLoss,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_batch_norm,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_conv,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.quantized_fully_connected,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.contrib.round_ste,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.Dropout,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.ElementWiseSum,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.erfinv,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.LayerNorm,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_gelqf,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.linalg_trsm,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.MAERegressionOutput,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.MakeLoss,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.multi_mp_sgd_mom_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.ones_like,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.Activation,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.arccosh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_greater_equal,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.broadcast_to,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.cast_storage,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.ceil,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.concat,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.diag,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.exp,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.fix,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.ftml_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.linalg_gelqf,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.log1p,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.mp_lamb_update_phase1,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.nag_mom_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.nansum,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.pad,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.random_poisson,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.sample_poisson,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.op.slice_axis,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.preloaded_multi_mp_sgd_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.random.normal_like,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sample_exponential,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.SequenceReverse,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.shuffle,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sinh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.space_to_depth,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.cosh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.elemwise_add,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.floor,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sparse.log,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.sqrt,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.take,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
mxnet.ndarray.random.gamma,alpha,The shape of the gamma distribution. Should be greater than zero.,The PARAM of the gamma distribution,int,,,,1,"[0,inf)",
mxnet.ndarray.mp_nag_mom_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,The penalty scales with the square of the magnitude of each PARAM,,,,,,,
mxnet.ndarray.op.ftrl_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,The penalty scales with the square of the magnitude of each PARAM,,,,,,,
mxnet.contrib.quantization.quantize_model,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",The quantized models generated in this mode are normally CONSTANT_NUM slower than those with calibrations during inference,,,,,,,
mxnet.ndarray.diag,axis2,The second axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,The second axis of the sub D_STRUCTURE of interest,int,,,,,"[0,inf)",
mxnet.ndarray.op.diag,axis2,The second axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,The second axis of the sub D_STRUCTURE of interest,int,,,,,"[0,inf)",
mxnet.ndarray.SwapAxis,dim2,the second axis to be swapped.,the second axis to be swapped,int,,,,,"[0,inf)",
mxnet.contrib.ndarray.MultiProposal,feature_stride,"The size of the receptive field each unit in the convolution layer of the rpn,for example the product of all stride's prior to this layer.",The size of the receptive field each unit in the convolution layer of the rpn for example the product of all stride prior to this layer,int,,,,,"[0,inf)",
mxnet.ndarray.zeros,stype,"The storage type of the empty array, such as 'row_sparse', 'csr', etc.",The storage type of the empty D_STRUCTURE such as QSTR etc,,,,,,,QSTR
mxnet.ndarray.op.reshape,shape,The target shape,The target shape,int,,,,1,"[0,inf)",
mxnet.ndarray.op.SequenceMask,value,The value to be used as a mask.,The value to be used as a mask,,,,,,,
mxnet.gluon.nn.SymbolBlock,inputs,The Variables in output's argument that should be used as inputs.,The Variables in output argument that should be used as inputs,,,,,,,
mxnet.context.cpu,device_id,The device id of the device. device_id is not needed for CPU. This is included to make interface compatible with GPU.,This is included to make interface compatible with GPU,,,,,,,
mxnet.metric.np,allow_extra_outputs,"Whether prediction output is allowed to have extra outputs. This is useful in cases like RNN where states are also part of output which can then be fed back to the RNN in the next step. By default, extra outputs are not allowed.",This is useful in cases like RNN where states are also part of output which can then be fed back to the RNN in the next step,,,,,,,
mxnet.ndarray.sample_multinomial,get_prob,"Whether to also return the log probability of sampled result. This is usually used for differentiating through stochastic variables, e.g. in reinforcement learning.",This is usually used for differentiating through stochastic variables e g,,,,,,,
mxnet.contrib.ndarray.quantized_batch_norm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,This will force change batch norm into a scale shift operator,,,,,,,
mxnet.contrib.ndarray.SyncBatchNorm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,This will force change batch norm into a scale shift operator,,,,,,,
mxnet.ndarray.BatchNorm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,This will force change batch norm into a scale shift operator,,,,,,,
mxnet.ndarray.op.GroupNorm,num_groups,Total number of groups.,Total number of groups,int,,,,0,"[0,inf)",
mxnet.ndarray.op.Convolution,cudnn_off,Turn off cudnn for this layer.,Turn off cudnn for this layer,,,,,,,
mxnet.ndarray.random.uniform,high,Upper boundary of the output interval. All values generated will be less than high. The default value is 1.0.,Upper boundary of the output interval,,,,,,,
mxnet.ndarray.UpSampling,sample_type,upsampling method,upsampling method,,,,,,,
mxnet.ndarray.op.linalg_trmm,transpose,Use transposed of the triangular matrix,Use transposed of the triangular matrix,,,,,,,
mxnet.test_utils.numeric_grad,aux_states,Auxiliary states values used as location to compute gradient Maps the name of aux_states to the corresponding numpy.ndarray. Value of all the auxiliary arguments must be provided.,Value of all the auxiliary arguments must be provided,,,,,,,
mxnet.ndarray.contrib.box_decode,std2,value to be divided from the 3rd encoded values,value to be divided from the 3rd encoded values,numeric,,,,,,
mxnet.contrib.ndarray.SparseEmbedding,input_dim,Vocabulary size of the input indices.,Vocabulary size of the input indices,int,,,,,"[0,inf)",
mxnet.contrib.ndarray.quantized_conv,weight,weight.,ONE_WORD weight,numeric,,,,,,
mxnet.contrib.ndarray.quantized_fully_connected,weight,weight.,ONE_WORD weight,numeric,,,,,,
mxnet.ndarray.op.ftml_update,weight,Weight,ONE_WORD weight,numeric,,,,,,
mxnet.ndarray.op.mp_sgd_mom_update,weight,Weight,ONE_WORD weight,numeric,,,,,,
mxnet.ndarray.op.sgd_mom_update,weight,Weight,ONE_WORD weight,numeric,,,,,,
mxnet.ndarray.op.signum_update,weight,Weight,ONE_WORD weight,numeric,,,,,,
mxnet.ndarray.rmsprop_update,weight,Weight,ONE_WORD weight,numeric,,,,,,
mxnet.contrib.ndarray.DeformableConvolution,weight,Weight matrix.,weight matrix,numeric,,,,,,
mxnet.ndarray.op.Convolution,weight,Weight matrix.,weight matrix,numeric,,,,,,
mxnet.ndarray.mp_lamb_update_phase1,weight32,Weight32,ONE_WORD weight32,numeric,,,,,,
mxnet.ndarray.mp_nag_mom_update,weight32,Weight32,ONE_WORD weight32,numeric,,,,,,
mxnet.ndarray.mp_sgd_update,weight32,Weight32,ONE_WORD weight32,numeric,,,,,,
mxnet.gluon.nn.AvgPool1D,count_include_pad,"When 'False', will exclude padding elements when computing the average value.",When QSTR will exclude PARAM elements when computing the average value,,,,,,,
mxnet.gluon.nn.BatchNorm,scale,"If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.",When the next layer is linear also e g,,,,,,,
mxnet.util.set_np,shape,"A boolean value indicating whether the NumPy-shape semantics should be turned on or off. When this flag is set to True, zero-size and zero-dim shapes are all valid shapes in shape inference process, instead of treated as unknown shapes in legacy mode.",When this flag is set to CONSTANT_BOOL zero size and zero dim shapes are all valid shapes in shape inference process instead of treated as unknown shapes in legacy mode,bool,,,,0,,
mxnet.metric.np,allow_extra_outputs,"Whether prediction output is allowed to have extra outputs. This is useful in cases like RNN where states are also part of output which can then be fed back to the RNN in the next step. By default, extra outputs are not allowed.",Whether prediction output is allowed to have extra outputs,bool,,,,0,,
mxnet.gluon.nn.Conv2DTranspose,use_bias,Whether the layer uses a bias vector.,Whether the layer uses a bias D_STRUCTURE,bool,,,,0,,
mxnet.ndarray.sample_multinomial,get_prob,"Whether to also return the log probability of sampled result. This is usually used for differentiating through stochastic variables, e.g. in reinforcement learning.",Whether to also return the log probability of sampled result,bool,,,,0,,
mxnet.image.CreateAugmenter,rand_mirror,Whether to apply horizontal flip to image with probability 0.5,Whether to apply horizontal flip to image with probability CONSTANT_NUM,bool,,,,0,,
mxnet.contrib.ndarray.quantized_fully_connected,flatten,Whether to collapse all but the first axis of the input data tensor.,Whether to collapse all but the first axis of the input PARAM D_STRUCTURE,bool,,,,0,,
mxnet.contrib.ndarray.quantized_fully_connected,no_bias,Whether to disable bias parameter.,Whether to disable PARAM parameter,bool,,,,0,,
mxnet.gluon.utils.split_data,even_split,"Whether to force all slices to have the same number of elements. If True, an error will be raised when num_slice does not evenly divide data.shape[batch_axis].",Whether to force all slices to have the same number of elements,bool,,,,0,,
mxnet.ndarray.RNN,state_outputs,Whether to have the states as symbol outputs.,Whether to have the states as symbol outputs,bool,,,,0,,
mxnet.gluon.model_zoo.vision.alexnet,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.densenet121,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.get_model,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.resnet50_v2,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.vgg11_bn,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.vgg13,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.gluon.model_zoo.vision.vgg19,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
mxnet.ndarray.Dropout,mode,Whether to only turn on dropout during training or to also turn on for inference.,Whether to only turn on dropout during training or to also turn on for inference,bool,,,,0,,
mxnet.ndarray.op.nansum,exclude,Whether to perform reduction on axis that are NOT in axis instead.,Whether to perform reduction on PARAM that are NOT in PARAM instead,bool,,,,0,,
mxnet.ndarray.op.sum_axis,exclude,Whether to perform reduction on axis that are NOT in axis instead.,Whether to perform reduction on PARAM that are NOT in PARAM instead,bool,,,,0,,
mxnet.ndarray.sparse.mean,exclude,Whether to perform reduction on axis that are NOT in axis instead.,Whether to perform reduction on PARAM that are NOT in PARAM instead,bool,,,,0,,
mxnet.profiler.set_config,continuous_dump,whether to periodically dump profiling data to file,whether to periodically dump profiling data to file,bool,,,,0,,
mxnet.ndarray.Deconvolution,cudnn_tune,Whether to pick convolution algorithm by running performance test.,Whether to pick convolution algorithm by running performance test,bool,,,,0,,
mxnet.ndarray.RNN,lstm_state_clip_nan,"Whether to stop NaN from propagating in state by clipping it to min/max. If clipping range is not specified, this option is ignored.",Whether to stop NaN from propagating in PARAM by clipping it to min max,bool,,,,0,,
mxnet.ndarray.op.softmin,use_length,Whether to use the length input as a mask over the data input.,Whether to use the length input as a mask over the PARAM input,bool,,,,0,,
mxnet.contrib.ndarray.quantized_batch_norm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,Whether use global moving statistics instead of local batch norm,bool,,,,0,,
mxnet.contrib.ndarray.SyncBatchNorm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,Whether use global moving statistics instead of local batch norm,bool,,,,0,,
mxnet.ndarray.BatchNorm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,Whether use global moving statistics instead of local batch norm,bool,,,,0,,
mxnet.gluon.utils.download,sha1_hash,Expected sha1 hash in hexadecimal digits. Will ignore existing file when hash is specified but doesn't match.,Will ignore existing file when hash is specified but doesn t match,,,,,,,