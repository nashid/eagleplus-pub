constraints:
  average:
    default: macro
    descp: 'string, [None, ''micro'', ''macro'' (default), ''samples'', ''weighted'']
      If ``None``, the scores for each class are returned. Otherwise, this determines
      the type of averaging performed on the data: ``''micro''``: Calculate metrics
      globally by considering each element of the label indicator matrix as a label.
      ``''macro''``: Calculate metrics for each label, and find their unweighted mean.  This
      does not take label imbalance into account. ``''weighted''``: Calculate metrics
      for each label, and find their average, weighted by support (the number of true
      instances for each label). ``''samples''``: Calculate metrics for each instance,
      and find their average. Will be ignored when ``y_true`` is binary.'
    dtype:
    - string
  pos_label:
    default: '1'
    descp: int or str (default=1) The label of the positive class. Only applied to
      binary ``y_true``. For multilabel-indicator ``y_true``, ``pos_label`` is fixed
      to 1.
    dtype:
    - int
    ndim:
    - '0'
  sample_weight:
    default: None
    descp: array-like of shape (n_samples,), default=None Sample weights.
    ndim:
    - '1'
    shape:
    - '[n_samples]'
  y_score:
    descp: array, shape = [n_samples] or [n_samples, n_classes] Target scores, can
      either be probability estimates of the positive class, confidence values, or
      non-thresholded measure of decisions (as returned by "decision_function" on
      some classifiers).
  y_true:
    descp: array, shape = [n_samples] or [n_samples, n_classes] True binary labels
      or binary label indicators.
dependency:
- n_samples
inputs:
  optional:
  - average
  - pos_label
  - sample_weight
  required:
  - y_true
  - y_score
link: ''
package: scikit-learn
target: average_precision_score
title: sklearn.metrics.average_precision_score
version: 0.24.X
