constraints:
  log_target:
    default: 'False'
    descp: 'Specifies whether target is passed in the log space. Default: `False`'
    doc_dtype:
    - bool
    sig_dtype: bool
  reduce:
    default: None
    descp: 'Deprecated (see `reduction`). By default, the losses are averaged or summed
      over observations for each minibatch depending on `size_average`. When `reduce`
      is `False`, returns a loss per batch element instead and ignores `size_average`.
      Default: `True`'
    doc_dtype:
    - bool
  reduction:
    default: mean
    descp: 'Specifies the reduction to apply to the output: `''none''` | `''batchmean''`
      | `''sum''` | `''mean''`. `''none''`: no reduction will be applied. `''batchmean''`:
      the sum of the output will be divided by batchsize. `''sum''`: the output will
      be summed. `''mean''`: the output will be divided by the number of elements
      in the output. Default: `''mean''`'
    doc_dtype:
    - string
    sig_dtype: str
  size_average:
    default: None
    descp: 'Deprecated (see `reduction`). By default, the losses are averaged over
      each loss element in the batch. Note that for some losses, there are multiple
      elements per sample. If the field `size_average` is set to `False`, the losses
      are instead summed for each minibatch. Ignored when reduce is `False`. Default:
      `True`'
    doc_dtype:
    - bool
inputs:
  optional:
  - size_average
  - reduce
  - reduction
  - log_target
  required: []
link: https://pytorch.org/docs/1.6.0/generated/torch.nn.KLDivLoss.html#torch.nn.KLDivLoss#torch.nn.KLDivLoss
package: torch
target: KLDivLoss
title: torch.nn.KLDivLoss
version: 1.6.0
