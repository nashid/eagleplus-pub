constraints:
  _weight:
    default: None
    descp: ''
  embedding_dim:
    descp: the size of each embedding vector
    doc_dtype:
    - python:int
  max_norm:
    default: None
    descp: If given, each embedding vector with norm larger than `max_norm` is renormalized
      to have norm `max_norm`.
    doc_dtype:
    - python:float
  mode:
    default: mean
    descp: '`"sum"`, `"mean"` or `"max"`. Specifies the way to reduce the bag. `"sum"`
      computes the weighted sum, taking `per_sample_weights` into consideration. `"mean"`
      computes the average of the values in the bag, `"max"` computes the max value
      over each bag. Default: `"mean"`'
    doc_dtype:
    - string
  norm_type:
    default: '2.0'
    descp: The p of the p-norm to compute for the `max_norm` option. Default `2`.
    doc_dtype:
    - python:float
  num_embeddings:
    descp: size of the dictionary of embeddings
    doc_dtype:
    - python:int
  scale_grad_by_freq:
    default: 'False'
    descp: 'if given, this will scale gradients by the inverse of frequency of the
      words in the mini-batch. Default `False`. Note: this option is not supported
      when `mode="max"`.'
    doc_dtype:
    - boolean
  sparse:
    default: 'False'
    descp: 'if `True`, gradient w.r.t. `weight` matrix will be a sparse tensor. See
      Notes for more details regarding sparse gradients. Note: this option is not
      supported when `mode="max"`.'
    doc_dtype:
    - bool
inputs:
  optional:
  - max_norm
  - norm_type
  - scale_grad_by_freq
  - mode
  - sparse
  - _weight
  required:
  - num_embeddings
  - embedding_dim
link: https://pytorch.org/docs/1.4.0/nn.html#torch.nn.EmbeddingBag
package: torch
target: EmbeddingBag
title: torch.nn.EmbeddingBag
version: 1.4.0
