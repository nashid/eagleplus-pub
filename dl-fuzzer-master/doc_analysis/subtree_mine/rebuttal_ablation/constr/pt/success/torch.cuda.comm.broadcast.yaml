constraints:
  devices:
    descp: an iterable of devices among which to broadcast. Note that it should be
      like (src, dst1, dst2,  u2026), the first element of which is the source device
      to broadcast from.
    doc_dtype: Iterable
    dtype:
    - int
    - numeric
    - string
    - torch.bool
    - torch.dtype
    ndim:
    - '0'
    - '1'
    - '3'
    - '4'
    range:
    - '[0,1]'
    - '[0,inf)'
    shape:
    - '[b,p,m]'
    - '[c]'
    - '[src,dst1,dst2,u2026]'
    structure:
    - list
  tensor:
    descp: tensor to broadcast.
    doc_dtype: Tensor
    dtype:
    - int
    - string
    ndim:
    - '1'
    range:
    - '[0,inf)'
    shape:
    - '[c]'
    tensor_t:
    - torch.tensor
inputs:
  optional: []
  required:
  - tensor
  - devices
link: https://pytorch.org/docs/stable/cuda.html#torch.cuda.comm.broadcast
package: torch
target: broadcast
title: torch.cuda.comm.broadcast
version: 1.5.0
