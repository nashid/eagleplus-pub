constraints:
  activation:
    default: tanh
    descp: Type of activation function used in n_t. If argument type is string, it's
      equivalent to nn.Activation(act_type=str). See `Activation()` for available
      choices. Alternatively, other activation blocks such as nn.LeakyReLU can be
      used.
    doc_dtype: str or gluon.Block, default 'tanh'
    normalized_default: DEFAULT DF_STR
    normalized_descp:
    - Type of activation function used in n_t
    - If argument type is D_TYPE, it equivalent to nn Activation act_type D_TYPE
    - See Activation for available choices
    - Alternatively, other activation blocks such as nn LeakyReLU can be used
    normalized_docdtype: D_TYPE or gluon Block, default QSTR
  conv_layout:
    default: NCDHW
    descp: Layout for all convolution inputs, outputs and weights. Options are 'NCDHW'
      and 'NDHWC'.
    doc_dtype: str, default 'NCDHW'
    normalized_default: DEFAULT DF_STR
    normalized_descp:
    - Layout for all convolution inputs, outputs and weights
    - Options are QSTR
    normalized_docdtype: D_TYPE, default QSTR
  h2h_bias_initializer:
    default: zeros
    descp: Initializer for the recurrent convolution bias vectors.
    doc_dtype: str or Initializer, default zeros
    normalized_default: DEFAULT DF_STR
    normalized_descp:
    - Initializer for the recurrent convolution bias D_STRUCTURE
    normalized_docdtype: D_TYPE or Initializer, default zeros
  h2h_dilate:
    default: (1,1,1)
    descp: Recurrent convolution dilate.
    doc_dtype: int or tuple of int, default (1, 1, 1
    normalized_default: CONSTANT_NUM CONSTANT_NUM CONSTANT_NUM
    normalized_descp:
    - Recurrent convolution dilate
    normalized_docdtype: D_TYPE or D_STRUCTURE of D_TYPE, default CONSTANT_NUM
  h2h_kernel:
    descp: Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.
    doc_dtype: int or tuple of int
    normalized_descp:
    - Recurrent convolution kernel sizes
    - Only odd numbered sizes are supported
    normalized_docdtype: D_TYPE or D_STRUCTURE of D_TYPE
  h2h_weight_initializer:
    default: None
    descp: Initializer for the recurrent weights matrix, used for the input convolutions.
    doc_dtype: str or Initializer
    normalized_default: DEFAULT None
    normalized_descp:
    - Initializer for the recurrent weights matrix, used for the input convolutions
    normalized_docdtype: D_TYPE or Initializer
  hidden_channels:
    descp: Number of output channels.
    doc_dtype: int
    normalized_descp:
    - Number of output channels
    normalized_docdtype: ONE_WORD D_TYPE
  i2h_bias_initializer:
    default: zeros
    descp: Initializer for the input convolution bias vectors.
    doc_dtype: str or Initializer, default zeros
    normalized_default: DEFAULT DF_STR
    normalized_descp:
    - Initializer for the input convolution bias D_STRUCTURE
    normalized_docdtype: D_TYPE or Initializer, default zeros
  i2h_dilate:
    default: (1,1,1)
    descp: Input convolution dilate.
    doc_dtype: int or tuple of int, default (1, 1, 1
    normalized_default: CONSTANT_NUM CONSTANT_NUM CONSTANT_NUM
    normalized_descp:
    - Input convolution dilate
    normalized_docdtype: D_TYPE or D_STRUCTURE of D_TYPE, default CONSTANT_NUM
  i2h_kernel:
    descp: Input convolution kernel sizes.
    doc_dtype: int or tuple of int
    normalized_descp:
    - Input convolution kernel sizes
    normalized_docdtype: D_TYPE or D_STRUCTURE of D_TYPE
  i2h_pad:
    default: (0,0,0)
    descp: Pad for input convolution.
    doc_dtype: int or tuple of int, default (0, 0, 0
    normalized_default: CONSTANT_NUM CONSTANT_NUM CONSTANT_NUM
    normalized_descp:
    - Pad for input convolution
    normalized_docdtype: D_TYPE or D_STRUCTURE of D_TYPE, default CONSTANT_NUM
  i2h_weight_initializer:
    default: None
    descp: Initializer for the input weights matrix, used for the input convolutions.
    doc_dtype: str or Initializer
    normalized_default: DEFAULT None
    normalized_descp:
    - Initializer for the input weights matrix, used for the input convolutions
    normalized_docdtype: D_TYPE or Initializer
  input_shape:
    descp: Input tensor shape at each time step for each sample, excluding dimension
      of the batch size and sequence length. Must be consistent with conv_layout.
      For example, for layout 'NCDHW' the shape should be (C, D, H, W).
    doc_dtype: tuple of int
    normalized_descp:
    - Input D_STRUCTURE shape at each time step for each sample, excluding dimension
      of the batch size and D_STRUCTURE length
    - Must be consistent with PARAM
    - For example, for layout QSTR the shape should be BSTR
    normalized_docdtype: D_STRUCTURE of D_TYPE
  params:
    default: None
    descp: Container for weight sharing between cells. Created if None.
    doc_dtype: RNNParams, default None
    normalized_default: DEFAULT None
    normalized_descp:
    - Container for weight sharing between cells
    - Created if None
    normalized_docdtype: RNNParams, default None
  prefix:
    default: None
    descp: Prefix for name of layers (and name of weight if params is None).
    doc_dtype: "str, default `'conv_gru_`\u2019"
    normalized_default: DEFAULT None
    normalized_descp:
    - Prefix for name of layers BSTR
    normalized_docdtype: D_TYPE, default QSTR
inputs:
  optional:
  - i2h_pad
  - i2h_dilate
  - h2h_dilate
  - i2h_weight_initializer
  - h2h_weight_initializer
  - i2h_bias_initializer
  - h2h_bias_initializer
  - conv_layout
  - activation
  - prefix
  - params
  required:
  - input_shape
  - hidden_channels
  - i2h_kernel
  - h2h_kernel
link: https://mxnet.apache.org/versions/1.6.0/api/python/docs/api/gluon/contrib/index.html#mxnet.gluon.contrib.rnn.Conv3DGRUCell
package: mxnet
target: Conv3DGRUCell
title: mxnet.gluon.contrib.rnn.Conv3DGRUCell
version: 1.6.0
