constraints:
  dtype:
    descp: 'A tf.DType from: tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16,
      tf.int8, tf.complex64, tf.int64, tf.qint8, tf.quint8, tf.qint32, tf.bfloat16,
      tf.uint16, tf.complex128, tf.half, tf.uint32, tf.uint64. The data type of accumulated
      gradients. Needs to correspond to the type of the accumulator.'
    dtype:
    - tf.dtype
    ndim:
    - '0'
  handle:
    descp: A Tensor of type mutable string. The handle to an accumulator.
    tensor_t:
    - tf.tensor
  name:
    default: None
    descp: A name for the operation (optional).
    dtype:
    - tf.string
    ndim:
    - '0'
  num_required:
    descp: A Tensor of type int32. Number of gradients required before we return an
      aggregate.
    dtype:
    - tf.int32
    ndim:
    - '0'
    range:
    - '[0,inf)'
    tensor_t:
    - tf.tensor
inputs:
  optional:
  - name
  required:
  - handle
  - num_required
  - dtype
link: https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/raw_ops/AccumulatorTakeGradient
outputs:
- A Tensor of type dtype.
package: tensorflow
target: AccumulatorTakeGradient
title: tf.raw_ops.AccumulatorTakeGradient
version: 2.3.0
