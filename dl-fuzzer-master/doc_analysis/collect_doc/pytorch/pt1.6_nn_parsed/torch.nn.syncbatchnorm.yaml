constraints:
  affine:
    default: 'True'
    descp: 'a boolean value that when set to `True`, this module has learnable affine
      parameters. Default: `True`'
    sig_dtype: bool
  eps:
    default: 1e-05
    descp: 'a value added to the denominator for numerical stability. Default: `1e-5`'
    sig_dtype: float
  momentum:
    default: '0.1'
    descp: 'the value used for the running_mean and running_var computation. Can be
      set to `None` for cumulative moving average (i.e. simple average). Default:
      0.1'
    sig_dtype: float
  num_features:
    descp: 'C  from an expected input of size (N, C, +) '
    sig_dtype: int
  process_group:
    default: None
    descp: synchronization of stats happen within each process group individually.
      Default behavior is synchronization across the whole world
    sig_dtype: Optional[Any]
  track_running_stats:
    default: 'True'
    descp: 'a boolean value that when set to `True`, this module tracks the running
      mean and variance, and when set to `False`, this module does not track such
      statistics and uses batch statistics instead in both training and eval modes
      if the running mean and variance are `None`. Default: `True`'
    sig_dtype: bool
inputs:
  optional:
  - eps
  - momentum
  - affine
  - track_running_stats
  - process_group
  required:
  - num_features
link: https://pytorch.org/docs/1.6.0/generated/torch.nn.SyncBatchNorm.html#torch.nn.SyncBatchNorm#torch.nn.SyncBatchNorm
package: torch
target: SyncBatchNorm
title: torch.nn.SyncBatchNorm
version: 1.6.0
