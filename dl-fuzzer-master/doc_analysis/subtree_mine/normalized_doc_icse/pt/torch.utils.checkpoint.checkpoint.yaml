constraints:
  '**kwargs':
    descp: ''
    normalized_descp: []
  '*args':
    descp: tuple containing inputs to the `function`
    normalized_descp:
    - D_STRUCTURE containing inputs to the PARAM
  function:
    descp: describes what to run in the forward pass of the model or part of the model.
      It should also know how to handle the inputs passed as the tuple. For example,
      in LSTM, if user passes `(activation, hidden)`, `function` should correctly
      use the first input as `activation` and the second input as `hidden`
    normalized_descp:
    - describes what to run in the forward pass of the model or part of the model
    - It should also know how to handle the inputs passed as the D_STRUCTURE
    - For example in LSTM if user passes BSTR QSTR should correctly use the first
      input as QSTR and the second input as QSTR
  preserve_rng_state:
    default: None
    descp: Omit stashing and restoring the RNG state during each checkpoint.
    doc_dtype: bool, optional, default=True
    normalized_default: DEFAULT None
    normalized_descp:
    - Omit stashing and restoring the RNG state during each checkpoint
    normalized_docdtype: D_TYPE optional default CONSTANT_BOOL
inputs:
  optional:
  - preserve_rng_state
  required:
  - function
  - '*args'
  - '**kwargs'
link: https://pytorch.org/docs/stable/checkpoint.html#torch.utils.checkpoint.checkpoint
package: torch
target: checkpoint
title: torch.utils.checkpoint.checkpoint
version: 1.5.0
