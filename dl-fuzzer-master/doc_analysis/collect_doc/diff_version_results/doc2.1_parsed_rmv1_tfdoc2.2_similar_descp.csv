API,Param,ratio,doc2.1_parsed_rmv1,tfdoc2.2
tf.keras.datasets.reuters.load_data.yaml,start_char,0.9401709401709402,The start of a sequence will be marked with this character. Set to 1 because 0 is usually the padding character.,int. The start of a sequence will be marked with this character. Defaults to 1 because 0 is usually the padding character.
tf.keras.datasets.reuters.load_data.yaml,index_from,0.9484536082474226,index actual words with this index and higher.,int. Index actual words with this index and higher.
tf.image.non_max_suppression_overlaps.yaml,max_output_size,0.9902912621359223,A scalar integer `Tensor` representing the maximum number of boxes to be selected by non max suppression.,A scalar integer Tensor representing the maximum number of boxes to be selected by non-max suppression.
tf.keras.estimator.model_to_estimator.yaml,keras_model_path,0.9521276595744681,"Path to a compiled Keras model saved on disk, in HDF5 format, which can be generated with the `save()` method of a Keras model. This argument is mutually exclusive with `keras_model`.","Path to a compiled Keras model saved on disk, in HDF5 format, which can be generated with the save() method of a Keras model. This argument is mutually exclusive with keras_model. Defaults to None."
tf.keras.estimator.model_to_estimator.yaml,checkpoint_format,0.9699481865284975,"Sets the format of the checkpoint saved by the estimator when training. May be `saver` or `checkpoint`, depending on whether to save checkpoints from `tf.compat.v1.train.Saver` or `tf.train.Checkpoint`. The default is `checkpoint`. Estimators use name-based `tf.train.Saver`checkpoints, while Keras models use object-based checkpoints from`tf.train.Checkpoint`. Currently, saving object-based checkpoints from`model_to_estimator` is only supported by Functional and Sequential models.","Sets the format of the checkpoint saved by the estimator when training. May be saver or checkpoint, depending on whether to save checkpoints from tf.compat.v1.train.Saver or tf.train.Checkpoint. The default is checkpoint. Estimators use name-based tf.train.Saver checkpoints, while Keras models use object-based checkpoints from tf.train.Checkpoint. Currently, saving object-based checkpoints from model_to_estimator is only supported by Functional and Sequential models. Defaults to 'checkpoint'."
tf.image.grayscale_to_rgb.yaml,images,0.9692307692307692,The Grayscale tensor to convert. Last dimension must be size 1.,The Grayscale tensor to convert. The last dimension must be size 1.
tf.argsort.yaml,direction,0.993006993006993,The direction in which to sort the values (`'ASCENDING'` or`'DESCENDING'`).,The direction in which to sort the values ('ASCENDING' or 'DESCENDING').
tf.image.non_max_suppression_padded.yaml,pad_to_max_output_size,0.9934640522875817,"bool.  If True, size of `selected_indices` output is padded to `max_output_size`.","bool. If True, size of selected_indices output is padded to max_output_size."
tf.image.non_max_suppression_padded.yaml,max_output_size,0.9902912621359223,A scalar integer `Tensor` representing the maximum number of boxes to be selected by non max suppression.,A scalar integer Tensor representing the maximum number of boxes to be selected by non-max suppression.
tf.shape.yaml,out_type,0.9945945945945946,(Optional) The specified output type of the operation (`int32` or`int64`). Defaults to `tf.int32`.,(Optional) The specified output type of the operation (int32 or int64). Defaults to tf.int32.
tf.data.experimental.make_csv_dataset.yaml,column_defaults,0.997624703087886,"A optional list of default values for the CSV fields. One item per selected column of the input record. Each item in the list is either a valid CSV dtype (float32, float64, int32, int64, or string), or a`Tensor` with one of the aforementioned types. The tensor can either be a scalar default value (if the column is optional), or an empty tensor (if the column is required). If a dtype is provided instead of a tensor, the column is also treated as required. If this list is not provided, tries to infer types based on reading the first num_rows_for_inference rows of files specified, and assumes all columns are optional, defaulting to `0`for numeric values and `""""` for string values. If both this and`select_columns` are specified, these must have the same lengths, and`column_defaults` is assumed to be sorted in order of increasing column index.","A optional list of default values for the CSV fields. One item per selected column of the input record. Each item in the list is either a valid CSV dtype (float32, float64, int32, int64, or string), or a Tensor with one of the aforementioned types. The tensor can either be a scalar default value (if the column is optional), or an empty tensor (if the column is required). If a dtype is provided instead of a tensor, the column is also treated as required. If this list is not provided, tries to infer types based on reading the first num_rows_for_inference rows of files specified, and assumes all columns are optional, defaulting to 0 for numeric values and """" for string values. If both this and select_columns are specified, these must have the same lengths, and column_defaults is assumed to be sorted in order of increasing column index."
tf.data.experimental.make_csv_dataset.yaml,select_columns,0.999163179916318,"An optional list of integer indices or string column names, that specifies a subset of columns of CSV data to select. If column names are provided, these must correspond to names provided in`column_names` or inferred from the file header lines. When this argument is specified, only a subset of CSV columns will be parsed and returned, corresponding to the columns specified. Using this results in faster parsing and lower memory usage. If both this and `column_defaults` are specified, these must have the same lengths, and `column_defaults` is assumed to be sorted in order of increasing column index.","An optional list of integer indices or string column names, that specifies a subset of columns of CSV data to select. If column names are provided, these must correspond to names provided in column_names or inferred from the file header lines. When this argument is specified, only a subset of CSV columns will be parsed and returned, corresponding to the columns specified. Using this results in faster parsing and lower memory usage. If both this and column_defaults are specified, these must have the same lengths, and column_defaults is assumed to be sorted in order of increasing column index."
tf.data.experimental.make_csv_dataset.yaml,compression_type,0.9957805907172996,"(Optional.) A `tf.string` scalar evaluating to one of`""""` (no compression), `""ZLIB""`, or `""GZIP""`. Defaults to no compression.","(Optional.) A tf.string scalar evaluating to one of """" (no compression), ""ZLIB"", or ""GZIP"". Defaults to no compression."
tf.debugging.experimental.enable_dump_debug_info.yaml,tensor_debug_mode,0.997979797979798,"Debug mode for tensor values, as a string. The currently supported options are: ""NO_TENSOR"": (Default) Only traces the execution of ops' output tensors, while not dumping the value of the ops' output tensors or any form of concise summary of them. ","Debug mode for tensor values, as a string. The currently supported options are: ""NO_TENSOR"": (Default) Only traces the execution of ops' output tensors, while not dumping the value of the ops' output tensors or any form of concise summary of them."
tf.debugging.experimental.enable_dump_debug_info.yaml,circular_buffer_size,0.9992229992229992,"Size of the circular buffers for execution events. These circular buffers are designed to reduce the overhead of debugging dumping. They hold the most recent debug events concerning eager execution of ops and `tf.function`s and traces of tensor values computed inside`tf.function`s. They are written to the file system only when the proper flushing method is called (see description of return values below). Expected to be an integer. If <= 0, the circular-buffer behavior will be disabled, i.e., the execution debug events will be written to the file writers in the same way as non-execution events such as op creations and source-file snapshots.","Size of the circular buffers for execution events. These circular buffers are designed to reduce the overhead of debugging dumping. They hold the most recent debug events concerning eager execution of ops and tf.functions and traces of tensor values computed inside tf.functions. They are written to the file system only when the proper flushing method is called (see description of return values below). Expected to be an integer. If <= 0, the circular-buffer behavior will be disabled, i.e., the execution debug events will be written to the file writers in the same way as non-execution events such as op creations and source-file snapshots."
tf.linalg.tridiagonal_matmul.yaml,diagonals,0.9970501474926253,"A `Tensor` or tuple of `Tensor`s describing left-hand sides. The shape depends of `diagonals_format`, see description above. Must be`float32`, `float64`, `complex64`, or `complex128`.","A Tensor or tuple of Tensors describing left-hand sides. The shape depends of diagonals_format, see description above. Must be float32, float64, complex64, or complex128."
tf.feature_column.categorical_column_with_vocabulary_list.yaml,dtype,0.9957081545064378,"The type of features. Only string and integer types are supported. If`None`, it will be inferred from `vocabulary_list`.","The type of features. Only string and integer types are supported. If None, it will be inferred from vocabulary_list."
tf.feature_column.categorical_column_with_vocabulary_list.yaml,default_value,0.9964912280701754,"The integer ID value to return for out-of-vocabulary feature values, defaults to `-1`. This can not be specified with a positive`num_oov_buckets`.","The integer ID value to return for out-of-vocabulary feature values, defaults to -1. This can not be specified with a positive num_oov_buckets."
tf.feature_column.categorical_column_with_vocabulary_list.yaml,num_oov_buckets,0.998272884283247,"Non-negative integer, the number of out-of-vocabulary buckets. All out-of-vocabulary inputs will be assigned IDs in the range`[len(vocabulary_list), len(vocabulary_list)+num_oov_buckets)` based on a hash of the input value. A positive `num_oov_buckets` can not be specified with `default_value`.","Non-negative integer, the number of out-of-vocabulary buckets. All out-of-vocabulary inputs will be assigned IDs in the range [len(vocabulary_list), len(vocabulary_list)+num_oov_buckets) based on a hash of the input value. A positive num_oov_buckets can not be specified with default_value."
tf.feature_column.categorical_column_with_vocabulary_list.yaml,key,0.9971014492753624,"A unique string identifying the input feature. It is used as the column name and the dictionary key for feature parsing configs, feature `Tensor`objects, and feature columns.","A unique string identifying the input feature. It is used as the column name and the dictionary key for feature parsing configs, feature Tensor objects, and feature columns."
tf.no_gradient.yaml,op_type,0.9956331877729258,The string type of an operation. This corresponds to the`OpDef.name` field for the proto that defines the operation.,The string type of an operation. This corresponds to the OpDef.name field for the proto that defines the operation.
tf.random.all_candidate_sampler.yaml,num_true,0.9914529914529915,An `int`.  The number of target classes per training example.,An int. The number of target classes per training example.
tf.random.all_candidate_sampler.yaml,num_sampled,0.9873417721518988,An `int`.  The number of possible classes.,An int. The number of possible classes.
tf.dtypes.as_dtype.yaml,type_value,0.9965870307167235,"A value that can be converted to a `tf.DType` object. This may currently be a `tf.DType` object, a `DataType`enum, a string type name, or a `numpy.dtype`.","A value that can be converted to a tf.DType object. This may currently be a tf.DType object, a DataType enum, a string type name, or a numpy.dtype."
tf.extract_volume_patches.yaml,strides,0.9970845481049563,"A list of `ints` that has length `>= 5`. 1-D of length 5. How far the centers of two consecutive patches are in`input`. Must be: `[1, stride_planes, stride_rows, stride_cols, 1]`.","A list of ints that has length >= 5. 1-D of length 5. How far the centers of two consecutive patches are in input. Must be: [1, stride_planes, stride_rows, stride_cols, 1]."
tf.sparse.segment_sum.yaml,num_segments,0.9923664122137404,An optional int32 scalar. Indicates the size of the output`Tensor`.,An optional int32 scalar. Indicates the size of the output Tensor.
tf.sparse.segment_sum.yaml,indices,0.9923664122137404,A 1-D `Tensor` with indices into `data`. Has same rank as`segment_ids`.,A 1-D Tensor with indices into data. Has same rank as segment_ids.
tf.config.optimizer.set_experimental_options.yaml,options,0.9948500454407755,"Dictionary of experimental optimizer options to configure. Valid keys: layout_optimizer: Optimize tensor layouts e.g. This will try to use NCHW layout on GPU which is faster.constant_folding: Fold constants Statically infer the value of tensors when possible, and materialize the result using constants.shape_optimization: Simplify computations made on shapes.remapping: Remap subgraphs onto more efficient implementations.arithmetic_optimization: Simplify arithmetic ops with common sub-expression elimination and arithmetic simplification.dependency_optimization: Control dependency optimizations. Remove redundant control dependencies, which may enable other optimization. This optimizer is also essential for pruning Identity and NoOp nodes.loop_optimization: Loop optimizations.function_optimization: Function optimizations and inlining.debug_stripper: Strips debug-related nodes from the graph.disable_model_pruning: Disable removal of unnecessary ops from the graphscoped_allocator_optimization: Try to allocate some independent Op outputs contiguously in order to merge or eliminate downstream Ops.pin_to_host_optimization: Force small ops onto the CPU.implementation_selector: Enable the swap of kernel implementations based on the device placement.auto_mixed_precision: Change certain float32 ops to float16 on Volta GPUs and above. Without the use of loss scaling, this can cause numerical underflow (see`keras.mixed_precision.experimental.LossScaleOptimizer`).disable_meta_optimizer: Disable the entire meta optimizer.min_graph_nodes: The minimum number of nodes in a graph to optimizer. For smaller graphs, optimization is skipped. ","Dictionary of experimental optimizer options to configure. Valid keys: layout_optimizer: Optimize tensor layouts e.g. This will try to use NCHW layout on GPU which is faster. constant_folding: Fold constants Statically infer the value of tensors when possible, and materialize the result using constants. shape_optimization: Simplify computations made on shapes. remapping: Remap subgraphs onto more efficient implementations. arithmetic_optimization: Simplify arithmetic ops with common sub-expression elimination and arithmetic simplification. dependency_optimization: Control dependency optimizations. Remove redundant control dependencies, which may enable other optimization. This optimizer is also essential for pruning Identity and NoOp nodes. loop_optimization: Loop optimizations. function_optimization: Function optimizations and inlining. debug_stripper: Strips debug-related nodes from the graph. disable_model_pruning: Disable removal of unnecessary ops from the graph scoped_allocator_optimization: Try to allocate some independent Op outputs contiguously in order to merge or eliminate downstream Ops. pin_to_host_optimization: Force small ops onto the CPU. implementation_selector: Enable the swap of kernel implementations based on the device placement. auto_mixed_precision: Change certain float32 ops to float16 on Volta GPUs and above. Without the use of loss scaling, this can cause numerical underflow (see keras.mixed_precision.experimental.LossScaleOptimizer). disable_meta_optimizer: Disable the entire meta optimizer. min_graph_nodes: The minimum number of nodes in a graph to optimizer. For smaller graphs, optimization is skipped."
tf.feature_column.numeric_column.yaml,default_value,0.9989258861439313,"A single value compatible with `dtype` or an iterable of values compatible with `dtype` which the column takes on during`tf.Example` parsing if data is missing. A default value of `None` will cause `tf.io.parse_example` to fail if an example does not contain this column. If a single value is provided, the same value will be applied as the default value for every item. If an iterable of values is provided, the shape of the `default_value` should be equal to the given `shape`.","A single value compatible with dtype or an iterable of values compatible with dtype which the column takes on during tf.Example parsing if data is missing. A default value of None will cause tf.io.parse_example to fail if an example does not contain this column. If a single value is provided, the same value will be applied as the default value for every item. If an iterable of values is provided, the shape of the default_value should be equal to the given shape."
tf.feature_column.numeric_column.yaml,key,0.9971014492753624,"A unique string identifying the input feature. It is used as the column name and the dictionary key for feature parsing configs, feature`Tensor` objects, and feature columns.","A unique string identifying the input feature. It is used as the column name and the dictionary key for feature parsing configs, feature Tensor objects, and feature columns."
tf.data.experimental.make_batched_features_dataset.yaml,label_key,0.9968652037617555,"(Optional) A string corresponding to the key labels are stored in`tf.Examples`. If provided, it must be one of the `features` key, otherwise results in `ValueError`.","(Optional) A string corresponding to the key labels are stored in tf.Examples. If provided, it must be one of the features key, otherwise results in ValueError."
tf.data.experimental.make_batched_features_dataset.yaml,drop_final_batch,0.9962546816479401,"If `True`, and the batch size does not evenly divide the input dataset size, the final smaller batch will be dropped. Defaults to`False`.","If True, and the batch size does not evenly divide the input dataset size, the final smaller batch will be dropped. Defaults to False."
tf.data.experimental.make_batched_features_dataset.yaml,file_pattern,0.9953051643192489,List of files or patterns of file paths containing`Example` records. See `tf.io.gfile.glob` for pattern rules.,List of files or patterns of file paths containing Example records. See tf.io.gfile.glob for pattern rules.
tf.data.experimental.make_batched_features_dataset.yaml,features,0.9947643979057592,A `dict` mapping feature keys to `FixedLenFeature` or`VarLenFeature` values. See `tf.io.parse_example`.,A dict mapping feature keys to FixedLenFeature or VarLenFeature values. See tf.io.parse_example.
tf.math.abs.yaml,x,0.9948717948717949,"A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,`int32`, `int64`, `complex64` or `complex128`.","A Tensor or SparseTensor of type float16, float32, float64, int32, int64, complex64 or complex128."
tf.reverse.yaml,axis,0.9968253968253968,"A `Tensor`. Must be one of the following types: `int32`, `int64`. 1-D. The indices of the dimensions to reverse. Must be in the range`[-rank(tensor), rank(tensor))`.","A Tensor. Must be one of the following types: int32, int64. 1-D. The indices of the dimensions to reverse. Must be in the range [-rank(tensor), rank(tensor))."
tf.signal.dct.yaml,type,0.9438202247191011,"The DCT type to perform. Must be 1, 2 or 3.","The DCT type to perform. Must be 1, 2, 3 or 4."
tf.signal.dct.yaml,norm,0.9947089947089947,The normalization to apply. `None` for no normalization or `'ortho'`for orthonormal normalization.,The normalization to apply. None for no normalization or 'ortho' for orthonormal normalization.
tf.image.random_flip_left_right.yaml,seed,0.9946524064171123,A Python integer. Used to create a random seed. See`tf.compat.v1.set_random_seed` for behavior.,A Python integer. Used to create a random seed. See tf.compat.v1.set_random_seed for behavior.
tf.tensordot.yaml,axes,0.9976359338061466,"Either a scalar `N`, or a list or an `int32` `Tensor` of shape [2, k]. If axes is a scalar, sum over the last N axes of a and the first N axes of b in order. If axes is a list or `Tensor` the first and second row contain the set of unique integers specifying axes along which the contraction is computed, for `a` and `b`, respectively. The number of axes for `a` and`b` must be equal. If `axes=0`, computes the outer product between `a` and`b`.","Either a scalar N, or a list or an int32 Tensor of shape [2, k]. If axes is a scalar, sum over the last N axes of a and the first N axes of b in order. If axes is a list or Tensor the first and second row contain the set of unique integers specifying axes along which the contraction is computed, for a and b, respectively. The number of axes for a and b must be equal. If axes=0, computes the outer product between a and b."
tf.linalg.normalize.yaml,ord,0.9971988795518207,"Order of the norm. Supported values are `'fro'`, `'euclidean'`, `1`,`2`, `np.inf` and any positive real number yielding the corresponding p-norm. Default is `'euclidean'` which is equivalent to Frobenius norm if`tensor` is a matrix and equivalent to 2-norm for vectors. Some restrictions apply: a) The Frobenius norm `'fro'` is not defined for vectors, b) If axis is a 2-tuple (matrix norm), only `'euclidean'`, '`fro'`, `1`, `2`, `np.inf` are supported. See the description of `axis`on how to compute norms for a batch of vectors or matrices stored in a tensor.","Order of the norm. Supported values are 'fro', 'euclidean', 1, 2, np.inf and any positive real number yielding the corresponding p-norm. Default is 'euclidean' which is equivalent to Frobenius norm if tensor is a matrix and equivalent to 2-norm for vectors. Some restrictions apply: a) The Frobenius norm 'fro' is not defined for vectors, b) If axis is a 2-tuple (matrix norm), only 'euclidean', 'fro', 1, 2, np.inf are supported. See the description of axis on how to compute norms for a batch of vectors or matrices stored in a tensor."
tf.linalg.normalize.yaml,axis,0.997979797979798,"If `axis` is `None` (the default), the input is considered a vector and a single vector norm is computed over the entire set of values in the tensor, i.e. `norm(tensor, ord=ord)` is equivalent to`norm(reshape(tensor, [-1]), ord=ord)`. If `axis` is a Python integer, the input is considered a batch of vectors, and `axis` determines the axis in`tensor` over which to compute vector norms. If `axis` is a 2-tuple of Python integers it is considered a batch of matrices and `axis` determines the axes in `tensor` over which to compute a matrix norm. Negative indices are supported. Example: If you are passing a tensor that can be either a matrix or a batch of matrices at runtime, pass`axis=[-2,-1]` instead of `axis=None` to make sure that matrix norms are computed.","If axis is None (the default), the input is considered a vector and a single vector norm is computed over the entire set of values in the tensor, i.e. norm(tensor, ord=ord) is equivalent to norm(reshape(tensor, [-1]), ord=ord). If axis is a Python integer, the input is considered a batch of vectors, and axis determines the axis in tensor over which to compute vector norms. If axis is a 2-tuple of Python integers it is considered a batch of matrices and axis determines the axes in tensor over which to compute a matrix norm. Negative indices are supported. Example: If you are passing a tensor that can be either a matrix or a batch of matrices at runtime, pass axis=[-2,-1] instead of axis=None to make sure that matrix norms are computed."
tf.ragged.segment_ids_to_row_splits.yaml,num_segments,0.99581589958159,A scalar integer indicating the number of segments.  Defaults to `max(segment_ids) + 1` (or zero if `segment_ids` is empty).,A scalar integer indicating the number of segments. Defaults to max(segment_ids) + 1 (or zero if segment_ids is empty).
tf.ragged.segment_ids_to_row_splits.yaml,out_type,0.9955555555555555,"The dtype for the return value.  Defaults to `segment_ids.dtype`, or `tf.int64` if `segment_ids` does not have a dtype.","The dtype for the return value. Defaults to segment_ids.dtype, or tf.int64 if segment_ids does not have a dtype."
tf.debugging.assert_equal.yaml,name,0.9923664122137404,"A name for this operation (optional).  Defaults to ""assert_equal"".","A name for this operation (optional). Defaults to ""assert_equal""."
tf.random.log_uniform_candidate_sampler.yaml,num_true,0.9914529914529915,An `int`.  The number of target classes per training example.,An int. The number of target classes per training example.
tf.random.log_uniform_candidate_sampler.yaml,num_sampled,0.98989898989899,An `int`.  The number of classes to randomly sample.,An int. The number of classes to randomly sample.
tf.cast.yaml,x,0.9946524064171123,"A `Tensor` or `SparseTensor` or `IndexedSlices` of numeric type. It could be `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`,`int64`, `float16`, `float32`, `float64`, `complex64`, `complex128`,`bfloat16`.","A Tensor or SparseTensor or IndexedSlices of numeric type. It could be uint8, uint16, uint32, uint64, int8, int16, int32, int64, float16, float32, float64, complex64, complex128, bfloat16."
tf.cast.yaml,dtype,0.9925925925925926,The destination type. The list of supported dtypes is the same as`x`.,The destination type. The list of supported dtypes is the same as x.
tf.math.unsorted_segment_sqrt_n.yaml,num_segments,0.991869918699187,An integer scalar `Tensor`.  The number of distinct segment IDs.,An integer scalar Tensor. The number of distinct segment IDs.
tf.image.adjust_saturation.yaml,image,0.9666666666666667,RGB image or images. Size of the last dimension must be 3.,RGB image or images. The size of the last dimension must be 3.
tf.print.yaml,output_stream,0.9826897470039947,"The output stream, logging level, or file to print to. Defaults to sys.stderr, but sys.stdout, tf.compat.v1.logging.info, tf.compat.v1.logging.warning, tf.compat.v1.logging.error, absl.logging.info, absl.logging.warning and absl.loogging,error are also supported. To print to a file, pass a string started with ""file://"" followed by the file path, e.g., ""file:///tmp/foo.out"".","The output stream, logging level, or file to print to. Defaults to sys.stderr, but sys.stdout, tf.compat.v1.logging.info, tf.compat.v1.logging.warning, tf.compat.v1.logging.error, absl.logging.info, absl.logging.warning and absl.logging.error are also supported. To print to a file, pass a string started with ""file://"" followed by the file path, e.g., ""file:///tmp/foo.out""."
tf.searchsorted.yaml,out_type,0.9908256880733946,The output type (`int32` or `int64`).  Default is `tf.int32`.,The output type (int32 or int64). Default is tf.int32.
tf.grad_pass_through.yaml,f,0.9932885906040269,function `f(*x)` that returns a `Tensor` or nested structure of `Tensor`outputs.,function f(*x) that returns a Tensor or nested structure of Tensor outputs.
tf.io.parse_tensor.yaml,out_type,0.996742671009772,A `tf.DType`. The type of the serialized tensor.  The provided type must match the type of the serialized tensor and no implicit conversion will take place.,A tf.DType. The type of the serialized tensor. The provided type must match the type of the serialized tensor and no implicit conversion will take place.
tf.feature_column.crossed_column.yaml,hash_key,0.996309963099631,Specify the hash_key that will be used by the `FingerprintCat64`function to combine the crosses fingerprints on SparseCrossOp (optional).,Specify the hash_key that will be used by the FingerprintCat64 function to combine the crosses fingerprints on SparseCrossOp (optional).
tf.feature_column.crossed_column.yaml,keys,0.9963235294117647,An iterable identifying the features to be crossed. Each element can be either: string: Will use the corresponding feature which must be of string type.`CategoricalColumn`: Will use the transformed tensor produced by this column. Does not support hashed categorical column. ,An iterable identifying the features to be crossed. Each element can be either: string: Will use the corresponding feature which must be of string type. CategoricalColumn: Will use the transformed tensor produced by this column. Does not support hashed categorical column.
tf.train.get_checkpoint_state.yaml,latest_filename,0.992,Optional name of the checkpoint file.  Default to 'checkpoint'.,Optional name of the checkpoint file. Default to 'checkpoint'.
tf.data.experimental.parse_example_dataset.yaml,features,0.9951219512195122,"A `dict` mapping feature keys to `FixedLenFeature`,`VarLenFeature`, `RaggedFeature`, and `SparseFeature` values.","A dict mapping feature keys to FixedLenFeature, VarLenFeature, RaggedFeature, and SparseFeature values."
tf.train.latest_checkpoint.yaml,latest_filename,0.9833887043189369,Optional name for the protocol buffer file that contains the list of most recent checkpoint filenames. See the corresponding argument to `Saver.save()`.,Optional name for the protocol buffer file that contains the list of most recent checkpoint filenames. See the corresponding argument to v1.Saver.save.
tf.summary.write.yaml,tensor,0.9978118161925602,"the Tensor holding the summary data to write or a callable that returns this Tensor. If a callable is passed, it will only be called when a default SummaryWriter exists and the recording condition specified by`record_if()` is met.","the Tensor holding the summary data to write or a callable that returns this Tensor. If a callable is passed, it will only be called when a default SummaryWriter exists and the recording condition specified by record_if() is met."
tf.sparse.fill_empty_rows.yaml,default_value,0.9922480620155039,"The value to fill for empty rows, with the same type as`sp_input.`","The value to fill for empty rows, with the same type as sp_input."
tf.feature_column.categorical_column_with_hash_bucket.yaml,key,0.9971014492753624,"A unique string identifying the input feature. It is used as the column name and the dictionary key for feature parsing configs, feature`Tensor` objects, and feature columns.","A unique string identifying the input feature. It is used as the column name and the dictionary key for feature parsing configs, feature Tensor objects, and feature columns."
tf.strings.bytes_split.yaml,input,0.9946524064171123,A string `Tensor` or `RaggedTensor`: the strings to split.  Must have a statically known rank (`N`).,A string Tensor or RaggedTensor: the strings to split. Must have a statically known rank (N).
tf.debugging.assert_less.yaml,name,0.9922480620155039,"A name for this operation (optional).  Defaults to ""assert_less"".","A name for this operation (optional). Defaults to ""assert_less""."
tf.math.confusion_matrix.yaml,num_classes,0.9457831325301205,"The possible number of labels the classification task can          have. If this value is not provided, it will be calculated          using both predictions and labels array.","The possible number of labels the classification task can have. If this value is not provided, it will be calculated using both predictions and labels array."
tf.saved_model.contains_saved_model.yaml,export_dir,0.9518072289156626,"Absolute string path to possible export location. For example,         '/my/foo/model'.","Absolute string path to possible export location. For example, '/my/foo/model'."
tf.histogram_fixed_width_bins.yaml,nbins,0.989247311827957,Scalar `int32 Tensor`.  Number of histogram bins.,Scalar int32 Tensor. Number of histogram bins.
tf.nn.compute_accidental_hits.yaml,num_true,0.9914529914529915,An `int`.  The number of target classes per training example.,An int. The number of target classes per training example.
tf.linalg.svd.yaml,tensor,0.9917355371900827,"`Tensor` of shape `[..., M, N]`. Let `P` be the minimum of `M` and`N`.","Tensor of shape [..., M, N]. Let P be the minimum of M and N."
tf.image.random_hue.yaml,image,0.9666666666666667,RGB image or images. Size of the last dimension must be 3.,RGB image or images. The size of the last dimension must be 3.
tf.image.random_hue.yaml,max_delta,0.9662921348314607,float.  Maximum value for the random delta.,float. The maximum value for the random delta.
tf.strings.unsorted_segment_join.yaml,segment_ids,0.9966101694915255,"A `Tensor`. Must be one of the following types: `int32`, `int64`. A tensor whose shape is a prefix of data.shape.  Negative segment ids are not supported.","A Tensor. Must be one of the following types: int32, int64. A tensor whose shape is a prefix of data.shape. Negative segment ids are not supported."
tf.math.cumprod.yaml,axis,0.9935483870967742,"A `Tensor` of type `int32` (default: 0). Must be in the range`[-rank(x), rank(x))`.","A Tensor of type int32 (default: 0). Must be in the range [-rank(x), rank(x))."
tf.math.cumprod.yaml,x,0.9935897435897436,"A `Tensor`. Must be one of the following types: `float32`, `float64`,`int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,`complex128`, `qint8`, `quint8`, `qint32`, `half`.","A Tensor. Must be one of the following types: float32, float64, int64, int32, uint8, uint16, int16, int8, complex64, complex128, qint8, quint8, qint32, half."
tf.nn.embedding_lookup.yaml,params,0.9969512195121951,"A single tensor representing the complete embedding tensor, or a list of P tensors all of same shape except for the first dimension, representing sharded embedding tensors.  Alternatively, a`PartitionedVariable`, created by partitioning along dimension 0. Each element must be appropriately sized for the 'div' `partition_strategy`.","A single tensor representing the complete embedding tensor, or a list of P tensors all of same shape except for the first dimension, representing sharded embedding tensors. Alternatively, a PartitionedVariable, created by partitioning along dimension 0. Each element must be appropriately sized for the 'div' partition_strategy."
tf.nn.conv1d.yaml,data_format,0.992,"An optional `string` from `""NWC"", ""NCW""`.  Defaults to `""NWC""`, the data is stored in the order of [batch, in_width, in_channels].  The`""NCW""` format stores data as [batch, in_channels, in_width].","An optional string from ""NWC"", ""NCW"". Defaults to ""NWC"", the data is stored in the order of [batch, in_width, in_channels]. The ""NCW"" format stores data as [batch, in_channels, in_width]."
tf.nn.conv1d.yaml,input,0.9914529914529915,"A 3D `Tensor`.  Must be of type `float16`, `float32`, or `float64`.","A 3D Tensor. Must be of type float16, float32, or float64."
tf.nn.conv1d.yaml,filters,0.989247311827957,A 3D `Tensor`.  Must have the same type as `input`.,A 3D Tensor. Must have the same type as input.
tf.nn.conv1d.yaml,stride,0.9957446808510638,An int or list of `ints` that has length `1` or `3`.  The number of entries by which the filter is moved right at each step.,An int or list of ints that has length 1 or 3. The number of entries by which the filter is moved right at each step.
tf.sparse.to_dense.yaml,default_value,0.9868421052631579,Scalar value to set for indices not specified in`sp_input`.  Defaults to zero.,Scalar value to set for indices not specified in sp_input. Defaults to zero.
tf.sparse.to_dense.yaml,validate_indices,0.9961089494163424,"A boolean value.  If `True`, indices are checked to make sure they are sorted in lexicographic order and that there are no repeats.","A boolean value. If True, indices are checked to make sure they are sorted in lexicographic order and that there are no repeats."
tf.sort.yaml,direction,0.993006993006993,The direction in which to sort the values (`'ASCENDING'` or`'DESCENDING'`).,The direction in which to sort the values ('ASCENDING' or 'DESCENDING').
tf.random.categorical.yaml,seed,0.9181818181818182,A Python integer. Used to create a random seed for the distribution. See `tf.compat.v1.set_random_seed` for behavior.,A Python integer. Used to create a random seed for the distribution. See tf.random.set_seed for behavior.
tf.random.categorical.yaml,logits,0.9922480620155039,"2-D Tensor with shape `[batch_size, num_classes]`.  Each slice`[i, :]` represents the unnormalized log-probabilities for all classes.","2-D Tensor with shape [batch_size, num_classes]. Each slice [i, :] represents the unnormalized log-probabilities for all classes."
tf.random.categorical.yaml,num_samples,0.992,0-D.  Number of independent samples to draw for each row slice.,0-D. Number of independent samples to draw for each row slice.
tf.feature_column.embedding_column.yaml,initializer,0.9974293059125964,"A variable initializer function to be used in embedding variable initialization. If not specified, defaults to`truncated_normal_initializer` with mean `0.0` and standard deviation `1/sqrt(dimension)`.","A variable initializer function to be used in embedding variable initialization. If not specified, defaults to truncated_normal_initializer with mean 0.0 and standard deviation 1/sqrt(dimension)."
tf.feature_column.embedding_column.yaml,combiner,0.9986244841815681,"A string specifying how to reduce if there are multiple entries in a single row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default. 'sqrtn' often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see`tf.embedding_lookup_sparse`.","A string specifying how to reduce if there are multiple entries in a single row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default. 'sqrtn' often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see tf.embedding_lookup_sparse."
tf.feature_column.embedding_column.yaml,tensor_name_in_ckpt,0.9959514170040485,Name of the `Tensor` in `ckpt_to_load_from` from which to restore the column weights. Required if `ckpt_to_load_from` is not`None`.,Name of the Tensor in ckpt_to_load_from from which to restore the column weights. Required if ckpt_to_load_from is not None.
tf.feature_column.embedding_column.yaml,categorical_column,0.9965397923875432,A `CategoricalColumn` created by a`categorical_column_with_*` function. This column produces the sparse IDs that are inputs to the embedding lookup.,A CategoricalColumn created by a categorical_column_with_* function. This column produces the sparse IDs that are inputs to the embedding lookup.
tf.gradients.yaml,grad_ys,0.9954337899543378,Optional. A `Tensor` or list of tensors the same size as`ys` and holding the gradients computed for each y in `ys`.,Optional. A Tensor or list of tensors the same size as ys and holding the gradients computed for each y in ys.
tf.gradients.yaml,gate_gradients,0.9951690821256038,"If True, add a tuple around the gradients returned for an operations.  This avoids some race conditions.","If True, add a tuple around the gradients returned for an operations. This avoids some race conditions."
tf.gradients.yaml,unconnected_gradients,0.9974811083123426,Optional. Specifies the gradient value returned when the given input tensors are unconnected. Accepted values are constants defined in the class `tf.UnconnectedGradients` and the default value is`none`.,Optional. Specifies the gradient value returned when the given input tensors are unconnected. Accepted values are constants defined in the class tf.UnconnectedGradients and the default value is none.
tf.nn.conv3d.yaml,data_format,0.9943977591036415,"An optional `string` from: `""NDHWC"", ""NCDHW""`. Defaults to `""NDHWC""`. The data format of the input and output data. With the default format ""NDHWC"", the data is stored in the order of:   [batch, in_depth, in_height, in_width, in_channels]. Alternatively, the format could be ""NCDHW"", the data storage order is:   [batch, in_channels, in_depth, in_height, in_width].","An optional string from: ""NDHWC"", ""NCDHW"". Defaults to ""NDHWC"". The data format of the input and output data. With the default format ""NDHWC"", the data is stored in the order of: [batch, in_depth, in_height, in_width, in_channels]. Alternatively, the format could be ""NCDHW"", the data storage order is: [batch, in_channels, in_depth, in_height, in_width]."
tf.nn.atrous_conv2d.yaml,filters,0.9969167523124358,"A 4-D `Tensor` with the same type as `value` and shape`[filter_height, filter_width, in_channels, out_channels]`. `filters`'`in_channels` dimension must match that of `value`. Atrous convolution is equivalent to standard convolution with upsampled filters with effective height `filter_height + (filter_height - 1) * (rate - 1)` and effective width `filter_width + (filter_width - 1) * (rate - 1)`, produced by inserting `rate - 1` zeros along consecutive elements across the`filters`' spatial dimensions.","A 4-D Tensor with the same type as value and shape [filter_height, filter_width, in_channels, out_channels]. filters' in_channels dimension must match that of value. Atrous convolution is equivalent to standard convolution with upsampled filters with effective height filter_height + (filter_height - 1) * (rate - 1) and effective width filter_width + (filter_width - 1) * (rate - 1), produced by inserting rate - 1 zeros along consecutive elements across the filters' spatial dimensions."
tf.nn.atrous_conv2d.yaml,rate,0.99836867862969,"A positive int32. The stride with which we sample input values across the `height` and `width` dimensions. Equivalently, the rate by which we upsample the filter values by inserting zeros across the `height` and`width` dimensions. In the literature, the same parameter is sometimes called `input stride` or `dilation`.","A positive int32. The stride with which we sample input values across the height and width dimensions. Equivalently, the rate by which we upsample the filter values by inserting zeros across the height and width dimensions. In the literature, the same parameter is sometimes called input stride or dilation."
tf.saved_model.load.yaml,tags,0.9785932721712538,"A tag or sequence of tags identifying the MetaGraph to load. Optional if the SavedModel contains a single MetaGraph, as for those exported from`tf.saved_model.load`.","A tag or sequence of tags identifying the MetaGraph to load. Optional if the SavedModel contains a single MetaGraph, as for those exported from tf.saved_model.save."
tf.config.experimental.set_device_policy.yaml,device_policy,0.9948612538540597,"A device policy. Valid values: None: Switch to a system default.'warn': Copies the tensors which are not on the right device and logs a warning.'explicit': Raises an error if the placement is not as required.'silent': Silently copies the tensors. Note that this may hide performance problems as there is no notification provided when operations are blocked on the tensor being copied between devices.'silent_for_int32': silently copies `int32` tensors, raising errors on the other ones. ","A device policy. Valid values: None: Switch to a system default. 'warn': Copies the tensors which are not on the right device and logs a warning. 'explicit': Raises an error if the placement is not as required. 'silent': Silently copies the tensors. Note that this may hide performance problems as there is no notification provided when operations are blocked on the tensor being copied between devices. 'silent_for_int32': silently copies int32 tensors, raising errors on the other ones."
tf.debugging.assert_greater_equal.yaml,name,0.9931972789115646,"A name for this operation (optional).  Defaults to ""assert_greater_equal"".","A name for this operation (optional). Defaults to ""assert_greater_equal""."
tf.nn.embedding_lookup_sparse.yaml,params,0.9969135802469136,"A single tensor representing the complete embedding tensor, or a list of P tensors all of same shape except for the first dimension, representing sharded embedding tensors.  Alternatively, a`PartitionedVariable`, created by partitioning along dimension 0. Each element must be appropriately sized for `""div""` `partition_strategy`.","A single tensor representing the complete embedding tensor, or a list of P tensors all of same shape except for the first dimension, representing sharded embedding tensors. Alternatively, a PartitionedVariable, created by partitioning along dimension 0. Each element must be appropriately sized for ""div"" partition_strategy."
tf.nn.embedding_lookup_sparse.yaml,sp_weights,0.9973045822102425,"either a `SparseTensor` of float / double weights, or `None` to indicate all weights should be taken to be 1. If specified, `sp_weights`must have exactly the same shape and indices as `sp_ids`.","either a SparseTensor of float / double weights, or None to indicate all weights should be taken to be 1. If specified, sp_weights must have exactly the same shape and indices as sp_ids."
tf.math.top_k.yaml,k,0.9953917050691244,0-D `int32` `Tensor`.  Number of top elements to look for along the last dimension (along each row for matrices).,0-D int32 Tensor. Number of top elements to look for along the last dimension (along each row for matrices).
tf.sparse.cross_hashed.yaml,hash_key,0.995260663507109,"Integer hash_key that will be used by the `FingerprintCat64`function. If not given, will use a default key.","Integer hash_key that will be used by the FingerprintCat64 function. If not given, will use a default key."
tf.debugging.assert_greater.yaml,name,0.9925925925925926,"A name for this operation (optional).  Defaults to ""assert_greater"".","A name for this operation (optional). Defaults to ""assert_greater""."
tf.nn.relu6.yaml,features,0.9928057553956835,"A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,`int16`, or `int8`.","A Tensor with type float, double, int32, int64, uint8, int16, or int8."
tf.image.combined_non_max_suppression.yaml,pad_per_class,0.998330550918197,"If false, the output nmsed boxes, scores and classes are padded/clipped to `max_total_size`. If true, the output nmsed boxes, scores and classes are padded to be of length`max_size_per_class`*`num_classes`, unless it exceeds `max_total_size` in which case it is clipped to `max_total_size`. Defaults to false.","If false, the output nmsed boxes, scores and classes are padded/clipped to max_total_size. If true, the output nmsed boxes, scores and classes are padded to be of length max_size_per_class*num_classes, unless it exceeds max_total_size in which case it is clipped to max_total_size. Defaults to false."
tf.image.combined_non_max_suppression.yaml,boxes,0.9973190348525469,"A 4-D float `Tensor` of shape `[batch_size, num_boxes, q, 4]`. If `q`is 1 then same boxes are used for all classes otherwise, if `q` is equal to number of classes, class-specific boxes are used.","A 4-D float Tensor of shape [batch_size, num_boxes, q, 4]. If q is 1 then same boxes are used for all classes otherwise, if q is equal to number of classes, class-specific boxes are used."
tf.image.combined_non_max_suppression.yaml,scores,0.9963898916967509,"A 3-D float `Tensor` of shape `[batch_size, num_boxes, num_classes]`representing a single score corresponding to each box (each row of boxes).","A 3-D float Tensor of shape [batch_size, num_boxes, num_classes] representing a single score corresponding to each box (each row of boxes)."
tf.image.combined_non_max_suppression.yaml,max_output_size_per_class,0.9910714285714286,A scalar integer `Tensor` representing the maximum number of boxes to be selected by non max suppression per class,A scalar integer Tensor representing the maximum number of boxes to be selected by non-max suppression per class
tf.image.combined_non_max_suppression.yaml,max_total_size,0.972972972972973,A scalar representing maximum number of boxes retained over all classes.,A scalar representing the maximum number of boxes retained over all classes.
tf.ragged.constant.yaml,dtype,0.9924242424242424,"The type of elements for the returned `RaggedTensor`.  If not specified, then a default is chosen based on the scalar values in`pylist`.","The type of elements for the returned RaggedTensor. If not specified, then a default is chosen based on the scalar values in pylist."
tf.ragged.constant.yaml,pylist,0.99644128113879,"A nested `list`, `tuple` or `np.ndarray`.  Any nested element that is not a `list`, `tuple` or `np.ndarray` must be a scalar value compatible with `dtype`.","A nested list, tuple or np.ndarray. Any nested element that is not a list, tuple or np.ndarray must be a scalar value compatible with dtype."
tf.nn.sampled_softmax_loss.yaml,num_true,0.9914529914529915,An `int`.  The number of target classes per training example.,An int. The number of target classes per training example.
tf.nn.sampled_softmax_loss.yaml,sampled_values,0.997134670487106,"a tuple of (`sampled_candidates`, `true_expected_count`,`sampled_expected_count`) returned by a `*_candidate_sampler` function. (if None, we default to `log_uniform_candidate_sampler`)","a tuple of (sampled_candidates, true_expected_count, sampled_expected_count) returned by a *_candidate_sampler function. (if None, we default to log_uniform_candidate_sampler)"
tf.nn.sampled_softmax_loss.yaml,remove_accidental_hits,0.9914529914529915,"A `bool`.  whether to remove ""accidental hits"" where a sampled class equals one of the target classes.  Default is True.","A bool. whether to remove ""accidental hits"" where a sampled class equals one of the target classes. Default is True."
tf.nn.sampled_softmax_loss.yaml,weights,0.9942528735632183,"A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`objects whose concatenation along dimension 0 has shape [num_classes, dim].  The (possibly-sharded) class embeddings.","A Tensor of shape [num_classes, dim], or a list of Tensor objects whose concatenation along dimension 0 has shape [num_classes, dim]. The (possibly-sharded) class embeddings."
tf.nn.sampled_softmax_loss.yaml,biases,0.9900990099009901,A `Tensor` of shape `[num_classes]`.  The class biases.,A Tensor of shape [num_classes]. The class biases.
tf.nn.sampled_softmax_loss.yaml,labels,0.9971014492753624,"A `Tensor` of type `int64` and shape `[batch_size, num_true]`. The target classes.  Note that this format differs from the `labels` argument of `nn.softmax_cross_entropy_with_logits`.","A Tensor of type int64 and shape [batch_size, num_true]. The target classes. Note that this format differs from the labels argument of nn.softmax_cross_entropy_with_logits."
tf.nn.sampled_softmax_loss.yaml,inputs,0.9939393939393939,"A `Tensor` of shape `[batch_size, dim]`.  The forward activations of the input network.","A Tensor of shape [batch_size, dim]. The forward activations of the input network."
tf.nn.sampled_softmax_loss.yaml,num_sampled,0.9915966386554622,An `int`.  The number of classes to randomly sample per batch.,An int. The number of classes to randomly sample per batch.
tf.train.experimental.enable_mixed_precision_graph_rewrite.yaml,loss_scale,0.9981308411214953,"Either an int/float, the string `""dynamic""`, or an instance of a`tf.mixed_precision.experimental.LossScale`. The loss scale to use. It is recommended to keep this as its default value of `""dynamic""`, which will adjust the scaling automatically to prevent `Inf` or `NaN` values.","Either an int/float, the string ""dynamic"", or an instance of a tf.mixed_precision.experimental.LossScale. The loss scale to use. It is recommended to keep this as its default value of ""dynamic"", which will adjust the scaling automatically to prevent Inf or NaN values."
tf.debugging.assert_non_negative.yaml,name,0.993103448275862,"A name for this operation (optional).  Defaults to ""assert_non_negative"".","A name for this operation (optional). Defaults to ""assert_non_negative""."
tf.keras.models.clone_model.yaml,clone_function,0.9983471074380166,"Callable to be used to clone each layer in the target model (except `InputLayer` instances). It takes as argument the layer instance to be cloned, and returns the corresponding layer instance to be used in the model copy. If unspecified, this callable defaults to the following serialization/deserialization function:`lambda layer: layer.__class__.from_config(layer.get_config())`. By passing a custom callable, you can customize your copy of the model, e.g. by wrapping certain layers of interest (you might want to replace all `LSTM` instances with equivalent`Bidirectional(LSTM(...))` instances, for example).","Callable to be used to clone each layer in the target model (except InputLayer instances). It takes as argument the layer instance to be cloned, and returns the corresponding layer instance to be used in the model copy. If unspecified, this callable defaults to the following serialization/deserialization function: lambda layer: layer.__class__.from_config(layer.get_config()). By passing a custom callable, you can customize your copy of the model, e.g. by wrapping certain layers of interest (you might want to replace all LSTM instances with equivalent Bidirectional(LSTM(...)) instances, for example)."
tf.keras.models.clone_model.yaml,model,0.9928057553956835,Instance of `Model`(could be a functional model or a Sequential model).,Instance of Model (could be a functional model or a Sequential model).
tf.math.accumulate_n.yaml,tensor_dtype,0.9950738916256158,"Expected data type of `inputs` (optional). A value of `None`means ""infer the input dtype from `inputs[0]`"".","Expected data type of inputs (optional). A value of None means ""infer the input dtype from inputs[0]""."
tf.strings.unicode_transcode.yaml,errors,0.9990867579908675,"An optional `string` from: `""strict"", ""replace"", ""ignore""`. Defaults to `""replace""`. Error handling policy when there is invalid formatting found in the input. The value of 'strict' will cause the operation to produce a InvalidArgument error on any invalid input formatting. A value of 'replace' (the default) will cause the operation to replace any invalid formatting in the input with the`replacement_char` codepoint. A value of 'ignore' will cause the operation to skip any invalid formatting in the input and produce no corresponding output character.","An optional string from: ""strict"", ""replace"", ""ignore"". Defaults to ""replace"". Error handling policy when there is invalid formatting found in the input. The value of 'strict' will cause the operation to produce a InvalidArgument error on any invalid input formatting. A value of 'replace' (the default) will cause the operation to replace any invalid formatting in the input with the replacement_char codepoint. A value of 'ignore' will cause the operation to skip any invalid formatting in the input and produce no corresponding output character."
tf.strings.unicode_transcode.yaml,replacement_char,0.9991503823279524,"An optional `int`. Defaults to `65533`. The replacement character codepoint to be used in place of any invalid formatting in the input when `errors='replace'`. Any valid unicode codepoint may be used. The default value is the default unicode replacement character is 0xFFFD or U+65533.)Note that for UTF-8, passing a replacement character expressible in 1 byte, such as ' ', will preserve string alignment to the source since invalid bytes will be replaced with a 1-byte replacement. For UTF-16-BE and UTF-16-LE, any 1 or 2 byte replacement character will preserve byte alignment to the source.","An optional int. Defaults to 65533. The replacement character codepoint to be used in place of any invalid formatting in the input when errors='replace'. Any valid unicode codepoint may be used. The default value is the default unicode replacement character is 0xFFFD or U+65533.) Note that for UTF-8, passing a replacement character expressible in 1 byte, such as ' ', will preserve string alignment to the source since invalid bytes will be replaced with a 1-byte replacement. For UTF-16-BE and UTF-16-LE, any 1 or 2 byte replacement character will preserve byte alignment to the source."
tf.strings.unicode_transcode.yaml,replace_control_characters,0.9962546816479401,An optional `bool`. Defaults to `False`. Whether to replace the C0 control characters (00-1F) with the`replacement_char`. Default is false.,An optional bool. Defaults to False. Whether to replace the C0 control characters (00-1F) with the replacement_char. Default is false.
tf.strings.unicode_transcode.yaml,output_encoding,0.9972602739726028,"A `string` from: `""UTF-8"", ""UTF-16-BE"", ""UTF-32-BE""`. The unicode encoding to use in the output. Must be one of`""UTF-8"", ""UTF-16-BE"", ""UTF-32-BE""`. Multi-byte encodings will be big-endian.","A string from: ""UTF-8"", ""UTF-16-BE"", ""UTF-32-BE"". The unicode encoding to use in the output. Must be one of ""UTF-8"", ""UTF-16-BE"", ""UTF-32-BE"". Multi-byte encodings will be big-endian."
tf.nn.avg_pool.yaml,input,0.9981167608286252,"Tensor of rank N+2, of shape `[batch_size] + input_spatial_shape + [num_channels]` if `data_format` does not start with ""NC"" (default), or`[batch_size, num_channels] + input_spatial_shape` if data_format starts with ""NC"". Pooling happens over the spatial dimensions only.","Tensor of rank N+2, of shape [batch_size] + input_spatial_shape + [num_channels] if data_format does not start with ""NC"" (default), or [batch_size, num_channels] + input_spatial_shape if data_format starts with ""NC"". Pooling happens over the spatial dimensions only."
tf.signal.idct.yaml,type,0.945054945054945,"The IDCT type to perform. Must be 1, 2 or 3.","The IDCT type to perform. Must be 1, 2, 3 or 4."
tf.signal.idct.yaml,norm,0.9947089947089947,The normalization to apply. `None` for no normalization or `'ortho'`for orthonormal normalization.,The normalization to apply. None for no normalization or 'ortho' for orthonormal normalization.
tf.math.bincount.yaml,weights,0.996309963099631,"If non-None, must be the same shape as arr. For each value in`arr`, the bin will be incremented by the corresponding weight instead of 1.","If non-None, must be the same shape as arr. For each value in arr, the bin will be incremented by the corresponding weight instead of 1."
tf.math.bincount.yaml,maxlength,0.9960159362549801,"If given, skips values in `arr` that are equal or greater than`maxlength`, ensuring that the output has length at most `maxlength`.","If given, skips values in arr that are equal or greater than maxlength, ensuring that the output has length at most maxlength."
tf.keras.backend.ones_like.yaml,dtype,0.9925925925925926,"String, dtype of returned Keras variable.  None uses the dtype of x.","String, dtype of returned Keras variable. None uses the dtype of x."
tf.random.fixed_unigram_candidate_sampler.yaml,distortion,0.9968553459119497,"The distortion is used to skew the unigram probability distribution.  Each weight is first raised to the distortion's power before adding to the internal unigram distribution. As a result,`distortion = 1.0` gives regular unigram sampling (as defined by the vocab file), and `distortion = 0.0` gives a uniform distribution.","The distortion is used to skew the unigram probability distribution. Each weight is first raised to the distortion's power before adding to the internal unigram distribution. As a result, distortion = 1.0 gives regular unigram sampling (as defined by the vocab file), and distortion = 0.0 gives a uniform distribution."
tf.random.fixed_unigram_candidate_sampler.yaml,num_reserved_ids,0.9975669099756691,"Optionally some reserved IDs can be added in the range`[0, num_reserved_ids)` by the users. One use case is that a special unknown word token is used as ID 0. These IDs will have a sampling probability of 0.","Optionally some reserved IDs can be added in the range [0, num_reserved_ids) by the users. One use case is that a special unknown word token is used as ID 0. These IDs will have a sampling probability of 0."
tf.random.fixed_unigram_candidate_sampler.yaml,num_true,0.9914529914529915,An `int`.  The number of target classes per training example.,An int. The number of target classes per training example.
tf.random.fixed_unigram_candidate_sampler.yaml,num_sampled,0.98989898989899,An `int`.  The number of classes to randomly sample.,An int. The number of classes to randomly sample.
tf.data.experimental.choose_from_datasets.yaml,choice_dataset,0.9934640522875817,A `tf.data.Dataset` of scalar `tf.int64` tensors between`0` and `len(datasets) - 1`.,A tf.data.Dataset of scalar tf.int64 tensors between 0 and len(datasets) - 1.
tf.keras.backend.ctc_decode.yaml,y_pred,0.9948186528497409,"tensor `(samples, time_steps, num_categories)`containing the prediction, or output of the softmax.","tensor (samples, time_steps, num_categories) containing the prediction, or output of the softmax."
tf.math.bessel_i1.yaml,x,0.9940828402366864,"A `Tensor` or `SparseTensor`. Must be one of the following types: `half`,`float32`, `float64`.","A Tensor or SparseTensor. Must be one of the following types: half, float32, float64."
tf.image.resize.yaml,preserve_aspect_ratio,0.9980657640232108,"Whether to preserve the aspect ratio. If this is set, then `images` will be resized to a size that fits in `size` while preserving the aspect ratio of the original image. Scales up the image if`size` is bigger than the current size of the `image`. Defaults to False.","Whether to preserve the aspect ratio. If this is set, then images will be resized to a size that fits in size while preserving the aspect ratio of the original image. Scales up the image if size is bigger than the current size of the image. Defaults to False."
tf.image.resize.yaml,size,0.9941520467836257,"A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The new size for the images.","A 1-D int32 Tensor of 2 elements: new_height, new_width. The new size for the images."
tf.foldl.yaml,elems,0.9973474801061007,"A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension.  The nested sequence of the resulting slices will be the first argument to `fn`.","A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension. The nested sequence of the resulting slices will be the first argument to fn."
tf.keras.optimizers.get.yaml,identifier,0.9956521739130435,"Optimizer identifier, one of String: name of an optimizerDictionary: configuration dictionary. - Keras Optimizer instance (it will be returned unchanged). - TensorFlow Optimizer instance (it will be wrapped as a Keras Optimizer). ","Optimizer identifier, one of String: name of an optimizer Dictionary: configuration dictionary. - Keras Optimizer instance (it will be returned unchanged). - TensorFlow Optimizer instance (it will be wrapped as a Keras Optimizer)."
tf.image.random_contrast.yaml,seed,0.9946524064171123,A Python integer. Used to create a random seed. See`tf.compat.v1.set_random_seed` for behavior.,A Python integer. Used to create a random seed. See tf.compat.v1.set_random_seed for behavior.
tf.image.random_contrast.yaml,lower,0.9900990099009901,float.  Lower bound for the random contrast factor.,float. Lower bound for the random contrast factor.
tf.image.random_contrast.yaml,upper,0.9900990099009901,float.  Upper bound for the random contrast factor.,float. Upper bound for the random contrast factor.
tf.linalg.expm.yaml,input,0.9945945945945946,"A `Tensor`. Must be `float16`, `float32`, `float64`, `complex64`, or`complex128` with shape `[..., M, M]`.","A Tensor. Must be float16, float32, float64, complex64, or complex128 with shape [..., M, M]."
tf.nn.separable_conv2d.yaml,pointwise_filter,0.9936708860759493,"4-D `Tensor` with shape `[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise filter to mix channels after`depthwise_filter` has convolved spatially.","4-D Tensor with shape [1, 1, channel_multiplier * in_channels, out_channels]. Pointwise filter to mix channels after depthwise_filter has convolved spatially."
tf.nn.separable_conv2d.yaml,strides,0.9941520467836257,1-D of size 4.  The strides for the depthwise convolution for each dimension of `input`.,1-D of size 4. The strides for the depthwise convolution for each dimension of input.
tf.nn.separable_conv2d.yaml,padding,0.9957805907172996,"A string, either `'VALID'` or `'SAME'`.  The padding algorithm. See the ""returns"" section of `tf.nn.convolution` for details.","A string, either 'VALID' or 'SAME'. The padding algorithm. See the ""returns"" section of tf.nn.convolution for details."
tf.estimator.add_metrics.yaml,metric_fn,0.9817265280403277,"A function which should obey the following signature: Args: can only have following four arguments in any order:predictions: Predictions `Tensor` or dict of `Tensor` created by given`estimator`.features: Input `dict` of `Tensor` objects created by `input_fn` which is given to `estimator.evaluate` as an argument.labels:  Labels `Tensor` or dict of `Tensor` created by `input_fn`which is given to `estimator.evaluate` as an argument.config: config attribute of the `estimator`.Returns: Dict of metric results keyed by name. Final metrics are a union of this and `estimator's` existing metrics. If there is a name conflict between this and `estimator`s existing metrics, this will override the existing one. The values of the dict are the results of calling a metric function, namely a `(metric_tensor, update_op)` tuple. ","A function which should obey the following signature: Args: can only have following four arguments in any order: predictions: Predictions Tensor or dict of Tensor created by given estimator. features: Input dict of Tensor objects created by input_fn which is given to estimator.evaluate as an argument. labels: Labels Tensor or dict of Tensor created by input_fn which is given to estimator.evaluate as an argument. config: config attribute of the estimator. Returns: Dict of metric results keyed by name. Final metrics are a union of this and estimator's existing metrics. If there is a name conflict between this and estimators existing metrics, this will override the existing one. The values of the dict are the results of calling a metric function, namely a (metric_tensor, update_op) tuple."
tf.linalg.lu_solve.yaml,rhs,0.9966996699669967,"Matrix-shaped float `Tensor` representing targets for which to solve;`A X = RHS`. To handle vector cases, use: `lu_solve(..., rhs[..., tf.newaxis])[..., 0]`.","Matrix-shaped float Tensor representing targets for which to solve; A X = RHS. To handle vector cases, use: lu_solve(..., rhs[..., tf.newaxis])[..., 0]."
tf.strings.unicode_decode_with_offsets.yaml,errors,0.994059405940594,Specifies the response when an input string can't be converted using the indicated encoding. One of: `'strict'`: Raise an exception for any illegal substrings.`'replace'`: Replace illegal substrings with `replacement_char`.`'ignore'`: Skip illegal substrings. ,Specifies the response when an input string can't be converted using the indicated encoding. One of: 'strict': Raise an exception for any illegal substrings. 'replace': Replace illegal substrings with replacement_char. 'ignore': Skip illegal substrings.
tf.strings.unicode_decode_with_offsets.yaml,replace_control_characters,0.9943502824858758,Whether to replace the C0 control characters`(U+0000 - U+001F)` with the `replacement_char`.,Whether to replace the C0 control characters (U+0000 - U+001F) with the replacement_char.
tf.strings.unicode_decode_with_offsets.yaml,input,0.98989898989899,An `N` dimensional potentially ragged `string` tensor with shape`[D1...DN]`.  `N` must be statically known.,An N dimensional potentially ragged string tensor with shape [D1...DN]. N must be statically known.
tf.random.normal.yaml,seed,0.908256880733945,A Python integer. Used to create a random seed for the distribution. See`tf.compat.v1.set_random_seed`for behavior.,A Python integer. Used to create a random seed for the distribution. See tf.random.set_seed for behavior.
tf.random.uniform_candidate_sampler.yaml,num_true,0.9914529914529915,An `int`.  The number of target classes per training example.,An int. The number of target classes per training example.
tf.random.uniform_candidate_sampler.yaml,num_sampled,0.991869918699187,"An `int`.  The number of classes to randomly sample. The`sampled_candidates` return value will have shape `[num_sampled]`. If`unique=True`, `num_sampled` must be less than or equal to `range_max`.","An int. The number of classes to randomly sample. The sampled_candidates return value will have shape [num_sampled]. If unique=True, num_sampled must be less than or equal to range_max."
tf.feature_column.categorical_column_with_vocabulary_file.yaml,default_value,0.9964912280701754,"The integer ID value to return for out-of-vocabulary feature values, defaults to `-1`. This can not be specified with a positive`num_oov_buckets`.","The integer ID value to return for out-of-vocabulary feature values, defaults to -1. This can not be specified with a positive num_oov_buckets."
tf.feature_column.categorical_column_with_vocabulary_file.yaml,num_oov_buckets,0.996415770609319,"Non-negative integer, the number of out-of-vocabulary buckets. All out-of-vocabulary inputs will be assigned IDs in the range`[vocabulary_size, vocabulary_size+num_oov_buckets)` based on a hash of the input value. A positive `num_oov_buckets` can not be specified with`default_value`.","Non-negative integer, the number of out-of-vocabulary buckets. All out-of-vocabulary inputs will be assigned IDs in the range [vocabulary_size, vocabulary_size+num_oov_buckets) based on a hash of the input value. A positive num_oov_buckets can not be specified with default_value."
tf.feature_column.categorical_column_with_vocabulary_file.yaml,key,0.9971014492753624,"A unique string identifying the input feature. It is used as the column name and the dictionary key for feature parsing configs, feature`Tensor` objects, and feature columns.","A unique string identifying the input feature. It is used as the column name and the dictionary key for feature parsing configs, feature Tensor objects, and feature columns."
tf.math.segment_min.yaml,segment_ids,0.9971671388101983,"A `Tensor`. Must be one of the following types: `int32`, `int64`. A 1-D tensor whose size is equal to the size of `data`'s first dimension.  Values should be sorted and can be repeated.","A Tensor. Must be one of the following types: int32, int64. A 1-D tensor whose size is equal to the size of data's first dimension. Values should be sorted and can be repeated."
tf.io.parse_sequence_example.yaml,context_features,0.9967213114754099,A `dict` mapping feature keys to `FixedLenFeature` or`VarLenFeature` or `RaggedFeature` values. These features are associated with a `SequenceExample` as a whole.,A dict mapping feature keys to FixedLenFeature or VarLenFeature or RaggedFeature values. These features are associated with a SequenceExample as a whole.
tf.io.parse_sequence_example.yaml,sequence_features,0.9974554707379135,A `dict` mapping feature keys to`FixedLenSequenceFeature` or `VarLenFeature` or `RaggedFeature` values. These features are associated with data within the `FeatureList` section of the `SequenceExample` proto.,A dict mapping feature keys to FixedLenSequenceFeature or VarLenFeature or RaggedFeature values. These features are associated with data within the FeatureList section of the SequenceExample proto.
tf.data.experimental.group_by_window.yaml,window_size,0.9975786924939467,"A `tf.int64` scalar `tf.Tensor`, representing the number of consecutive elements matching the same key to combine in a single batch, which will be passed to `reduce_func`. Mutually exclusive with`window_size_func`.","A tf.int64 scalar tf.Tensor, representing the number of consecutive elements matching the same key to combine in a single batch, which will be passed to reduce_func. Mutually exclusive with window_size_func."
tf.data.experimental.group_by_window.yaml,window_size_func,0.9956331877729258,"A function mapping a key to a `tf.int64` scalar`tf.Tensor`, representing the number of consecutive elements matching the same key to combine in a single batch, which will be passed to`reduce_func`. Mutually exclusive with `window_size`.","A function mapping a key to a tf.int64 scalar tf.Tensor, representing the number of consecutive elements matching the same key to combine in a single batch, which will be passed to reduce_func. Mutually exclusive with window_size."
tf.data.experimental.group_by_window.yaml,key_func,0.9967637540453075,A function mapping a nested structure of tensors (having shapes and types defined by `self.output_shapes` and`self.output_types`) to a scalar `tf.int64` tensor.,A function mapping a nested structure of tensors (having shapes and types defined by self.output_shapes and self.output_types) to a scalar tf.int64 tensor.
tf.data.experimental.group_by_window.yaml,reduce_func,0.9957446808510638,A function mapping a key and a dataset of up to `window_size`consecutive elements matching that key to another dataset.,A function mapping a key and a dataset of up to window_size consecutive elements matching that key to another dataset.
tf.nn.sparse_softmax_cross_entropy_with_logits.yaml,labels,0.9965753424657534,"`Tensor` of shape `[d_0, d_1, ..., d_{r-1}]` (where `r` is rank of`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`must be an index in `[0, num_classes)`. Other values will raise an exception when this op is run on CPU, and return `NaN` for corresponding loss and gradient rows on GPU.","Tensor of shape [d_0, d_1, ..., d_{r-1}] (where r is rank of labels and result) and dtype int32 or int64. Each entry in labels must be an index in [0, num_classes). Other values will raise an exception when this op is run on CPU, and return NaN for corresponding loss and gradient rows on GPU."
tf.meshgrid.yaml,**kwargs,0.9850746268656716,"- indexing: Either 'xy' or 'ij' (optional, default: 'xy'). name: A name for the operation (optional). ","indexing: Either 'xy' or 'ij' (optional, default: 'xy'). name: A name for the operation (optional)."
tf.norm.yaml,ord,0.9953488372093023,"Order of the norm. Supported values are `'fro'`, `'euclidean'`,`1`, `2`, `np.inf` and any positive real number yielding the corresponding p-norm. Default is `'euclidean'` which is equivalent to Frobenius norm if`tensor` is a matrix and equivalent to 2-norm for vectors. Some restrictions apply: a) The Frobenius norm `'fro'` is not defined for vectors, b) If axis is a 2-tuple (matrix norm), only `'euclidean'`, '`fro'`, `1`,    `2`, `np.inf` are supported. See the description of `axis` on how to compute norms for a batch of vectors or matrices stored in a tensor.","Order of the norm. Supported values are 'fro', 'euclidean', 1, 2, np.inf and any positive real number yielding the corresponding p-norm. Default is 'euclidean' which is equivalent to Frobenius norm if tensor is a matrix and equivalent to 2-norm for vectors. Some restrictions apply: a) The Frobenius norm 'fro' is not defined for vectors, b) If axis is a 2-tuple (matrix norm), only 'euclidean', 'fro', 1, 2, np.inf are supported. See the description of axis on how to compute norms for a batch of vectors or matrices stored in a tensor."
tf.norm.yaml,axis,0.9986541049798116,"If `axis` is `None` (the default), the input is considered a vector and a single vector norm is computed over the entire set of values in the tensor, i.e. `norm(tensor, ord=ord)` is equivalent to`norm(reshape(tensor, [-1]), ord=ord)`. If `axis` is a Python integer, the input is considered a batch of vectors, and `axis` determines the axis in `tensor` over which to compute vector norms. If `axis` is a 2-tuple of Python integers it is considered a batch of matrices and `axis` determines the axes in `tensor` over which to compute a matrix norm. Negative indices are supported. Example: If you are passing a tensor that can be either a matrix or a batch of matrices at runtime, pass`axis=[-2,-1]` instead of `axis=None` to make sure that matrix norms are computed.","If axis is None (the default), the input is considered a vector and a single vector norm is computed over the entire set of values in the tensor, i.e. norm(tensor, ord=ord) is equivalent to norm(reshape(tensor, [-1]), ord=ord). If axis is a Python integer, the input is considered a batch of vectors, and axis determines the axis in tensor over which to compute vector norms. If axis is a 2-tuple of Python integers it is considered a batch of matrices and axis determines the axes in tensor over which to compute a matrix norm. Negative indices are supported. Example: If you are passing a tensor that can be either a matrix or a batch of matrices at runtime, pass axis=[-2,-1] instead of axis=None to make sure that matrix norms are computed."
tf.nn.conv2d.yaml,data_format,0.9937888198757764,"An optional `string` from: `""NHWC"", ""NCHW""`. Defaults to `""NHWC""`. Specify the data format of the input and output data. With the default format ""NHWC"", the data is stored in the order of:   [batch, height, width, channels]. Alternatively, the format could be ""NCHW"", the data storage order of:   [batch, channels, height, width].","An optional string from: ""NHWC"", ""NCHW"". Defaults to ""NHWC"". Specify the data format of the input and output data. With the default format ""NHWC"", the data is stored in the order of: [batch, height, width, channels]. Alternatively, the format could be ""NCHW"", the data storage order of: [batch, channels, height, width]."
tf.nn.conv2d.yaml,input,0.9973614775725593,"A `Tensor`. Must be one of the following types:`half`, `bfloat16`, `float32`, `float64`. A 4-D tensor. The dimension order is interpreted according to the value of `data_format`, see below for details.","A Tensor. Must be one of the following types: half, bfloat16, float32, float64. A 4-D tensor. The dimension order is interpreted according to the value of data_format, see below for details."
tf.nn.conv2d.yaml,filters,0.9958847736625515,"A `Tensor`. Must have the same type as `input`. A 4-D tensor of shape`[filter_height, filter_width, in_channels, out_channels]`","A Tensor. Must have the same type as input. A 4-D tensor of shape [filter_height, filter_width, in_channels, out_channels]"
tf.nn.conv2d.yaml,strides,0.9984152139461173,"An int or list of `ints` that has length `1`, `2` or `4`.  The stride of the sliding window for each dimension of `input`. If a single value is given it is replicated in the `H` and `W` dimension. By default the `N` and `C` dimensions are set to 1. The dimension order is determined by the value of `data_format`, see below for details.","An int or list of ints that has length 1, 2 or 4. The stride of the sliding window for each dimension of input. If a single value is given it is replicated in the H and W dimension. By default the N and C dimensions are set to 1. The dimension order is determined by the value of data_format, see below for details."
tf.math.segment_sum.yaml,segment_ids,0.9971671388101983,"A `Tensor`. Must be one of the following types: `int32`, `int64`. A 1-D tensor whose size is equal to the size of `data`'s first dimension.  Values should be sorted and can be repeated.","A Tensor. Must be one of the following types: int32, int64. A 1-D tensor whose size is equal to the size of data's first dimension. Values should be sorted and can be repeated."
tf.image.crop_and_resize.yaml,crop_size,0.9977426636568849,"A 1-D tensor of 2 elements, `size = [crop_height, crop_width]`. All cropped image patches are resized to this size. The aspect ratio of the image content is not preserved. Both `crop_height` and `crop_width`need to be positive.","A 1-D tensor of 2 elements, size = [crop_height, crop_width]. All cropped image patches are resized to this size. The aspect ratio of the image content is not preserved. Both crop_height and crop_width need to be positive."
tf.feature_column.categorical_column_with_identity.yaml,key,0.9971014492753624,"A unique string identifying the input feature. It is used as the column name and the dictionary key for feature parsing configs, feature`Tensor` objects, and feature columns.","A unique string identifying the input feature. It is used as the column name and the dictionary key for feature parsing configs, feature Tensor objects, and feature columns."
tf.io.decode_and_crop_jpeg.yaml,dct_method,0.9956709956709957,"An optional `string`. Defaults to `""""`. string specifying a hint about the algorithm used for decompression.  Defaults to """" which maps to a system-specific default.  Currently valid values are [""INTEGER_FAST"", ""INTEGER_ACCURATE""].  The hint may be ignored (e.g., the internal jpeg library changes to a version that does not have that specific option.)","An optional string. Defaults to """". string specifying a hint about the algorithm used for decompression. Defaults to """" which maps to a system-specific default. Currently valid values are [""INTEGER_FAST"", ""INTEGER_ACCURATE""]. The hint may be ignored (e.g., the internal jpeg library changes to a version that does not have that specific option.)"
tf.io.decode_and_crop_jpeg.yaml,contents,0.9906542056074766,A `Tensor` of type `string`. 0-D.  The JPEG-encoded image.,A Tensor of type string. 0-D. The JPEG-encoded image.
tf.io.decode_and_crop_jpeg.yaml,crop_window,0.9943502824858758,"A `Tensor` of type `int32`. 1-D.  The crop window: [crop_y, crop_x, crop_height, crop_width].","A Tensor of type int32. 1-D. The crop window: [crop_y, crop_x, crop_height, crop_width]."
tf.ones.yaml,dtype,0.9933774834437086,Optional DType of an element in the resulting `Tensor`. Default is`tf.float32`.,Optional DType of an element in the resulting Tensor. Default is tf.float32.
tf.strings.unicode_decode.yaml,errors,0.994059405940594,Specifies the response when an input string can't be converted using the indicated encoding. One of: `'strict'`: Raise an exception for any illegal substrings.`'replace'`: Replace illegal substrings with `replacement_char`.`'ignore'`: Skip illegal substrings. ,Specifies the response when an input string can't be converted using the indicated encoding. One of: 'strict': Raise an exception for any illegal substrings. 'replace': Replace illegal substrings with replacement_char. 'ignore': Skip illegal substrings.
tf.strings.unicode_decode.yaml,replace_control_characters,0.9943502824858758,Whether to replace the C0 control characters`(U+0000 - U+001F)` with the `replacement_char`.,Whether to replace the C0 control characters (U+0000 - U+001F) with the replacement_char.
tf.strings.unicode_decode.yaml,input,0.98989898989899,An `N` dimensional potentially ragged `string` tensor with shape`[D1...DN]`.  `N` must be statically known.,An N dimensional potentially ragged string tensor with shape [D1...DN]. N must be statically known.
tf.compat.forward_compatibility_horizon.yaml,day,0.9927007299270073,"A day (1 <= day <= 31, or 30, or 29, or 28) in month. Must be an`int`.","A day (1 <= day <= 31, or 30, or 29, or 28) in month. Must be an int."
tf.config.experimental.set_synchronous_execution.yaml,enable,0.9921259842519685,Whether operations should be dispatched synchronously. Valid values: None: sets the system default.True: executes each operation synchronously.False: executes each operation asynchronously. ,Whether operations should be dispatched synchronously. Valid values: None: sets the system default. True: executes each operation synchronously. False: executes each operation asynchronously.
tf.sparse.sparse_dense_matmul.yaml,adjoint_a,0.9915966386554622,"Use the adjoint of A in the matrix multiply.  If A is complex, this is transpose(conj(A)).  Otherwise it's transpose(A).","Use the adjoint of A in the matrix multiply. If A is complex, this is transpose(conj(A)). Otherwise it's transpose(A)."
tf.sparse.sparse_dense_matmul.yaml,adjoint_b,0.9915966386554622,"Use the adjoint of B in the matrix multiply.  If B is complex, this is transpose(conj(B)).  Otherwise it's transpose(B).","Use the adjoint of B in the matrix multiply. If B is complex, this is transpose(conj(B)). Otherwise it's transpose(B)."
tf.summary.audio.yaml,max_outputs,0.9956140350877193,"Optional `int` or rank-0 integer `Tensor`. At most this many audio clips will be emitted at each step. When more than`max_outputs` many clips are provided, the first `max_outputs`many clips will be used and the rest silently discarded.","Optional int or rank-0 integer Tensor. At most this many audio clips will be emitted at each step. When more than max_outputs many clips are provided, the first max_outputs many clips will be used and the rest silently discarded."
tf.sparse.reset_shape.yaml,new_shape,0.9931972789115646,None or a vector representing the new shape for the returned`SparseTensor`.,None or a vector representing the new shape for the returned SparseTensor.
tf.while_loop.yaml,maximum_iterations,0.9953051643192489,"Optional maximum number of iterations of the while loop to run.  If provided, the `cond` output is AND-ed with an additional condition ensuring the number of iterations executed is no greater than`maximum_iterations`.","Optional maximum number of iterations of the while loop to run. If provided, the cond output is AND-ed with an additional condition ensuring the number of iterations executed is no greater than maximum_iterations."
tf.while_loop.yaml,loop_vars,0.9946524064171123,"A (possibly nested) tuple, namedtuple or list of numpy array,`Tensor`, and `TensorArray` objects.","A (possibly nested) tuple, namedtuple or list of numpy array, Tensor, and TensorArray objects."
tf.nest.assert_same_structure.yaml,expand_composites,0.9957446808510638,"If true, then composite tensors such as `tf.SparseTensor`and `tf.RaggedTensor` are expanded into their component tensors.","If true, then composite tensors such as tf.SparseTensor and tf.RaggedTensor are expanded into their component tensors."
tf.nn.conv2d_transpose.yaml,filters,0.9967637540453075,"A 4-D `Tensor` with the same type as `input` and shape `[height, width, output_channels, in_channels]`.  `filter`'s `in_channels` dimension must match that of `input`.","A 4-D Tensor with the same type as input and shape [height, width, output_channels, in_channels]. filter's in_channels dimension must match that of input."
tf.nn.conv2d_transpose.yaml,strides,0.9984152139461173,"An int or list of `ints` that has length `1`, `2` or `4`.  The stride of the sliding window for each dimension of `input`. If a single value is given it is replicated in the `H` and `W` dimension. By default the `N` and `C` dimensions are set to 0. The dimension order is determined by the value of `data_format`, see below for details.","An int or list of ints that has length 1, 2 or 4. The stride of the sliding window for each dimension of input. If a single value is given it is replicated in the H and W dimension. By default the N and C dimensions are set to 0. The dimension order is determined by the value of data_format, see below for details."
tf.strings.as_string.yaml,fill,0.9940476190476191,"An optional `string`. Defaults to `""""`. The value to pad if width > -1.  If empty, pads with spaces. Another typical value is '0'.  String cannot be longer than 1 character.","An optional string. Defaults to """". The value to pad if width > -1. If empty, pads with spaces. Another typical value is '0'. String cannot be longer than 1 character."
tf.image.ssim_multiscale.yaml,power_factors,0.9984496124031008,"Iterable of weights for each of the scales. The number of scales used is the length of the list. Index 0 is the unscaled resolution's weight and each increasing scale corresponds to the image being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363, 0.1333), which are the values obtained in the original paper.","Iterable of weights for each of the scales. The number of scales used is the length of the list. Index 0 is the unscaled resolution's weight and each increasing scale corresponds to the image being downsampled by 2. Defaults to (0.0448, 0.2856, 0.3001, 0.2363, 0.1333), which are the values obtained in the original paper."
tf.image.ssim_multiscale.yaml,k2,0.9608540925266904,"Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so it would be better if we taken the values in range of 0< K2 <0.4).","Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so it would be better if we took the values in the range of 0 < K2 < 0.4)."
tf.math.segment_max.yaml,segment_ids,0.9971671388101983,"A `Tensor`. Must be one of the following types: `int32`, `int64`. A 1-D tensor whose size is equal to the size of `data`'s first dimension.  Values should be sorted and can be repeated.","A Tensor. Must be one of the following types: int32, int64. A 1-D tensor whose size is equal to the size of data's first dimension. Values should be sorted and can be repeated."
tf.custom_gradient.yaml,f,0.9961656441717791,"function `f(*x)` that returns a tuple `(y, grad_fn)` where: `x` is a sequence of `Tensor` inputs to the function.`y` is a `Tensor` or sequence of `Tensor` outputs of applying TensorFlow operations in `f` to `x`.`grad_fn` is a function with the signature `g(*grad_ys)` which returns a list of `Tensor`s - the derivatives of `Tensor`s in `y` with respect to the `Tensor`s in `x`.  `grad_ys` is a `Tensor` or sequence of`Tensor`s the same size as `y` holding the initial value gradients for each `Tensor` in `y`. In a pure mathematical sense, a vector-argument vector-valued function `f`'s derivatives should be its Jacobian matrix`J`. Here we are expressing the Jacobian `J` as a function `grad_fn`which defines how `J` will transform a vector `grad_ys` when left-multiplied with it (`grad_ys * J`). This functional representation of a matrix is convenient to use for chain-rule calculation (in e.g. the back-propagation algorithm).If `f` uses `Variable`s (that are not part of the inputs), i.e. through `get_variable`, then `grad_fn` should have signature `g(*grad_ys, variables=None)`, where `variables` is a list of the `Variable`s, and return a 2-tuple `(grad_xs, grad_vars)`, where`grad_xs` is the same as above, and `grad_vars` is a `list<Tensor>`with the derivatives of `Tensor`s in `y` with respect to the variables (that is, grad_vars has one Tensor per variable in variables). ","function f(*x) that returns a tuple (y, grad_fn) where: x is a sequence of Tensor inputs to the function. y is a Tensor or sequence of Tensor outputs of applying TensorFlow operations in f to x. grad_fn is a function with the signature g(*grad_ys) which returns a list of Tensors - the derivatives of Tensors in y with respect to the Tensors in x. grad_ys is a Tensor or sequence of Tensors the same size as y holding the initial value gradients for each Tensor in y. In a pure mathematical sense, a vector-argument vector-valued function f's derivatives should be its Jacobian matrix J. Here we are expressing the Jacobian J as a function grad_fn which defines how J will transform a vector grad_ys when left-multiplied with it (grad_ys * J). This functional representation of a matrix is convenient to use for chain-rule calculation (in e.g. the back-propagation algorithm). If f uses Variables (that are not part of the inputs), i.e. through get_variable, then grad_fn should have signature g(*grad_ys, variables=None), where variables is a list of the Variables, and return a 2-tuple (grad_xs, grad_vars), where grad_xs is the same as above, and grad_vars is a list<Tensor> with the derivatives of Tensors in y with respect to the variables (that is, grad_vars has one Tensor per variable in variables)."
tf.feature_column.shared_embeddings.yaml,initializer,0.9974293059125964,"A variable initializer function to be used in embedding variable initialization. If not specified, defaults to`truncated_normal_initializer` with mean `0.0` and standard deviation `1/sqrt(dimension)`.","A variable initializer function to be used in embedding variable initialization. If not specified, defaults to truncated_normal_initializer with mean 0.0 and standard deviation 1/sqrt(dimension)."
tf.feature_column.shared_embeddings.yaml,combiner,0.9986244841815681,"A string specifying how to reduce if there are multiple entries in a single row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default. 'sqrtn' often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see`tf.embedding_lookup_sparse`.","A string specifying how to reduce if there are multiple entries in a single row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default. 'sqrtn' often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see tf.embedding_lookup_sparse."
tf.feature_column.shared_embeddings.yaml,shared_embedding_collection_name,0.9961977186311787,"Optional collective name of these columns. If not given, a reasonable name will be chosen based on the names of`categorical_columns`.","Optional collective name of these columns. If not given, a reasonable name will be chosen based on the names of categorical_columns."
tf.feature_column.shared_embeddings.yaml,categorical_columns,0.9986893840104849,List of categorical columns created by a`categorical_column_with_*` function. These columns produce the sparse IDs that are inputs to the embedding lookup. All columns must be of the same type and have the same arguments except `key`. E.g. they can be categorical_column_with_vocabulary_file with the same vocabulary_file. Some or all columns could also be weighted_categorical_column.,List of categorical columns created by a categorical_column_with_* function. These columns produce the sparse IDs that are inputs to the embedding lookup. All columns must be of the same type and have the same arguments except key. E.g. they can be categorical_column_with_vocabulary_file with the same vocabulary_file. Some or all columns could also be weighted_categorical_column.
tf.py_function.yaml,func,0.9981024667931688,"A Python function which accepts a list of `Tensor` objects having element types that match the corresponding `tf.Tensor` objects in `inp`and returns a list of `Tensor` objects (or a single `Tensor`, or `None`) having element types that match the corresponding values in `Tout`.","A Python function which accepts a list of Tensor objects having element types that match the corresponding tf.Tensor objects in inp and returns a list of Tensor objects (or a single Tensor, or None) having element types that match the corresponding values in Tout."
tf.math.cumsum.yaml,axis,0.9935483870967742,"A `Tensor` of type `int32` (default: 0). Must be in the range`[-rank(x), rank(x))`.","A Tensor of type int32 (default: 0). Must be in the range [-rank(x), rank(x))."
tf.math.cumsum.yaml,x,0.9935897435897436,"A `Tensor`. Must be one of the following types: `float32`, `float64`,`int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,`complex128`, `qint8`, `quint8`, `qint32`, `half`.","A Tensor. Must be one of the following types: float32, float64, int64, int32, uint8, uint16, int16, int8, complex64, complex128, qint8, quint8, qint32, half."
tf.nn.crelu.yaml,features,0.9928057553956835,"A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,`int16`, or `int8`.","A Tensor with type float, double, int32, int64, uint8, int16, or int8."
tf.nn.dropout.yaml,seed,0.9939393939393939,A Python integer. Used to create random seeds. See`tf.random.set_seed` for behavior.,A Python integer. Used to create random seeds. See tf.random.set_seed for behavior.
tf.data.experimental.rejection_resample.yaml,initial_dist,0.9900332225913622,"(Optional.)  A floating point type tensor, shaped`[num_classes]`.  If not provided, the true class distribution is estimated live in a streaming fashion.","(Optional.) A floating point type tensor, shaped [num_classes]. If not provided, the true class distribution is estimated live in a streaming fashion."
tf.data.experimental.rejection_resample.yaml,class_func,0.9957081545064378,"A function mapping an element of the input dataset to a scalar`tf.int32` tensor. Values should be in `[0, num_classes)`.","A function mapping an element of the input dataset to a scalar tf.int32 tensor. Values should be in [0, num_classes)."
tf.nn.moments.yaml,axes,0.991869918699187,Array of ints.  Axes along which to compute mean and variance.,Array of ints. Axes along which to compute mean and variance.
tf.sparse.reduce_max.yaml,output_is_sparse,0.993006993006993,"If true, returns a `SparseTensor` instead of a dense`Tensor` (the default).","If true, returns a SparseTensor instead of a dense Tensor (the default)."
tf.io.parse_single_sequence_example.yaml,context_features,0.9967213114754099,A `dict` mapping feature keys to `FixedLenFeature` or`VarLenFeature` or `RaggedFeature` values. These features are associated with a `SequenceExample` as a whole.,A dict mapping feature keys to FixedLenFeature or VarLenFeature or RaggedFeature values. These features are associated with a SequenceExample as a whole.
tf.io.parse_single_sequence_example.yaml,sequence_features,0.9974554707379135,A `dict` mapping feature keys to`FixedLenSequenceFeature` or `VarLenFeature` or `RaggedFeature` values. These features are associated with data within the `FeatureList` section of the `SequenceExample` proto.,A dict mapping feature keys to FixedLenSequenceFeature or VarLenFeature or RaggedFeature values. These features are associated with data within the FeatureList section of the SequenceExample proto.
tf.image.sample_distorted_bounding_box.yaml,seed,0.9968454258675079,"An optional `int`. Defaults to `0`. If `seed` is set to non-zero, the random number generator is seeded by the given `seed`.  Otherwise, it is seeded by a random seed.","An optional int. Defaults to 0. If seed is set to non-zero, the random number generator is seeded by the given seed. Otherwise, it is seeded by a random seed."
tf.image.sample_distorted_bounding_box.yaml,image_size,0.9958847736625515,"A `Tensor`. Must be one of the following types: `uint8`, `int8`,`int16`, `int32`, `int64`. 1-D, containing `[height, width, channels]`.","A Tensor. Must be one of the following types: uint8, int8, int16, int32, int64. 1-D, containing [height, width, channels]."
tf.image.sample_distorted_bounding_box.yaml,bounding_boxes,0.9955555555555555,"A `Tensor` of type `float32`. 3-D with shape `[batch, N, 4]`describing the N bounding boxes associated with the image.","A Tensor of type float32. 3-D with shape [batch, N, 4] describing the N bounding boxes associated with the image."
tf.nn.max_pool_with_argmax.yaml,data_format,0.9956709956709957,"An optional `string`, must be set to `""NHWC""`. Defaults to`""NHWC""`. Specify the data format of the input and output data.","An optional string, must be set to ""NHWC"". Defaults to ""NHWC"". Specify the data format of the input and output data."
tf.nn.max_pool_with_argmax.yaml,input,0.9927007299270073,"A `Tensor`. Must be one of the following types: `float32`, `float64`,`int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`,`uint32`, `uint64`. 4-D with shape `[batch, height, width, channels]`.  Input to pool over.","A Tensor. Must be one of the following types: float32, float64, int32, uint8, int16, int8, int64, bfloat16, uint16, half, uint32, uint64. 4-D with shape [batch, height, width, channels]. Input to pool over."
tf.io.decode_png.yaml,contents,0.9904761904761905,A `Tensor` of type `string`. 0-D.  The PNG-encoded image.,A Tensor of type string. 0-D. The PNG-encoded image.
tf.random.stateless_categorical.yaml,logits,0.9922480620155039,"2-D Tensor with shape `[batch_size, num_classes]`.  Each slice`[i, :]` represents the unnormalized log-probabilities for all classes.","2-D Tensor with shape [batch_size, num_classes]. Each slice [i, :] represents the unnormalized log-probabilities for all classes."
tf.random.stateless_categorical.yaml,num_samples,0.992,0-D.  Number of independent samples to draw for each row slice.,0-D. Number of independent samples to draw for each row slice.
tf.compat.forward_compatible.yaml,day,0.9927007299270073,"A day (1 <= day <= 31, or 30, or 29, or 28) in month. Must be an`int`.","A day (1 <= day <= 31, or 30, or 29, or 28) in month. Must be an int."
tf.math.angle.yaml,input,0.9939393939393939,"A `Tensor`. Must be one of the following types: `float`, `double`,`complex64`, `complex128`.","A Tensor. Must be one of the following types: float, double, complex64, complex128."
tf.nn.softmax.yaml,logits,0.9936305732484076,"A non-empty `Tensor`. Must be one of the following types: `half`,`float32`, `float64`.","A non-empty Tensor. Must be one of the following types: half, float32, float64."
tf.histogram_fixed_width.yaml,nbins,0.989247311827957,Scalar `int32 Tensor`.  Number of histogram bins.,Scalar int32 Tensor. Number of histogram bins.
tf.io.parse_single_example.yaml,features,0.9929078014184397,A `dict` mapping feature keys to `FixedLenFeature` or`VarLenFeature` values.,A dict mapping feature keys to FixedLenFeature or VarLenFeature values.
tf.repeat.yaml,repeats,0.997275204359673,An 1-D `int` Tensor. The number of repetitions for each element. repeats is broadcasted to fit the shape of the given axis. `len(repeats)`must equal `input.shape[axis]` if axis is not None.,An 1-D int Tensor. The number of repetitions for each element. repeats is broadcasted to fit the shape of the given axis. len(repeats) must equal input.shape[axis] if axis is not None.
tf.keras.datasets.imdb.load_data.yaml,start_char,0.9401709401709402,The start of a sequence will be marked with this character. Set to 1 because 0 is usually the padding character.,int. The start of a sequence will be marked with this character. Defaults to 1 because 0 is usually the padding character.
tf.keras.datasets.imdb.load_data.yaml,index_from,0.9484536082474226,index actual words with this index and higher.,int. Index actual words with this index and higher.
tf.linalg.pinv.yaml,rcond,0.9980806142034548,"`Tensor` of small singular value cutoffs.  Singular values smaller (in modulus) than `rcond` * largest_singular_value (again, in modulus) are set to zero. Must broadcast against `tf.shape(a)[:-2]`. Default value: `10. * max(num_rows, num_cols) * np.finfo(a.dtype).eps`.","Tensor of small singular value cutoffs. Singular values smaller (in modulus) than rcond * largest_singular_value (again, in modulus) are set to zero. Must broadcast against tf.shape(a)[:-2]. Default value: 10. * max(num_rows, num_cols) * np.finfo(a.dtype).eps."
tf.summary.image.yaml,max_outputs,0.9977827050997783,"Optional `int` or rank-0 integer `Tensor`. At most this many images will be emitted at each step. When more than`max_outputs` many images are provided, the first `max_outputs` many images will be used and the rest silently discarded.","Optional int or rank-0 integer Tensor. At most this many images will be emitted at each step. When more than max_outputs many images are provided, the first max_outputs many images will be used and the rest silently discarded."
tf.cond.yaml,pred,0.993103448275862,A scalar determining whether to return the result of `true_fn` or`false_fn`.,A scalar determining whether to return the result of true_fn or false_fn.
tf.math.pow.yaml,x,0.9939393939393939,"A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,`complex64`, or `complex128`.","A Tensor of type float16, float32, float64, int32, int64, complex64, or complex128."
tf.math.pow.yaml,y,0.9939393939393939,"A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,`complex64`, or `complex128`.","A Tensor of type float16, float32, float64, int32, int64, complex64, or complex128."
tf.keras.backend.batch_set_value.yaml,tuples,0.9921259842519685,"a list of tuples `(tensor, value)`.`value` should be a Numpy array.","a list of tuples (tensor, value). value should be a Numpy array."
tf.nn.dilation2d.yaml,input,0.9946808510638298,"A `Tensor`. Must be one of the following types: `float32`, `float64`,`int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`,`uint32`, `uint64`. 4-D with shape `[batch, in_height, in_width, depth]`.","A Tensor. Must be one of the following types: float32, float64, int32, uint8, int16, int8, int64, bfloat16, uint16, half, uint32, uint64. 4-D with shape [batch, in_height, in_width, depth]."
tf.nn.dilation2d.yaml,dilations,0.9961389961389961,"A list of `ints` that has length `>= 4`. The input stride for atrous morphological dilation. Must be:`[1, rate_height, rate_width, 1]`.","A list of ints that has length >= 4. The input stride for atrous morphological dilation. Must be: [1, rate_height, rate_width, 1]."
tf.nn.safe_embedding_lookup_sparse.yaml,embedding_weights,0.9950900163666121,"A list of `P` float `Tensor`s or values representing partitioned embedding `Tensor`s.  Alternatively, a `PartitionedVariable`created by partitioning along dimension 0.  The total unpartitioned shape should be `[e_0, e_1, ..., e_m]`, where `e_0` represents the vocab size and `e_1, ..., e_m` are the embedding dimensions.","A list of P float Tensors or values representing partitioned embedding Tensors. Alternatively, a PartitionedVariable created by partitioning along dimension 0. The total unpartitioned shape should be [e_0, e_1, ..., e_m], where e_0 represents the vocab size and e_1, ..., e_m are the embedding dimensions."
tf.io.parse_example.yaml,features,0.9951219512195122,"A `dict` mapping feature keys to `FixedLenFeature`,`VarLenFeature`, `SparseFeature`, and `RaggedFeature` values.","A dict mapping feature keys to FixedLenFeature, VarLenFeature, SparseFeature, and RaggedFeature values."
tf.nn.batch_normalization.yaml,scale,0.9958847736625515,"A scale `Tensor`, often denoted \(\gamma\) in equations, or`None`. If present, the scale is applied to the normalized tensor.","A scale Tensor, often denoted \(\gamma\) in equations, or None. If present, the scale is applied to the normalized tensor."
tf.range.yaml,start,0.9963898916967509,"A 0-D `Tensor` (scalar). Acts as first entry in the range if `limit`is not None; otherwise, acts as range limit and first entry defaults to 0.","A 0-D Tensor (scalar). Acts as first entry in the range if limit is not None; otherwise, acts as range limit and first entry defaults to 0."
tf.eye.yaml,num_columns,0.9956331877729258,Optional non-negative `int32` scalar `Tensor` giving the number of columns in each batch matrix.  Defaults to `num_rows`.,Optional non-negative int32 scalar Tensor giving the number of columns in each batch matrix. Defaults to num_rows.
tf.eye.yaml,name,0.987012987012987,"A name for this `Op`.  Defaults to ""eye"".","A name for this Op. Defaults to ""eye""."
tf.linalg.matvec.yaml,a,0.9940119760479041,"`Tensor` of type `float16`, `float32`, `float64`, `int32`, `complex64`,`complex128` and rank > 1.","Tensor of type float16, float32, float64, int32, complex64, complex128 and rank > 1."
tf.nn.avg_pool3d.yaml,input,0.9953051643192489,"A 5-D `Tensor` of shape `[batch, height, width, channels]` and type`float32`, `float64`, `qint8`, `quint8`, or `qint32`.","A 5-D Tensor of shape [batch, height, width, channels] and type float32, float64, qint8, quint8, or qint32."
tf.nn.bias_add.yaml,value,0.9945945945945946,"A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,`int16`, `int8`, `complex64`, or `complex128`.","A Tensor with type float, double, int64, int32, uint8, int16, int8, complex64, or complex128."
tf.feature_column.bucketized_column.yaml,source_column,0.9928057553956835,A one-dimensional dense column which is generated with`numeric_column`.,A one-dimensional dense column which is generated with numeric_column.
tf.math.sigmoid.yaml,x,0.9929078014184397,"A Tensor with type `float16`, `float32`, `float64`, `complex64`, or`complex128`.","A Tensor with type float16, float32, float64, complex64, or complex128."
tf.nest.map_structure.yaml,*structure,0.967032967032967,"scalar, or tuple or list of constructed scalars and/or other tuples/lists, or scalars.  Note: numpy arrays are considered as scalars.","scalar, or tuple or dict or list of constructed scalars and/or other tuples/lists, or scalars. Note: numpy arrays are considered as scalars."
tf.nest.map_structure.yaml,**kwargs,0.995475113122172,"Valid keyword args are: `check_types`: If set to `True` (default) the types of iterables within the structures have to be same (e.g.`map_structure(func, [1], (1,))` raises a `TypeError`exception). To allow this set this argument to `False`. Note that namedtuples with identical name and fields are always considered to have the same shallow structure.`expand_composites`: If set to `True`, then composite tensors such as `tf.SparseTensor` and `tf.RaggedTensor` are expanded into their component tensors.  If `False` (the default), then composite tensors are not expanded. ","Valid keyword args are: check_types: If set to True (default) the types of iterables within the structures have to be same (e.g. map_structure(func, [1], (1,)) raises a TypeError exception). To allow this set this argument to False. Note that namedtuples with identical name and fields are always considered to have the same shallow structure. expand_composites: If set to True, then composite tensors such as tf.SparseTensor and tf.RaggedTensor are expanded into their component tensors. If False (the default), then composite tensors are not expanded."
tf.image.adjust_contrast.yaml,images,0.9841269841269841,Images to adjust.  At least 3-D.,Images to adjust. At least 3-D.
tf.autograph.to_code.yaml,experimental_optional_features,0.9928057553956835,"`None`, a tuple of, or a single`tf.autograph.experimental.Feature` value.","None, a tuple of, or a single tf.autograph.experimental.Feature value."
tf.image.random_flip_up_down.yaml,seed,0.9946524064171123,A Python integer. Used to create a random seed. See`tf.compat.v1.set_random_seed` for behavior.,A Python integer. Used to create a random seed. See tf.compat.v1.set_random_seed for behavior.
tf.graph_util.import_graph_def.yaml,input_map,0.9973333333333333,A dictionary mapping input names (as strings) in `graph_def`to `Tensor` objects. The values of the named input tensors in the imported graph will be re-mapped to the respective `Tensor` values.,A dictionary mapping input names (as strings) in graph_def to Tensor objects. The values of the named input tensors in the imported graph will be re-mapped to the respective Tensor values.
tf.graph_util.import_graph_def.yaml,return_elements,0.997134670487106,A list of strings containing operation names in`graph_def` that will be returned as `Operation` objects; and/or tensor names in `graph_def` that will be returned as `Tensor` objects.,A list of strings containing operation names in graph_def that will be returned as Operation objects; and/or tensor names in graph_def that will be returned as Tensor objects.
tf.graph_util.import_graph_def.yaml,name,0.9966555183946488,"(Optional.) A prefix that will be prepended to the names in`graph_def`. Note that this does not apply to imported function names. Defaults to `""import""`.","(Optional.) A prefix that will be prepended to the names in graph_def. Note that this does not apply to imported function names. Defaults to ""import""."
tf.graph_util.import_graph_def.yaml,producer_op_list,0.9985052316890882,"(Optional.) An `OpList` proto with the (possibly stripped) list of `OpDef`s used by the producer of the graph. If provided, unrecognized attrs for ops in `graph_def` that have their default value according to `producer_op_list` will be removed. This will allow some more`GraphDef`s produced by later binaries to be accepted by earlier binaries.","(Optional.) An OpList proto with the (possibly stripped) list of OpDefs used by the producer of the graph. If provided, unrecognized attrs for ops in graph_def that have their default value according to producer_op_list will be removed. This will allow some more GraphDefs produced by later binaries to be accepted by earlier binaries."
tf.config.set_logical_device_configuration.yaml,logical_devices,0.9968253968253968,"(optional) List of `tf.config.LogicalDeviceConfiguration`objects to allocate for the specified `PhysicalDevice`. If None, the default configuration will be used.","(optional) List of tf.config.LogicalDeviceConfiguration objects to allocate for the specified PhysicalDevice. If None, the default configuration will be used."
tf.scan.yaml,fn,0.9947089947089947,"The callable to be performed.  It accepts two arguments.  The first will have the same structure as `initializer` if one is provided, otherwise it will have the same structure as `elems`.  The second will have the same (possibly nested) structure as `elems`.  Its output must have the same structure as `initializer` if one is provided, otherwise it must have the same structure as `elems`.","The callable to be performed. It accepts two arguments. The first will have the same structure as initializer if one is provided, otherwise it will have the same structure as elems. The second will have the same (possibly nested) structure as elems. Its output must have the same structure as initializer if one is provided, otherwise it must have the same structure as elems."
tf.scan.yaml,elems,0.9973474801061007,"A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension.  The nested sequence of the resulting slices will be the first argument to `fn`.","A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension. The nested sequence of the resulting slices will be the first argument to fn."
tf.nn.ctc_loss.yaml,unique,0.9965156794425087,"(optional) Unique label indices as computed by ctc_unique_labels(labels).  If supplied, enable a faster, memory efficient implementation on TPU.","(optional) Unique label indices as computed by ctc_unique_labels(labels). If supplied, enable a faster, memory efficient implementation on TPU."
tf.image.non_max_suppression.yaml,max_output_size,0.9902912621359223,A scalar integer `Tensor` representing the maximum number of boxes to be selected by non max suppression.,A scalar integer Tensor representing the maximum number of boxes to be selected by non-max suppression.
tf.linalg.logdet.yaml,name,0.9885057471264368,A name to give this `Op`.  Defaults to `logdet`.,A name to give this Op. Defaults to logdet.
tf.expand_dims.yaml,axis,0.9967845659163987,"Integer specifying the dimension index at which to expand the shape of `input`. Given an input of D dimensions, `axis` must be in range`[-(D+1), D]` (inclusive).","Integer specifying the dimension index at which to expand the shape of input. Given an input of D dimensions, axis must be in range [-(D+1), D] (inclusive)."
tf.strings.unicode_encode.yaml,errors,0.9538461538461539,Specifies the response when an invalid codepoint is encountered (optional). One of:     * `'replace'`: Replace invalid codepoint with the       `replacement_char`. (default)     * `'ignore'`: Skip invalid codepoints.     * `'strict'`: Raise an exception for any invalid codepoint.,Specifies the response when an invalid codepoint is encountered (optional). One of: 'replace': Replace invalid codepoint with the replacement_char. (default) 'ignore': Skip invalid codepoints. 'strict': Raise an exception for any invalid codepoint.
tf.strings.unicode_encode.yaml,input,0.9940828402366864,"An `N+1` dimensional potentially ragged integer tensor with shape`[D1...DN, num_chars]`.","An N+1 dimensional potentially ragged integer tensor with shape [D1...DN, num_chars]."
tf.strings.unicode_encode.yaml,output_encoding,0.9957081545064378,"Unicode encoding that should be used to encode each codepoint sequence.  Can be `""UTF-8""`, `""UTF-16-BE""`, or `""UTF-32-BE""`.","Unicode encoding that should be used to encode each codepoint sequence. Can be ""UTF-8"", ""UTF-16-BE"", or ""UTF-32-BE""."
tf.nn.pool.yaml,strides,0.9922480620155039,"Optional. Sequence of N ints >= 1.  Defaults to [1]*N. If any value of strides is > 1, then all values of dilation_rate must be 1.","Optional. Sequence of N ints >= 1. Defaults to [1]N. If any value of strides is > 1, then all values of dilation_rate must be 1."
tf.nn.pool.yaml,data_format,0.9480354879594424,"A string or None.  Specifies whether the channel dimension of the `input` and output is the last dimension (default, or if `data_format`does not start with ""NC""), or the second dimension (if `data_format`starts with ""NC"").  For N=1, the valid values are ""NWC"" (default) and ""NCW"".  For N=2, the valid values are ""NHWC"" (default) and ""NCHW"". For N=3, the valid values are ""NDHWC"" (default) and ""NCDHW"".","A string or None. Specifies whether the channel dimension of the input and output is the last dimension (default, or if data_format does not start with ""NC""), or the second dimension (if data_format starts with ""NC""). For N=1, the valid values are ""NWC"" (default) and ""NCW"". For N=2, the valid values are ""NHWC"" (default) and ""NCHW"". For N=3, the valid values are ""NDHWC"" (default) and ""NCDHW""."
tf.nn.pool.yaml,dilations,0.9858156028368794,"Optional.  Dilation rate.  List of N ints >= 1. Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values of strides must be 1.","Optional. Dilation rate. List of N ints >= 1. Defaults to [1]N. If any value of dilation_rate is > 1, then all values of strides must be 1."
tf.nn.pool.yaml,input,0.9962406015037594,"Tensor of rank N+2, of shape `[batch_size] + input_spatial_shape + [num_channels]` if data_format does not start with ""NC"" (default), or`[batch_size, num_channels] + input_spatial_shape` if data_format starts with ""NC"".  Pooling happens over the spatial dimensions only.","Tensor of rank N+2, of shape [batch_size] + input_spatial_shape + [num_channels] if data_format does not start with ""NC"" (default), or [batch_size, num_channels] + input_spatial_shape if data_format starts with ""NC"". Pooling happens over the spatial dimensions only."
tf.sparse.segment_sqrt_n.yaml,num_segments,0.9923664122137404,An optional int32 scalar. Indicates the size of the output`Tensor`.,An optional int32 scalar. Indicates the size of the output Tensor.
tf.sparse.segment_sqrt_n.yaml,indices,0.9923664122137404,A 1-D `Tensor` with indices into `data`. Has same rank as`segment_ids`.,A 1-D Tensor with indices into data. Has same rank as segment_ids.
tf.math.imag.yaml,input,0.9939393939393939,"A `Tensor`. Must be one of the following types: `float`, `double`,`complex64`, `complex128`.","A Tensor. Must be one of the following types: float, double, complex64, complex128."
tf.nn.atrous_conv2d_transpose.yaml,value,0.9960159362549801,"A 4-D `Tensor` of type `float`. It needs to be in the default `NHWC`format. Its shape is `[batch, in_height, in_width, in_channels]`.","A 4-D Tensor of type float. It needs to be in the default NHWC format. Its shape is [batch, in_height, in_width, in_channels]."
tf.nn.atrous_conv2d_transpose.yaml,filters,0.9969167523124358,"A 4-D `Tensor` with the same type as `value` and shape`[filter_height, filter_width, out_channels, in_channels]`. `filters`'`in_channels` dimension must match that of `value`. Atrous convolution is equivalent to standard convolution with upsampled filters with effective height `filter_height + (filter_height - 1) * (rate - 1)` and effective width `filter_width + (filter_width - 1) * (rate - 1)`, produced by inserting `rate - 1` zeros along consecutive elements across the`filters`' spatial dimensions.","A 4-D Tensor with the same type as value and shape [filter_height, filter_width, out_channels, in_channels]. filters' in_channels dimension must match that of value. Atrous convolution is equivalent to standard convolution with upsampled filters with effective height filter_height + (filter_height - 1) * (rate - 1) and effective width filter_width + (filter_width - 1) * (rate - 1), produced by inserting rate - 1 zeros along consecutive elements across the filters' spatial dimensions."
tf.nn.atrous_conv2d_transpose.yaml,rate,0.99836867862969,"A positive int32. The stride with which we sample input values across the `height` and `width` dimensions. Equivalently, the rate by which we upsample the filter values by inserting zeros across the `height` and`width` dimensions. In the literature, the same parameter is sometimes called `input stride` or `dilation`.","A positive int32. The stride with which we sample input values across the height and width dimensions. Equivalently, the rate by which we upsample the filter values by inserting zeros across the height and width dimensions. In the literature, the same parameter is sometimes called input stride or dilation."
tf.math.is_non_decreasing.yaml,name,0.9928057553956835,"A name for this operation (optional).  Defaults to ""is_non_decreasing""","A name for this operation (optional). Defaults to ""is_non_decreasing"""
tf.xla.experimental.compile.yaml,computation,0.9947089947089947,"A Python function that builds a computation to apply to the input. If the function takes n inputs, 'inputs' should be a list of n tensors.`computation` may return a list of operations and tensors.  Tensors must come before operations in the returned list.  The return value of`compile` is a list of tensors corresponding to the tensors from the output of `computation`.All `Operation`s returned from `computation` will be executed when evaluating any of the returned output tensors.","A Python function that builds a computation to apply to the input. If the function takes n inputs, 'inputs' should be a list of n tensors. computation may return a list of operations and tensors. Tensors must come before operations in the returned list. The return value of compile is a list of tensors corresponding to the tensors from the output of computation. All Operations returned from computation will be executed when evaluating any of the returned output tensors."
tf.keras.backend.rnn.yaml,time_major,0.9974747474747475,"Boolean. If true, the inputs and outputs will be in shape`(timesteps, batch, ...)`, whereas in the False case, it will be`(batch, timesteps, ...)`. Using `time_major = True` is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form.","Boolean. If true, the inputs and outputs will be in shape (timesteps, batch, ...), whereas in the False case, it will be (batch, timesteps, ...). Using time_major = True is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form."
tf.keras.backend.rnn.yaml,inputs,0.9926470588235294,"Tensor of temporal data of shape `(samples, time, ...)`(at least 3D), or nested tensors, and each of which has shape`(samples, time, ...)`.","Tensor of temporal data of shape (samples, time, ...) (at least 3D), or nested tensors, and each of which has shape (samples, time, ...)."
tf.keras.backend.rnn.yaml,initial_states,0.9979879275653923,"Tensor with shape `(samples, state_size)`(no time dimension), containing the initial values for the states used in the step function. In the case that state_size is in a nested shape, the shape of initial_states will also follow the nested structure.","Tensor with shape (samples, state_size) (no time dimension), containing the initial values for the states used in the step function. In the case that state_size is in a nested shape, the shape of initial_states will also follow the nested structure."
tf.function.yaml,func,0.9981916817359855,"the function to be compiled. If `func` is None, `tf.function` returns a decorator that can be invoked with a single argument - `func`. In other words, `tf.function(input_signature=...)(func)` is equivalent to`tf.function(func, input_signature=...)`. The former can be used as decorator.","the function to be compiled. If func is None, tf.function returns a decorator that can be invoked with a single argument - func. In other words, tf.function(input_signature=...)(func) is equivalent to tf.function(func, input_signature=...). The former can be used as decorator."
tf.function.yaml,input_signature,0.9969040247678018,"A possibly nested sequence of `tf.TensorSpec` objects specifying the shapes and dtypes of the Tensors that will be supplied to this function. If `None`, a separate function is instantiated for each inferred input signature.  If input_signature is specified, every input to`func` must be a `Tensor`, and `func` cannot accept `**kwargs`.","A possibly nested sequence of tf.TensorSpec objects specifying the shapes and dtypes of the Tensors that will be supplied to this function. If None, a separate function is instantiated for each inferred input signature. If input_signature is specified, every input to func must be a Tensor, and func cannot accept **kwargs."
tf.function.yaml,experimental_autograph_options,0.9914529914529915,Optional tuple of`tf.autograph.experimental.Feature` values.,Optional tuple of tf.autograph.experimental.Feature values.
tf.function.yaml,experimental_compile,0.996309963099631,"If True, the function is always compiled byXLA. XLA may be more efficient in some cases (e.g. TPU, XLA_GPU, dense tensor computations).","If True, the function is always compiled by XLA. XLA may be more efficient in some cases (e.g. TPU, XLA_GPU, dense tensor computations)."
tf.keras.backend.placeholder.yaml,ragged,0.9975062344139651,"Boolean, whether the placeholder should have a ragged type. In this case, values of 'None' in the 'shape' argument represent ragged dimensions. For more information about RaggedTensors, see thisguide.","Boolean, whether the placeholder should have a ragged type. In this case, values of 'None' in the 'shape' argument represent ragged dimensions. For more information about RaggedTensors, see this guide."
tf.saved_model.save.yaml,signatures,0.998158379373849,"Optional, either a `tf.function` with an input signature specified or the result of `f.get_concrete_function` on a`@tf.function`-decorated function `f`, in which case `f` will be used to generate a signature for the SavedModel under the default serving signature key. `signatures` may also be a dictionary, in which case it maps from signature keys to either `tf.function` instances with input signatures or concrete functions. The keys of such a dictionary may be arbitrary strings, but will typically be from the`tf.saved_model.signature_constants` module.","Optional, either a tf.function with an input signature specified or the result of f.get_concrete_function on a @tf.function-decorated function f, in which case f will be used to generate a signature for the SavedModel under the default serving signature key. signatures may also be a dictionary, in which case it maps from signature keys to either tf.function instances with input signatures or concrete functions. The keys of such a dictionary may be arbitrary strings, but will typically be from the tf.saved_model.signature_constants module."
tf.nn.max_pool.yaml,input,0.9981167608286252,"Tensor of rank N+2, of shape `[batch_size] + input_spatial_shape + [num_channels]` if `data_format` does not start with ""NC"" (default), or`[batch_size, num_channels] + input_spatial_shape` if data_format starts with ""NC"". Pooling happens over the spatial dimensions only.","Tensor of rank N+2, of shape [batch_size] + input_spatial_shape + [num_channels] if data_format does not start with ""NC"" (default), or [batch_size, num_channels] + input_spatial_shape if data_format starts with ""NC"". Pooling happens over the spatial dimensions only."
tf.ragged.stack_dynamic_partitions.yaml,partitions,0.994535519125683,"An `int32` or `int64` `Tensor` or `RaggedTensor` specifying the partition that each slice of `data` should be added to.`partitions.shape` must be a prefix of `data.shape`.  Values must be greater than or equal to zero, and less than `num_partitions`.`partitions` is not required to be sorted.","An int32 or int64 Tensor or RaggedTensor specifying the partition that each slice of data should be added to. partitions.shape must be a prefix of data.shape. Values must be greater than or equal to zero, and less than num_partitions. partitions is not required to be sorted."
tf.ragged.stack_dynamic_partitions.yaml,num_partitions,0.9957446808510638,An `int32` or `int64` scalar specifying the number of partitions to output.  This determines the number of rows in `output`.,An int32 or int64 scalar specifying the number of partitions to output. This determines the number of rows in output.
tf.squeeze.yaml,axis,0.9963369963369964,"An optional list of `ints`. Defaults to `[]`. If specified, only squeezes the dimensions listed. The dimension index starts at 0. It is an error to squeeze a dimension that is not 1. Must be in the range`[-rank(input), rank(input))`. Must be specified if `input` is a`RaggedTensor`.","An optional list of ints. Defaults to []. If specified, only squeezes the dimensions listed. The dimension index starts at 0. It is an error to squeeze a dimension that is not 1. Must be in the range [-rank(input), rank(input)). Must be specified if input is a RaggedTensor."
tf.ragged.stack.yaml,axis,0.9978308026030369,"A python integer, indicating the dimension along which to stack. (Note: Unlike `tf.stack`, the `axis` parameter must be statically known.) Negative values are supported only if the rank of at least one`values` value is statically known.","A python integer, indicating the dimension along which to stack. (Note: Unlike tf.stack, the axis parameter must be statically known.) Negative values are supported only if the rank of at least one values value is statically known."
tf.ragged.stack.yaml,values,0.9913544668587896,"A list of `tf.Tensor` or `tf.RaggedTensor`.  May not be empty. All`values` must have the same rank and the same dtype; but unlike`tf.stack`, they can have arbitrary dimension sizes.","A list of tf.Tensor or tf.RaggedTensor. May not be empty. All values must have the same rank and the same dtype; but unlike tf.stack, they can have arbitrary dimension sizes."
tf.train.checkpoints_iterator.yaml,timeout_fn,0.9949748743718593,"Optional function to call after a timeout.  If the function returns True, then it means that no new checkpoints will be generated and the iterator will exit.  The function is called with no arguments.","Optional function to call after a timeout. If the function returns True, then it means that no new checkpoints will be generated and the iterator will exit. The function is called with no arguments."
tf.math.logical_and.yaml,y,0.9361702127659575,A `Tensor` of type `bool`.,A tf.Tensor of type bool.
tf.dynamic_partition.yaml,partitions,0.9934640522875817,"A `Tensor` of type `int32`. Any shape.  Indices in the range `[0, num_partitions)`.","A Tensor of type int32. Any shape. Indices in the range [0, num_partitions)."
tf.math.logical_xor.yaml,x,0.926829268292683,A `Tensor` type bool.,A tf.Tensor type bool.
tf.math.logical_xor.yaml,y,0.9361702127659575,A `Tensor` of type bool.,A tf.Tensor of type bool.
tf.nn.conv1d_transpose.yaml,input,0.9929078014184397,"A 3-D `Tensor` of type `float` and shape`[batch, in_width, in_channels]` for `NWC` data format or`[batch, in_channels, in_width]` for `NCW` data format.","A 3-D Tensor of type float and shape [batch, in_width, in_channels] for NWC data format or [batch, in_channels, in_width] for NCW data format."
tf.nn.conv1d_transpose.yaml,filters,0.9901639344262295,"A 3-D `Tensor` with the same type as `value` and shape`[filter_width, output_channels, in_channels]`.  `filter`'s`in_channels` dimension must match that of `value`.","A 3-D Tensor with the same type as value and shape [filter_width, output_channels, in_channels]. filter's in_channels dimension must match that of value."
tf.nn.conv1d_transpose.yaml,strides,0.9957446808510638,An int or list of `ints` that has length `1` or `3`.  The number of entries by which the filter is moved right at each step.,An int or list of ints that has length 1 or 3. The number of entries by which the filter is moved right at each step.
tf.zeros_like.yaml,dtype,0.9570957095709571,"A type for the returned `Tensor`. Must be `float16`, `float32`,`float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`,`complex64`, `complex128`, `bool` or `string`.","A type for the returned Tensor. Must be float16, float32, float64, int8, uint8, int16, uint16, int32, int64, complex64, complex128, bool or string (optional)."
tf.random.gamma.yaml,beta,0.9973045822102425,A Tensor or Python value or N-D array of type `dtype`. Defaults to 1.`beta` provides the inverse scale parameter(s) of the gamma distribution(s) to sample. Must be broadcastable with `alpha`.,A Tensor or Python value or N-D array of type dtype. Defaults to 1. beta provides the inverse scale parameter(s) of the gamma distribution(s) to sample. Must be broadcastable with alpha.
tf.random.gamma.yaml,dtype,0.9928057553956835,"The type of alpha, beta, and the output: `float16`, `float32`, or`float64`.","The type of alpha, beta, and the output: float16, float32, or float64."
tf.random.gamma.yaml,seed,0.9090909090909091,A Python integer. Used to create a random seed for the distributions. See`tf.compat.v1.set_random_seed`for behavior.,A Python integer. Used to create a random seed for the distributions. See tf.random.set_seed for behavior.
tf.random.gamma.yaml,alpha,0.9970674486803519,A Tensor or Python value or N-D array of type `dtype`. `alpha`provides the shape parameter(s) describing the gamma distribution(s) to sample. Must be broadcastable with `beta`.,A Tensor or Python value or N-D array of type dtype. alpha provides the shape parameter(s) describing the gamma distribution(s) to sample. Must be broadcastable with beta.
tf.estimator.regressor_parse_example_spec.yaml,label_dtype,0.9928057553956835,A `tf.dtype` identifies the type of labels. By default it is`tf.float32`.,A tf.dtype identifies the type of labels. By default it is tf.float32.
tf.estimator.regressor_parse_example_spec.yaml,label_default,0.9970674486803519,"used as label if label_key does not exist in given tf.Example. By default default_value is none, which means`tf.parse_example` will error out if there is any missing label.","used as label if label_key does not exist in given tf.Example. By default default_value is none, which means tf.parse_example will error out if there is any missing label."
tf.estimator.regressor_parse_example_spec.yaml,weight_column,0.9977973568281938,"A string or a `NumericColumn` created by`tf.feature_column.numeric_column` defining feature column representing weights. It is used to down weight or boost examples during training. It will be multiplied by the loss of the example. If it is a string, it is used as a key to fetch weight tensor from the `features`. If it is a`NumericColumn`, raw tensor is fetched by key `weight_column.key`, then weight_column.normalizer_fn is applied on it to get weight tensor.","A string or a NumericColumn created by tf.feature_column.numeric_column defining feature column representing weights. It is used to down weight or boost examples during training. It will be multiplied by the loss of the example. If it is a string, it is used as a key to fetch weight tensor from the features. If it is a NumericColumn, raw tensor is fetched by key weight_column.key, then weight_column.normalizer_fn is applied on it to get weight tensor."
tf.keras.backend.ctc_batch_cost.yaml,y_true,0.9921259842519685,"tensor `(samples, max_string_length)`containing the truth labels.","tensor (samples, max_string_length) containing the truth labels."
tf.keras.backend.ctc_batch_cost.yaml,y_pred,0.9948186528497409,"tensor `(samples, time_steps, num_categories)`containing the prediction, or output of the softmax.","tensor (samples, time_steps, num_categories) containing the prediction, or output of the softmax."
tf.math.conj.yaml,x,0.990990990990991,`Tensor` to conjugate.  Must have numeric or variant type.,Tensor to conjugate. Must have numeric or variant type.
tf.random.uniform.yaml,minval,0.993421052631579,"A Tensor or Python value of type `dtype`, broadcastable with`maxval`. The lower bound on the range of random values to generate (inclusive).  Defaults to 0.","A Tensor or Python value of type dtype, broadcastable with maxval. The lower bound on the range of random values to generate (inclusive). Defaults to 0."
tf.random.uniform.yaml,maxval,0.9971988795518207,"A Tensor or Python value of type `dtype`, broadcastable with`minval`. The upper bound on the range of random values to generate (exclusive). Defaults to 1 if `dtype` is floating point.","A Tensor or Python value of type dtype, broadcastable with minval. The upper bound on the range of random values to generate (exclusive). Defaults to 1 if dtype is floating point."
tf.nn.fractional_max_pool.yaml,overlapping,0.9235294117647059,"An optional `bool`.  Defaults to `False`.  When set to `True`, it means when pooling, the values at the boundary of adjacent pooling cells are used by both cells. For example:`index  0  1  2  3  4``value  20 5  16 3  7`If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.  The result would be [20, 16] for fractional max pooling.","An optional bool. Defaults to False. When set to True, it means when pooling, the values at the boundary of adjacent pooling cells are used by both cells. For example: index 0 1 2 3 4 value 20 5 16 3 7 If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice. The result would be [20, 16] for fractional max pooling."
tf.nn.fractional_max_pool.yaml,seed,0.990228013029316,"An optional `int`.  Defaults to `0`.  If set to be non-zero, the random number generator is seeded by the given seed.  Otherwise it is seeded by a random seed.","An optional int. Defaults to 0. If set to be non-zero, the random number generator is seeded by the given seed. Otherwise it is seeded by a random seed."
tf.nn.fractional_max_pool.yaml,pooling_ratio,0.9987878787878788,"An int or list of `ints` that has length `1`, `2` or `4`. Pooling ratio for each dimension of `value`, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling ratio on height and width dimensions respectively.","An int or list of ints that has length 1, 2 or 4. Pooling ratio for each dimension of value, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions. 1.44 and 1.73 are pooling ratio on height and width dimensions respectively."
tf.where.yaml,condition,0.9333333333333333,A `Tensor` of type `bool`,A tf.Tensor of type bool
tf.math.ceil.yaml,x,0.9461077844311377,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.","A tf.Tensor. Must be one of the following types: bfloat16, half, float32, float64. int32"
tf.xla.experimental.jit_scope.yaml,compile_ops,0.9967213114754099,"Whether to enable or disable compilation in the scope. Either a Python bool, or a callable that accepts the parameter`node_def` and returns a python bool.","Whether to enable or disable compilation in the scope. Either a Python bool, or a callable that accepts the parameter node_def and returns a python bool."
tf.nn.avg_pool2d.yaml,input,0.9953051643192489,"A 4-D `Tensor` of shape `[batch, height, width, channels]` and type`float32`, `float64`, `qint8`, `quint8`, or `qint32`.","A 4-D Tensor of shape [batch, height, width, channels] and type float32, float64, qint8, quint8, or qint32."
tf.data.experimental.bucket_by_sequence_length.yaml,padded_shapes,0.9955555555555555,"Nested structure of `tf.TensorShape` to pass to`tf.data.Dataset.padded_batch`. If not provided, will use`dataset.output_shapes`, which will result in variable length dimensions being padded out to the maximum length in each batch.","Nested structure of tf.TensorShape to pass to tf.data.Dataset.padded_batch. If not provided, will use dataset.output_shapes, which will result in variable length dimensions being padded out to the maximum length in each batch."
tf.data.experimental.bucket_by_sequence_length.yaml,padding_values,0.9942196531791907,"Values to pad with, passed to`tf.data.Dataset.padded_batch`. Defaults to padding with 0.","Values to pad with, passed to tf.data.Dataset.padded_batch. Defaults to padding with 0."
tf.data.experimental.bucket_by_sequence_length.yaml,drop_remainder,0.9974811083123426,"(Optional.) A `tf.bool` scalar `tf.Tensor`, representing whether the last batch should be dropped in the case it has fewer than`batch_size` elements; the default behavior is not to drop the smaller batch.","(Optional.) A tf.bool scalar tf.Tensor, representing whether the last batch should be dropped in the case it has fewer than batch_size elements; the default behavior is not to drop the smaller batch."
tf.data.experimental.bucket_by_sequence_length.yaml,bucket_batch_sizes,0.9935483870967742,"`list<int>`, batch size per bucket. Length should be`len(bucket_boundaries) + 1`.","list<int>, batch size per bucket. Length should be len(bucket_boundaries) + 1."
tf.lite.experimental.load_delegate.yaml,library,0.9904761904761905,Name of shared library containing theTfLiteDelegate.,Name of shared library containing the TfLiteDelegate.
tf.keras.backend.set_learning_phase.yaml,value,0.9781021897810219,"Learning phase value, either 0 or 1 (integers).    0 = test, 1 = train","Learning phase value, either 0 or 1 (integers). 0 = test, 1 = train"
tf.strings.unicode_split.yaml,errors,0.994059405940594,Specifies the response when an input string can't be converted using the indicated encoding. One of: `'strict'`: Raise an exception for any illegal substrings.`'replace'`: Replace illegal substrings with `replacement_char`.`'ignore'`: Skip illegal substrings. ,Specifies the response when an input string can't be converted using the indicated encoding. One of: 'strict': Raise an exception for any illegal substrings. 'replace': Replace illegal substrings with replacement_char. 'ignore': Skip illegal substrings.
tf.strings.unicode_split.yaml,input,0.98989898989899,An `N` dimensional potentially ragged `string` tensor with shape`[D1...DN]`.  `N` must be statically known.,An N dimensional potentially ragged string tensor with shape [D1...DN]. N must be statically known.
tf.nn.convolution.yaml,strides,0.9905956112852664,"Optional.  Sequence of N ints >= 1.  Specifies the output stride. Defaults to [1]*N.  If any value of strides is > 1, then all values of dilation_rate must be 1.","Optional. Sequence of N ints >= 1. Specifies the output stride. Defaults to [1]*N. If any value of strides is > 1, then all values of dilation_rate must be 1."
tf.nn.convolution.yaml,data_format,0.9480354879594424,"A string or None.  Specifies whether the channel dimension of the `input` and output is the last dimension (default, or if `data_format`does not start with ""NC""), or the second dimension (if `data_format`starts with ""NC"").  For N=1, the valid values are ""NWC"" (default) and ""NCW"".  For N=2, the valid values are ""NHWC"" (default) and ""NCHW"". For N=3, the valid values are ""NDHWC"" (default) and ""NCDHW"".","A string or None. Specifies whether the channel dimension of the input and output is the last dimension (default, or if data_format does not start with ""NC""), or the second dimension (if data_format starts with ""NC""). For N=1, the valid values are ""NWC"" (default) and ""NCW"". For N=2, the valid values are ""NHWC"" (default) and ""NCHW"". For N=3, the valid values are ""NDHWC"" (default) and ""NCDHW""."
tf.nn.convolution.yaml,input,0.9954954954954955,"An (N+2)-D `Tensor` of type `T`, of shape`[batch_size] + input_spatial_shape + [in_channels]` if data_format does not start with ""NC"" (default), or`[batch_size, in_channels] + input_spatial_shape` if data_format starts with ""NC"".","An (N+2)-D Tensor of type T, of shape [batch_size] + input_spatial_shape + [in_channels] if data_format does not start with ""NC"" (default), or [batch_size, in_channels] + input_spatial_shape if data_format starts with ""NC""."
tf.io.decode_gif.yaml,contents,0.9904761904761905,A `Tensor` of type `string`. 0-D.  The GIF-encoded image.,A Tensor of type string. 0-D. The GIF-encoded image.
tf.strings.unicode_split_with_offsets.yaml,errors,0.994059405940594,Specifies the response when an input string can't be converted using the indicated encoding. One of: `'strict'`: Raise an exception for any illegal substrings.`'replace'`: Replace illegal substrings with `replacement_char`.`'ignore'`: Skip illegal substrings. ,Specifies the response when an input string can't be converted using the indicated encoding. One of: 'strict': Raise an exception for any illegal substrings. 'replace': Replace illegal substrings with replacement_char. 'ignore': Skip illegal substrings.
tf.strings.unicode_split_with_offsets.yaml,input,0.98989898989899,An `N` dimensional potentially ragged `string` tensor with shape`[D1...DN]`.  `N` must be statically known.,An N dimensional potentially ragged string tensor with shape [D1...DN]. N must be statically known.
tf.gather.yaml,axis,0.9953917050691244,"A `Tensor`. Must be one of the following types: `int32`, `int64`. The`axis` in `params` to gather `indices` from. Must be greater than or equal to `batch_dims`.  Defaults to the first non-batch dimension. Supports negative indexes.","A Tensor. Must be one of the following types: int32, int64. The axis in params to gather indices from. Must be greater than or equal to batch_dims. Defaults to the first non-batch dimension. Supports negative indexes."
tf.gather.yaml,batch_dims,0.9156626506024096,An `integer`.  The number of batch dimensions.  Must be less than `rank(indices)`.,An integer. The number of batch dimensions. Must be less than or equal to rank(indices).
tf.gather.yaml,params,0.9929078014184397,The `Tensor` from which to gather values. Must be at least rank`axis + 1`.,The Tensor from which to gather values. Must be at least rank axis + 1.
tf.gather.yaml,indices,0.9908256880733946,"The index `Tensor`.  Must be one of the following types: `int32`,`int64`. Must be in range `[0, params.shape[axis])`.","The index Tensor. Must be one of the following types: int32, int64. Must be in range [0, params.shape[axis])."
tf.ragged.row_splits_to_segment_ids.yaml,out_type,0.9951219512195122,"The dtype for the return value.  Defaults to `splits.dtype`, or `tf.int64` if `splits` does not have a dtype.","The dtype for the return value. Defaults to splits.dtype, or tf.int64 if splits does not have a dtype."
tf.ragged.row_splits_to_segment_ids.yaml,splits,0.9904761904761905,A sorted 1-D integer Tensor.  `splits[0]` must be zero.,A sorted 1-D integer Tensor. splits[0] must be zero.
tf.concat.yaml,axis,0.998272884283247,"0-D `int32` `Tensor`.  Dimension along which to concatenate. Must be in the range `[-rank(values), rank(values))`. As in Python, indexing for axis is 0-based. Positive axis in the rage of `[0, rank(values))` refers to `axis`-th dimension. And negative axis refers to `axis + rank(values)`-th dimension.","0-D int32 Tensor. Dimension along which to concatenate. Must be in the range [-rank(values), rank(values)). As in Python, indexing for axis is 0-based. Positive axis in the rage of [0, rank(values)) refers to axis-th dimension. And negative axis refers to axis + rank(values)-th dimension."
tf.ragged.range.yaml,limits,0.9935483870967742,Vector or scalar `Tensor`.  Specifies the exclusive upper limits for each range.,Vector or scalar Tensor. Specifies the exclusive upper limits for each range.
tf.ragged.range.yaml,deltas,0.9937106918238994,Vector or scalar `Tensor`.  Specifies the increment for each range. Defaults to `1`.,Vector or scalar Tensor. Specifies the increment for each range. Defaults to 1.
tf.ragged.range.yaml,dtype,0.9956709956709957,"The type of the elements of the resulting tensor.  If not specified, then a value is chosen based on the other args.","The type of the elements of the resulting tensor. If not specified, then a value is chosen based on the other args."
tf.ragged.range.yaml,row_splits_dtype,0.9882352941176471,`dtype` for the returned `RaggedTensor`'s `row_splits`tensor.  One of `tf.int32` or `tf.int64`.,dtype for the returned RaggedTensor's row_splits tensor. One of tf.int32 or tf.int64.
tf.ragged.range.yaml,starts,0.9969418960244648,"Vector or scalar `Tensor`.  Specifies the first entry for each range if `limits` is not `None`; otherwise, specifies the range limits, and the first entries default to `0`.","Vector or scalar Tensor. Specifies the first entry for each range if limits is not None; otherwise, specifies the range limits, and the first entries default to 0."
tf.ragged.boolean_mask.yaml,mask,0.9917355371900827,A potentially ragged boolean tensor.  `mask`'s shape must be a prefix of `data`'s shape.  `rank(mask)` must be known statically.,A potentially ragged boolean tensor. mask's shape must be a prefix of data's shape. rank(mask) must be known statically.
tf.io.decode_bmp.yaml,contents,0.9904761904761905,A `Tensor` of type `string`. 0-D.  The BMP-encoded image.,A Tensor of type string. 0-D. The BMP-encoded image.
tf.linalg.triangular_solve.yaml,adjoint,0.9699570815450643,An optional `bool`. Defaults to `False`. Boolean indicating whether to solve with `matrix` or its (block-wise)        adjoint.,An optional bool. Defaults to False. Boolean indicating whether to solve with matrix or its (block-wise) adjoint.
tf.linalg.triangular_solve.yaml,rhs,0.9848484848484849,"A `Tensor`. Must have the same type as `matrix`. Shape is `[..., M, K]`.","A Tensor. Must have the same type as matrix. Shape is [..., M, N]."
tf.roll.yaml,axis,0.9983079526226735,"A `Tensor`. Must be one of the following types: `int32`, `int64`. Dimension must be 0-D or 1-D. `axis[i]` specifies the dimension that the shift`shift[i]` should occur. If the same axis is referenced more than once, the total shift for that axis will be the sum of all the shifts that belong to that axis.","A Tensor. Must be one of the following types: int32, int64. Dimension must be 0-D or 1-D. axis[i] specifies the dimension that the shift shift[i] should occur. If the same axis is referenced more than once, the total shift for that axis will be the sum of all the shifts that belong to that axis."
tf.estimator.experimental.make_early_stopping_hook.yaml,run_every_secs,0.993006993006993,"If specified, calls `should_stop_fn` at an interval of`run_every_secs` seconds. Defaults to 60 seconds. Either this or`run_every_steps` must be set.","If specified, calls should_stop_fn at an interval of run_every_secs seconds. Defaults to 60 seconds. Either this or run_every_steps must be set."
tf.estimator.experimental.make_early_stopping_hook.yaml,run_every_steps,0.995260663507109,"If specified, calls `should_stop_fn` every`run_every_steps` steps. Either this or `run_every_secs` must be set.","If specified, calls should_stop_fn every run_every_steps steps. Either this or run_every_secs must be set."
tf.estimator.experimental.make_early_stopping_hook.yaml,should_stop_fn,0.9962264150943396,"`callable`, function that takes no arguments and returns a`bool`. If the function returns `True`, stopping will be initiated by the chief.","callable, function that takes no arguments and returns a bool. If the function returns True, stopping will be initiated by the chief."
tf.debugging.assert_negative.yaml,name,0.9927007299270073,"A name for this operation (optional).  Defaults to ""assert_negative"".","A name for this operation (optional). Defaults to ""assert_negative""."
tf.strings.ngrams.yaml,padding_width,0.9973753280839895,"If set, `padding_width` pad values will be added to both sides of each sequence. Defaults to `ngram_width`-1. Must be greater than (Note that 1-grams are never padded, regardless of this value.) ","If set, padding_width pad values will be added to both sides of each sequence. Defaults to ngram_width-1. Must be greater than (Note that 1-grams are never padded, regardless of this value.)"
tf.strings.ngrams.yaml,preserve_short_sequences,0.9966666666666667,"If true, then ensure that at least one ngram is generated for each input sequence.  In particular, if an input sequence is shorter than `min(ngram_width) + 2*pad_width`, then generate a single ngram containing the entire sequence.  If false, then no ngrams are generated for these short input sequences.","If true, then ensure that at least one ngram is generated for each input sequence. In particular, if an input sequence is shorter than min(ngram_width) + 2*pad_width, then generate a single ngram containing the entire sequence. If false, then no ngrams are generated for these short input sequences."
tf.nn.nce_loss.yaml,num_true,0.9914529914529915,An `int`.  The number of target classes per training example.,An int. The number of target classes per training example.
tf.nn.nce_loss.yaml,sampled_values,0.997134670487106,"a tuple of (`sampled_candidates`, `true_expected_count`,`sampled_expected_count`) returned by a `*_candidate_sampler` function. (if None, we default to `log_uniform_candidate_sampler`)","a tuple of (sampled_candidates, true_expected_count, sampled_expected_count) returned by a *_candidate_sampler function. (if None, we default to log_uniform_candidate_sampler)"
tf.nn.nce_loss.yaml,remove_accidental_hits,0.972176759410802,"A `bool`.  Whether to remove ""accidental hits"" where a sampled class equals one of the target classes.  If set to `True`, this is a ""Sampled Logistic"" loss instead of NCE, and we are learning to generate log-odds instead of log probabilities.  See our Candidate Sampling Algorithms Reference. Default is   False.","A bool. Whether to remove ""accidental hits"" where a sampled class equals one of the target classes. If set to True, this is a ""Sampled Logistic"" loss instead of NCE, and we are learning to generate log-odds instead of log probabilities. See our Candidate Sampling Algorithms Reference. Default is False."
tf.nn.nce_loss.yaml,weights,0.9943820224719101,"A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`objects whose concatenation along dimension 0 has shape [num_classes, dim].  The (possibly-partitioned) class embeddings.","A Tensor of shape [num_classes, dim], or a list of Tensor objects whose concatenation along dimension 0 has shape [num_classes, dim]. The (possibly-partitioned) class embeddings."
tf.nn.nce_loss.yaml,biases,0.9900990099009901,A `Tensor` of shape `[num_classes]`.  The class biases.,A Tensor of shape [num_classes]. The class biases.
tf.nn.nce_loss.yaml,inputs,0.9939393939393939,"A `Tensor` of shape `[batch_size, dim]`.  The forward activations of the input network.","A Tensor of shape [batch_size, dim]. The forward activations of the input network."
tf.nn.nce_loss.yaml,num_sampled,0.9966996699669967,An `int`.  The number of negative classes to randomly sample per batch. This single sample of negative classes is evaluated for each element in the batch.,An int. The number of negative classes to randomly sample per batch. This single sample of negative classes is evaluated for each element in the batch.
tf.strings.split.yaml,input,0.9913793103448276,"A string `Tensor` of rank `N`, the strings to split.  If`rank(input)` is not known statically, then it is assumed to be `1`.","A string Tensor of rank N, the strings to split. If rank(input) is not known statically, then it is assumed to be 1."
tf.feature_column.weighted_categorical_column.yaml,categorical_column,0.9924812030075187,A `CategoricalColumn` created by`categorical_column_with_*` functions.,A CategoricalColumn created by categorical_column_with_* functions.
tf.image.ssim.yaml,k2,0.9608540925266904,"Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so it would be better if we taken the values in range of 0< K2 <0.4).","Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so it would be better if we took the values in the range of 0 < K2 < 0.4)."
tf.nn.local_response_normalization.yaml,depth_radius,0.9937888198757764,An optional `int`. Defaults to `5`. 0-D.  Half-width of the 1-D normalization window.,An optional int. Defaults to 5. 0-D. Half-width of the 1-D normalization window.
tf.map_fn.yaml,dtype,0.9974160206718347,"(optional) The output type(s) of `fn`.  If `fn` returns a structure of Tensors differing from the structure of `elems`, then `dtype` is not optional and must have the same structure as the output of `fn`.","(optional) The output type(s) of fn. If fn returns a structure of Tensors differing from the structure of elems, then dtype is not optional and must have the same structure as the output of fn."
tf.map_fn.yaml,fn,0.99581589958159,"The callable to be performed.  It accepts one argument, which will have the same (possibly nested) structure as `elems`.  Its output must have the same structure as `dtype` if one is provided, otherwise it must have the same structure as `elems`.","The callable to be performed. It accepts one argument, which will have the same (possibly nested) structure as elems. Its output must have the same structure as dtype if one is provided, otherwise it must have the same structure as elems."
tf.map_fn.yaml,elems,0.9971830985915493,"A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension.  The nested sequence of the resulting slices will be applied to `fn`.","A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension. The nested sequence of the resulting slices will be applied to fn."
tf.data.experimental.dense_to_sparse_batch.yaml,row_shape,0.9963369963369964,"A `tf.TensorShape` or `tf.int64` vector tensor-like object representing the equivalent dense shape of a row in the resulting`tf.SparseTensor`. Each element of this dataset must have the same rank as`row_shape`, and must have size less than or equal to `row_shape` in each dimension.","A tf.TensorShape or tf.int64 vector tensor-like object representing the equivalent dense shape of a row in the resulting tf.SparseTensor. Each element of this dataset must have the same rank as row_shape, and must have size less than or equal to row_shape in each dimension."
tf.required_space_to_batch_paddings.yaml,base_paddings,0.9898305084745763,"Optional int32 Tensor of shape [N, 2].  Specifies the minimum amount of padding to use.  All elements must be >= 0.  If not specified, defaults to 0.","Optional int32 Tensor of shape [N, 2]. Specifies the minimum amount of padding to use. All elements must be >= 0. If not specified, defaults to 0."
tf.required_space_to_batch_paddings.yaml,name,0.9830508474576272,string.  Optional name prefix.,string. Optional name prefix.
tf.math.cumulative_logsumexp.yaml,x,0.993006993006993,"A `Tensor`. Must be one of the following types: `float16`, `float32`,`float64`.","A Tensor. Must be one of the following types: float16, float32, float64."
tf.random.learned_unigram_candidate_sampler.yaml,num_true,0.9914529914529915,An `int`.  The number of target classes per training example.,An int. The number of target classes per training example.
tf.random.learned_unigram_candidate_sampler.yaml,num_sampled,0.98989898989899,An `int`.  The number of classes to randomly sample.,An int. The number of classes to randomly sample.
tf.debugging.assert_rank_at_least.yaml,name,0.9931972789115646,"A name for this operation (optional).  Defaults to ""assert_rank_at_least"".","A name for this operation (optional). Defaults to ""assert_rank_at_least""."
tf.keras.backend.one_hot.yaml,indices,0.9922480620155039,"nD integer tensor of shape`(batch_size, dim1, dim2, ... dim(n-1))`","nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))"
tf.foldr.yaml,elems,0.9973474801061007,"A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension.  The nested sequence of the resulting slices will be the first argument to `fn`.","A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension. The nested sequence of the resulting slices will be the first argument to fn."
tf.feature_column.indicator_column.yaml,categorical_column,0.9946524064171123,A `CategoricalColumn` which is created by`categorical_column_with_*` or `crossed_column` functions.,A CategoricalColumn which is created by categorical_column_with_* or crossed_column functions.
tf.nn.depthwise_conv2d.yaml,filter,0.9935483870967742,"4-D with shape`[filter_height, filter_width, in_channels, channel_multiplier]`.","4-D with shape [filter_height, filter_width, in_channels, channel_multiplier]."
tf.nn.depthwise_conv2d.yaml,strides,0.9934640522875817,1-D of size 4.  The stride of the sliding window for each dimension of `input`.,1-D of size 4. The stride of the sliding window for each dimension of input.
tf.image.sobel_edges.yaml,image,0.995475113122172,"Image tensor with shape [batch_size, h, w, d] and type float32 or float64.  The image(s) must be 2x2 or larger.","Image tensor with shape [batch_size, h, w, d] and type float32 or float64. The image(s) must be 2x2 or larger."
tf.debugging.assert_shapes.yaml,data,0.9959839357429718,The tensors to print out if the condition is False.  Defaults to error message and first few entries of the violating tensor.,The tensors to print out if the condition is False. Defaults to error message and first few entries of the violating tensor.
tf.debugging.assert_shapes.yaml,name,0.9924812030075187,"A name for this operation (optional).  Defaults to ""assert_shapes"".","A name for this operation (optional). Defaults to ""assert_shapes""."
tf.split.yaml,num_or_size_splits,0.996551724137931,"Either an integer indicating the number of splits along`axis` or a 1-D integer `Tensor` or Python list containing the sizes of each output tensor along `axis`. If a scalar, then it must evenly divide`value.shape[axis]`; otherwise the sum of sizes along the split axis must match that of the `value`.","Either an integer indicating the number of splits along axis or a 1-D integer Tensor or Python list containing the sizes of each output tensor along axis. If a scalar, then it must evenly divide value.shape[axis]; otherwise the sum of sizes along the split axis must match that of the value."
tf.image.rgb_to_grayscale.yaml,images,0.978021978021978,The RGB tensor to convert. Last dimension must have size 3 and should contain RGB values.,The RGB tensor to convert. The last dimension must have size 3 and should contain RGB values.
tf.debugging.assert_near.yaml,rtol,0.989247311827957,"`Tensor`.  Same `dtype` as, and broadcastable to, `x`. The relative tolerance.  Default is `10 * eps`.","Tensor. Same dtype as, and broadcastable to, x. The relative tolerance. Default is 10 * eps."
tf.debugging.assert_near.yaml,atol,0.989247311827957,"`Tensor`.  Same `dtype` as, and broadcastable to, `x`. The absolute tolerance.  Default is `10 * eps`.","Tensor. Same dtype as, and broadcastable to, x. The absolute tolerance. Default is 10 * eps."
tf.debugging.assert_near.yaml,name,0.9922480620155039,"A name for this operation (optional).  Defaults to ""assert_near"".","A name for this operation (optional). Defaults to ""assert_near""."
tf.ones_like.yaml,dtype,0.9931506849315068,"A type for the returned `Tensor`. Must be `float16`, `float32`,`float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`,`complex64`, `complex128`, `bool` or `string`.","A type for the returned Tensor. Must be float16, float32, float64, int8, uint8, int16, uint16, int32, int64, complex64, complex128, bool or string."
tf.mlir.experimental.convert_graph_def.yaml,pass_pipeline,0.9961089494163424,"A textual description of an MLIR Pass Pipeline to run on the module, see MLIR documentation for thetextual pass pipeline syntax.","A textual description of an MLIR Pass Pipeline to run on the module, see MLIR documentation for the textual pass pipeline syntax."
tf.estimator.experimental.stop_if_no_increase_hook.yaml,run_every_secs,0.993006993006993,"If specified, calls `should_stop_fn` at an interval of`run_every_secs` seconds. Defaults to 60 seconds. Either this or`run_every_steps` must be set.","If specified, calls should_stop_fn at an interval of run_every_secs seconds. Defaults to 60 seconds. Either this or run_every_steps must be set."
tf.estimator.experimental.stop_if_no_increase_hook.yaml,run_every_steps,0.995260663507109,"If specified, calls `should_stop_fn` every`run_every_steps` steps. Either this or `run_every_secs` must be set.","If specified, calls should_stop_fn every run_every_steps steps. Either this or run_every_secs must be set."
tf.nn.depthwise_conv2d_backprop_input.yaml,data_format,0.9937888198757764,"An optional `string` from: `""NHWC"", ""NCHW""`. Defaults to `""NHWC""`. Specify the data format of the input and output data. With the default format ""NHWC"", the data is stored in the order of:   [batch, height, width, channels]. Alternatively, the format could be ""NCHW"", the data storage order of:   [batch, channels, height, width].","An optional string from: ""NHWC"", ""NCHW"". Defaults to ""NHWC"". Specify the data format of the input and output data. With the default format ""NHWC"", the data is stored in the order of: [batch, height, width, channels]. Alternatively, the format could be ""NCHW"", the data storage order of: [batch, channels, height, width]."
tf.nn.depthwise_conv2d_backprop_input.yaml,input_sizes,0.9948717948717949,"A `Tensor` of type `int32`. An integer vector representing the shape of `input`, based on `data_format`.  For example, if `data_format` is 'NHWC' then`input` is a 4-D `[batch, height, width, channels]` tensor.","A Tensor of type int32. An integer vector representing the shape of input, based on data_format. For example, if data_format is 'NHWC' then input is a 4-D [batch, height, width, channels] tensor."
tf.nn.depthwise_conv2d_backprop_input.yaml,filter,0.9968652037617555,"A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 4-D with shape`[filter_height, filter_width, in_channels, depthwise_multiplier]`.","A Tensor. Must be one of the following types: half, bfloat16, float32, float64. 4-D with shape [filter_height, filter_width, in_channels, depthwise_multiplier]."
tf.nn.depthwise_conv2d_backprop_input.yaml,out_backprop,0.997920997920998,"A `Tensor`. Must have the same type as `filter`. 4-D with shape  based on `data_format`. For example, if `data_format` is 'NHWC' then out_backprop shape is `[batch, out_height, out_width, out_channels]`. Gradients w.r.t. the output of the convolution.","A Tensor. Must have the same type as filter. 4-D with shape based on data_format. For example, if data_format is 'NHWC' then out_backprop shape is [batch, out_height, out_width, out_channels]. Gradients w.r.t. the output of the convolution."
tf.batch_to_space.yaml,input,0.9620253164556962,"A `Tensor`. N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`, where spatial_shape has M dimensions.","A N-D Tensor with shape input_shape = [batch] + spatial_shape + remaining_shape, where spatial_shape has M dimensions."
tf.batch_to_space.yaml,block_shape,0.9026217228464419,"A `Tensor`. Must be one of the following types: `int32`,`int64`. 1-D with shape `[M]`, all values must be >= 1. For backwards compatibility with TF 1.0, this parameter may be an int, in which case it is converted to `numpy.array([block_shape, block_shape], dtype=numpy.int64)`.","A 1-D Tensor with shape [M]. Must be one of the following types: int32, int64. All values must be >= 1. For backwards compatibility with TF 1.0, this parameter may be an int, in which case it is converted to numpy.array([block_shape, block_shape], dtype=numpy.int64)."
tf.sparse.segment_mean.yaml,num_segments,0.9923664122137404,An optional int32 scalar. Indicates the size of the output`Tensor`.,An optional int32 scalar. Indicates the size of the output Tensor.
tf.sparse.segment_mean.yaml,indices,0.9923664122137404,A 1-D `Tensor` with indices into `data`. Has same rank as`segment_ids`.,A 1-D Tensor with indices into data. Has same rank as segment_ids.
tf.nn.log_softmax.yaml,logits,0.9936305732484076,"A non-empty `Tensor`. Must be one of the following types: `half`,`float32`, `float64`.","A non-empty Tensor. Must be one of the following types: half, float32, float64."
tf.image.adjust_jpeg_quality.yaml,image,0.9666666666666667,"3D image. Size of the last dimension must be None, 1 or 3.","3D image. The size of the last dimension must be None, 1 or 3."
tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient.yaml,gradients,0.9963369963369964,"A `Tensor` of type `float32`. Backpropagated gradients above the FakeQuantWithMinMaxVars operation, shape one of: `[d]`, `[b, d]`,  `[b, h, w, d]`.","A Tensor of type float32. Backpropagated gradients above the FakeQuantWithMinMaxVars operation, shape one of: [d], [b, d], [b, h, w, d]."
tf.estimator.experimental.stop_if_higher_hook.yaml,run_every_secs,0.993006993006993,"If specified, calls `should_stop_fn` at an interval of`run_every_secs` seconds. Defaults to 60 seconds. Either this or`run_every_steps` must be set.","If specified, calls should_stop_fn at an interval of run_every_secs seconds. Defaults to 60 seconds. Either this or run_every_steps must be set."
tf.estimator.experimental.stop_if_higher_hook.yaml,run_every_steps,0.995260663507109,"If specified, calls `should_stop_fn` every`run_every_steps` steps. Either this or `run_every_secs` must be set.","If specified, calls should_stop_fn every run_every_steps steps. Either this or run_every_secs must be set."
tf.sparse.to_indicator.yaml,sp_input,0.9914529914529915,A `SparseTensor` with `values` property of type `int32` or`int64`.,A SparseTensor with values property of type int32 or int64.
tf.feature_column.sequence_categorical_column_with_identity.yaml,default_value,0.9971014492753624,"If `None`, this column's graph operations will fail for out-of-range inputs. Otherwise, this value must be in the range`[0, num_buckets)`, and will replace out-of-range inputs.","If None, this column's graph operations will fail for out-of-range inputs. Otherwise, this value must be in the range [0, num_buckets), and will replace out-of-range inputs."
tf.random.shuffle.yaml,seed,0.908256880733945,A Python integer. Used to create a random seed for the distribution. See`tf.compat.v1.set_random_seed`for behavior.,A Python integer. Used to create a random seed for the distribution. See tf.random.set_seed for behavior.
tf.strings.format.yaml,summarize,0.9974683544303797,"An optional `int`. Defaults to `3`. When formatting the tensors, show the first and last `summarize`entries of each tensor dimension (recursively). If set to -1, all elements of the tensor will be shown.","An optional int. Defaults to 3. When formatting the tensors, show the first and last summarize entries of each tensor dimension (recursively). If set to -1, all elements of the tensor will be shown."
tf.image.non_max_suppression_with_scores.yaml,soft_nms_sigma,0.9947368421052631,"A scalar float representing the Soft NMS sigma parameter; See Bodla et al, https://arxiv.org/abs/1704.04503).  When`soft_nms_sigma=0.0` (which is default), we fall back to standard (hard) NMS.","A scalar float representing the Soft NMS sigma parameter; See Bodla et al, https://arxiv.org/abs/1704.04503). When soft_nms_sigma=0.0 (which is default), we fall back to standard (hard) NMS."
tf.image.non_max_suppression_with_scores.yaml,max_output_size,0.9902912621359223,A scalar integer `Tensor` representing the maximum number of boxes to be selected by non max suppression.,A scalar integer Tensor representing the maximum number of boxes to be selected by non-max suppression.
tf.linalg.matmul.yaml,a,0.9942196531791907,"`tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,`complex64`, `complex128` and rank > 1.","tf.Tensor of type float16, float32, float64, int32, complex64, complex128 and rank > 1."
tf.math.segment_mean.yaml,segment_ids,0.9971671388101983,"A `Tensor`. Must be one of the following types: `int32`, `int64`. A 1-D tensor whose size is equal to the size of `data`'s first dimension.  Values should be sorted and can be repeated.","A Tensor. Must be one of the following types: int32, int64. A 1-D tensor whose size is equal to the size of data's first dimension. Values should be sorted and can be repeated."
tf.math.l2_normalize.yaml,axis,0.9928057553956835,Dimension along which to normalize.  A scalar or a vector of integers.,Dimension along which to normalize. A scalar or a vector of integers.
tf.linalg.tridiagonal_solve.yaml,diagonals_format,0.990990990990991,"one of `matrix`, `sequence`, or `compact`. Default is`compact`.","one of matrix, sequence, or compact. Default is compact."
tf.linalg.tridiagonal_solve.yaml,diagonals,0.9970501474926253,"A `Tensor` or tuple of `Tensor`s describing left-hand sides. The shape depends of `diagonals_format`, see description above. Must be`float32`, `float64`, `complex64`, or `complex128`.","A Tensor or tuple of Tensors describing left-hand sides. The shape depends of diagonals_format, see description above. Must be float32, float64, complex64, or complex128."
tf.linalg.tridiagonal_solve.yaml,rhs,0.9974937343358395,"A `Tensor` of shape [..., M] or [..., M, K] and with the same dtype as`diagonals`. Note that if the shape of `rhs` and/or `diags` isn't known statically, `rhs` will be treated as a matrix rather than a vector.","A Tensor of shape [..., M] or [..., M, K] and with the same dtype as diagonals. Note that if the shape of rhs and/or diags isn't known statically, rhs will be treated as a matrix rather than a vector."
tf.autograph.to_graph.yaml,experimental_optional_features,0.9928057553956835,"`None`, a tuple of, or a single`tf.autograph.experimental.Feature` value.","None, a tuple of, or a single tf.autograph.experimental.Feature value."
tf.debugging.assert_none_equal.yaml,name,0.9929078014184397,"A name for this operation (optional).  Defaults to ""assert_none_equal"".","A name for this operation (optional). Defaults to ""assert_none_equal""."
tf.unstack.yaml,num,0.9942196531791907,An `int`. The length of the dimension `axis`. Automatically inferred if`None` (the default).,An int. The length of the dimension axis. Automatically inferred if None (the default).
tf.data.experimental.sample_from_datasets.yaml,weights,0.9633699633699634,"(Optional.) A list of `len(datasets)` floating-point values where`weights[i]` represents the probability with which an element should be sampled from `datasets[i]`, or a `tf.data.Dataset` object where each element is such a list. Defaults to a uniform distribution across`datasets`.","(Optional.) A list of len(datasets) floating-point values where weights[i] represents the probability with which an element should be sampled from datasets[i], or a tf.data.Dataset object where each element is such a list. Defaults to a uniform distribution across datasets."
tf.data.experimental.sample_from_datasets.yaml,seed,0.939297124600639,"(Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random seed that will be used to create the distribution. See`tf.compat.v1.set_random_seed` for behavior.","(Optional.) A tf.int64 scalar tf.Tensor, representing the random seed that will be used to create the distribution. See tf.random.set_seed for behavior."
tf.nn.depthwise_conv2d_backprop_filter.yaml,data_format,0.9937888198757764,"An optional `string` from: `""NHWC"", ""NCHW""`. Defaults to `""NHWC""`. Specify the data format of the input and output data. With the default format ""NHWC"", the data is stored in the order of:   [batch, height, width, channels]. Alternatively, the format could be ""NCHW"", the data storage order of:   [batch, channels, height, width].","An optional string from: ""NHWC"", ""NCHW"". Defaults to ""NHWC"". Specify the data format of the input and output data. With the default format ""NHWC"", the data is stored in the order of: [batch, height, width, channels]. Alternatively, the format could be ""NCHW"", the data storage order of: [batch, channels, height, width]."
tf.nn.depthwise_conv2d_backprop_filter.yaml,input,0.9955357142857143,"A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 4-D with shape based on `data_format`.  For example, if`data_format` is 'NHWC' then `input` is a 4-D `[batch, in_height, in_width, in_channels]` tensor.","A Tensor. Must be one of the following types: half, bfloat16, float32, float64. 4-D with shape based on data_format. For example, if data_format is 'NHWC' then input is a 4-D [batch, in_height, in_width, in_channels] tensor."
tf.nn.depthwise_conv2d_backprop_filter.yaml,filter_sizes,0.9971671388101983,"A `Tensor` of type `int32`. An integer vector representing the tensor shape of `filter`, where `filter` is a 4-D`[filter_height, filter_width, in_channels, depthwise_multiplier]` tensor.","A Tensor of type int32. An integer vector representing the tensor shape of filter, where filter is a 4-D [filter_height, filter_width, in_channels, depthwise_multiplier] tensor."
tf.nn.depthwise_conv2d_backprop_filter.yaml,out_backprop,0.9979123173277662,"A `Tensor`. Must have the same type as `input`. 4-D with shape  based on `data_format`. For example, if `data_format` is 'NHWC' then out_backprop shape is `[batch, out_height, out_width, out_channels]`. Gradients w.r.t. the output of the convolution.","A Tensor. Must have the same type as input. 4-D with shape based on data_format. For example, if data_format is 'NHWC' then out_backprop shape is [batch, out_height, out_width, out_channels]. Gradients w.r.t. the output of the convolution."
tf.nn.ctc_beam_search_decoder.yaml,sequence_length,0.9929078014184397,"1-D `int32` vector containing sequence lengths, having size`[batch_size]`.","1-D int32 vector containing sequence lengths, having size [batch_size]."
tf.sparse.reduce_sum.yaml,output_is_sparse,0.993006993006993,"If true, returns a `SparseTensor` instead of a dense`Tensor` (the default).","If true, returns a SparseTensor instead of a dense Tensor (the default)."
tf.nn.conv_transpose.yaml,data_format,0.9480354879594424,"A string or None.  Specifies whether the channel dimension of the `input` and output is the last dimension (default, or if `data_format`does not start with ""NC""), or the second dimension (if `data_format`starts with ""NC"").  For N=1, the valid values are ""NWC"" (default) and ""NCW"".  For N=2, the valid values are ""NHWC"" (default) and ""NCHW"". For N=3, the valid values are ""NDHWC"" (default) and ""NCDHW"".","A string or None. Specifies whether the channel dimension of the input and output is the last dimension (default, or if data_format does not start with ""NC""), or the second dimension (if data_format starts with ""NC""). For N=1, the valid values are ""NWC"" (default) and ""NCW"". For N=2, the valid values are ""NHWC"" (default) and ""NCHW"". For N=3, the valid values are ""NDHWC"" (default) and ""NCDHW""."
tf.nn.conv_transpose.yaml,input,0.9948542024013722,"An N+2 dimensional `Tensor` of shape`[batch_size] + input_spatial_shape + [in_channels]` if data_format does not start with ""NC"" (default), or`[batch_size, in_channels] + input_spatial_shape` if data_format starts with ""NC"". It must be one of the following types:`half`, `bfloat16`, `float32`, `float64`.","An N+2 dimensional Tensor of shape [batch_size] + input_spatial_shape + [in_channels] if data_format does not start with ""NC"" (default), or [batch_size, in_channels] + input_spatial_shape if data_format starts with ""NC"". It must be one of the following types: half, bfloat16, float32, float64."
tf.nn.conv_transpose.yaml,strides,0.9984301412872841,"An int or list of `ints` that has length `1`, `N` or `N+2`.  The stride of the sliding window for each dimension of `input`. If a single value is given it is replicated in the spatial dimensions. By default the `N` and `C` dimensions are set to 0. The dimension order is determined by the value of `data_format`, see below for details.","An int or list of ints that has length 1, N or N+2. The stride of the sliding window for each dimension of input. If a single value is given it is replicated in the spatial dimensions. By default the N and C dimensions are set to 0. The dimension order is determined by the value of data_format, see below for details."
tf.io.decode_image.yaml,expand_animations,0.996742671009772,"Controls the shape of the returned op's output. If`True`, the returned op will produce a 3-D tensor for PNG, JPEG, and BMP files; and a 4-D tensor for all GIFs, whether animated or not. If,`False`, the returned op will produce a 3-D tensor for all file types and will truncate animated GIFs to the first frame.","Controls the shape of the returned op's output. If True, the returned op will produce a 3-D tensor for PNG, JPEG, and BMP files; and a 4-D tensor for all GIFs, whether animated or not. If, False, the returned op will produce a 3-D tensor for all file types and will truncate animated GIFs to the first frame."
tf.random.truncated_normal.yaml,seed,0.908256880733945,A Python integer. Used to create a random seed for the distribution. See`tf.compat.v1.set_random_seed`for behavior.,A Python integer. Used to create a random seed for the distribution. See tf.random.set_seed for behavior.
tf.ensure_shape.yaml,shape,0.9948717948717949,"A `TensorShape` representing the shape of this tensor, a`TensorShapeProto`, a list, a tuple, or None.","A TensorShape representing the shape of this tensor, a TensorShapeProto, a list, a tuple, or None."
tf.image.adjust_hue.yaml,image,0.9666666666666667,RGB image or images. Size of the last dimension must be 3.,RGB image or images. The size of the last dimension must be 3.
tf.image.adjust_hue.yaml,delta,0.9882352941176471,float.  How much to add to the hue channel.,float. How much to add to the hue channel.
tf.math.segment_prod.yaml,segment_ids,0.9971671388101983,"A `Tensor`. Must be one of the following types: `int32`, `int64`. A 1-D tensor whose size is equal to the size of `data`'s first dimension.  Values should be sorted and can be repeated.","A Tensor. Must be one of the following types: int32, int64. A 1-D tensor whose size is equal to the size of data's first dimension. Values should be sorted and can be repeated."
tf.debugging.assert_non_positive.yaml,name,0.993103448275862,"A name for this operation (optional).  Defaults to ""assert_non_positive"".","A name for this operation (optional). Defaults to ""assert_non_positive""."
tf.nn.softmax_cross_entropy_with_logits.yaml,labels,0.9977220956719818,"Each vector along the class dimension should hold a valid probability distribution e.g. for the case in which labels are of shape`[batch_size, num_classes]`, each row of `labels[i]` must be a valid probability distribution.","Each vector along the class dimension should hold a valid probability distribution e.g. for the case in which labels are of shape [batch_size, num_classes], each row of labels[i] must be a valid probability distribution."
tf.feature_column.sequence_categorical_column_with_vocabulary_file.yaml,num_oov_buckets,0.996415770609319,"Non-negative integer, the number of out-of-vocabulary buckets. All out-of-vocabulary inputs will be assigned IDs in the range`[vocabulary_size, vocabulary_size+num_oov_buckets)` based on a hash of the input value. A positive `num_oov_buckets` can not be specified with`default_value`.","Non-negative integer, the number of out-of-vocabulary buckets. All out-of-vocabulary inputs will be assigned IDs in the range [vocabulary_size, vocabulary_size+num_oov_buckets) based on a hash of the input value. A positive num_oov_buckets can not be specified with default_value."
tf.feature_column.sequence_categorical_column_with_vocabulary_file.yaml,default_value,0.9964912280701754,"The integer ID value to return for out-of-vocabulary feature values, defaults to `-1`. This can not be specified with a positive`num_oov_buckets`.","The integer ID value to return for out-of-vocabulary feature values, defaults to -1. This can not be specified with a positive num_oov_buckets."
tf.math.reciprocal_no_nan.yaml,x,0.9924812030075187,"A `Tensor` of type `float16`, `float32`, `float64` `complex64` or`complex128`.","A Tensor of type float16, float32, float64 complex64 or complex128."
tf.numpy_function.yaml,func,0.9985795454545454,"A Python function, which accepts `numpy.ndarray` objects as arguments and returns a list of `numpy.ndarray` objects (or a single`numpy.ndarray`). This function must accept as many arguments as there are tensors in `inp`, and these argument types will match the corresponding`tf.Tensor` objects in `inp`. The returns `numpy.ndarray`s must match the number and types defined `Tout`. Important Note: Input and output `numpy.ndarray`s of `func` are not guaranteed to be copies. In some cases their underlying memory will be shared with the corresponding TensorFlow tensors. In-place modification or storing `func` input or return values in python datastructures without explicit (np.)copy can have non-deterministic consequences.","A Python function, which accepts numpy.ndarray objects as arguments and returns a list of numpy.ndarray objects (or a single numpy.ndarray). This function must accept as many arguments as there are tensors in inp, and these argument types will match the corresponding tf.Tensor objects in inp. The returns numpy.ndarrays must match the number and types defined Tout. Important Note: Input and output numpy.ndarrays of func are not guaranteed to be copies. In some cases their underlying memory will be shared with the corresponding TensorFlow tensors. In-place modification or storing func input or return values in python datastructures without explicit (np.)copy can have non-deterministic consequences."
tf.nn.with_space_to_batch.yaml,spatial_dims,0.9915014164305949,"Monotonically increasing sequence of `num_spatial_dims`integers (which are >= 1) specifying the spatial dimensions of `input`and output.  Defaults to: `range(1, num_spatial_dims+1)`.","Monotonically increasing sequence of num_spatial_dims integers (which are >= 1) specifying the spatial dimensions of input and output. Defaults to: range(1, num_spatial_dims+1)."
tf.nn.with_space_to_batch.yaml,data_format,0.9480354879594424,"A string or None.  Specifies whether the channel dimension of the `input` and output is the last dimension (default, or if `data_format`does not start with ""NC""), or the second dimension (if `data_format`starts with ""NC"").  For N=1, the valid values are ""NWC"" (default) and ""NCW"".  For N=2, the valid values are ""NHWC"" (default) and ""NCHW"". For N=3, the valid values are ""NDHWC"" (default) and ""NCDHW"".","A string or None. Specifies whether the channel dimension of the input and output is the last dimension (default, or if data_format does not start with ""NC""), or the second dimension (if data_format starts with ""NC""). For N=1, the valid values are ""NWC"" (default) and ""NCW"". For N=2, the valid values are ""NHWC"" (default) and ""NCHW"". For N=3, the valid values are ""NDHWC"" (default) and ""NCDHW""."
tf.keras.models.save_model.yaml,signatures,0.9965635738831615,Signatures to save with the SavedModel. Applicable to the 'tf' format only. Please see the `signatures` argument in`tf.saved_model.save` for details.,Signatures to save with the SavedModel. Applicable to the 'tf' format only. Please see the signatures argument in tf.saved_model.save for details.
tf.linalg.cholesky_solve.yaml,name,0.9902912621359223,A name to give this `Op`.  Defaults to `cholesky_solve`.,A name to give this Op. Defaults to cholesky_solve.
tf.linalg.cholesky_solve.yaml,chol,0.996742671009772,"A `Tensor`.  Must be `float32` or `float64`, shape is `[..., M, M]`. Cholesky factorization of `A`, e.g. `chol = tf.linalg.cholesky(A)`. For that reason, only the lower triangular parts (including the diagonal) of the last two dimensions of `chol` are used.  The strictly upper part is assumed to be zero and not accessed.","A Tensor. Must be float32 or float64, shape is [..., M, M]. Cholesky factorization of A, e.g. chol = tf.linalg.cholesky(A). For that reason, only the lower triangular parts (including the diagonal) of the last two dimensions of chol are used. The strictly upper part is assumed to be zero and not accessed."
tf.estimator.experimental.stop_if_lower_hook.yaml,run_every_secs,0.993006993006993,"If specified, calls `should_stop_fn` at an interval of`run_every_secs` seconds. Defaults to 60 seconds. Either this or`run_every_steps` must be set.","If specified, calls should_stop_fn at an interval of run_every_secs seconds. Defaults to 60 seconds. Either this or run_every_steps must be set."
tf.estimator.experimental.stop_if_lower_hook.yaml,run_every_steps,0.995260663507109,"If specified, calls `should_stop_fn` every`run_every_steps` steps. Either this or `run_every_secs` must be set.","If specified, calls should_stop_fn every run_every_steps steps. Either this or run_every_secs must be set."
tf.ragged.map_flat_values.yaml,op,0.9953488372093023,"The operation that should be applied to the RaggedTensor `flat_values`.`op` is typically an element-wise operation (such as math_ops.add), but any operation that preserves the size of the outermost dimension can be used.  I.e., `shape[0]` of the value returned by `op` must match`shape[0]` of the `RaggedTensor`s' `flat_values` tensors.","The operation that should be applied to the RaggedTensor flat_values. op is typically an element-wise operation (such as math_ops.add), but any operation that preserves the size of the outermost dimension can be used. I.e., shape[0] of the value returned by op must match shape[0] of the RaggedTensors' flat_values tensors."
tf.math.argmin.yaml,output_type,0.9925925925925926,"An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to`tf.int64`.","An optional tf.DType from: tf.int32, tf.int64. Defaults to tf.int64."
tf.math.argmin.yaml,input,0.9917355371900827,"A `Tensor`. Must be one of the following types: `float32`, `float64`,`int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`,`quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`,`uint64`.","A Tensor. Must be one of the following types: float32, float64, int32, uint8, int16, int8, complex64, int64, qint8, quint8, qint32, bfloat16, uint16, complex128, half, uint32, uint64."
tf.data.experimental.dense_to_ragged_batch.yaml,drop_remainder,0.9974811083123426,"(Optional.) A `tf.bool` scalar `tf.Tensor`, representing whether the last batch should be dropped in the case it has fewer than`batch_size` elements; the default behavior is not to drop the smaller batch.","(Optional.) A tf.bool scalar tf.Tensor, representing whether the last batch should be dropped in the case it has fewer than batch_size elements; the default behavior is not to drop the smaller batch."
tf.data.experimental.dense_to_ragged_batch.yaml,row_splits_dtype,0.996742671009772,The dtype that should be used for the `row_splits` of any new ragged tensors.  Existing `tf.RaggedTensor` elements do not have their row_splits dtype changed.,The dtype that should be used for the row_splits of any new ragged tensors. Existing tf.RaggedTensor elements do not have their row_splits dtype changed.
tf.signal.inverse_stft.yaml,fft_length,0.9925925925925926,"An integer scalar `Tensor`. The size of the FFT that produced`stfts`. If not provided, uses the smallest power of 2 enclosing`frame_length`.","An integer scalar Tensor. The size of the FFT that produced stfts. If not provided, uses the smallest power of 2 enclosing frame_length."
tf.signal.inverse_stft.yaml,stfts,0.9969604863221885,"A `complex64`/`complex128` `[..., frames, fft_unique_bins]``Tensor` of STFT bins representing a batch of `fft_length`-point STFTs where `fft_unique_bins` is `fft_length // 2 + 1`","A complex64/complex128 [..., frames, fft_unique_bins] Tensor of STFT bins representing a batch of fft_length-point STFTs where fft_unique_bins is fft_length // 2 + 1"
tf.keras.utils.get_file.yaml,cache_dir,0.9871794871794872,"Location to store cached files, when None it defaults to the Keras   Directory.","Location to store cached files, when None it defaults to the Keras Directory."
tf.einsum.yaml,equation,0.9927007299270073,"a `str` describing the contraction, in the same format as`numpy.einsum`.","a str describing the contraction, in the same format as numpy.einsum."
tf.einsum.yaml,**kwargs,0.9887640449438202,"- optimize: Optimization strategy to use to find contraction path using opt_einsum. Must be 'greedy', 'optimal', 'branch-2', 'branch-all' or   'auto'. (optional, default: 'greedy'). name: A name for the operation (optional). ","optimize: Optimization strategy to use to find contraction path using opt_einsum. Must be 'greedy', 'optimal', 'branch-2', 'branch-all' or 'auto'. (optional, default: 'greedy'). name: A name for the operation (optional)."
tf.keras.backend.learning_phase_scope.yaml,value,0.9781021897810219,"Learning phase value, either 0 or 1 (integers).    0 = test, 1 = train","Learning phase value, either 0 or 1 (integers). 0 = test, 1 = train"
tf.nest.pack_sequence_as.yaml,expand_composites,0.9957446808510638,"If true, then composite tensors such as `tf.SparseTensor`and `tf.RaggedTensor` are expanded into their component tensors.","If true, then composite tensors such as tf.SparseTensor and tf.RaggedTensor are expanded into their component tensors."
tf.image.random_saturation.yaml,image,0.9666666666666667,RGB image or images. Size of the last dimension must be 3.,RGB image or images. The size of the last dimension must be 3.
tf.image.random_saturation.yaml,lower,0.9904761904761905,float.  Lower bound for the random saturation factor.,float. Lower bound for the random saturation factor.
tf.image.random_saturation.yaml,upper,0.9904761904761905,float.  Upper bound for the random saturation factor.,float. Upper bound for the random saturation factor.
tf.io.decode_raw.yaml,fixed_length,0.9963768115942029,"If set, the first `fixed_length` bytes of each element will be converted. Data will be zero-padded or truncated to the specified length.`fixed_length` must be a multiple of the size of `out_type`.`fixed_length` must be specified if the elements of `input_bytes` are of variable length.","If set, the first fixed_length bytes of each element will be converted. Data will be zero-padded or truncated to the specified length. fixed_length must be a multiple of the size of out_type. fixed_length must be specified if the elements of input_bytes are of variable length."
tf.io.decode_raw.yaml,out_type,0.9951690821256038,"`DType` of the output. Acceptable types are `half`, `float`, `double`,`int32`, `uint16`, `uint8`, `int16`, `int8`, `int64`.","DType of the output. Acceptable types are half, float, double, int32, uint16, uint8, int16, int8, int64."
tf.signal.mfccs_from_log_mel_spectrograms.yaml,log_mel_spectrograms,0.9940828402366864,"A `[..., num_mel_bins]` `float32`/`float64` `Tensor`of log-magnitude mel-scale spectrograms.","A [..., num_mel_bins] float32/float64 Tensor of log-magnitude mel-scale spectrograms."
tf.nn.fractional_avg_pool.yaml,overlapping,0.9235294117647059,"An optional `bool`.  Defaults to `False`.  When set to `True`, it means when pooling, the values at the boundary of adjacent pooling cells are used by both cells. For example:`index  0  1  2  3  4``value  20 5  16 3  7`If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.  The result would be [20, 16] for fractional avg pooling.","An optional bool. Defaults to False. When set to True, it means when pooling, the values at the boundary of adjacent pooling cells are used by both cells. For example: index 0 1 2 3 4 value 20 5 16 3 7 If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice. The result would be [20, 16] for fractional avg pooling."
tf.nn.fractional_avg_pool.yaml,seed,0.990228013029316,"An optional `int`.  Defaults to `0`.  If set to be non-zero, the random number generator is seeded by the given seed.  Otherwise it is seeded by a random seed.","An optional int. Defaults to 0. If set to be non-zero, the random number generator is seeded by the given seed. Otherwise it is seeded by a random seed."
tf.nn.fractional_avg_pool.yaml,pooling_ratio,0.9975124378109452,"A list of `floats` that has length >= 4.  Pooling ratio for each dimension of `value`, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling ratio on height and width dimensions respectively.","A list of floats that has length >= 4. Pooling ratio for each dimension of value, currently only supports row and col dimension and should be >= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't allow pooling on batch and channels dimensions. 1.44 and 1.73 are pooling ratio on height and width dimensions respectively."
tf.io.decode_jpeg.yaml,dct_method,0.9956709956709957,"An optional `string`. Defaults to `""""`. string specifying a hint about the algorithm used for decompression.  Defaults to """" which maps to a system-specific default.  Currently valid values are [""INTEGER_FAST"", ""INTEGER_ACCURATE""].  The hint may be ignored (e.g., the internal jpeg library changes to a version that does not have that specific option.)","An optional string. Defaults to """". string specifying a hint about the algorithm used for decompression. Defaults to """" which maps to a system-specific default. Currently valid values are [""INTEGER_FAST"", ""INTEGER_ACCURATE""]. The hint may be ignored (e.g., the internal jpeg library changes to a version that does not have that specific option.)"
tf.io.decode_jpeg.yaml,contents,0.9906542056074766,A `Tensor` of type `string`. 0-D.  The JPEG-encoded image.,A Tensor of type string. 0-D. The JPEG-encoded image.
tf.image.adjust_gamma.yaml,gamma,0.9777777777777777,A scalar or tensor. Non negative real number.,A scalar or tensor. Non-negative real number.
tf.math.unsorted_segment_mean.yaml,num_segments,0.991869918699187,An integer scalar `Tensor`.  The number of distinct segment IDs.,An integer scalar Tensor. The number of distinct segment IDs.
tf.random.poisson.yaml,dtype,0.9923664122137404,"The type of the output: `float16`, `float32`, `float64`, `int32` or`int64`.","The type of the output: float16, float32, float64, int32 or int64."
tf.random.poisson.yaml,seed,0.9090909090909091,A Python integer. Used to create a random seed for the distributions. See`tf.compat.v1.set_random_seed`for behavior.,A Python integer. Used to create a random seed for the distributions. See tf.random.set_seed for behavior.
tf.random.poisson.yaml,lam,0.9963369963369964,A Tensor or Python value or N-D array of type `dtype`.`lam` provides the rate parameter(s) describing the poisson distribution(s) to sample.,A Tensor or Python value or N-D array of type dtype. lam provides the rate parameter(s) describing the poisson distribution(s) to sample.
tf.image.random_brightness.yaml,seed,0.9946524064171123,A Python integer. Used to create a random seed. See`tf.compat.v1.set_random_seed` for behavior.,A Python integer. Used to create a random seed. See tf.compat.v1.set_random_seed for behavior.
tf.feature_column.sequence_categorical_column_with_vocabulary_list.yaml,default_value,0.9964912280701754,"The integer ID value to return for out-of-vocabulary feature values, defaults to `-1`. This can not be specified with a positive`num_oov_buckets`.","The integer ID value to return for out-of-vocabulary feature values, defaults to -1. This can not be specified with a positive num_oov_buckets."
tf.feature_column.sequence_categorical_column_with_vocabulary_list.yaml,num_oov_buckets,0.998272884283247,"Non-negative integer, the number of out-of-vocabulary buckets. All out-of-vocabulary inputs will be assigned IDs in the range`[len(vocabulary_list), len(vocabulary_list)+num_oov_buckets)` based on a hash of the input value. A positive `num_oov_buckets` can not be specified with `default_value`.","Non-negative integer, the number of out-of-vocabulary buckets. All out-of-vocabulary inputs will be assigned IDs in the range [len(vocabulary_list), len(vocabulary_list)+num_oov_buckets) based on a hash of the input value. A positive num_oov_buckets can not be specified with default_value."
tf.math.exp.yaml,x,0.9855072463768116,"A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.","A tf.Tensor. Must be one of the following types: bfloat16, half, float32, float64, complex64, complex128."
tf.signal.fftshift.yaml,axes,0.9947089947089947,"`int` or shape `tuple`, optional Axes over which to shift.  Default is None, which shifts all axes.","int or shape tuple, optional Axes over which to shift. Default is None, which shifts all axes."
tf.math.bessel_i0.yaml,x,0.9940828402366864,"A `Tensor` or `SparseTensor`. Must be one of the following types: `half`,`float32`, `float64`.","A Tensor or SparseTensor. Must be one of the following types: half, float32, float64."
tf.data.experimental.group_by_reducer.yaml,key_func,0.9967637540453075,A function mapping a nested structure of tensors (having shapes and types defined by `self.output_shapes` and`self.output_types`) to a scalar `tf.int64` tensor.,A function mapping a nested structure of tensors (having shapes and types defined by self.output_shapes and self.output_types) to a scalar tf.int64 tensor.
tf.nn.conv3d_transpose.yaml,filters,0.9967637540453075,"A 5-D `Tensor` with the same type as `value` and shape `[height, width, output_channels, in_channels]`.  `filter`'s `in_channels` dimension must match that of `value`.","A 5-D Tensor with the same type as value and shape [height, width, output_channels, in_channels]. filter's in_channels dimension must match that of value."
tf.nn.conv3d_transpose.yaml,strides,0.9984301412872841,"An int or list of `ints` that has length `1`, `3` or `5`.  The stride of the sliding window for each dimension of `input`. If a single value is given it is replicated in the `D`, `H` and `W` dimension. By default the `N` and `C` dimensions are set to 0. The dimension order is determined by the value of `data_format`, see below for details.","An int or list of ints that has length 1, 3 or 5. The stride of the sliding window for each dimension of input. If a single value is given it is replicated in the D, H and W dimension. By default the N and C dimensions are set to 0. The dimension order is determined by the value of data_format, see below for details."
tf.quantization.quantized_concat.yaml,concat_dim,0.990990990990991,"A `Tensor` of type `int32`. 0-D.  The dimension along which to concatenate.  Must be in the range [0, rank(values)).","A Tensor of type int32. 0-D. The dimension along which to concatenate. Must be in the range [0, rank(values))."
tf.estimator.classifier_parse_example_spec.yaml,label_dtype,0.995,"A `tf.dtype` identifies the type of labels. By default it is`tf.int64`. If user defines a `label_vocabulary`, this should be set as`tf.string`. `tf.float32` labels are only supported for binary classification.","A tf.dtype identifies the type of labels. By default it is tf.int64. If user defines a label_vocabulary, this should be set as tf.string. tf.float32 labels are only supported for binary classification."
tf.estimator.classifier_parse_example_spec.yaml,label_default,0.9974747474747475,"used as label if label_key does not exist in given tf.Example. An example usage: let's say `label_key` is 'clicked' and tf.Example contains clicked data only for positive examples in following format `key:clicked, value:1`. This means that if there is no data with key 'clicked' it should count as negative example by setting`label_deafault=0`. Type of this value should be compatible with`label_dtype`.","used as label if label_key does not exist in given tf.Example. An example usage: let's say label_key is 'clicked' and tf.Example contains clicked data only for positive examples in following format key:clicked, value:1. This means that if there is no data with key 'clicked' it should count as negative example by setting label_deafault=0. Type of this value should be compatible with label_dtype."
tf.estimator.classifier_parse_example_spec.yaml,weight_column,0.9977973568281938,"A string or a `NumericColumn` created by`tf.feature_column.numeric_column` defining feature column representing weights. It is used to down weight or boost examples during training. It will be multiplied by the loss of the example. If it is a string, it is used as a key to fetch weight tensor from the `features`. If it is a`NumericColumn`, raw tensor is fetched by key `weight_column.key`, then weight_column.normalizer_fn is applied on it to get weight tensor.","A string or a NumericColumn created by tf.feature_column.numeric_column defining feature column representing weights. It is used to down weight or boost examples during training. It will be multiplied by the loss of the example. If it is a string, it is used as a key to fetch weight tensor from the features. If it is a NumericColumn, raw tensor is fetched by key weight_column.key, then weight_column.normalizer_fn is applied on it to get weight tensor."
tf.keras.backend.binary_crossentropy.yaml,from_logits,0.995850622406639,"Whether `output` is expected to be a logits tensor. By default, we consider that `output`encodes a probability distribution.","Whether output is expected to be a logits tensor. By default, we consider that output encodes a probability distribution."
tf.nn.ctc_greedy_decoder.yaml,merge_repeated,0.9787234042553191,Boolean.  Default: True.,Boolean. Default: True.
tf.nn.ctc_greedy_decoder.yaml,sequence_length,0.9929078014184397,"1-D `int32` vector containing sequence lengths, having size`[batch_size]`.","1-D int32 vector containing sequence lengths, having size [batch_size]."
tf.estimator.experimental.stop_if_no_decrease_hook.yaml,run_every_secs,0.993006993006993,"If specified, calls `should_stop_fn` at an interval of`run_every_secs` seconds. Defaults to 60 seconds. Either this or`run_every_steps` must be set.","If specified, calls should_stop_fn at an interval of run_every_secs seconds. Defaults to 60 seconds. Either this or run_every_steps must be set."
tf.estimator.experimental.stop_if_no_decrease_hook.yaml,run_every_steps,0.995260663507109,"If specified, calls `should_stop_fn` every`run_every_steps` steps. Either this or `run_every_secs` must be set.","If specified, calls should_stop_fn every run_every_steps steps. Either this or run_every_secs must be set."
tf.register_tensor_conversion_function.yaml,base_type,0.9938650306748467,The base type or tuple of base types for all objects that`conversion_func` accepts.,The base type or tuple of base types for all objects that conversion_func accepts.
tf.register_tensor_conversion_function.yaml,conversion_func,0.991304347826087,A function that converts instances of `base_type` to`Tensor`.,A function that converts instances of base_type to Tensor.
tf.image.extract_glimpse.yaml,input,0.994535519125683,"A `Tensor` of type `float32`. A 4-D float tensor of shape`[batch_size, height, width, channels]`.","A Tensor of type float32. A 4-D float tensor of shape [batch_size, height, width, channels]."
tf.image.extract_glimpse.yaml,size,0.997134670487106,"A `Tensor` of type `int32`. A 1-D tensor of 2 elements containing the size of the glimpses to extract.  The glimpse height must be specified first, following by the glimpse width.","A Tensor of type int32. A 1-D tensor of 2 elements containing the size of the glimpses to extract. The glimpse height must be specified first, following by the glimpse width."
tf.image.extract_glimpse.yaml,offsets,0.9961685823754789,"A `Tensor` of type `float32`. A 2-D integer tensor of shape`[batch_size, 2]` containing the y, x locations of the center of each window.","A Tensor of type float32. A 2-D integer tensor of shape [batch_size, 2] containing the y, x locations of the center of each window."
tf.keras.backend.zeros_like.yaml,dtype,0.9752066115702479,dtype of returned Keras variable.    `None` uses the dtype of `x`.,dtype of returned Keras variable. None uses the dtype of x.
