constraints:
  '**kwargs':
    default: null
    descp: ''
    normalized_descp: []
  activation:
    default: tanh
    descp: 'Activation function to use. Default: hyperbolic tangent (`tanh`). If you
      pass `None`, no activation is applied (ie. "linear" activation: `a(x) = x`).'
    normalized_default: DEFAULT DF_STR
    normalized_descp:
    - Activation function to use
    - Default hyperbolic tangent QSTR
    - If you pass QSTR , no activation is applied ie
    - QSTR activation a BSTR x
  activity_regularizer:
    default: None
    descp: 'Regularizer function applied to the output of the layer (its "activation").
      Default: `None`.'
    normalized_default: DEFAULT None
    normalized_descp:
    - Regularizer function applied to the output of the layer BSTR
    - Default QSTR
  bias_constraint:
    default: None
    descp: Constraint function applied to the bias vector. Default:`None`.
    normalized_default: DEFAULT None
    normalized_descp:
    - Constraint function applied to the bias D_STRUCTURE
    - Default QSTR
  bias_initializer:
    default: zeros
    descp: 'Initializer for the bias vector. Default: `zeros`.'
    normalized_default: DEFAULT DF_STR
    normalized_descp:
    - Initializer for the bias D_STRUCTURE
    - Default QSTR
  bias_regularizer:
    default: None
    descp: Regularizer function applied to the bias vector. Default:`None`.
    normalized_default: DEFAULT None
    normalized_descp:
    - Regularizer function applied to the bias D_STRUCTURE
    - Default QSTR
  dropout:
    default: '0.0'
    descp: 'Float between 0 and 1. Fraction of the units to drop for the linear transformation
      of the inputs. Default: 0.'
    normalized_default: DEFAULT CONSTANT_FLOAT
    normalized_descp:
    - D_TYPE between CONSTANT_NUM
    - Fraction of the PARAM to drop for the linear transformation of the inputs
    - Default CONSTANT_NUM
  go_backwards:
    default: 'False'
    descp: Boolean (default `False`). If True, process the input sequence backwards
      and return the reversed sequence.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - D_TYPE default CONSTANT_BOOL
    - If CONSTANT_BOOL, process the input D_STRUCTURE backwards and return the reversed
      D_STRUCTURE
  implementation:
    default: '2'
    descp: 'Implementation mode, either 1 or 2. Mode 1 will structure its operations
      as a larger number of smaller dot products and additions, whereas mode 2 will
      batch them into fewer, larger operations. These modes will have different performance
      profiles on different hardware and for different applications. Default: 2.'
    normalized_default: DEFAULT CONSTANT_NUM
    normalized_descp:
    - Implementation mode, either CONSTANT_NUM
    - Mode CONSTANT_NUM will structure its operations as a larger number of smaller
      dot products and additions, whereas mode CONSTANT_NUM will batch them into fewer,
      larger operations
    - These modes will have different performance profiles on different hardware and
      for different applications
    - Default CONSTANT_NUM
  kernel_constraint:
    default: None
    descp: 'Constraint function applied to the `kernel` weights matrix. Default: `None`.'
    normalized_default: DEFAULT None
    normalized_descp:
    - Constraint function applied to the QSTR weights matrix
    - Default QSTR
  kernel_initializer:
    default: glorot_uniform
    descp: 'Initializer for the `kernel` weights matrix, used for the linear transformation
      of the inputs. Default: `glorot_uniform`.'
    normalized_default: DEFAULT DF_STR
    normalized_descp:
    - Initializer for the QSTR weights matrix, used for the linear transformation
      of the inputs
    - Default QSTR
  kernel_regularizer:
    default: None
    descp: 'Regularizer function applied to the `kernel` weights matrix. Default:
      `None`.'
    normalized_default: DEFAULT None
    normalized_descp:
    - Regularizer function applied to the QSTR weights matrix
    - Default QSTR
  recurrent_activation:
    default: sigmoid
    descp: 'Activation function to use for the recurrent step. Default: sigmoid (`sigmoid`).
      If you pass `None`, no activation is applied (ie. "linear" activation: `a(x)
      = x`).'
    normalized_default: DEFAULT DF_STR
    normalized_descp:
    - PARAM function to use for the recurrent step
    - Default sigmoid QSTR
    - If you pass QSTR , no PARAM is applied ie
    - QSTR PARAM a BSTR x
  recurrent_constraint:
    default: None
    descp: 'Constraint function applied to the `recurrent_kernel`weights matrix. Default:
      `None`.'
    normalized_default: DEFAULT None
    normalized_descp:
    - Constraint function applied to the QSTR weights matrix
    - Default QSTR
  recurrent_dropout:
    default: '0.0'
    descp: 'Float between 0 and 1. Fraction of the units to drop for the linear transformation
      of the recurrent state. Default: 0.'
    normalized_default: DEFAULT CONSTANT_FLOAT
    normalized_descp:
    - D_TYPE between CONSTANT_NUM
    - Fraction of the PARAM to drop for the linear transformation of the recurrent
      state
    - Default CONSTANT_NUM
  recurrent_initializer:
    default: orthogonal
    descp: 'Initializer for the `recurrent_kernel` weights matrix, used for the linear
      transformation of the recurrent state. Default: `orthogonal`.'
    normalized_default: DEFAULT DF_STR
    normalized_descp:
    - Initializer for the QSTR weights matrix, used for the linear transformation
      of the recurrent state
    - Default QSTR
  recurrent_regularizer:
    default: None
    descp: 'Regularizer function applied to the`recurrent_kernel` weights matrix.
      Default: `None`.'
    normalized_default: DEFAULT None
    normalized_descp:
    - Regularizer function applied to the QSTR weights matrix
    - Default QSTR
  return_sequences:
    default: 'False'
    descp: 'Boolean. Whether to return the last output. in the output sequence, or
      the full sequence. Default: `False`.'
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - ONE_WORD D_TYPE
    - Whether to return the last output
    - in the output D_STRUCTURE, or the full D_STRUCTURE
    - Default CONSTANT_BOOL
  return_state:
    default: 'False'
    descp: 'Boolean. Whether to return the last state in addition to the output. Default:
      `False`.'
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - ONE_WORD D_TYPE
    - Whether to return the last state in addition to the output
    - Default CONSTANT_BOOL
  stateful:
    default: 'False'
    descp: Boolean (default `False`). If True, the last state for each sample at index
      i in a batch will be used as initial state for the sample of index i in the
      following batch.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - D_TYPE default CONSTANT_BOOL
    - If CONSTANT_BOOL, the last state for each sample at index i in a batch will
      be used as initial state for the sample of index i in the following batch
  time_major:
    default: 'False'
    descp: The shape format of the `inputs` and `outputs` tensors. If True, the inputs
      and outputs will be in shape`[timesteps, batch, feature]`, whereas in the False
      case, it will be`[batch, timesteps, feature]`. Using `time_major = True` is
      a bit more efficient because it avoids transposes at the beginning and end of
      the RNN calculation. However, most TensorFlow data is batch-major, so by default
      this function accepts input and emits output in batch-major form.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - The shape format of the QSTR D_STRUCTURE
    - If CONSTANT_BOOL, the inputs and outputs will be in shape BSTR, whereas in the
      CONSTANT_BOOL case, it will be BSTR
    - Using time_major CONSTANT_BOOL is a bit more efficient because it avoids transposes
      at the beginning and end of the RNN calculation
    - However, most TensorFlow data is batch major, so by default this function accepts
      input and emits output in batch major form
  unit_forget_bias:
    default: 'True'
    descp: Boolean (default `True`). If True, add 1 to the bias of the forget gate
      at initialization. Setting it to true will also force`bias_initializer="zeros"`.
      This is recommended in Jozefowicz et   al..
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - D_TYPE default CONSTANT_BOOL
    - If CONSTANT_BOOL, add CONSTANT_NUM to the bias of the forget gate at initialization
    - Setting it to CONSTANT_BOOL will also force PARAM QSTR
    - This is recommended in Jozefowicz et al
  units:
    descp: Positive integer, dimensionality of the output space.
    normalized_descp:
    - Positive D_TYPE, dimensionality of the output space
  unroll:
    default: 'False'
    descp: Boolean (default `False`). If True, the network will be unrolled, else
      a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends
      to be more memory-intensive. Unrolling is only suitable for short sequences.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - D_TYPE default CONSTANT_BOOL
    - If CONSTANT_BOOL, the network will be unrolled, else a symbolic loop will be
      used
    - Unrolling can speed up a RNN, although it tends to be more memory intensive
    - Unrolling is only suitable for short sequences
  use_bias:
    default: 'True'
    descp: Boolean (default `True`), whether the layer uses a bias vector.
    normalized_default: DEFAULT CONSTANT_BOOL
    normalized_descp:
    - D_TYPE default CONSTANT_BOOL , whether the layer uses a bias D_STRUCTURE
exceptions:
- AttributeError: When the RNN layer is not stateful.
- ValueError: When the batch size of the RNN layer is unknown.
- ValueError: When the input numpy array is not compatible with the RNN layer state,
    either size wise or dtype wise.
inputs:
  optional:
  - activation
  - recurrent_activation
  - use_bias
  - kernel_initializer
  - recurrent_initializer
  - bias_initializer
  - unit_forget_bias
  - kernel_regularizer
  - recurrent_regularizer
  - bias_regularizer
  - activity_regularizer
  - kernel_constraint
  - recurrent_constraint
  - bias_constraint
  - dropout
  - recurrent_dropout
  - implementation
  - return_sequences
  - return_state
  - go_backwards
  - stateful
  - time_major
  - unroll
  - '**kwargs'
  required:
  - units
link: https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/layers/LSTM
outputs: List of mask tensor, generated or cached mask based on context.
package: tensorflow
target: LSTM
title: tf.keras.layers.LSTM
version: 2.1.0
