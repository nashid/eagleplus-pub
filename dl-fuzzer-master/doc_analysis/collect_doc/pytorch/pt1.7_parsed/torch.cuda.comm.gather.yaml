constraints:
  destination:
    default: None
    descp: 'the output device. Can be CPU or CUDA. Default: the current CUDA device.'
    doc_dtype:
    - torch.device
    - str
    - int
  dim:
    default: '0'
    descp: 'a dimension along which the tensors will be concatenated. Default: `0`.'
    doc_dtype:
    - int
  out:
    default: None
    descp: the tensor to store gather result. Its sizes must match those of `tensors`,
      except for `dim`, where the size must equal `sum(tensor.size(dim) for tensor
      in tensors)`. Can be on CPU or CUDA.
    doc_dtype:
    - Tensor
    - keyword-only
  tensors:
    descp: an iterable of tensors to gather. Tensor sizes in all dimensions other
      than `dim` have to match.
    doc_dtype:
    - Iterable[Tensor]
inputs:
  keyword_only:
  - out
  optional:
  - dim
  - destination
  - out
  required:
  - tensors
link: https://pytorch.org/docs/1.7.0/cuda.html#torch.cuda.comm.gather
package: torch
target: gather
title: torch.cuda.comm.gather
version: 1.7.0
