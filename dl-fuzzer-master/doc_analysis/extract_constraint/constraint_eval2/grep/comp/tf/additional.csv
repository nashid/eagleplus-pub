File,Arg,Type,Constr,Descp
tf.data.experimental.make_csv_dataset,column_defaults,prim_dtype,"['numeric', 'tf.dtype', 'tf.float32', 'tf.float64', 'tf.int32', 'tf.int64', 'tf.string']","A optional list of default values for the CSV fields. One item per selected column of the input record. Each item in the list is either a valid CSV dtype (float32, float64, int32, int64, or string), or a`Tensor` with one of the aforementioned types. The tensor can either be a scalar default value (if the column is optional), or an empty tensor (if the column is required). If a dtype is provided instead of a tensor, the column is also treated as required. If this list is not provided, tries to infer types based on reading the first num_rows_for_inference rows of files specified, and assumes all columns are optional, defaulting to `0`for numeric values and `""""` for string values. If both this and`select_columns` are specified, these must have the same lengths, and`column_defaults` is assumed to be sorted in order of increasing column index."
tf.graph_util.import_graph_def,input_map,prim_dtype,['tf.string'],A dictionary mapping input names (as strings) in `graph_def`to `Tensor` objects. The values of the named input tensors in the imported graph will be re-mapped to the respective `Tensor` values.
tf.feature_column.sequence_numeric_column,shape,nonprim_dtype,['list'],"The shape of the input data per sequence id. E.g. if `shape=(2,)`, each example must contain `2 * sequence_length` values."
tf.split,num_or_size_splits,nonprim_dtype,['list'],"Either an integer indicating the number of splits along`axis` or a 1-D integer `Tensor` or Python list containing the sizes of each output tensor along `axis`. If a scalar, then it must evenly divide`value.shape[axis]`; otherwise the sum of sizes along the split axis must match that of the `value`."
tf.keras.datasets.imdb.load_data,start_char,nonprim_dtype,['list'],The start of a sequence will be marked with this character. Set to 1 because 0 is usually the padding character.
tf.random.stateless_truncated_normal,shape,nonprim_dtype,['list'],A 1-D integer Tensor or Python array. The shape of the output tensor.
tf.keras.utils.get_file,file_hash,prim_dtype,['tf.string'],The expected hash string of the file after download. The sha256 and md5 hash algorithms are both supported.
tf.keras.preprocessing.image.apply_affine_transform,x,nonprim_dtype,['list'],"2D numpy array, single image."
tf.config.experimental_connect_to_host,remote_host,nonprim_dtype,['list'],a single or a list the remote server addr in host-port format.
tf.estimator.experimental.stop_if_no_increase_hook,eval_dir,prim_dtype,['tf.string'],"If set, directory containing summary files with eval metrics. By default, `estimator.eval_dir()` will be used."
tf.random.stateless_normal,shape,nonprim_dtype,['list'],A 1-D integer Tensor or Python array. The shape of the output tensor.
tf.keras.layers.LSTM,activation,prim_dtype,['tf.string'],"Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation is applied (ie. ""linear"" activation: `a(x) = x`)."
tf.keras.layers.LSTM,recurrent_activation,prim_dtype,['tf.string'],"Activation function to use for the recurrent step. Default: sigmoid (`sigmoid`). If you pass `None`, no activation is applied (ie. ""linear"" activation: `a(x) = x`)."
tf.keras.layers.experimental.preprocessing.Normalization,data,nonprim_dtype,['list'],"The data to train on. It can be passed either as a tf.data Dataset, or as a numpy array."
tf.math.multiply_no_nan,y,prim_dtype,['tf.dtype'],A `Tensor` whose dtype is compatible with `x`.
tf.strings.ngrams,ngram_width,nonprim_dtype,"['list', 'tuple']","The width(s) of the ngrams to create. If this is a list or tuple, the op will return ngrams of all specified arities in list order. Values must be non-Tensor integers greater than 0."
tf.strings.ngrams,padding_width,nonprim_dtype,['list'],"If set, `padding_width` pad values will be added to both sides of each sequence. Defaults to `ngram_width`-1. Must be greater than (Note that 1-grams are never padded, regardless of this value.) "
tf.estimator.experimental.stop_if_no_decrease_hook,eval_dir,prim_dtype,['tf.string'],"If set, directory containing summary files with eval metrics. By default, `estimator.eval_dir()` will be used."
tf.ragged.stack,values,prim_dtype,['tf.dtype'],"A list of `tf.Tensor` or `tf.RaggedTensor`.  May not be empty. All`values` must have the same rank and the same dtype; but unlike`tf.stack`, they can have arbitrary dimension sizes."
tf.nn.ctc_loss,label_length,nonprim_dtype,['list'],"tensor of shape [batch_size], None if labels is SparseTensor Length of reference label sequence in labels."
tf.nn.ctc_loss,logit_length,nonprim_dtype,['list'],tensor of shape [batch_size] Length of input sequence in logits.
tf.keras.backend.constant,value,nonprim_dtype,['list'],A constant value (or list)
tf.nn.ctc_greedy_decoder,sequence_length,nonprim_dtype,['list'],"1-D `int32` vector containing sequence lengths, having size`[batch_size]`."
tf.random.stateless_uniform,shape,nonprim_dtype,['list'],A 1-D integer Tensor or Python array. The shape of the output tensor.
tf.nn.collapse_repeated,seq_length,nonprim_dtype,['list'],"Tensor of shape [batch], sequence length of each batch element."
tf.sparse.maximum,sp_a,prim_dtype,['tf.dtype'],"a `SparseTensor` operand whose dtype is real, and indices lexicographically ordered."
tf.keras.layers.experimental.preprocessing.PreprocessingLayer,data,nonprim_dtype,['list'],"The data to train on. It can be passed either as a tf.data Dataset, or as a numpy array."
tf.keras.preprocessing.image.array_to_img,x,nonprim_dtype,['list'],Input Numpy array.
tf.keras.layers.GRU,activation,prim_dtype,['tf.string'],"Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation is applied (ie. ""linear"" activation: `a(x) = x`)."
tf.keras.layers.GRU,recurrent_activation,prim_dtype,['tf.string'],"Activation function to use for the recurrent step. Default: sigmoid (`sigmoid`). If you pass `None`, no activation is applied (ie. ""linear"" activation: `a(x) = x`)."
tf.keras.models.save_model,filepath,prim_dtype,['tf.string'],"One of the following: String, path where to save the model`h5py.File` object where to save the model "
tf.compat.forward_compatibility_horizon,day,prim_dtype,['int'],"A day (1 <= day <= 31, or 30, or 29, or 28) in month. Must be an`int`."
tf.keras.preprocessing.image.save_img,file_format,prim_dtype,['tf.string'],"Optional file format override. If omitted, the format to use is determined from the filename extension. If a file object was used instead of a filename, this parameter should always be used."
tf.keras.layers.LayerNormalization,axis,nonprim_dtype,"['list', 'tuple']",Integer or List/Tuple. The axis that should be normalized (typically the features axis).
tf.keras.backend.placeholder,shape,nonprim_dtype,['tuple'],"Shape of the placeholder (integer tuple, may include `None` entries)."
tf.keras.preprocessing.image.img_to_array,dtype,nonprim_dtype,['list'],Dtype to use for the returned array.
tf.compat.forward_compatible,day,prim_dtype,['int'],"A day (1 <= day <= 31, or 30, or 29, or 28) in month. Must be an`int`."
tf.keras.backend.ctc_batch_cost,input_length,nonprim_dtype,['list'],"tensor `(samples, 1)` containing the sequence length for each batch item in `y_pred`."
tf.keras.backend.ctc_batch_cost,label_length,nonprim_dtype,['list'],"tensor `(samples, 1)` containing the sequence length for each batch item in `y_true`."
tf.keras.layers.SimpleRNNCell,activation,prim_dtype,['tf.string'],"Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation is applied (ie. ""linear"" activation: `a(x) = x`)."
tf.keras.preprocessing.image.load_img,interpolation,prim_dtype,['tf.string'],"Interpolation method used to resample the image if the     target size is different from that of the loaded image.     Supported methods are ""nearest"", ""bilinear"", and ""bicubic"".     If PIL version 1.1.3 or newer is installed, ""lanczos"" is also     supported. If PIL version 3.4.0 or newer is installed, ""box"" and     ""hamming"" are also supported. By default, ""nearest"" is used.`"
tf.unravel_index,dims,nonprim_dtype,['list'],A `Tensor`. Must have the same type as `indices`. An 1-D `int` Tensor. The shape of the array to use for unraveling indices.
tf.xla.experimental.compile,computation,nonprim_dtype,['list'],"A Python function that builds a computation to apply to the input. If the function takes n inputs, 'inputs' should be a list of n tensors.`computation` may return a list of operations and tensors.  Tensors must come before operations in the returned list.  The return value of`compile` is a list of tensors corresponding to the tensors from the output of `computation`.All `Operation`s returned from `computation` will be executed when evaluating any of the returned output tensors."
tf.sparse.reduce_sum,axis,nonprim_dtype,['list'],"The dimensions to reduce; list or scalar. If `None` (the default), reduces all dimensions."
tf.print,*inputs,nonprim_dtype,['list'],"Positional arguments that are the inputs to print. Inputs in the printed output will be separated by spaces. Inputs may be python primitives, tensors, data structures such as dicts and lists that may contain tensors (with the data structures possibly nested in arbitrary ways), and printable python objects."
tf.print,end,prim_dtype,['tf.string'],End character that is appended at the end the printed string. Defaults to the newline character.
tf.print,output_stream,prim_dtype,['tf.string'],"The output stream, logging level, or file to print to. Defaults to sys.stderr, but sys.stdout, tf.compat.v1.logging.info, tf.compat.v1.logging.warning, tf.compat.v1.logging.error, absl.logging.info, absl.logging.warning and absl.loogging,error are also supported. To print to a file, pass a string started with ""file://"" followed by the file path, e.g., ""file:///tmp/foo.out""."
tf.sparse.minimum,sp_a,prim_dtype,['tf.dtype'],"a `SparseTensor` operand whose dtype is real, and indices lexicographically ordered."
tf.function,experimental_implements,prim_dtype,['tf.string'],"If provided, contains a name of a ""known"" function this implements. For example ""mycompany.my_recurrent_cell"". This is stored as an attribute in inference function, which can then be detected when processing serialized function. Seehttps://github.com/tensorflow/community/blob/master/rfcs/20190610-standardizing-composite_ops.mdfor details.  For an example of utilizing this attribute see:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/transforms/prepare_composite_functions_tf.ccThe code above automatically detects and substitutes function that implements ""embedded_matmul"" and allows TFLite to substitute its own implementations. For instance, a tensorflow user can use this attribute to mark that their function also implements`embedded_matmul``` (perhaps more efficiently!) by specifying it using this flag."
tf.function,input_signature,prim_dtype,['tf.dtype'],"A possibly nested sequence of `tf.TensorSpec` objects specifying the shapes and dtypes of the Tensors that will be supplied to this function. If `None`, a separate function is instantiated for each inferred input signature.  If input_signature is specified, every input to`func` must be a `Tensor`, and `func` cannot accept `**kwargs`."
tf.data.experimental.bucket_by_sequence_length,padded_shapes,prim_dtype,['int'],"Nested structure of `tf.TensorShape` to pass to`tf.data.Dataset.padded_batch`. If not provided, will use`dataset.output_shapes`, which will result in variable length dimensions being padded out to the maximum length in each batch."
tf.feature_column.categorical_column_with_vocabulary_list,vocabulary_list,prim_dtype,['tf.dtype'],An ordered iterable defining the vocabulary. Each feature is mapped to the index of its value (if present) in `vocabulary_list`. Must be castable to `dtype`.
tf.saved_model.load,export_dir,prim_dtype,['tf.string'],The SavedModel directory to load from.
tf.keras.optimizers.deserialize,custom_objects,prim_dtype,['tf.string'],Optional dictionary mapping names (strings) to custom objects (classes and functions) to be considered during deserialization.
tf.clip_by_global_norm,clip_norm,prim_dtype,['numeric'],A 0-D (scalar) `Tensor` > 0. The clipping ratio.
tf.searchsorted,sorted_sequence,nonprim_dtype,['list'],N-D `Tensor` containing a sorted sequence.
tf.math.divide_no_nan,y,prim_dtype,['tf.dtype'],A `Tensor` whose dtype is compatible with `x`.
tf.keras.backend.conv2d_transpose,strides,prim_dtype,['int'],strides tuple.
tf.keras.backend.conv2d_transpose,strides,nonprim_dtype,['tuple'],strides tuple.
tf.keras.layers.Lambda,output_shape,prim_dtype,['int'],"Expected output shape from function. This argument can be inferred if not explicitly provided. Can be a tuple or function. If a tuple, it only specifies the first dimension onward; sample dimension is assumed either the same as the input: `output_shape = (input_shape[0], ) + output_shape` or, the input is `None` and the sample dimension is also `None`: `output_shape = (None, ) + output_shape` If a function, it specifies the entire shape as a function of the input shape: `output_shape = f(input_shape)`"
tf.keras.layers.Lambda,output_shape,nonprim_dtype,['tuple'],"Expected output shape from function. This argument can be inferred if not explicitly provided. Can be a tuple or function. If a tuple, it only specifies the first dimension onward; sample dimension is assumed either the same as the input: `output_shape = (input_shape[0], ) + output_shape` or, the input is `None` and the sample dimension is also `None`: `output_shape = (None, ) + output_shape` If a function, it specifies the entire shape as a function of the input shape: `output_shape = f(input_shape)`"
tf.clip_by_norm,clip_norm,prim_dtype,['numeric'],A 0-D (scalar) `Tensor` > 0. A maximum clipping value.
tf.keras.preprocessing.sequence.skipgrams,sequence,prim_dtype,['int'],"A word sequence (sentence), encoded as a list     of word indices (integers). If using a `sampling_table`,     word indices are expected to match the rank     of the words in a reference dataset (e.g. 10 would encode     the 10-th most frequently occurring token).     Note that index 0 is expected to be a non-word and will be skipped."
tf.math.confusion_matrix,num_classes,nonprim_dtype,['list'],"The possible number of labels the classification task can          have. If this value is not provided, it will be calculated          using both predictions and labels array."
tf.signal.ifftshift,axes,nonprim_dtype,['tuple'],"`int` or shape `tuple` Axes over which to calculate. Defaults to None, which shifts all axes."
tf.autograph.to_code,experimental_optional_features,nonprim_dtype,['tuple'],"`None`, a tuple of, or a single`tf.autograph.experimental.Feature` value."
tf.autograph.to_graph,experimental_optional_features,nonprim_dtype,['tuple'],"`None`, a tuple of, or a single`tf.autograph.experimental.Feature` value."
tf.keras.layers.InputSpec,shape,nonprim_dtype,['tuple'],"Shape tuple, expected shape of the input (may include None for unchecked axes)."
tf.keras.datasets.reuters.load_data,start_char,nonprim_dtype,['list'],The start of a sequence will be marked with this character. Set to 1 because 0 is usually the padding character.
tf.keras.backend.set_value,value,nonprim_dtype,['list'],"Value to set the tensor to, as a Numpy array (of the same shape)."
tf.linalg.pinv,rcond,prim_dtype,['tf.dtype'],"`Tensor` of small singular value cutoffs.  Singular values smaller (in modulus) than `rcond` * largest_singular_value (again, in modulus) are set to zero. Must broadcast against `tf.shape(a)[:-2]`. Default value: `10. * max(num_rows, num_cols) * np.finfo(a.dtype).eps`."
tf.keras.backend.switch,condition,prim_dtype,"['int', 'tf.bool']",tensor (`int` or `bool`).
tf.random.uniform,shape,nonprim_dtype,['list'],A 1-D integer Tensor or Python array. The shape of the output tensor.
tf.keras.models.model_from_config,custom_objects,prim_dtype,['tf.string'],Optional dictionary mapping names (strings) to custom classes or functions to be considered during deserialization.
tf.estimator.experimental.stop_if_lower_hook,eval_dir,prim_dtype,['tf.string'],"If set, directory containing summary files with eval metrics. By default, `estimator.eval_dir()` will be used."
tf.tensordot,axes,nonprim_dtype,['list'],"Either a scalar `N`, or a list or an `int32` `Tensor` of shape [2, k]. If axes is a scalar, sum over the last N axes of a and the first N axes of b in order. If axes is a list or `Tensor` the first and second row contain the set of unique integers specifying axes along which the contraction is computed, for `a` and `b`, respectively. The number of axes for `a` and`b` must be equal. If `axes=0`, computes the outer product between `a` and`b`."
tf.range,limit,prim_dtype,['numeric'],"A 0-D `Tensor` (scalar). Upper limit of sequence, exclusive. If None, defaults to the value of `start` while the first entry of the range defaults to 0."
tf.range,limit,nonprim_dtype,['list'],"A 0-D `Tensor` (scalar). Upper limit of sequence, exclusive. If None, defaults to the value of `start` while the first entry of the range defaults to 0."
tf.range,start,prim_dtype,['numeric'],"A 0-D `Tensor` (scalar). Acts as first entry in the range if `limit`is not None; otherwise, acts as range limit and first entry defaults to 0."
tf.repeat,axis,nonprim_dtype,['list'],"An int. The axis along which to repeat values. By default (axis=None), use the flattened input array, and return a flat output array."
tf.keras.layers.InputLayer,input_shape,nonprim_dtype,['tuple'],"Shape tuple (not including the batch axis), or `TensorShape`instance (not including the batch axis)."
tf.random.truncated_normal,shape,nonprim_dtype,['list'],A 1-D integer Tensor or Python array. The shape of the output tensor.
tf.nest.flatten,structure,prim_dtype,['numeric'],"an arbitrarily nested structure or a scalar object. Note, numpy arrays are considered scalars."
tf.random.normal,shape,nonprim_dtype,['list'],A 1-D integer Tensor or Python array. The shape of the output tensor.
tf.math.conj,x,prim_dtype,"['numeric', 'tf.variant']",`Tensor` to conjugate.  Must have numeric or variant type.
tf.case,default,nonprim_dtype,['list'],Optional callable that returns a list of tensors.
tf.io.parse_example,serialized,prim_dtype,['tf.string'],"A vector (1-D Tensor) of strings, a batch of binary serialized `Example` protos."
tf.keras.backend.conv2d,strides,prim_dtype,['int'],strides tuple.
tf.keras.backend.conv2d,strides,nonprim_dtype,['tuple'],strides tuple.
tf.nn.separable_conv2d,strides,prim_dtype,['int'],1-D of size 4.  The strides for the depthwise convolution for each dimension of `input`.
tf.fill,value,prim_dtype,['numeric'],A `Tensor`. 0-D (scalar). Value to fill the returned tensor. @compatibility(numpy) Equivalent to np.full @end_compatibility
tf.keras.layers.deserialize,config,prim_dtype,['tf.string'],"dict of the form {'class_name': str, 'config': dict}"
tf.keras.backend.depthwise_conv2d,strides,prim_dtype,['int'],strides tuple (length 2).
tf.keras.backend.depthwise_conv2d,strides,nonprim_dtype,['tuple'],strides tuple (length 2).
tf.keras.models.model_from_yaml,custom_objects,prim_dtype,['tf.string'],Optional dictionary mapping names (strings) to custom classes or functions to be considered during deserialization.
tf.keras.layers.ConvLSTM2D,activation,prim_dtype,['tf.string'],Activation function to use. By default hyperbolic tangent activation function is applied (`tanh(x)`).
tf.keras.layers.ConvLSTM2D,recurrent_activation,prim_dtype,['tf.string'],Activation function to use for the recurrent step.
tf.ensure_shape,shape,nonprim_dtype,"['list', 'tuple']","A `TensorShape` representing the shape of this tensor, a`TensorShapeProto`, a list, a tuple, or None."
tf.signal.dct,n,nonprim_dtype,['list'],"The length of the transform. If length is less than sequence length, only the first n elements of the sequence are considered for the DCT. If n is greater than the sequence length, zeros are padded and then the DCT is computed as usual."
tf.signal.fftshift,axes,nonprim_dtype,['tuple'],"`int` or shape `tuple`, optional Axes over which to shift.  Default is None, which shifts all axes."
tf.py_function,Tout,prim_dtype,['tf.dtype'],"A list or tuple of tensorflow data types or a single tensorflow data type if there is only one, indicating what `func` returns; an empty list if no value is returned (i.e., if the return value is `None`)."
tf.keras.layers.GRUCell,activation,prim_dtype,['tf.string'],"Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass None, no activation is applied (ie. ""linear"" activation: `a(x) = x`)."
tf.keras.layers.GRUCell,recurrent_activation,prim_dtype,['tf.string'],"Activation function to use for the recurrent step. Default: sigmoid (`sigmoid`). If you pass `None`, no activation is applied (ie. ""linear"" activation: `a(x) = x`)."
tf.strings.unicode_encode,output_encoding,nonprim_dtype,['list'],"Unicode encoding that should be used to encode each codepoint sequence.  Can be `""UTF-8""`, `""UTF-16-BE""`, or `""UTF-32-BE""`."
tf.nn.RNNCellDropoutWrapper,dropout_state_filter_visitor,prim_dtype,['numeric'],"(optional), default: (see below).  Function that takes any hierarchical level of the state and returns a scalar or depth=1 structure of Python booleans describing which terms in the state should be dropped out.  In addition, if the function returns `True`, dropout is applied across this sublevel.  If the function returns`False`, dropout is not applied across this entire sublevel. Default behavior: perform dropout on all terms except the memory (`c`) state of `LSTMCellState` objects, and don't try to apply dropout to`TensorArray` objects: `def dropout_state_filter_visitor(s): if isinstance(s, LSTMCellState): # Never perform dropout on the c   state. return LSTMCellState(c=False, h=True) elif isinstance(s, TensorArray): return False return True`"
tf.nn.RNNCellDropoutWrapper,input_keep_prob,prim_dtype,['float'],"unit Tensor or float between 0 and 1, input keep probability; if it is constant and 1, no input dropout will be added."
tf.nn.RNNCellDropoutWrapper,input_size,nonprim_dtype,['tuple'],(optional) (possibly nested tuple of) `TensorShape` objects containing the depth(s) of the input tensors expected to be passed in to the `DropoutWrapper`.  Required and used <strong>iff</strong> `variational_recurrent = True` and `input_keep_prob < 1`.
tf.nn.RNNCellDropoutWrapper,output_keep_prob,prim_dtype,['float'],"unit Tensor or float between 0 and 1, output keep probability; if it is constant and 1, no output dropout will be added."
tf.nn.RNNCellDropoutWrapper,state_keep_prob,prim_dtype,['float'],"unit Tensor or float between 0 and 1, output keep probability; if it is constant and 1, no output dropout will be added. State dropout is performed on the outgoing states of the cell. <strong>Note</strong>the state components to which dropout is applied when `state_keep_prob`is in `(0, 1)` are also determined by the argument`dropout_state_filter_visitor` (e.g. by default dropout is never applied to the `c` component of an `LSTMStateTuple`)."
tf.keras.backend.reshape,shape,nonprim_dtype,['tuple'],Target shape tuple.
tf.keras.models.model_from_json,custom_objects,prim_dtype,['tf.string'],Optional dictionary mapping names (strings) to custom classes or functions to be considered during deserialization.
tf.sparse.reduce_max,axis,nonprim_dtype,['list'],"The dimensions to reduce; list or scalar. If `None` (the default), reduces all dimensions."
tf.nn.ctc_beam_search_decoder,sequence_length,nonprim_dtype,['list'],"1-D `int32` vector containing sequence lengths, having size`[batch_size]`."
tf.random.poisson,shape,nonprim_dtype,['list'],"A 1-D integer Tensor or Python array. The shape of the output samples to be drawn per ""rate""-parameterized distribution."
tf.keras.layers.PReLU,alpha_initializer,prim_dtype,['tf.string'],Initializer function for the weights.
tf.keras.backend.conv3d,strides,prim_dtype,['int'],strides tuple.
tf.keras.backend.conv3d,strides,nonprim_dtype,['tuple'],strides tuple.
tf.keras.layers.LSTMCell,activation,prim_dtype,['tf.string'],"Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation is applied (ie. ""linear"" activation: `a(x) = x`)."
tf.keras.layers.LSTMCell,recurrent_activation,prim_dtype,['tf.string'],"Activation function to use for the recurrent step. Default: sigmoid (`sigmoid`). If you pass `None`, no activation is applied (ie. ""linear"" activation: `a(x) = x`)."
tf.random.gamma,shape,nonprim_dtype,['list'],A 1-D integer Tensor or Python array. The shape of the output samples to be drawn per alpha/beta-parameterized distribution.
tf.compat.as_text,bytes_or_text,prim_dtype,['tf.string'],"A `bytes`, `str`, or `unicode` object."
tf.keras.backend.ctc_decode,input_length,nonprim_dtype,['list'],"tensor `(samples, )` containing the sequence length for each batch item in `y_pred`."
tf.feature_column.sequence_categorical_column_with_vocabulary_list,vocabulary_list,prim_dtype,['tf.dtype'],An ordered iterable defining the vocabulary. Each feature is mapped to the index of its value (if present) in `vocabulary_list`. Must be castable to `dtype`.
tf.switch_case,branch_fns,prim_dtype,['int'],"A `dict` mapping `int`s to callables, or a `list` of (`int`, callable) pairs, or simply a list of callables (in which case the index serves as the key). Each callable must return a matching structure of tensors."
tf.keras.utils.to_categorical,y,prim_dtype,['int'],class vector to be converted into a matrix (integers from 0 to num_classes).
tf.summary.histogram,data,prim_dtype,['tf.float64'],A `Tensor` of any shape. Must be castable to `float64`.
tf.saved_model.save,signatures,prim_dtype,['tf.string'],"Optional, either a `tf.function` with an input signature specified or the result of `f.get_concrete_function` on a`@tf.function`-decorated function `f`, in which case `f` will be used to generate a signature for the SavedModel under the default serving signature key. `signatures` may also be a dictionary, in which case it maps from signature keys to either `tf.function` instances with input signatures or concrete functions. The keys of such a dictionary may be arbitrary strings, but will typically be from the`tf.saved_model.signature_constants` module."
tf.batch_to_space,block_shape,nonprim_dtype,['list'],"A `Tensor`. Must be one of the following types: `int32`,`int64`. 1-D with shape `[M]`, all values must be >= 1. For backwards compatibility with TF 1.0, this parameter may be an int, in which case it is converted to `numpy.array([block_shape, block_shape], dtype=numpy.int64)`."
tf.constant,value,prim_dtype,['tf.dtype'],A constant value (or list) of output type `dtype`.
tf.constant,value,nonprim_dtype,['list'],A constant value (or list) of output type `dtype`.
tf.keras.Input,shape,nonprim_dtype,['tuple'],"A shape tuple (integers), not including the batch size. For instance, `shape=(32,)` indicates that the expected input will be batches of 32-dimensional vectors. Elements of this tuple can be None; 'None' elements represent dimensions where the shape is not known."
tf.lite.experimental.load_delegate,options,prim_dtype,['tf.string'],Dictionary of options that are required to load the delegate. All keys and values in the dictionary should be convertible to str. Consult the documentation of the specific delegate for required and legal options. (default None)
tf.summary.trace_export,profiler_outdir,prim_dtype,['tf.string'],"Output directory for profiler. It is required when profiler is enabled when trace was started. Otherwise, it is ignored."
tf.keras.models.load_model,custom_objects,prim_dtype,['tf.string'],Optional dictionary mapping names (strings) to custom classes or functions to be considered during deserialization.
tf.keras.models.load_model,filepath,prim_dtype,['tf.string'],"One of the following: String, path to the saved model`h5py.File` object from which to load the model "
tf.strings.format,inputs,prim_dtype,['tf.string'],"A list of `Tensor` objects, or a single Tensor. The list of tensors to format into the template string. If a solitary tensor is passed in, the input tensor will automatically be wrapped as a list."
tf.nest.pack_sequence_as,flat_sequence,nonprim_dtype,['list'],flat sequence to pack.
tf.nest.pack_sequence_as,structure,prim_dtype,['tf.string'],"Nested structure, whose structure is given by nested lists, tuples, and dicts. Note: numpy arrays and strings are considered scalars."
tf.keras.layers.SimpleRNN,activation,prim_dtype,['tf.string'],"Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass None, no activation is applied (ie. ""linear"" activation: `a(x) = x`)."
tf.estimator.experimental.stop_if_higher_hook,eval_dir,prim_dtype,['tf.string'],"If set, directory containing summary files with eval metrics. By default, `estimator.eval_dir()` will be used."
tf.compat.as_bytes,bytes_or_text,prim_dtype,['tf.string'],"A `bytearray`, `bytes`, `str`, or `unicode` object."
tf.keras.backend.separable_conv2d,strides,prim_dtype,['int'],strides tuple (length 2).
tf.keras.backend.separable_conv2d,strides,nonprim_dtype,['tuple'],strides tuple (length 2).
tf.image.extract_patches,strides,prim_dtype,['int'],"A 1-D Tensor of length 4. How far the centers of two consecutive patches are in the images. Must be: `[1, stride_rows, stride_cols, 1]`."
tf.keras.layers.experimental.preprocessing.TextVectorization,data,nonprim_dtype,['list'],"The data to train on. It can be passed either as a tf.data Dataset, or as a numpy array."
tf.keras.layers.experimental.preprocessing.TextVectorization,output_mode,nonprim_dtype,['list'],"Optional specification for the output of the layer. Values can be ""int"", ""binary"", ""count"" or ""tf-idf"", configuring the layer as follows: ""int"": Outputs integer indices, one integer index per split string   token. ""binary"": Outputs a single int array per batch, of either vocab_size or   max_tokens size, containing 1s in all elements where the token mapped   to that index exists at least once in the batch item. ""count"": As ""binary"", but the int array contains a count of the number   of times the token at that index appeared in the batch item. ""tf-idf"": As ""binary"", but the TF-IDF algorithm is applied to find the   value in each token slot."
tf.keras.optimizers.get,identifier,prim_dtype,['tf.string'],"Optimizer identifier, one of String: name of an optimizerDictionary: configuration dictionary. - Keras Optimizer instance (it will be returned unchanged). - TensorFlow Optimizer instance (it will be wrapped as a Keras Optimizer). "
tf.data.experimental.take_while,predicate,prim_dtype,['tf.bool'],A function that maps a nested structure of tensors (having shapes and types defined by `self.output_shapes` and `self.output_types`) to a scalar `tf.bool` tensor.
tf.dtypes.as_dtype,type_value,prim_dtype,"['tf.dtype', 'tf.string']","A value that can be converted to a `tf.DType` object. This may currently be a `tf.DType` object, a `DataType`enum, a string type name, or a `numpy.dtype`."
tf.compat.as_str_any,value,prim_dtype,['tf.string'],A object that can be converted to `str`.
tf.keras.backend.learning_phase_scope,value,prim_dtype,['int'],"Learning phase value, either 0 or 1 (integers).    0 = test, 1 = train"
tf.keras.layers.Activation,activation,prim_dtype,['tf.string'],"Activation function, such as `tf.nn.relu`, or string name of built-in activation function, such as ""relu""."
tf.ragged.map_flat_values,op,prim_dtype,['numeric'],"The operation that should be applied to the RaggedTensor `flat_values`.`op` is typically an element-wise operation (such as math_ops.add), but any operation that preserves the size of the outermost dimension can be used.  I.e., `shape[0]` of the value returned by `op` must match`shape[0]` of the `RaggedTensor`s' `flat_values` tensors."
tf.recompute_grad,f,nonprim_dtype,['list'],function `f(*x)` that returns a `Tensor` or sequence of `Tensor` outputs.
tf.nest.is_nested,seq,nonprim_dtype,['list'],an input sequence.
tf.keras.activations.get,identifier,prim_dtype,['tf.string'],Function or string
tf.keras.mixed_precision.experimental.set_policy,policy,prim_dtype,['tf.string'],"A Policy, or a string that will be converted to a Policy.."
tf.keras.backend.set_learning_phase,value,prim_dtype,['int'],"Learning phase value, either 0 or 1 (integers).    0 = test, 1 = train"
tf.custom_gradient,f,nonprim_dtype,"['list', 'tuple']","function `f(*x)` that returns a tuple `(y, grad_fn)` where: `x` is a sequence of `Tensor` inputs to the function.`y` is a `Tensor` or sequence of `Tensor` outputs of applying TensorFlow operations in `f` to `x`.`grad_fn` is a function with the signature `g(*grad_ys)` which returns a list of `Tensor`s - the derivatives of `Tensor`s in `y` with respect to the `Tensor`s in `x`.  `grad_ys` is a `Tensor` or sequence of`Tensor`s the same size as `y` holding the initial value gradients for each `Tensor` in `y`. In a pure mathematical sense, a vector-argument vector-valued function `f`'s derivatives should be its Jacobian matrix`J`. Here we are expressing the Jacobian `J` as a function `grad_fn`which defines how `J` will transform a vector `grad_ys` when left-multiplied with it (`grad_ys * J`). This functional representation of a matrix is convenient to use for chain-rule calculation (in e.g. the back-propagation algorithm).If `f` uses `Variable`s (that are not part of the inputs), i.e. through `get_variable`, then `grad_fn` should have signature `g(*grad_ys, variables=None)`, where `variables` is a list of the `Variable`s, and return a 2-tuple `(grad_xs, grad_vars)`, where`grad_xs` is the same as above, and `grad_vars` is a `list<Tensor>`with the derivatives of `Tensor`s in `y` with respect to the variables (that is, grad_vars has one Tensor per variable in variables). "
