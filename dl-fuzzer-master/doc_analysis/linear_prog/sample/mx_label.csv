,Unnamed: 0,API,Arg,Descp,Normalized_descp,dtype,tensor_t,structure,shape,ndim,range,enum
0,237,mxnet.ndarray.contrib.calibrate_entropy,hist_edges,A ndarray/symbol of type float32,A D_STRUCTURE symbol of type D_TYPE,D_TYPE,,D_STRUCTURE,,,,
1,559,mxnet.util.set_np,shape,"A boolean value indicating whether the NumPy-shape semantics should be turned on or off. When this flag is set to True, zero-size and zero-dim shapes are all valid shapes in shape inference process, instead of treated as unknown shapes in legacy mode.",A D_TYPE value indicating whether the NumPy shape semantics should be turned on or off,D_TYPE,,,,0,,
2,214,mxnet.test_utils.chi_square_check,generator,A function that is assumed to generate i.i.d samples from a specific distribution. generator(N) should generate N random samples.,A function that is assumed to generate i i d samples from a specific distribution,,,,,,,
3,381,mxnet.test_utils.np_reduce,numpy_reduce_func,A NumPy reducing function like `np.sum` or `np.max`.,A NumPy reducing function like np sum QSTR np max,,,,,,,
4,196,mxnet.ndarray.op.rmspropalex_update,epsilon,A small constant for numerical stability.,A small constant for numerical stability,numeric,,,,0,,
5,197,mxnet.ndarray.rmspropalex_update,epsilon,A small constant for numerical stability.,A small constant for numerical stability,numeric,,,,0,,
6,9,mxnet.ndarray.Activation,act_type,Activation function to be applied.,Activation function to be applied,,,,,,,QSTR
7,13,mxnet.gluon.nn.Dense,activation,"Activation function to use. See help on Activation layer. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",activation function to use,,,,,,,
8,537,mxnet.io.ImageRecordIter,saturation,"Add a random value in `[-saturation, saturation]` to the saturation of image.",Add a random value in BSTR to the saturation of image,,,,,,,
9,28,mxnet.io.ImageDetRecordIter,aug_seq,"Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. Make sure you don't use normal augmenters for detection tasks.",Additional keyword parameters will be seen by these augmenters,,,,,,,
10,322,mxnet.ndarray.random.uniform,low,Lower boundary of the output interval. All values generated will be greater than or equal to low. The default value is 0.,All values generated will be greater than or equal to low,,,,,,,
11,234,mxnet.ndarray.random.uniform,high,Upper boundary of the output interval. All values generated will be less than high. The default value is 1.0.,All values generated will be less than high,,,,,,,
12,20,mxnet.ndarray.op.random_generalized_negative_binomial,alpha,Alpha (dispersion) parameter of the negative binomial distribution.,alpha BSTR parameter of the negative binomial distribution,,,,,,,
13,21,mxnet.ndarray.random_pdf_gamma,alpha,Alpha (shape) parameters of the distributions.,alpha BSTR parameters of the distributions,,,,,,,
14,566,mxnet.ndarray.op.split,squeeze_axis,"If true, Removes the axis with length 1 from the shapes of the output arrays. Note that setting squeeze_axis to `true` removes axis with length 1 only along the axis which it is split. Also squeeze_axis can be set to `true` only if `input.shape[axis] == num_outputs`.",Also squeeze_axis can be set to CONSTANT_BOOL only if input shape BSTR PARAM,bool,,,,0,,
15,617,mxnet.contrib.autograd.grad,argnum,DD: an int or a list of int,an D_TYPE or a D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
16,187,mxnet.ndarray.topk,dtype,"DType of the output indices when ret_typ is ""indices"" or ""both"". An error will be raised if the selected data type cannot precisely represent the indices.",An error will be raised if the selected PARAM type cannot precisely represent the indices,,,,,,,
17,189,mxnet.ndarray.zeros,dtype,An optional value type (default is float32),An optional value type BSTR,dtype,,,,0,,
18,190,mxnet.ndarray.zeros,dtype,An optional value type (default is float32),An optional value type BSTR,dtype,,,,0,,
19,581,mxnet.contrib.ndarray.box_nms,topk,"Apply nms to topk boxes with descending scores, -1 to no restriction.",Apply nms to topk boxes with descending scores CONSTANT_NUM to no restriction,,,,,,,
20,504,mxnet.io.ImageDetRecordIter,resize_mode,"Augmentation Param: How image data fit in data_shape. force: force reshape to data_shape regardless of aspect ratio; shrink: ensure each side fit in data_shape, preserve aspect ratio; fit: fit image to data_shape, preserve ratio, will upscale if applicable.",Augmentation Param How image data fit in PARAM,,,,,,,
21,343,mxnet.io.ImageDetRecordIter,max_random_contrast,Augmentation Param: Maximum random value of delta contrast.,Augmentation Param Maximum random value of delta contrast,numeric,,,,,,
22,495,mxnet.io.ImageDetRecordIter,random_illumination_prob,Augmentation Param: Probability to apply random illumination.,Augmentation Param Probability to apply random illumination,float,,,,,"[0,1]",
23,544,mxnet.io.ImageDetRecordIter,scale,Augmentation Param: Scale in color space.,Augmentation Param scale in color space,,,,,,,
24,29,mxnet.io.ImageDetRecordIter,aug_seq,"Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. Make sure you don't use normal augmenters for detection tasks.",Augmentation Param the augmenter names to represent D_STRUCTURE of augmenters to be applied seperated by comma,string,,,,0,,
25,33,mxnet.test_utils.numeric_grad,aux_states,Auxiliary states values used as location to compute gradient Maps the name of aux_states to the corresponding numpy.ndarray. Value of all the auxiliary arguments must be provided.,Auxiliary states values used as PARAM to compute gradient Maps the name of aux_states to the corresponding numpy D_STRUCTURE,,,,,,,
26,40,mxnet.ndarray.op.cumsum,axis,Axis along which the cumulative sum is computed. The default (None) is to compute the cumsum over the flattened array.,axis along which the cumulative sum is computed,int,,,,,"[0,inf)",
27,63,mxnet.io.MNISTIter,batch_size,Batch Param: Batch Size.,Batch Param Batch Size,numeric,,,,,"[0,inf)",
28,62,mxnet.io.ImageDetRecordIter,batch_size,Batch size.,Batch size,numeric,,,,,"[0,inf)",
29,525,mxnet.ndarray.ROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]], where (x1, y1) and (x2, y2) are top left and bottom right corners of designated region of interest. batch_index indicates the index of corresponding image in the input array",batch_index indicates the index of corresponding image in the input D_STRUCTURE,int,,,,0,,
30,522,mxnet.ndarray.contrib.DeformablePSROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]]. (x1, y1) and (x2, y2) are top left and down right corners of designated region of interest. batch_index indicates the index of corresponding image in the input data",batch_index indicates the index of corresponding image in the input PARAM,int,,,,0,,
31,64,mxnet.contrib.ndarray.quantized_batch_norm,beta,beta.,ONE_WORD beta,,,,,,,
32,65,mxnet.ndarray.BatchNorm,beta,beta array,beta D_STRUCTURE,,,D_STRUCTURE,,,,
33,68,mxnet.ndarray.LayerNorm,beta,beta array,beta D_STRUCTURE,,,D_STRUCTURE,,,,
34,69,mxnet.ndarray.contrib.quantized_conv,bias,bias.,ONE_WORD bias,,,,,,,
35,71,mxnet.ndarray.op.Deconvolution,bias,Bias added to the result after the deconvolution operation.,bias added to the result after the deconvolution operation,,,,,,,
36,70,mxnet.ndarray.FullyConnected,bias,Bias parameter.,bias parameter,,,,,,,
37,79,mxnet.image.copyMakeBorder,bot,Bottom margin.,Bottom margin,,,,,,,
38,523,mxnet.ndarray.contrib.DeformablePSROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]]. (x1, y1) and (x2, y2) are top left and down right corners of designated region of interest. batch_index indicates the index of corresponding image in the input data",Bounding box coordinates a CONSTANT_NUM D D_STRUCTURE of BSTR,,,D_STRUCTURE,BSTR,CONSTANT_NUM,,
39,526,mxnet.ndarray.ROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]], where (x1, y1) and (x2, y2) are top left and bottom right corners of designated region of interest. batch_index indicates the index of corresponding image in the input array",Bounding box coordinates a CONSTANT_NUM D D_STRUCTURE of BSTR where BSTR are top left and bottom right corners of designated region of interest,,,D_STRUCTURE,BSTR,CONSTANT_NUM,,
40,257,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",ONE_WORD BSTR,,,,,,,
41,561,mxnet.ndarray.op.LeakyReLU,slope,Init slope for the activation. (For leaky and elu only),ONE_WORD BSTR,,,,,,,
42,524,mxnet.ndarray.contrib.DeformablePSROIPooling,rois,"Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]]. (x1, y1) and (x2, y2) are top left and down right corners of designated region of interest. batch_index indicates the index of corresponding image in the input data",BSTR are top left and down right corners of designated region of interest,,,,,,,
43,494,mxnet.image.CreateDetAugmenter,rand_pad,"[0, 1], probability to apply random padding",BSTR probability to apply random padding,float,,,,0,"[0,1]",
44,335,mxnet.contrib.ndarray.box_encode,matches,"(B, N) value range [0, M)",BSTR value range BSTR,,,,BSTR,,BSTR,
45,258,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",But when the image is zoomed it is similar to the Nearest Neighbors method,,,,,,,
46,15,mxnet.metric.np,allow_extra_outputs,"Whether prediction output is allowed to have extra outputs. This is useful in cases like RNN where states are also part of output which can then be fed back to the RNN in the next step. By default, extra outputs are not allowed.",By default extra outputs are not allowed,,,,,,,
47,37,mxnet.ndarray.transpose,axes,Target axis order. By default the axes will be inverted.,By default the axes will be inverted,,,,,,,
48,563,mxnet.profiler.dumps,sort_by,"can take 'total', 'avg', 'min', 'max', or 'count' by which stat to sort the entries in each category defaults to 'total'",can take QSTR by which stat to sort the entries in each category defaults to QSTR,,,,,,,QSTR
49,84,mxnet.ndarray.multi_sgd_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",Clip gradient to the range of BSTR If clip_gradient REXPR gradient clipping is turned off,,,,,,BSTR,
50,86,mxnet.ndarray.op.where,condition,condition array,condition D_STRUCTURE,,,D_STRUCTURE,,,,
51,325,mxnet.ndarray.op.linalg_trsm,lower,"True if the triangular matrix is lower triangular, false if it is upper triangular.",CONSTANT_BOOL if the triangular matrix is lower triangular CONSTANT_BOOL if it is upper triangular,bool,,,,0,,
52,259,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Area based BSTR,,,,,,,CONSTANT_NUM
53,260,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Bicubic interpolation over 4x4 pixel neighborhood,,,,,,,CONSTANT_NUM
54,261,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Bilinear interpolation,,,,,,,CONSTANT_NUM
55,382,mxnet.ndarray.linalg.extracttrian,offset,"Offset of the diagonal versus the main diagonal. 0 corresponds to the main diagonal, a negative/positive value to diagonals below/above the main diagonal.",CONSTANT_NUM corresponds to the main diagonal a negative positive value to diagonals below above the main diagonal,,,,,,,CONSTANT_NUM
56,262,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Cubic for enlarge area for shrink bilinear for others CONSTANT_NUM Random select from interpolation method metioned above,,,,,,,CONSTANT_NUM
57,207,mxnet.image.imdecode,flag,1 for three channel color output. 0 for grayscale output.,CONSTANT_NUM for grayscale output,,,,,,,CONSTANT_NUM
58,208,mxnet.image.imdecode,flag,1 for three channel color output. 0 for grayscale output.,CONSTANT_NUM for three channel color output,,,,,,,CONSTANT_NUM
59,263,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",CONSTANT_NUM Lanczos interpolation over 8x8 pixel neighborhood,,,,,,,CONSTANT_NUM
60,462,mxnet.gluon.contrib.rnn.Conv3DGRUCell,params,Container for weight sharing between cells. Created if None.,Container for weight sharing between cells,numeric,,,,,,
61,464,mxnet.gluon.contrib.rnn.Conv3DLSTMCell,params,Container for weight sharing between cells. Created if None.,Container for weight sharing between cells,numeric,,,,,,
62,466,mxnet.gluon.contrib.rnn.Conv3DRNNCell,params,Container for weight sharing between cells. Created if None.,Container for weight sharing between cells,numeric,,,,,,
63,619,mxnet.gluon.model_zoo.vision.vgg16_bn,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
64,620,mxnet.gluon.model_zoo.vision.densenet161,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
65,621,mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
66,622,mxnet.gluon.model_zoo.vision.resnet152_v1,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
67,623,mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
68,624,mxnet.gluon.model_zoo.vision.densenet121,ctx,"DD: Context, default CPU",Context default CPU,,,,,,,
69,98,mxnet.ndarray.random_generalized_negative_binomial,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls.",Context of output in format cpu gpu cpu_pinned BSTR,,,,,,,
70,97,mxnet.ndarray.contrib.arange_like,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n).Only used for imperative calls.",Context of output in format cpu gpu cpu_pinned BSTR Only used for imperative calls,,,,,,,
71,625,mxnet.ndarray.random.generalized_negative_binomial,ctx,"DD: Context, optional",Context optional,,,,,,,
72,626,mxnet.ndarray.sparse.row_sparse_array,ctx,"DD: Context, optional",Context optional,,,,,,,
73,627,mxnet.ndarray.random.uniform,ctx,"DD: Context, optional",Context optional,,,,,,,
74,628,mxnet.ndarray.random.randint,ctx,"DD: Context, optional",Context optional,,,,,,,
75,629,mxnet.ndarray.array,ctx,"DD: Context, optional",Context optional,,,,,,,
76,630,mxnet.contrib.onnx.import_to_gluon,ctx,DD: Context or list of Context,Context or D_STRUCTURE of Context,,,D_STRUCTURE,,,,
77,289,mxnet.gluon.nn.Conv2D,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",Convolution is applied on the QSTR dimensions,,,,,,,
78,463,mxnet.gluon.contrib.rnn.Conv3DGRUCell,params,Container for weight sharing between cells. Created if None.,Created if None,,,,,,,
79,465,mxnet.gluon.contrib.rnn.Conv3DLSTMCell,params,Container for weight sharing between cells. Created if None.,Created if None,,,,,,,
80,467,mxnet.gluon.contrib.rnn.Conv3DRNNCell,params,Container for weight sharing between cells. Created if None.,Created if None,,,,,,,
81,128,mxnet.ndarray.op.all_finite,data,Array,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
82,496,mxnet.contrib.ndarray.MultiBoxPrior,ratios,List of aspect ratios of generated MultiBoxPriores.,D_STRUCTURE of aspect ratios of generated MultiBoxPriores,,,D_STRUCTURE,,,,
83,1,mxnet.ndarray.stack,*data,List of arrays to stack,D_STRUCTURE of D_STRUCTURE to stack,,,D_STRUCTURE,,,,
84,763,mxnet.image.CreateAugmenter,data_shape,DD: tuple of int,D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
85,764,mxnet.gluon.contrib.rnn.Conv2DRNNCell,input_shape,DD: tuple of int,D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
86,765,mxnet.gluon.nn.Dropout,axes,"DD: tuple of int, default ",D_STRUCTURE of D_TYPE default,D_TYPE,,D_STRUCTURE,,,,
87,766,mxnet.model.save_checkpoint,arg_params,DD: dict of str to NDArray,D_STRUCTURE of D_TYPE to D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
88,145,mxnet.ndarray.op.unravel_index,data,Array of flat indices,D_STRUCTURE of flat indices,int,,D_STRUCTURE,,,,
89,7,mxnet.ndarray.op.linalg_gemm2,A,Tensor of input matrices,D_STRUCTURE of input matrices,numeric,D_STRUCTURE,,,,,
90,5,mxnet.ndarray.linalg.potrf,A,Tensor of input matrices to be decomposed,D_STRUCTURE of input matrices to be decomposed,numeric,D_STRUCTURE,,,,,
91,3,mxnet.ndarray.linalg_potri,A,Tensor of lower triangular matrices,D_STRUCTURE of lower triangular matrices,numeric,D_STRUCTURE,,,,,
92,59,mxnet.ndarray.linalg_trsm,B,Tensor of matrices,D_STRUCTURE of matrices,numeric,D_STRUCTURE,,,,,
93,25,mxnet.contrib.quantization.quantize_graph,arg_params,Dictionary of name to NDArray.,D_STRUCTURE of name to D_STRUCTURE,string,,D_STRUCTURE,,,,
94,31,mxnet.contrib.quantization.quantize_graph,aux_params,Dictionary of name to NDArray.,D_STRUCTURE of name to D_STRUCTURE,string,,D_STRUCTURE,,,,
95,767,mxnet.test_utils.check_symbolic_forward,aux_states,"DD: list of np.ndarray of dict, optional",D_STRUCTURE of np D_STRUCTURE of D_STRUCTURE optional,,,D_STRUCTURE,,,,
96,768,mxnet.test_utils.check_symbolic_forward,expected,DD: list of np.ndarray or dict of str to np.ndarray,D_STRUCTURE of np D_STRUCTURE of D_TYPE to np D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
97,4,mxnet.ndarray.linalg_trsm,A,Tensor of lower triangular matrices,D_STRUCTURE of PARAM triangular matrices,numeric,D_STRUCTURE,,,,,
98,8,mxnet.ndarray.op.linalg_trmm,A,Tensor of lower triangular matrices,D_STRUCTURE of PARAM triangular matrices,numeric,D_STRUCTURE,,,,,
99,769,mxnet.contrib.ndarray.MultiBoxPrior,ratios,"DD: tuple of <float>, optional, default=[1]",D_STRUCTURE of REXPR optional default BSTR,D_TYPE,,D_STRUCTURE,,1,,
100,770,mxnet.ndarray.op.multi_sgd_mom_update,lrs,"DD: tuple of <float>, required",D_STRUCTURE of REXPR required,D_TYPE,,D_STRUCTURE,,,,
101,771,mxnet.ndarray.op.multi_mp_sgd_mom_update,lrs,"DD: tuple of <float>, required",D_STRUCTURE of REXPR required,D_TYPE,,D_STRUCTURE,,,,
102,2,mxnet.ndarray.linalg_inverse,A,Tensor of square matrix,D_STRUCTURE of square matrix,numeric,D_STRUCTURE,,,,,
103,6,mxnet.ndarray.op.linalg_det,A,Tensor of square matrix,D_STRUCTURE of square matrix,numeric,D_STRUCTURE,,,,,
104,772,mxnet.ndarray.op.broadcast_greater_equal,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
105,773,mxnet.ndarray.arccos,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
106,774,mxnet.ndarray.linalg_trsm,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
107,775,mxnet.ndarray.contrib.quantized_fully_connected,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
108,776,mxnet.contrib.ndarray.MultiBoxDetection,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
109,777,mxnet.ndarray.op.broadcast_to,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
110,778,mxnet.contrib.ndarray.fft,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
111,779,mxnet.ndarray.arctanh,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
112,780,mxnet.ndarray.broadcast_greater,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
113,781,mxnet.ndarray.multi_mp_sgd_mom_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
114,782,mxnet.ndarray.ones_like,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
115,783,mxnet.ndarray.Dropout,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
116,784,mxnet.ndarray.op.diag,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
117,785,mxnet.ndarray.space_to_depth,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
118,786,mxnet.contrib.ndarray.ROIAlign,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
119,787,mxnet.ndarray.op.ftml_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
120,788,mxnet.ndarray.sparse.floor,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
121,789,mxnet.ndarray.contrib.round_ste,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
122,790,mxnet.ndarray.broadcast_plus,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
123,791,mxnet.ndarray.arctan,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
124,792,mxnet.ndarray.broadcast_mul,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
125,793,mxnet.ndarray.sparse.elemwise_add,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
126,794,mxnet.ndarray.contrib.quantized_conv,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
127,795,mxnet.image.imresize,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
128,796,mxnet.ndarray.op.fix,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
129,797,mxnet.ndarray.op.concat,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
130,798,mxnet.ndarray.op.slice_axis,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
131,799,mxnet.ndarray.MakeLoss,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
132,800,mxnet.ndarray.op.linalg_gelqf,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
133,801,mxnet.ndarray.random.normal,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
134,802,mxnet.ndarray.shuffle,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
135,803,mxnet.contrib.ndarray.SparseEmbedding,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
136,804,mxnet.contrib.ndarray.allclose,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
137,805,mxnet.ndarray.sqrt,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
138,806,mxnet.ndarray.op.cast_storage,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
139,807,mxnet.contrib.ndarray.getnnz,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
140,808,mxnet.ndarray.Activation,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
141,809,mxnet.ndarray.SequenceReverse,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
142,810,mxnet.ndarray.contrib.backward_hawkesll,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
143,811,mxnet.ndarray.op.exp,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
144,812,mxnet.ndarray.op.sample_poisson,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
145,813,mxnet.ndarray.contrib.CTCLoss,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
146,814,mxnet.ndarray.preloaded_multi_mp_sgd_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
147,815,mxnet.ndarray.MAERegressionOutput,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
148,816,mxnet.ndarray.ElementWiseSum,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
149,817,mxnet.ndarray.contrib.quantized_batch_norm,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
150,818,mxnet.ndarray.op.pad,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
151,819,mxnet.ndarray.op.Activation,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
152,820,mxnet.ndarray.LayerNorm,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
153,821,mxnet.ndarray.op.arccosh,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
154,822,mxnet.ndarray.ones,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
155,823,mxnet.ndarray.op.nag_mom_update,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
156,824,mxnet.ndarray.take,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
157,825,mxnet.ndarray.broadcast_axes,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
158,826,mxnet.ndarray.sparse.log,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
159,827,mxnet.ndarray.random.normal_like,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
160,828,mxnet.ndarray.broadcast_logical_and,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
161,829,mxnet.ndarray.op.nansum,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
162,830,mxnet.ndarray.op.ceil,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
163,831,mxnet.ndarray.sinh,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
164,832,mxnet.contrib.ndarray.AdaptiveAvgPooling2D,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
165,833,mxnet.ndarray.op.mp_lamb_update_phase1,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
166,834,mxnet.ndarray.op.random_poisson,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
167,835,mxnet.ndarray.sparse.cosh,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
168,836,mxnet.ndarray.linalg_gelqf,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
169,837,mxnet.ndarray.erfinv,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
170,838,mxnet.ndarray.cast_storage,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
171,839,mxnet.ndarray.sample_exponential,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
172,840,mxnet.ndarray.op.log1p,out,"DD: NDArray, optional",D_STRUCTURE optional,,,D_STRUCTURE,,,,
173,864,mxnet.ndarray.LRN,nsize,"DD: int (non-negative), required",D_TYPE BSTR required,D_TYPE,,,,,"[0,inf)",
174,865,mxnet.io.ImageDetRecordIter,batch_size,"DD: int (non-negative), required",D_TYPE BSTR required,D_TYPE,,,,,"[0,inf)",
175,530,mxnet.recordio.unpack,s,String buffer from `MXRecordIO.read`.,D_TYPE buffer from MXRecordIO read,D_TYPE,,,,,,
176,866,mxnet.gluon.model_zoo.vision.alexnet,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
177,867,mxnet.gluon.model_zoo.vision.vgg19,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
178,868,mxnet.gluon.utils.split_data,even_split,"DD: bool, default True",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
179,869,mxnet.gluon.nn.BatchNorm,scale,"DD: bool, default True",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
180,870,mxnet.gluon.model_zoo.vision.densenet121,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
181,871,mxnet.gluon.model_zoo.vision.vgg11_bn,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
182,872,mxnet.gluon.nn.AvgPool1D,count_include_pad,"DD: bool, default True",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
183,873,mxnet.gluon.model_zoo.vision.vgg13,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
184,874,mxnet.gluon.model_zoo.vision.resnet50_v2,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
185,875,mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75,pretrained,"DD: bool, default False",D_TYPE default CONSTANT_BOOL,D_TYPE,,,,,,
186,876,mxnet.gluon.nn.LayerNorm,epsilon,"DD: float, default 1e-5",D_TYPE default CONSTANT_FLOAT,D_TYPE,,,,0,,
187,877,mxnet.gluon.nn.GroupNorm,num_groups,"DD: int, default 1",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
188,878,mxnet.gluon.nn.Conv2DTranspose,in_channels,"DD: int, default 0",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
189,879,mxnet.gluon.rnn.RNN,input_size,"DD: int, default 0",D_TYPE default CONSTANT_NUM,D_TYPE,,,,0,,
190,880,mxnet.gluon.model_zoo.vision.resnet152_v2,root,"DD: str, default '$MXNET_HOME/models'",D_TYPE default MXNET_HOME models,D_TYPE,,,,,,
191,881,mxnet.gluon.model_zoo.vision.inception_v3,root,"DD: str, default $MXNET_HOME/models",D_TYPE default MXNET_HOME models,D_TYPE,,,,,,
192,882,mxnet.gluon.contrib.rnn.Conv1DLSTMCell,prefix,"DD: str, default `'conv_lstm_`’",D_TYPE default QSTR,D_TYPE,,,,,,
193,883,mxnet.gluon.nn.MaxPool3D,layout,"DD: str, default 'NCDHW'",D_TYPE default QSTR,D_TYPE,,,,,,
194,884,mxnet.gluon.rnn.RNN,layout,"DD: str, default 'TNC'",D_TYPE default QSTR,D_TYPE,,,,,,
195,885,mxnet.gluon.rnn.GRUCell,prefix,"DD: str, default `'gru_'`",D_TYPE default QSTR,D_TYPE,,,,,,
196,886,mxnet.gluon.nn.MaxPool1D,layout,"DD: str, default 'NCW'",D_TYPE default QSTR,D_TYPE,,,,,,
197,887,mxnet.gluon.nn.Conv2D,layout,"DD: str, default 'NCHW'",D_TYPE default QSTR,D_TYPE,,,,,,
198,888,mxnet.gluon.nn.MaxPool2D,layout,"DD: str, default 'NCHW'",D_TYPE default QSTR,D_TYPE,,,,,,
199,889,mxnet.gluon.contrib.rnn.Conv1DGRUCell,prefix,"DD: str, default `'conv_gru_`’",D_TYPE default QSTR,D_TYPE,,,,,,
200,890,mxnet.ndarray.zeros,dtype,"DD: str or numpy.dtype, optional",D_TYPE optional,D_TYPE,,,,,,
201,891,mxnet.context.cpu,device_id,"DD: int, optional",D_TYPE optional,D_TYPE,,,,,,
202,892,mxnet.ndarray.zeros,dtype,"DD: str or numpy.dtype, optional",D_TYPE optional,D_TYPE,,,,,,
203,893,mxnet.ndarray.arange,dtype,"DD: str or numpy.dtype, optional",D_TYPE optional,D_TYPE,,,,,,
204,894,mxnet.ndarray.zeros,stype,"DD: string, optional",D_TYPE optional,D_TYPE,,,,,,
205,895,mxnet.gluon.utils.download,sha1_hash,"DD: str, optional",D_TYPE optional,D_TYPE,,,,,,
206,896,mxnet.test_utils.download,overwrite,"DD: bool, optional",D_TYPE optional,D_TYPE,,,,,,
207,897,mxnet.callback.do_checkpoint,period,"DD: int, optional",D_TYPE optional,D_TYPE,,,,,,
208,898,mxnet.test_utils.assert_almost_equal,equal_nan,"DD: boolean, optional",D_TYPE optional,D_TYPE,,,,,,
209,899,mxnet.metric.np,allow_extra_outputs,"DD: bool, optional",D_TYPE optional,D_TYPE,,,,,,
210,900,mxnet.ndarray.contrib.arange_like,ctx,"DD: string, optional, default=''",D_TYPE optional default,D_TYPE,,,,,,
211,901,mxnet.ndarray.random_generalized_negative_binomial,ctx,"DD: string, optional, default=''",D_TYPE optional default,D_TYPE,,,,,,
212,902,mxnet.ndarray.rmspropalex_update,epsilon,"DD: float, optional, default=9.99999994e-09",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
213,903,mxnet.contrib.ndarray.quantized_batch_norm,eps,"DD: double, optional, default=0.0010000000474974513",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
214,904,mxnet.ndarray.op.LeakyReLU,slope,"DD: float, optional, default=0.25",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
215,905,mxnet.ndarray.op.rmspropalex_update,epsilon,"DD: float, optional, default=9.99999994e-09",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
216,906,mxnet.ndarray.op.BatchNorm,eps,"DD: double, optional, default=0.0010000000474974513",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
217,907,mxnet.ndarray.contrib.MultiProposal,threshold,"DD: float, optional, default=0.699999988",D_TYPE optional default CONSTANT_FLOAT,D_TYPE,,,,0,,
218,908,mxnet.io.ImageDetRecordIter,num_parts,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
219,909,mxnet.ndarray.op.random_pdf_generalized_negative_binomial,is_log,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
220,910,mxnet.ndarray.random.negative_binomial_like,p,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
221,911,mxnet.ndarray.op.signsgd_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
222,912,mxnet.ndarray.op.Convolution,cudnn_off,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
223,913,mxnet.ndarray.op.rmsprop_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
224,914,mxnet.ndarray.contrib.bipartite_matching,topk,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
225,915,mxnet.ndarray.op.linalg_trmm,transpose,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
226,916,mxnet.ndarray.op.sgd_mom_update,lazy_update,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
227,917,mxnet.ndarray.op.ftrl_update,wd,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
228,918,mxnet.ndarray.random.normal_like,loc,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
229,919,mxnet.ndarray.linalg_trsm,rightside,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
230,920,mxnet.ndarray.op.SoftmaxOutput,ignore_label,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
231,921,mxnet.contrib.ndarray.box_nms,topk,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
232,922,mxnet.ndarray.op.max_axis,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
233,923,mxnet.contrib.ndarray.SyncBatchNorm,use_global_stats,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
234,924,mxnet.contrib.ndarray.quantized_batch_norm,use_global_stats,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
235,925,mxnet.ndarray.op.max,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
236,926,mxnet.ndarray.op.nansum,exclude,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
237,927,mxnet.ndarray.op.linalg_trsm,rightside,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
238,928,mxnet.ndarray.multi_sgd_update,clip_gradient,"DD: float, optional, default=-1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
239,929,mxnet.ndarray.sample_multinomial,get_prob,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
240,930,mxnet.ndarray.sparse.adam_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
241,931,mxnet.ndarray.multi_lars,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
242,932,mxnet.io.MNISTIter,batch_size,"DD: int, optional, default='128'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
243,933,mxnet.ndarray.op.diag,axis2,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
244,934,mxnet.io.ImageRecordIter,saturation,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
245,935,mxnet.contrib.ndarray.box_nms,id_index,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
246,936,mxnet.ndarray.diag,axis2,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
247,937,mxnet.ndarray.random_pdf_gamma,is_log,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
248,938,mxnet.ndarray.linalg_gemm,transpose_a,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
249,939,mxnet.ndarray.sparse.mean,exclude,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
250,940,mxnet.ndarray.signsgd_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
251,941,mxnet.ndarray.contrib.PSROIPooling,group_size,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
252,942,mxnet.ndarray.ftrl_update,beta,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
253,943,mxnet.ndarray.ftml_update,rescale_grad,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
254,944,mxnet.ndarray.min_axis,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
255,945,mxnet.ndarray.op.random_generalized_negative_binomial,alpha,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
256,946,mxnet.image.imresize,interp,"DD: int, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
257,947,mxnet.ndarray.op.sum_axis,exclude,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
258,948,mxnet.ndarray.SwapAxis,dim2,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
259,949,mxnet.ndarray.op.random_normal,scale,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
260,950,mxnet.ndarray.op.linalg_trsm,lower,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
261,951,mxnet.ndarray.BatchNorm,fix_gamma,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
262,952,mxnet.io.ImageDetRecordIter,scale,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
263,953,mxnet.ndarray.op.nanprod,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
264,954,mxnet.contrib.ndarray.quantized_fully_connected,flatten,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
265,955,mxnet.ndarray.contrib.arange_like,step,"DD: double, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
266,956,mxnet.ndarray.MakeLoss,grad_scale,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
267,957,mxnet.ndarray.op.random_generalized_negative_binomial,mu,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
268,958,mxnet.ndarray.SequenceLast,axis,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
269,959,mxnet.ndarray.BatchNorm,use_global_stats,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
270,960,mxnet.ndarray.op.SequenceMask,value,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
271,961,mxnet.ndarray.contrib.quantized_batch_norm,output_mean_var,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
272,962,mxnet.ndarray.contrib.ROIAlign,sample_ratio,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
273,963,mxnet.ndarray.linalg.extracttrian,offset,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
274,964,mxnet.ndarray.op.Softmax,preserve_shape,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
275,965,mxnet.ndarray.GroupNorm,output_mean_var,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
276,966,mxnet.ndarray.argmin,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
277,967,mxnet.ndarray.RNN,state_outputs,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
278,968,mxnet.ndarray.contrib.box_nms,id_index,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
279,969,mxnet.io.ImageRecordIter,mean_g,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
280,970,mxnet.image.imdecode,flag,"DD: int, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
281,971,mxnet.ndarray.op.random_negative_binomial,k,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
282,972,mxnet.ndarray.multi_sgd_mom_update,momentum,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
283,973,mxnet.ndarray.mp_nag_mom_update,wd,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
284,974,mxnet.ndarray.op.mp_sgd_update,lazy_update,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
285,975,mxnet.contrib.ndarray.MultiProposal,feature_stride,"DD: int, optional, default='16'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
286,976,mxnet.ndarray.op.linalg_trmm,rightside,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
287,977,mxnet.ndarray.contrib.box_nms,background_id,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
288,978,mxnet.contrib.ndarray.calibrate_entropy,num_quantized_bins,"DD: int, optional, default='255'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
289,979,mxnet.io.ImageDetRecordIter,random_illumination_prob,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
290,980,mxnet.ndarray.nansum,keepdims,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
291,981,mxnet.ndarray.op.SequenceMask,use_sequence_length,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
292,982,mxnet.io.ImageDetRecordIter,max_random_contrast,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
293,983,mxnet.ndarray.op.SoftmaxOutput,preserve_shape,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
294,984,mxnet.ndarray.op.split,squeeze_axis,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
295,985,mxnet.contrib.ndarray.quantized_fully_connected,no_bias,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
296,986,mxnet.io.ImageRecordIter,verbose,"DD: boolean, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
297,987,mxnet.ndarray.op.linalg_gemm,transpose_a,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
298,988,mxnet.ndarray.UpSampling,num_filter,"DD: int, optional, default='0'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
299,989,mxnet.ndarray.contrib.box_decode,std2,"DD: float, optional, default=1",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
300,990,mxnet.ndarray.RNN,lstm_state_clip_nan,"DD: boolean, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
301,991,mxnet.contrib.ndarray.ROIAlign,sample_ratio,"DD: int, optional, default='-1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
302,992,mxnet.ndarray.op.GroupNorm,num_groups,"DD: int, optional, default='1'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
303,993,mxnet.ndarray.op.multi_mp_sgd_mom_update,momentum,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
304,994,mxnet.contrib.ndarray.MultiProposal,rpn_pre_nms_top_n,"DD: int, optional, default='6000'",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
305,995,mxnet.ndarray.random_normal,loc,"DD: float, optional, default=0",D_TYPE optional default CONSTANT_NUM,D_TYPE,,,,0,,
306,996,mxnet.io.ImageDetRecordIter,aug_seq,"DD: string, optional, default='det_aug_default'",D_TYPE optional default QSTR,D_TYPE,,,,,,
307,997,mxnet.io.MNISTIter,image,"DD: string, optional, default='./train-images-idx3-ubyte'",D_TYPE optional default train images idx3 ubyte,D_TYPE,,,,,,
308,998,mxnet.gluon.nn.Conv3DTranspose,padding,"DD: int or a tuple/list of 3 int,",D_TYPE or a D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
309,999,mxnet.ndarray.random.randn,scale,DD: float or NDArray,D_TYPE or D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
310,1000,mxnet.gluon.nn.Conv1DTranspose,kernel_size,DD: int or tuple/list of 1 int,D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
311,1001,mxnet.gluon.nn.Conv3D,dilation,DD: int or tuple/list of 3 int,D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
312,1002,mxnet.gluon.nn.Conv3DTranspose,strides,DD: int or tuple/list of 3 int,D_TYPE or D_STRUCTURE of CONSTANT_NUM D_TYPE,D_TYPE,,D_STRUCTURE,[CONSTANT_NUM],1,,
313,1003,mxnet.gluon.contrib.rnn.Conv3DGRUCell,i2h_kernel,DD: int or tuple of int,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
314,1004,mxnet.gluon.contrib.rnn.Conv2DLSTMCell,h2h_kernel,DD: int or tuple of int,D_TYPE or D_STRUCTURE of D_TYPE,D_TYPE,,D_STRUCTURE,,,,
315,1005,mxnet.gluon.contrib.rnn.Conv1DGRUCell,h2h_dilate,"DD: int or tuple of int, default (1,",D_TYPE or D_STRUCTURE of D_TYPE default CONSTANT_NUM,D_TYPE,,D_STRUCTURE,,,,
316,1006,mxnet.gluon.contrib.rnn.Conv1DRNNCell,i2h_dilate,"DD: int or tuple of int, default (1,",D_TYPE or D_STRUCTURE of D_TYPE default CONSTANT_NUM,D_TYPE,,D_STRUCTURE,,,,
317,1007,mxnet.ndarray.random.gamma,shape,"DD: int or tuple of ints, optional",D_TYPE or D_STRUCTURE of D_TYPE optional,D_TYPE,,D_STRUCTURE,,,,
318,1008,mxnet.test_utils.check_symbolic_backward,grad_req,"DD: str or list of str or dict of str to str, optional",D_TYPE or D_STRUCTURE of D_TYPE or D_STRUCTURE of D_TYPE to D_TYPE optional,D_TYPE,,D_STRUCTURE,,,,
319,1009,mxnet.ndarray.random.uniform,low,"DD: float or NDArray, optional",D_TYPE or D_STRUCTURE optional,D_TYPE,,D_STRUCTURE,,,,
320,1010,mxnet.ndarray.random.uniform,high,"DD: float or NDArray, optional",D_TYPE or D_STRUCTURE optional,D_TYPE,,D_STRUCTURE,,,,
321,1011,mxnet.ndarray.random.gamma,alpha,"DD: float or NDArray, optional",D_TYPE or D_STRUCTURE optional,D_TYPE,,D_STRUCTURE,,,,
322,1012,mxnet.gluon.nn.Conv3DTranspose,weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
323,1013,mxnet.gluon.nn.Dense,bias_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
324,1014,mxnet.gluon.rnn.RNNCell,i2h_weight_initializer,DD: str or Initializer,D_TYPE or Initializer,D_TYPE,,,,,,
325,1015,mxnet.gluon.contrib.rnn.Conv2DGRUCell,i2h_bias_initializer,"DD: str or Initializer, default zeros",D_TYPE or Initializer default zeros,D_TYPE,,,,,,
326,1016,mxnet.ndarray.op.softmin,use_length,"DD: boolean or None, optional, default=0",D_TYPE or None optional default CONSTANT_NUM,D_TYPE,,,,,,
327,1017,mxnet.ndarray.BatchNorm,max_calib_range,"DD: float or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
328,1018,mxnet.ndarray.contrib.requantize,max_calib_range,"DD: float or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
329,1019,mxnet.contrib.ndarray.BilinearResize2D,scale_width,"DD: float or None, optional, default=None",D_TYPE or None optional default None,D_TYPE,,,,,,
330,1020,mxnet.io.ImageRecordIter,seed_aug,"DD: int or None, optional, default='None'",D_TYPE or None optional default QSTR,D_TYPE,,,,,,
331,1021,mxnet.ndarray.op.cumsum,axis,"DD: int or None, optional, default='None'",D_TYPE or None optional default QSTR,D_TYPE,,,,,,
332,1022,mxnet.ndarray.sgd_mom_update,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
333,1023,mxnet.ndarray.split,num_outputs,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
334,1024,mxnet.ndarray.op.repeat,repeats,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
335,1025,mxnet.contrib.ndarray.interleaved_matmul_encdec_qk,heads,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
336,1026,mxnet.image.copyMakeBorder,right,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
337,1027,mxnet.ndarray.op.ftrl_update,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
338,1028,mxnet.contrib.ndarray.SparseEmbedding,input_dim,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
339,1029,mxnet.ndarray.op.ftml_update,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
340,1030,mxnet.image.copyMakeBorder,bot,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
341,1031,mxnet.ndarray.op.adam_update,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
342,1032,mxnet.ndarray.ROIPooling,spatial_scale,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
343,1033,mxnet.image.copyMakeBorder,left,"DD: int, required",D_TYPE required,D_TYPE,,,,,,
344,1034,mxnet.ndarray.mp_lamb_update_phase2,lr,"DD: float, required",D_TYPE required,D_TYPE,,,,,,
345,134,mxnet.ndarray.op.gather_nd,data,data,ONE_WORD data,,,,,,,
346,148,mxnet.ndarray.scatter_nd,data,data,ONE_WORD data,,,,,,,
347,149,mxnet.ndarray.shuffle,data,Data to be shuffled.,data to be shuffled,,,,,,,
348,181,mxnet.ndarray.random.gamma,dtype,Data type of output samples. Default is 'float32',Data type of output samples,dtype,,,,,,
349,183,mxnet.ndarray.random.generalized_negative_binomial,dtype,Data type of output samples. Default is 'float32',Data type of output samples,dtype,,,,,,
350,245,mxnet.io.MNISTIter,image,Dataset Param: Mnist image path.,Dataset Param Mnist image path,,,,,,,
351,457,mxnet.test_utils.download,overwrite,"Default is false, which means skipping download if the local file exists. If true, then download the url to overwrite the local file if exists.",Default is CONSTANT_BOOL which means skipping download if the local file exists,bool,,,,0,,
352,100,mxnet.ndarray.random.generalized_negative_binomial,ctx,Device context of output. Default is current context. Overridden by mu.context when mu is an NDArray.,Default is current context,,,,,,,
353,103,mxnet.ndarray.random.randint,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Default is current context,,,,,,,
354,106,mxnet.ndarray.random.randn,ctx,Device context of output. Default is current context. Overridden by loc.context when loc is an NDArray.,Default is current context,,,,,,,
355,109,mxnet.ndarray.random.uniform,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Default is current context,,,,,,,
356,182,mxnet.ndarray.random.gamma,dtype,Data type of output samples. Default is 'float32',Default is QSTR,,,,,,,
357,184,mxnet.ndarray.random.generalized_negative_binomial,dtype,Data type of output samples. Default is 'float32',Default is QSTR,,,,,,,
358,353,mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",Default is QSTR,,,,,,,
359,358,mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",Default is QSTR,,,,,,,
360,468,mxnet.callback.do_checkpoint,period,Interval (number of epochs) between checkpoints. Default period is 1.,Default period is CONSTANT_NUM,,,,,,,
361,177,mxnet.ndarray.op.random_negative_binomial,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,,,,,,,
362,179,mxnet.ndarray.random_uniform,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,,,,,,,
363,185,mxnet.ndarray.sample_exponential,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,Defaults to D_TYPE if not defined dtype None,,,,,,,
364,165,mxnet.ndarray.rmspropalex_update,delta,delta,ONE_WORD delta,,,,,,,
365,96,mxnet.ndarray.array,ctx,Device context (default is the current default context).,Device context BSTR,,,,,,,
366,112,mxnet.ndarray.sparse.row_sparse_array,ctx,Device context (default is the current default context).,Device context BSTR,,,,,,,
367,101,mxnet.ndarray.random.generalized_negative_binomial,ctx,Device context of output. Default is current context. Overridden by mu.context when mu is an NDArray.,Device context of output,,,,,,,
368,104,mxnet.ndarray.random.randint,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Device context of output,,,,,,,
369,107,mxnet.ndarray.random.randn,ctx,Device context of output. Default is current context. Overridden by loc.context when loc is an NDArray.,Device context of output,,,,,,,
370,110,mxnet.ndarray.random.uniform,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Device context of output,,,,,,,
371,168,mxnet.context.cpu,device_id,The device id of the device. device_id is not needed for CPU. This is included to make interface compatible with GPU.,device_id is not needed for CPU,int,,,,0,"[0,inf)",
372,293,mxnet.gluon.nn.MaxPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Pooling is applied on the W dimension.",Dimension ordering of data and out QSTR,,,,,,,
373,296,mxnet.gluon.nn.MaxPool2D,layout,"Dimension ordering of data and out ('NCHW' or 'NHWC'). 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. padding is applied on 'H' and 'W' dimension.",Dimension ordering of data and out QSTR,,,,,,,
374,299,mxnet.gluon.nn.MaxPool3D,layout,"Dimension ordering of data and out ('NCDHW' or 'NDHWC'). 'N', 'C', 'H', 'W', 'D' stands for batch, channel, height, width and depth dimensions respectively. padding is applied on 'D', 'H' and 'W' dimension.",Dimension ordering of data and out QSTR,,,,,,,
375,290,mxnet.gluon.nn.Conv2D,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",Dimension ordering of data and weight,numeric,,,,,,
376,138,mxnet.ndarray.op.sample_multinomial,data,Distribution probabilities. Must sum to one on the last axis.,Distribution probabilities,,,,,,,
377,178,mxnet.ndarray.op.random_negative_binomial,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,dtype of the output in case this can t be inferred,dtype,,,,,,
378,180,mxnet.ndarray.random_uniform,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,dtype of the output in case this can t be inferred,dtype,,,,,,
379,186,mxnet.ndarray.sample_exponential,dtype,DType of the output in case this can't be inferred. Defaults to float32 if not defined (dtype=None).,dtype of the output in case this can t be inferred,dtype,,,,,,
380,188,mxnet.ndarray.topk,dtype,"DType of the output indices when ret_typ is ""indices"" or ""both"". An error will be raised if the selected data type cannot precisely represent the indices.",dtype of the output indices when PARAM is QSTR,dtype,,,,,,
381,246,mxnet.recordio.pack_img,img_fmt,"Encoding of the image (.jpg for JPEG, .png for PNG).",Encoding of the image BSTR,,,,,,,
382,191,mxnet.contrib.ndarray.quantized_batch_norm,eps,Epsilon to prevent div 0. Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn.h when using cudnn (usually 1e-5),Epsilon to prevent div CONSTANT_NUM,numeric,,,,,,
383,193,mxnet.ndarray.op.BatchNorm,eps,Epsilon to prevent div 0. Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn.h when using cudnn (usually 1e-5),Epsilon to prevent div CONSTANT_NUM,numeric,,,,,,
384,564,mxnet.ndarray.ROIPooling,spatial_scale,Ratio of input feature map height (or w) to raw image height (or w). Equals the reciprocal of total stride in convolutional layers,Equals the reciprocal of total stride in convolutional layers,,,,,,,
385,549,mxnet.gluon.utils.download,sha1_hash,Expected sha1 hash in hexadecimal digits. Will ignore existing file when hash is specified but doesn't match.,Expected sha1 hash in hexadecimal digits,,,,,,,
386,460,mxnet.ndarray.sample_negative_binomial,p,Failure probabilities in each experiment.,Failure probabilities in each experiment,float,,,,,"[0,1]",
387,459,mxnet.ndarray.random.negative_binomial_like,p,Failure probability in each experiment.,Failure probability in each experiment,float,,,,,"[0,1]",
388,595,mxnet.ndarray.full,val,Fill value.,Fill value,,,,,,,
389,314,mxnet.ndarray.sparse.add,lhs,First array to be added.,First D_STRUCTURE to be added,,,D_STRUCTURE,,,,
390,310,mxnet.ndarray.minimum,lhs,First array to be compared.,First D_STRUCTURE to be compared,,,D_STRUCTURE,,,,
391,317,mxnet.ndarray.subtract,lhs,First array to be subtracted.,First D_STRUCTURE to be subtracted,,,D_STRUCTURE,,,,
392,309,mxnet.ndarray.elemwise_div,lhs,first input,first input,,,,,,,
393,312,mxnet.ndarray.op.elemwise_add,lhs,first input,first input,,,,,,,
394,313,mxnet.ndarray.op.reshape_like,lhs,First input.,First input,,,,,,,
395,315,mxnet.ndarray.sparse.elemwise_add,lhs,first input,first input,,,,,,,
396,316,mxnet.ndarray.sparse.elemwise_sub,lhs,first input,first input,,,,,,,
397,308,mxnet.ndarray.broadcast_not_equal,lhs,First input to the function,First input to the function,,,,,,,
398,311,mxnet.ndarray.op.broadcast_add,lhs,First input to the function,First input to the function,,,,,,,
399,227,mxnet.ndarray.contrib.PSROIPooling,group_size,fix group size,fix group size,numeric,,,,,"[0,inf)",
400,206,mxnet.ndarray.BatchNorm,fix_gamma,Fix gamma while training,Fix PARAM while training,,,,,,,
401,251,mxnet.gluon.contrib.rnn.Conv2DRNNCell,input_shape,"Input tensor shape at each time step for each sample, excluding dimension of the batch size and sequence length. Must be consistent with conv_layout. For example, for layout 'NCHW' the shape should be (C, H, W).",For example for layout QSTR the shape should be BSTR,,,,,,,
402,505,mxnet.io.ImageDetRecordIter,resize_mode,"Augmentation Param: How image data fit in data_shape. force: force reshape to data_shape regardless of aspect ratio; shrink: ensure each side fit in data_shape, preserve aspect ratio; fit: fit image to data_shape, preserve ratio, will upscale if applicable.",force force reshape to PARAM regardless of aspect ratio shrink ensure each side fit in PARAM preserve aspect ratio fit fit image to PARAM preserve ratio will upscale if applicable,,,,,,,
403,213,mxnet.ndarray.rmspropalex_update,g,g,ONE_WORD g,,,,,,,
404,215,mxnet.test_utils.chi_square_check,generator,A function that is assumed to generate i.i.d samples from a specific distribution. generator(N) should generate N random samples.,generator BSTR should generate N random samples,,,,,,,
405,85,mxnet.ndarray.multi_sgd_update,clip_gradient,"Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).",grad max BSTR,,,,,,,
406,219,mxnet.ndarray.contrib.group_adagrad_update,grad,Gradient,ONE_WORD Gradient,numeric,,,,,,
407,220,mxnet.ndarray.ftrl_update,grad,Gradient,ONE_WORD Gradient,numeric,,,,,,
408,221,mxnet.ndarray.mp_lamb_update_phase1,grad,Gradient,ONE_WORD Gradient,numeric,,,,,,
409,222,mxnet.ndarray.op.signum_update,grad,Gradient,ONE_WORD Gradient,numeric,,,,,,
410,223,mxnet.ndarray.signum_update,grad,Gradient,ONE_WORD Gradient,numeric,,,,,,
411,224,mxnet.test_utils.check_symbolic_backward,grad_req,"Gradient requirements. 'write', 'add' or 'null'.",Gradient requirements,,,,,,,
412,499,mxnet.ndarray.multi_lars,rescale_grad,Gradient rescaling factor,Gradient rescaling factor,,,,,,,
413,226,mxnet.ndarray.MakeLoss,grad_scale,Gradient scale as a supplement to unary and binary operators,Gradient scale as a supplement to unary and binary operators,,,,,,,
414,280,mxnet.ndarray.contrib.CTCLoss,label,Ground-truth labels for the loss.,Ground truth labels for the loss,,,,,,,
415,281,mxnet.ndarray.ctc_loss,label,Ground-truth labels for the loss.,Ground truth labels for the loss,,,,,,,
416,42,mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is a D_STRUCTURE of D_TYPE a reduction is performed on all the axes specified in the D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
417,48,mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is a D_STRUCTURE of D_TYPE a reduction is performed on all the axes specified in the D_STRUCTURE,D_TYPE,,D_STRUCTURE,,,,
418,43,mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is D_TYPE a reduction is performed on a particular axis,D_TYPE,,,,,,
419,49,mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If axis is D_TYPE a reduction is performed on a particular axis,D_TYPE,,,,,,
420,80,mxnet.contrib.quantization.quantize_model,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",If calib_mode QSTR BSTR the thresholds for quantization will be derived such that the KL divergence between the distributions of D_TYPE layer outputs and quantized layer outputs is minimized based upon the calibration dataset,,,,,,,QSTR
421,81,mxnet.contrib.quantization.quantize_model,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",If calib_mode QSTR no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators,,,,,,,QSTR
422,82,mxnet.contrib.quantization.quantize_model,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",If calib_mode QSTR the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization,,,,,,,QSTR
423,333,mxnet.ndarray.RNN,lstm_state_clip_nan,"Whether to stop NaN from propagating in state by clipping it to min/max. If clipping range is not specified, this option is ignored.",If clipping range is not specified this option is ignored,,,,,,,
424,199,mxnet.gluon.utils.split_data,even_split,"Whether to force all slices to have the same number of elements. If True, an error will be raised when num_slice does not evenly divide data.shape[batch_axis].",If CONSTANT_BOOL an error will be raised when PARAM does not evenly divide PARAM shape BSTR,bool,,,,0,,
425,540,mxnet.gluon.nn.BatchNorm,scale,"If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.",If CONSTANT_BOOL gamma is not used,bool,,,,0,,
426,304,mxnet.ndarray.op.mp_sgd_update,lazy_update,"If true, lazy updates are applied if gradient's stype is row_sparse.",If CONSTANT_BOOL lazy updates are applied if gradient stype is row_sparse,bool,,,,0,,
427,305,mxnet.ndarray.op.sgd_mom_update,lazy_update,"If true, lazy updates are applied if gradient's stype is row_sparse and both weight and momentum have the same stype",If CONSTANT_BOOL lazy updates are applied if gradient stype is row_sparse and both PARAM and PARAM have the same stype,bool,,,,0,,
428,541,mxnet.gluon.nn.BatchNorm,scale,"If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.",If CONSTANT_BOOL multiply by gamma,bool,,,,0,,
429,567,mxnet.ndarray.op.split,squeeze_axis,"If true, Removes the axis with length 1 from the shapes of the output arrays. Note that setting squeeze_axis to `true` removes axis with length 1 only along the axis which it is split. Also squeeze_axis can be set to `true` only if `input.shape[axis] == num_outputs`.",If CONSTANT_BOOL Removes the PARAM with length CONSTANT_NUM from the shapes of the output D_STRUCTURE,bool,,,,0,,
430,458,mxnet.test_utils.download,overwrite,"Default is false, which means skipping download if the local file exists. If true, then download the url to overwrite the local file if exists.",If CONSTANT_BOOL then download the PARAM to overwrite the local file if exists,bool,,,,0,,
431,35,mxnet.gluon.nn.Dropout,axes,"The axes on which dropout mask is shared. If empty, regular dropout is applied.",If empty regular dropout is applied,,,,,,,
432,247,mxnet.gluon.nn.Conv2DTranspose,in_channels,"The number of input channels to this layer. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",If not specified initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data,,,,,,,
433,254,mxnet.gluon.rnn.RNN,input_size,"The number of expected features in the input x. If not specified, it will be inferred from input.",If not specified it will be inferred from input,,,,,,,
434,598,mxnet.io.ImageRecordIter,verbose,If or not output verbose information.,If or not output verbose information,,,,,,,
435,461,mxnet.gluon.nn.Conv3DTranspose,padding,"If padding is non-zero, then the input is implicitly zero-padded on both sides for padding number of points",If padding is non zero then the input is implicitly zero padded on both sides for padding number of points,,,,,,,
436,555,mxnet.ndarray.random.gamma,shape,"The number of samples to draw. If shape is, e.g., (m, n) and alpha and beta are scalars, output shape will be (m, n). If alpha and beta are NDArrays with shape, e.g., (x, y), then output will have shape (x, y, m, n), where m*n samples are drawn for each [alpha, beta) pair.",If PARAM and PARAM are NDArrays with shape e g BSTR where m n samples are drawn for each BSTR pair,,,,,,,
437,41,mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If PARAM is CONSTANT_BOOL reduction will be performed on the axes that are NOT in axis instead,,,,,,,
438,47,mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",If PARAM is CONSTANT_BOOL reduction will be performed on the axes that are NOT in axis instead,,,,,,,
439,509,mxnet.ndarray.equal,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",If PARAM shape rhs shape they must be broadcastable to a common shape,,,,,,,
440,511,mxnet.ndarray.minimum,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",If PARAM shape rhs shape they must be broadcastable to a common shape,,,,,,,
441,516,mxnet.ndarray.sparse.subtract,rhs,"Second array to be subtracted. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.__spec__",If PARAM shape rhs shape they must be broadcastable to a common shape spec,,,,,,,
442,338,mxnet.ndarray.BatchNorm,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to by quantized batch norm op to calculate primitive scale.Note: this calib_range is to calib bn output.",If present it will be used to by quantized batch norm op to calculate primitive scale Note this calib_range is to calib bn output,,,,,,,
443,340,mxnet.ndarray.contrib.requantize,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to requantize the int32 data into int8.",If present it will be used to requantize the D_TYPE PARAM into D_TYPE,,,,,,,
444,73,mxnet.ndarray.ctc_loss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",If QSTR last PARAM value QSTR is reserved for blank PARAM instead and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
445,75,mxnet.ndarray.CTCLoss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",If QSTR last PARAM value QSTR is reserved for blank PARAM instead and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
446,77,mxnet.ndarray.op.ctc_loss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",If QSTR last PARAM value QSTR is reserved for blank PARAM instead and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
447,269,mxnet.ndarray.op.random_pdf_generalized_negative_binomial,is_log,"If set, compute the density of the log-probability instead of the probability.",If set compute the density of the log probability instead of the probability,,,,,,,
448,270,mxnet.ndarray.random_pdf_gamma,is_log,"If set, compute the density of the log-probability instead of the probability.",If set compute the density of the log probability instead of the probability,,,,,,,
449,481,mxnet.ndarray.op.Softmax,preserve_shape,"If set to `true`, the softmax function will be computed along the last axis (`-1`).",If set to CONSTANT_BOOL the softmax function will be computed along the last axis CONSTANT_NUM,bool,,,,0,,
450,482,mxnet.ndarray.op.SoftmaxOutput,preserve_shape,"If set to `true`, the softmax function will be computed along the last axis (`-1`).",If set to CONSTANT_BOOL the softmax function will be computed along the last axis CONSTANT_NUM,bool,,,,0,,
451,594,mxnet.ndarray.op.SequenceMask,use_sequence_length,"If set to true, this layer takes in an extra input parameter sequence_length to specify variable length sequence",If set to CONSTANT_BOOL this layer takes in an extra input parameter PARAM to specify variable length D_STRUCTURE,bool,,,,0,,
452,556,mxnet.ndarray.random.gamma,shape,"The number of samples to draw. If shape is, e.g., (m, n) and alpha and beta are scalars, output shape will be (m, n). If alpha and beta are NDArrays with shape, e.g., (x, y), then output will have shape (x, y, m, n), where m*n samples are drawn for each [alpha, beta) pair.",If shape is e g BSTR,,,,BSTR,,,
453,273,mxnet.ndarray.min_axis,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
454,274,mxnet.ndarray.nansum,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
455,275,mxnet.ndarray.op.max,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
456,276,mxnet.ndarray.op.max_axis,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
457,277,mxnet.ndarray.op.nanprod,keepdims,"If this is set to True, the reduced axes are left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced axes are left in the result as dimension with size one,bool,,,,0,,
458,272,mxnet.ndarray.argmin,keepdims,"If this is set to True, the reduced axis is left in the result as dimension with size one.",If this is set to CONSTANT_BOOL the reduced PARAM is left in the result as dimension with size one,bool,,,,0,,
459,32,mxnet.test_utils.check_symbolic_forward,aux_states,if type is list of np.ndarrayContains all the NumPy arrays corresponding to sym.list_auxiliary_states,if type is D_STRUCTURE of np ndarrayContains all the NumPy D_STRUCTURE corresponding to PARAM list_auxiliary_states,,,D_STRUCTURE,,,,
460,10,mxnet.gluon.nn.Dense,activation,"Activation function to use. See help on Activation layer. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",If you don t specify anything no activation is applied ie,,,,,,,
461,55,mxnet.ndarray.diag,axis2,The second axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,Ignored when the input is a CONSTANT_NUM D D_STRUCTURE,,,,,,,
462,57,mxnet.ndarray.op.diag,axis2,The second axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,Ignored when the input is a CONSTANT_NUM D D_STRUCTURE,,,,,,,
463,216,mxnet.ndarray.sample_multinomial,get_prob,"Whether to also return the log probability of sampled result. This is usually used for differentiating through stochastic variables, e.g. in reinforcement learning.",in reinforcement learning,,,,,,,
464,562,mxnet.ndarray.op.LeakyReLU,slope,Init slope for the activation. (For leaky and elu only),Init slope for the activation,,,,,,,
465,72,mxnet.gluon.nn.Dense,bias_initializer,Initializer for the bias vector.,Initializer for the bias vector,,,,,,,
466,24,mxnet.gluon.nn.PReLU,alpha_initializer,Initializer for the embeddings matrix.,Initializer for the embeddings matrix,,,,,,,
467,238,mxnet.gluon.contrib.rnn.Conv2DGRUCell,i2h_bias_initializer,Initializer for the input convolution bias vectors.,Initializer for the input convolution bias vectors,,,,,,,
468,241,mxnet.gluon.rnn.RNNCell,i2h_weight_initializer,"Initializer for the input weights matrix, used for the linear transformation of the inputs.",Initializer for the input weights matrix used for the linear transformation of the inputs,,,,,,,
469,613,mxnet.gluon.nn.Conv3DTranspose,weight_initializer,Initializer for the weight weights matrix.,Initializer for the weight weights matrix,,,,,,,
470,239,mxnet.gluon.contrib.rnn.Conv1DRNNCell,i2h_dilate,Input convolution dilate.,Input convolution dilate,,,,,,,
471,240,mxnet.gluon.contrib.rnn.Conv3DGRUCell,i2h_kernel,Input convolution kernel sizes.,Input convolution kernel sizes,numeric,,,,,"[0,inf)",
472,123,mxnet.ndarray.depth_to_space,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
473,126,mxnet.ndarray.image.to_tensor,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
474,131,mxnet.ndarray.op.ctc_loss,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
475,132,mxnet.ndarray.op.CTCLoss,data,Input ndarray,Input D_STRUCTURE,,,D_STRUCTURE,,,,
476,141,mxnet.ndarray.op.SoftmaxOutput,data,Input array.,Input D_STRUCTURE,,,D_STRUCTURE,,,,
477,143,mxnet.ndarray.op.swapaxes,data,Input array.,Input D_STRUCTURE,,,D_STRUCTURE,,,,
478,152,mxnet.ndarray.SoftmaxOutput,data,Input array.,Input D_STRUCTURE,,,D_STRUCTURE,,,,
479,252,mxnet.gluon.contrib.rnn.Conv2DRNNCell,input_shape,"Input tensor shape at each time step for each sample, excluding dimension of the batch size and sequence length. Must be consistent with conv_layout. For example, for layout 'NCHW' the shape should be (C, H, W).",Input D_STRUCTURE shape at each time step for each sample excluding dimension of the batch size and D_STRUCTURE length,int,,,,,"[0,inf)",
480,117,mxnet.contrib.ndarray.quantized_act,data,Input data.,Input data,,,,,,,
481,160,mxnet.ndarray.to_dlpack_for_write,data,input data.,input data,,,,,,,
482,147,mxnet.ndarray.RNN,data,Input data to RNN,Input data to RNN,,,,,,,
483,116,mxnet.contrib.ndarray.fft,data,Input data to the FFTOp.,Input data to the FFTOp,,,,,,,
484,122,mxnet.ndarray.contrib.PSROIPooling,data,"Input data to the pooling operator, a 4D Feature maps",Input data to the pooling operator a CONSTANT_NUM D Feature maps,,,,,,,
485,373,mxnet.ndarray.UpSampling,num_filter,"Input filter. Only used by bilinear sample_type.Since bilinear upsampling uses deconvolution, num_filters is set to the number of channels.",Input filter,,,,,,,
486,283,mxnet.ndarray.op.softmax_cross_entropy,label,Input label,Input label,,,,,,,
487,282,mxnet.ndarray.LogisticRegressionOutput,label,Input label to the function.,Input label to the function,,,,,,,
488,284,mxnet.ndarray.sparse.MAERegressionOutput,label,Input label to the function.,Input label to the function,,,,,,,
489,264,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",Interpolation method default cv2 INTER_LINEAR,,,,,,,
490,469,mxnet.callback.do_checkpoint,period,Interval (number of epochs) between checkpoints. Default period is 1.,Interval BSTR between checkpoints,,,,,,,
491,265,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",It may be a preferred method for image decimation as it gives moire free results,,,,,,,
492,539,mxnet.contrib.ndarray.gradientmultiplier,scalar,lambda multiplier,lambda multiplier,,,,,,,
493,326,mxnet.ndarray.mp_lamb_update_phase2,lr,Learning rate,Learning rate,float,,,,0,"[0,1]",
494,327,mxnet.ndarray.op.adam_update,lr,Learning rate,Learning rate,float,,,,0,"[0,1]",
495,328,mxnet.ndarray.op.ftml_update,lr,Learning rate.,Learning rate,float,,,,0,"[0,1]",
496,329,mxnet.ndarray.op.ftrl_update,lr,Learning rate,Learning rate,float,,,,0,"[0,1]",
497,330,mxnet.ndarray.sgd_mom_update,lr,Learning rate,Learning rate,float,,,,0,"[0,1]",
498,331,mxnet.ndarray.op.multi_mp_sgd_mom_update,lrs,Learning rates.,Learning rates,float,,,,1,"[0,1]",
499,332,mxnet.ndarray.op.multi_sgd_mom_update,lrs,Learning rates.,Learning rates,float,,,,1,"[0,1]",
500,306,mxnet.image.copyMakeBorder,left,Left margin.,left margin,,,,,,,
501,285,mxnet.ndarray.contrib.CTCLoss,label_lengths,Lengths of labels for each of the samples. Only required when use_label_lengths is true.,Lengths of labels for each of the samples,numeric,,,,,"[0,inf)",
502,287,mxnet.ndarray.op.CTCLoss,label_lengths,Lengths of labels for each of the samples. Only required when use_label_lengths is true.,Lengths of labels for each of the samples,numeric,,,,,"[0,inf)",
503,162,mxnet.ndarray.contrib.CTCLoss,data_lengths,Lengths of data for each of the samples. Only required when use_data_lengths is true.,Lengths of PARAM for each of the samples,numeric,,,,,"[0,inf)",
504,271,mxnet.ndarray.op.random_negative_binomial,k,Limit of unsuccessful experiments.,Limit of unsuccessful experiments,,,,,,,
505,582,mxnet.ndarray.contrib.bipartite_matching,topk,"Limit the number of matches to topk, set -1 for no limit",Limit the number of matches to topk set CONSTANT_NUM for no limit,,,,,,,
506,89,mxnet.contrib.onnx.import_to_gluon,ctx,Loads the model into one or many context(s).,Loads the model into one or many context BSTR,,,,,,,
507,527,mxnet.gluon.model_zoo.vision.inception_v3,root,Location for keeping the model parameters.,Location for keeping the model parameters,,,,,,,
508,528,mxnet.gluon.model_zoo.vision.resnet152_v2,root,Location for keeping the model parameters.,Location for keeping the model parameters,,,,,,,
509,321,mxnet.contrib.ndarray.MultiBoxDetection,loc_pred,Location regression predictions.,Location regression predictions,,,,,,,
510,1038,mxnet.io.ImageDetRecordIter,prefetch_buffer,"DD: long (non-negative), optional, default=4",long BSTR optional default CONSTANT_NUM,D_TYPE,,,,0,"[0,inf)",
511,323,mxnet.ndarray.random.uniform,low,Lower boundary of the output interval. All values generated will be greater than or equal to low. The default value is 0.,Lower boundary of the output interval,,,,,,,
512,30,mxnet.io.ImageDetRecordIter,aug_seq,"Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters. Make sure you don't use normal augmenters for detection tasks.",Make sure you don t use normal augmenters for detection tasks,,,,,,,
513,477,mxnet.io.ImageDetRecordIter,prefetch_buffer,Maximum number of batches to prefetch.,Maximum number of batches to prefetch,int,,,,0,"[0,inf)",
514,336,mxnet.ndarray.contrib.quantized_conv,max_bias,Maximum value of bias.,Maximum value of PARAM,numeric,,,,0,,
515,337,mxnet.ndarray.contrib.quantized_fully_connected,max_bias,Maximum value of bias.,Maximum value of PARAM,numeric,,,,0,,
516,342,mxnet.contrib.ndarray.quantized_batch_norm,max_data,Maximum value of data.,Maximum value of PARAM,numeric,,,,0,,
517,346,mxnet.ndarray.contrib.quantized_conv,max_weight,Maximum value of weight.,Maximum value of PARAM,numeric,,,,0,,
518,319,mxnet.ndarray.random_normal,loc,Mean of the distribution.,Mean of the distribution,numeric,,,,0,,
519,320,mxnet.ndarray.random.normal_like,loc,Mean of the distribution.,Mean of the distribution,numeric,,,,0,,
520,367,mxnet.ndarray.op.random_generalized_negative_binomial,mu,Mean of the negative binomial distribution.,Mean of the negative binomial distribution,numeric,,,,0,,
521,368,mxnet.ndarray.sample_generalized_negative_binomial,mu,Means of the distributions.,Means of the distributions,numeric,,,,1,,
522,26,mxnet.model.save_checkpoint,arg_params,"Model parameter, dict of name to NDArray of net's weights.",Model parameter D_STRUCTURE of name to D_STRUCTURE of net weights,string,,D_STRUCTURE,,,,
523,266,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",More details can be found in the documentation of OpenCV please refer to http docs opencv org master da d54 group__imgproc__transform html,,,,,,,
524,519,mxnet.ndarray.linalg_trsm,rightside,Multiply triangular matrix from the right to non-triangular one.,Multiply triangular matrix from the right to non triangular one,numeric,,,,,,
525,520,mxnet.ndarray.op.linalg_trmm,rightside,Multiply triangular matrix from the right to non-triangular one.,Multiply triangular matrix from the right to non triangular one,numeric,,,,,,
526,521,mxnet.ndarray.op.linalg_trsm,rightside,Multiply triangular matrix from the right to non-triangular one.,Multiply triangular matrix from the right to non triangular one,numeric,,,,,,
527,584,mxnet.ndarray.linalg_gemm,transpose_a,Multiply with transposed of first input (A).,Multiply with transposed of first input BSTR,,,,,,,
528,585,mxnet.ndarray.op.linalg_gemm,transpose_a,Multiply with transposed of first input (A).,Multiply with transposed of first input BSTR,,,,,,,
529,253,mxnet.gluon.contrib.rnn.Conv2DRNNCell,input_shape,"Input tensor shape at each time step for each sample, excluding dimension of the batch size and sequence length. Must be consistent with conv_layout. For example, for layout 'NCHW' the shape should be (C, H, W).",Must be consistent with PARAM,,,,,,,
530,192,mxnet.contrib.ndarray.quantized_batch_norm,eps,Epsilon to prevent div 0. Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn.h when using cudnn (usually 1e-5),Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn h when using cudnn BSTR,,,,,,,
531,194,mxnet.ndarray.op.BatchNorm,eps,Epsilon to prevent div 0. Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn.h when using cudnn (usually 1e-5),Must be no less than CUDNN_BN_MIN_EPSILON defined in cudnn h when using cudnn BSTR,,,,,,,
532,18,mxnet.gluon.nn.LeakyReLU,alpha,slope coefficient for the negative half axis. Must be >= 0.,Must be REXPR,,,,,,REXPR,
533,139,mxnet.ndarray.op.sample_multinomial,data,Distribution probabilities. Must sum to one on the last axis.,Must sum to one on the last axis,,,,,,,
534,140,mxnet.ndarray.op.SequenceMask,data,"n-dimensional input array of the form [max_sequence_length, batch_size, other_feature_dims] where n>2",n dimensional input D_STRUCTURE of the form BSTR where n REXPR,,,D_STRUCTURE,,REXPR,,
535,369,mxnet.gluon.model_zoo.vision.get_model,name,Name of the model.,name of the model,string,,,,0,,
536,44,mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",Negative values means indexing from right to left,,,,,,,
537,50,mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",Negative values means indexing from right to left,,,,,,,
538,580,mxnet.ndarray.contrib.MultiProposal,threshold,"NMS value, below which to suppress.",NMS value below which to suppress,,,,,,,
539,542,mxnet.gluon.nn.BatchNorm,scale,"If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.",nn relu this can be disabled since the scaling will be done by the next layer,,,,,,,
540,1039,mxnet.test_utils.numeric_grad,aux_states,"DD: None or list of numpy.ndarray or dict of str to numpy.ndarray, optional",None or D_STRUCTURE of numpy D_STRUCTURE of D_TYPE to numpy D_STRUCTURE optional,D_TYPE,,D_STRUCTURE,,,,
541,1040,mxnet.ndarray.Deconvolution,cudnn_tune,"DD: {None, 'fastest', 'limited_workspace', 'off'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
542,1041,mxnet.ndarray.op.dot,forward_stype,"DD: {None, 'csr', 'default', 'row_sparse'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
543,1042,mxnet.io.CSVIter,dtype,"DD: {None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
544,1043,mxnet.io.LibSVMIter,dtype,"DD: {None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None'",None QSTR optional default QSTR,,,,,,,QSTR
545,372,mxnet.ndarray.LRN,nsize,normalization window width in elements.,normalization window width in elements,numeric,,,,,"[0,inf)",
546,568,mxnet.ndarray.op.split,squeeze_axis,"If true, Removes the axis with length 1 from the shapes of the output arrays. Note that setting squeeze_axis to `true` removes axis with length 1 only along the axis which it is split. Also squeeze_axis can be set to `true` only if `input.shape[axis] == num_outputs`.",Note that setting squeeze_axis to CONSTANT_BOOL removes PARAM with length CONSTANT_NUM only along the PARAM which it is split,,,,,,,
547,377,mxnet.ndarray.split,num_outputs,Number of splits. Note that this should evenly divide the length of the axis.,Note that this should evenly divide the length of the PARAM,,,,,,,
548,267,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",Note When shrinking an image it will generally look best with AREA based interpolation whereas when enlarging an image it will generally look best with Bicubic BSTR,,,,,,,
549,375,mxnet.gluon.nn.GroupNorm,num_groups,Number of groups to separate the channel axis into.,Number of groups to separate the channel axis into,int,,,,0,"[0,inf)",
550,378,mxnet.ndarray.split,num_outputs,Number of splits. Note that this should evenly divide the length of the axis.,Number of splits,int,,,,0,"[0,inf)",
551,529,mxnet.contrib.ndarray.MultiProposal,rpn_pre_nms_top_n,Number of top scoring boxes to keep before applying NMS to RPN proposals,Number of top scoring boxes to keep before applying NMS to RPN proposals,int,,,,0,"[0,inf)",
552,232,mxnet.gluon.contrib.rnn.LSTMPCell,hidden_size,Number of units in cell state symbol.,Number of units in cell state symbol,int,,,,0,"[0,inf)",
553,1044,mxnet.ndarray.arange,start,"DD: number, optional",number optional,numeric,,,,,,
554,383,mxnet.ndarray.linalg.extracttrian,offset,"Offset of the diagonal versus the main diagonal. 0 corresponds to the main diagonal, a negative/positive value to diagonals below/above the main diagonal.",offset of the diagonal versus the main diagonal,,,,,,,
555,618,mxnet.ndarray.random.randn,ctx,DD: Context,ONE_WORD Context,,,,,,,
556,631,mxnet.contrib.ndarray.hawkesll,max_time,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
557,632,mxnet.ndarray.op.Convolution,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
558,633,mxnet.ndarray.op.where,condition,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
559,634,mxnet.ndarray.linalg_inverse,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
560,635,mxnet.ndarray.op.reshape_like,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
561,636,mxnet.ndarray.sparse.elemwise_sub,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
562,637,mxnet.ndarray.mp_lamb_update_phase2,r1,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
563,638,mxnet.contrib.ndarray.hawkesll,valid_length,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
564,639,mxnet.ndarray.op.mp_lamb_update_phase2,r2,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
565,640,mxnet.ndarray.sparse.add_n,*args,DD: NDArray[],ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
566,641,mxnet.ndarray.SoftmaxOutput,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
567,642,mxnet.ndarray.sign,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
568,643,mxnet.ndarray.linalg_trsm,B,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
569,644,mxnet.ndarray.sparse.MAERegressionOutput,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
570,645,mxnet.ndarray.contrib.hawkesll,beta,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
571,646,mxnet.ndarray.mp_lamb_update_phase1,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
572,647,mxnet.ndarray.op.arccos,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
573,648,mxnet.contrib.ndarray.bipartite_matching,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
574,649,mxnet.ndarray.op.linalg_gemm2,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
575,650,mxnet.ndarray.op.mp_sgd_mom_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
576,651,mxnet.ndarray.sparse.arcsinh,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
577,652,mxnet.ndarray.sparse.cosh,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
578,653,mxnet.ndarray.op.SoftmaxOutput,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
579,654,mxnet.ndarray.op.random_pdf_uniform,sample,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
580,655,mxnet.ndarray.pick,index,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
581,656,mxnet.ndarray.to_dlpack_for_write,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
582,657,mxnet.ndarray.sum,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
583,658,mxnet.contrib.quantization.quantize_graph,arg_params,DD: dict,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
584,659,mxnet.ndarray.rmsprop_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
585,660,mxnet.ndarray.op.rcbrt,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
586,661,mxnet.ndarray.contrib.quantized_conv,max_weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
587,662,mxnet.contrib.ndarray.BilinearResize2D,like,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
588,663,mxnet.ndarray.LayerNorm,beta,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
589,664,mxnet.ndarray.random_pdf_gamma,alpha,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
590,665,mxnet.ndarray.op.CTCLoss,label_lengths,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
591,666,mxnet.contrib.ndarray.box_encode,matches,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
592,667,mxnet.ndarray.rmspropalex_update,g,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
593,668,mxnet.ndarray.BatchNorm,moving_mean,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
594,669,mxnet.ndarray.mp_nag_mom_update,weight32,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
595,670,mxnet.ndarray.contrib.calibrate_entropy,hist_edges,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
596,671,mxnet.ndarray.random_pdf_dirichlet,sample,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
597,672,mxnet.ndarray.op.CTCLoss,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
598,673,mxnet.ndarray.mp_lamb_update_phase1,weight32,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
599,674,mxnet.ndarray.sample_generalized_negative_binomial,mu,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
600,675,mxnet.ndarray.argmin,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
601,676,mxnet.ndarray.contrib.group_adagrad_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
602,677,mxnet.ndarray.op.amp_cast,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
603,678,mxnet.ndarray.signum_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
604,679,mxnet.ndarray.ROIPooling,rois,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
605,680,mxnet.ndarray.ftrl_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
606,681,mxnet.ndarray.contrib.backward_gradientmultiplier,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
607,682,mxnet.ndarray.op.swapaxes,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
608,683,mxnet.ndarray.stack,*data,DD: NDArray[],ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
609,684,mxnet.ndarray.FullyConnected,bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
610,685,mxnet.contrib.ndarray.hawkesll,state,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
611,686,mxnet.ndarray.image.random_lighting,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
612,687,mxnet.ndarray.op.ROIPooling,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
613,688,mxnet.ndarray.choose_element_0index,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
614,689,mxnet.ndarray.sparse.log,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
615,690,mxnet.ndarray.image.to_tensor,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
616,691,mxnet.ndarray.op.unravel_index,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
617,692,mxnet.ndarray.transpose,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
618,693,mxnet.ndarray.rmspropalex_update,delta,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
619,694,mxnet.ndarray.op.transpose,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
620,695,mxnet.ndarray.expm1,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
621,696,mxnet.ndarray.BatchNorm,beta,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
622,697,mxnet.ndarray.linalg_trsm,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
623,698,mxnet.contrib.ndarray.quantized_act,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
624,699,mxnet.ndarray.op.elemwise_add,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
625,700,mxnet.ndarray.contrib.quantize,min_range,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
626,701,mxnet.ndarray.op.all_finite,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
627,702,mxnet.ndarray.contrib.quantized_fully_connected,max_bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
628,703,mxnet.ndarray.contrib.CTCLoss,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
629,704,mxnet.ndarray.sparse.retain,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
630,705,mxnet.ndarray.op.log,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
631,706,mxnet.ndarray.sparse.log2,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
632,707,mxnet.ndarray.op.broadcast_equal,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
633,708,mxnet.ndarray.op.softmax_cross_entropy,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
634,709,mxnet.ndarray.contrib.quantized_conv,bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
635,710,mxnet.ndarray.elemwise_add,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
636,711,mxnet.contrib.ndarray.fft,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
637,712,mxnet.ndarray.op.ctc_loss,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
638,713,mxnet.ndarray.op.signum_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
639,714,mxnet.contrib.ndarray.quantized_fully_connected,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
640,715,mxnet.ndarray.batch_dot,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
641,716,mxnet.ndarray.contrib.quantized_conv,max_bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
642,717,mxnet.ndarray.sparse.elemwise_add,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
643,718,mxnet.ndarray.random_pdf_exponential,sample,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
644,719,mxnet.ndarray.sample_negative_binomial,p,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
645,720,mxnet.ndarray.op.ftml_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
646,721,mxnet.ndarray.shuffle,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
647,722,mxnet.contrib.ndarray.quantized_batch_norm,max_data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
648,723,mxnet.contrib.ndarray.DeformableConvolution,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
649,724,mxnet.ndarray.linalg_potri,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
650,725,mxnet.ndarray.op.signum_update,grad,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
651,726,mxnet.ndarray.contrib.CTCLoss,label_lengths,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
652,727,mxnet.ndarray.contrib.quantize,max_range,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
653,728,mxnet.contrib.ndarray.quantized_conv,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
654,729,mxnet.ndarray.contrib.CTCLoss,data_lengths,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
655,730,mxnet.ndarray.broadcast_sub,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
656,731,mxnet.contrib.ndarray.quantized_batch_norm,beta,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
657,732,mxnet.ndarray.mp_sgd_update,weight32,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
658,733,mxnet.ndarray.op.square,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
659,734,mxnet.ndarray.op.Deconvolution,bias,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
660,735,mxnet.ndarray.broadcast_to,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
661,736,mxnet.ndarray.op.gather_nd,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
662,737,mxnet.ndarray.nanprod,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
663,738,mxnet.ndarray.sin,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
664,739,mxnet.ndarray.elemwise_div,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
665,740,mxnet.ndarray.lamb_update_phase2,g,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
666,741,mxnet.ndarray.sqrt,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
667,742,mxnet.ndarray.op.linalg_trmm,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
668,743,mxnet.ndarray.op.broadcast_add,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
669,744,mxnet.ndarray.sparse.elemwise_sub,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
670,745,mxnet.ndarray.radians,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
671,746,mxnet.ndarray.op.SequenceMask,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
672,747,mxnet.ndarray.op.sample_multinomial,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
673,748,mxnet.ndarray.op.linalg_det,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
674,749,mxnet.ndarray.LogisticRegressionOutput,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
675,750,mxnet.ndarray.broadcast_not_equal,lhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
676,751,mxnet.contrib.quantization.quantize_graph,aux_params,DD: dict,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
677,752,mxnet.ndarray.RNN,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
678,753,mxnet.ndarray.depth_to_space,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
679,754,mxnet.contrib.ndarray.MultiBoxDetection,loc_pred,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
680,755,mxnet.ndarray.scatter_nd,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
681,756,mxnet.ndarray.broadcast_logical_or,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
682,757,mxnet.ndarray.Embedding,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
683,758,mxnet.ndarray.op.elemwise_mul,rhs,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
684,759,mxnet.ndarray.linalg.potrf,A,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
685,760,mxnet.ndarray.op.sgd_mom_update,weight,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
686,761,mxnet.ndarray.ctc_loss,label,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
687,762,mxnet.ndarray.op.exp,data,DD: NDArray,ONE_WORD D_STRUCTURE,,,D_STRUCTURE,,,,
688,841,mxnet.gluon.nn.Conv2DTranspose,use_bias,DD: bool,ONE_WORD D_TYPE,D_TYPE,,,,,,
689,842,mxnet.ndarray.utils.save,fname,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
690,843,mxnet.test_utils.verify_generator,success_rate,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
691,844,mxnet.profiler.dumps,sort_by,DD: string,ONE_WORD D_TYPE,D_TYPE,,,,,,
692,845,mxnet.gluon.nn.LeakyReLU,alpha,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
693,846,mxnet.contrib.onnx.export_model,onnx_file_path,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
694,847,mxnet.gluon.model_zoo.vision.get_model,pretrained,DD: bool,ONE_WORD D_TYPE,D_TYPE,,,,,,
695,848,mxnet.callback.log_train_metric,period,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
696,849,mxnet.profiler.set_config,continuous_dump,"DD: boolean,",ONE_WORD D_TYPE,D_TYPE,,,,,,
697,850,mxnet.gluon.nn.Dense,activation,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
698,851,mxnet.test_utils.verify_generator,nsamples,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
699,852,mxnet.recordio.pack_img,img_fmt,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
700,853,mxnet.image.CreateDetAugmenter,rand_pad,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
701,854,mxnet.gluon.contrib.rnn.LSTMPCell,hidden_size,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
702,855,mxnet.contrib.ndarray.gradientmultiplier,scalar,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
703,856,mxnet.gluon.nn.AvgPool1D,pool_size,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
704,857,mxnet.recordio.unpack,s,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
705,858,mxnet.util.set_np,shape,DD: bool,ONE_WORD D_TYPE,D_TYPE,,,,,,
706,859,mxnet.contrib.quantization.quantize_model,calib_mode,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
707,860,mxnet.gluon.model_zoo.vision.get_model,name,DD: str,ONE_WORD D_TYPE,D_TYPE,,,,,,
708,861,mxnet.contrib.ndarray.backward_gradientmultiplier,scalar,DD: float,ONE_WORD D_TYPE,D_TYPE,,,,,,
709,862,mxnet.image.CreateAugmenter,rand_mirror,DD: bool,ONE_WORD D_TYPE,D_TYPE,,,,,,
710,863,mxnet.gluon.rnn.LSTM,hidden_size,DD: int,ONE_WORD D_TYPE,D_TYPE,,,,,,
711,1035,mxnet.test_utils.np_reduce,numpy_reduce_func,DD: function,ONE_WORD function,,,,,,,
712,1036,mxnet.test_utils.chi_square_check,generator,DD: function,ONE_WORD function,,,,,,,
713,1037,mxnet.gluon.nn.PReLU,alpha_initializer,DD: Initializer,ONE_WORD Initializer,,,,,,,
714,1065,mxnet.gluon.contrib.rnn.VariationalDropoutCell,base_cell,DD: RecurrentCell,ONE_WORD RecurrentCell,,,,,,,
715,1069,mxnet.ndarray.full,val,DD: scalar,ONE_WORD scalar,,,,,0,,
716,1089,mxnet.test_utils.check_symbolic_forward,sym,DD: Symbol,ONE_WORD Symbol,,,,,,,
717,1090,mxnet.ndarray.contrib.PSROIPooling,data,DD: Symbol,ONE_WORD Symbol,,,,,,,
718,1091,mxnet.ndarray.contrib.DeformablePSROIPooling,rois,DD: Symbol,ONE_WORD Symbol,,,,,,,
719,229,mxnet.gluon.contrib.rnn.Conv2DLSTMCell,h2h_kernel,Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.,Only odd numbered sizes are supported,,,,,,,
720,163,mxnet.ndarray.contrib.CTCLoss,data_lengths,Lengths of data for each of the samples. Only required when use_data_lengths is true.,Only required when PARAM is CONSTANT_BOOL,,,,,,,
721,286,mxnet.ndarray.contrib.CTCLoss,label_lengths,Lengths of labels for each of the samples. Only required when use_label_lengths is true.,Only required when PARAM is CONSTANT_BOOL,,,,,,,
722,288,mxnet.ndarray.op.CTCLoss,label_lengths,Lengths of labels for each of the samples. Only required when use_label_lengths is true.,Only required when PARAM is CONSTANT_BOOL,,,,,,,
723,291,mxnet.gluon.nn.Conv2D,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",Only supports QSTR layout for now,,,,,,,QSTR
724,374,mxnet.ndarray.UpSampling,num_filter,"Input filter. Only used by bilinear sample_type.Since bilinear upsampling uses deconvolution, num_filters is set to the number of channels.",Only used by bilinear PARAM Since bilinear upsampling uses deconvolution num_filters is set to the number of channels,,,,,,,
725,99,mxnet.ndarray.random_generalized_negative_binomial,ctx,"Context of output, in format [cpu|gpu|cpu_pinned](n). Only used for imperative calls.",Only used for imperative calls,,,,,,,
726,53,mxnet.ndarray.SequenceLast,axis,The sequence axis. Only values of 0 and 1 are currently supported.,Only values of CONSTANT_NUM are currently supported,,,,,,,CONSTANT_NUM
727,60,mxnet.ndarray.contrib.box_nms,background_id,"Optional, id of the background class which will be ignored in nms.",Optional id of the background class which will be ignored in nms,int,,,,0,"[0,inf)",
728,242,mxnet.contrib.ndarray.box_nms,id_index,"Optional, index of the class categories, -1 to disable.",Optional index of the class categories CONSTANT_NUM to disable,int,,,,0,,
729,243,mxnet.ndarray.contrib.box_nms,id_index,"Optional, index of the class categories, -1 to disable.",Optional index of the class categories CONSTANT_NUM to disable,int,,,,0,,
730,534,mxnet.contrib.ndarray.ROIAlign,sample_ratio,"Optional sampling ratio of ROI align, using adaptive size by default.",Optional sampling ratio of ROI align using adaptive size by default,numeric,,,,,,
731,535,mxnet.ndarray.contrib.ROIAlign,sample_ratio,"Optional sampling ratio of ROI align, using adaptive size by default.",Optional sampling ratio of ROI align using adaptive size by default,numeric,,,,,,
732,171,mxnet.io.CSVIter,dtype,Output data type. `None` means no change.,Output data type,dtype,,,,,,
733,173,mxnet.io.LibSVMIter,dtype,Output data type. `None` means no change.,Output data type,dtype,,,,,,
734,212,mxnet.ndarray.lamb_update_phase2,g,Output of lamb_update_phase 1,Output of lamb_update_phase CONSTANT_NUM,,,,,,,
735,454,mxnet.contrib.ndarray.dequantize,out_type,Output data type.,Output PARAM type,dtype,,,,,,
736,578,mxnet.test_utils.check_symbolic_forward,sym,output symbol,output symbol,,,,,,,
737,455,mxnet.ndarray.contrib.quantized_batch_norm,output_mean_var,Output the mean and inverse std,Output the mean and inverse std,numeric,,,,,,
738,456,mxnet.ndarray.GroupNorm,output_mean_var,Output the mean and std calculated along the given axis.,Output the mean and std calculated along the given axis,numeric,,,,,,
739,102,mxnet.ndarray.random.generalized_negative_binomial,ctx,Device context of output. Default is current context. Overridden by mu.context when mu is an NDArray.,Overridden by PARAM context when PARAM is an D_STRUCTURE,,,,,,,
740,105,mxnet.ndarray.random.randint,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Overridden by PARAM context when PARAM is an D_STRUCTURE,,,,,,,
741,108,mxnet.ndarray.random.randn,ctx,Device context of output. Default is current context. Overridden by loc.context when loc is an NDArray.,Overridden by PARAM context when PARAM is an D_STRUCTURE,,,,,,,
742,111,mxnet.ndarray.random.uniform,ctx,Device context of output. Default is current context. Overridden by low.context when low is an NDArray.,Overridden by PARAM context when PARAM is an D_STRUCTURE,,,,,,,
743,599,mxnet.ndarray.mp_nag_mom_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,PARAM decay augments the objective function with a regularization term that penalizes large weights,,,,,,,
744,601,mxnet.ndarray.op.ftrl_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,PARAM decay augments the objective function with a regularization term that penalizes large weights,,,,,,,
745,297,mxnet.gluon.nn.MaxPool2D,layout,"Dimension ordering of data and out ('NCHW' or 'NHWC'). 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. padding is applied on 'H' and 'W' dimension.",PARAM is applied on QSTR dimension,,,,,,,
746,300,mxnet.gluon.nn.MaxPool3D,layout,"Dimension ordering of data and out ('NCDHW' or 'NDHWC'). 'N', 'C', 'H', 'W', 'D' stands for batch, channel, height, width and depth dimensions respectively. padding is applied on 'D', 'H' and 'W' dimension.",PARAM is applied on QSTR dimension,,,,,,,
747,1045,mxnet.ndarray.contrib.BilinearResize2D,mode,"DD: {'like', 'odd_scale', 'size', 'to_even_down', 'to_even_up', 'to_odd_down', 'to_odd_up'},optional, default='size'",PARAM QSTR optional default QSTR,,,,,,,QSTR
748,379,mxnet.io.ImageDetRecordIter,num_parts,partition the data into multiple parts,partition the data into multiple parts,,,,,,,
749,384,mxnet.contrib.onnx.export_model,onnx_file_path,Path where to save the generated onnx file,Path where to save the generated onnx file,string,,,,0,,
750,67,mxnet.ndarray.ftrl_update,beta,Per-Coordinate Learning Rate beta.,Per Coordinate Learning Rate beta,float,,,,,"[0,1]",
751,475,mxnet.ndarray.contrib.quantized_pooling,pooling_convention,Pooling convention to be applied.,Pooling convention to be applied,,,,,,,
752,476,mxnet.ndarray.op.Pooling,pooling_convention,Pooling convention to be applied.,Pooling convention to be applied,,,,,,,
753,294,mxnet.gluon.nn.MaxPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Pooling is applied on the W dimension.",Pooling is applied on the W dimension,,,,,,,
754,278,mxnet.ndarray.Pooling,kernel,"Pooling kernel size: (y, x) or (d, y, x)",Pooling kernel size BSTR,numeric,,,BSTR,,"[0,inf)",
755,0,mxnet.ndarray.sparse.add_n,*args,Positional input arguments,Positional input arguments,,,,,,,
756,268,mxnet.image.imresize,interp,"Interpolation method (default=cv2.INTER_LINEAR). Possible values: 0: Nearest Neighbors Interpolation. 1: Bilinear interpolation. 2: Bicubic interpolation over 4x4 pixel neighborhood. 3: Area-based (resampling using pixel area relation). It may be a preferred method for image decimation, as it gives moire-free results. But when the image is zoomed, it is similar to the Nearest Neighbors method. (used by default). 4: Lanczos interpolation over 8x8 pixel neighborhood. 9: Cubic for enlarge, area for shrink, bilinear for others 10: Random select from interpolation method metioned above. Note: When shrinking an image, it will generally look best with AREA-based interpolation, whereas, when enlarging an image, it will generally look best with Bicubic (slow) or Bilinear (faster but still looks OK). More details can be found in the documentation of OpenCV, please refer to http://docs.opencv.org/master/da/d54/group__imgproc__transform.html.",Possible values CONSTANT_NUM Nearest Neighbors Interpolation,,,,,,,CONSTANT_NUM
757,480,mxnet.gluon.rnn.GRUCell,prefix,prefix for name of Block`s (and name of weight if params is `None).,prefix for name of Block and name of weight if PARAM is None,string,,,,0,,
758,478,mxnet.gluon.contrib.rnn.Conv1DGRUCell,prefix,Prefix for name of layers (and name of weight if params is None).,prefix for name of layers BSTR,string,,,,0,,
759,479,mxnet.gluon.contrib.rnn.Conv1DLSTMCell,prefix,Prefix for name of layers (and name of weight if params is None).,prefix for name of layers BSTR,string,,,,0,,
760,225,mxnet.test_utils.check_symbolic_backward,grad_req,"Gradient requirements. 'write', 'add' or 'null'.",ONE_WORD QSTR,,,,,,,QSTR
761,11,mxnet.gluon.nn.Dense,activation,"Activation function to use. See help on Activation layer. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",QSTR activation a BSTR x,,,,,,,
762,1046,mxnet.gluon.rnn.RNN,activation,"DD: {'relu' or 'tanh'}, default 'relu'",QSTR default QSTR,,,,,,,QSTR
763,354,mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",QSTR means clip to the range,,,,,,,QSTR
764,359,mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",QSTR means clip to the range,,,,,,,QSTR
765,172,mxnet.io.CSVIter,dtype,Output data type. `None` means no change.,QSTR means no change,,,,,,,QSTR
766,174,mxnet.io.LibSVMIter,dtype,Output data type. `None` means no change.,QSTR means no change,,,,,,,QSTR
767,360,mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",QSTR means to raise an error when index PARAM of range,,,,,,,QSTR
768,355,mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",QSTR means to wrap around,,,,,,,QSTR
769,361,mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",QSTR means to wrap around,,,,,,,QSTR
770,1047,mxnet.ndarray.random.gamma,dtype,"DD: {'float16', 'float32', 'float64'}, optional",QSTR optional,,,,,,,QSTR
771,1048,mxnet.ndarray.random.generalized_negative_binomial,dtype,"DD: {'float16', 'float32', 'float64'}, optional",QSTR optional,,,,,,,QSTR
772,1049,mxnet.ndarray.Dropout,mode,"DD: {'always', 'training'},optional, default='training'",QSTR optional default QSTR,,,,,,,QSTR
773,1050,mxnet.io.ImageDetRecordIter,resize_mode,"DD: {'fit', 'force', 'shrink'},optional, default='force'",QSTR optional default QSTR,,,,,,,QSTR
774,1051,mxnet.ndarray.op.Pooling,pooling_convention,"DD: {'full', 'same', 'valid'},optional, default='valid'",QSTR optional default QSTR,,,,,,,QSTR
775,1052,mxnet.contrib.ndarray.dequantize,out_type,"DD: {'float32'},optional, default='float32'",QSTR optional default QSTR,,,,,,,QSTR
776,1053,mxnet.ndarray.random_uniform,dtype,"DD: {'None', 'float16', 'float32', 'float64'},optional, default='None'",QSTR optional default QSTR,,,,,,,QSTR
777,1054,mxnet.ndarray.take,mode,"DD: {'clip', 'raise', 'wrap'},optional, default='clip'",QSTR optional default QSTR,,,,,,,QSTR
778,1055,mxnet.ndarray.op.ctc_loss,blank_label,"DD: {'first', 'last'},optional, default='first'",QSTR optional default QSTR,,,,,,,QSTR
779,1056,mxnet.ndarray.ctc_loss,blank_label,"DD: {'first', 'last'},optional, default='first'",QSTR optional default QSTR,,,,,,,QSTR
780,1057,mxnet.ndarray.sample_exponential,dtype,"DD: {'None', 'float16', 'float32', 'float64'},optional, default='None'",QSTR optional default QSTR,,,,,,,QSTR
781,1058,mxnet.ndarray.CTCLoss,blank_label,"DD: {'first', 'last'},optional, default='first'",QSTR optional default QSTR,,,,,,,QSTR
782,1059,mxnet.ndarray.op.random_negative_binomial,dtype,"DD: {'None', 'float16', 'float32', 'float64'},optional, default='None'",QSTR optional default QSTR,,,,,,,QSTR
783,1060,mxnet.ndarray.contrib.quantized_pooling,pooling_convention,"DD: {'full', 'same', 'valid'},optional, default='valid'",QSTR optional default QSTR,,,,,,,QSTR
784,1061,mxnet.ndarray.pick,mode,"DD: {'clip', 'wrap'},optional, default='clip'",QSTR optional default QSTR,,,,,,,QSTR
785,1062,mxnet.ndarray.topk,dtype,"DD: {'float16', 'float32', 'float64', 'int32', 'int64', 'uint8'},optional, default='float32'",QSTR optional default QSTR,,,,,,,QSTR
786,349,mxnet.ndarray.contrib.BilinearResize2D,mode,"resizing mode. ""simple"" - output height equals parameter ""height"" if ""scale_height"" parameter is not defined or input height multiplied by ""scale_height"" otherwise. Same for width;""odd_scale"" - if original height or width is odd, then result height is calculated like result_h = (original_h - 1) * scale + 1; for scale > 1 the result shape would be like if we did deconvolution with kernel = (1, 1) and stride = (height_scale, width_scale); and for scale < 1 shape would be like we did convolution with kernel = (1, 1) and stride = (int(1 / height_scale), int( 1/ width_scale);""like"" - resize first input to the height and width of second input; ""to_even_down"" - resize input to nearest lower even height and width (if original height is odd then result height = original height - 1);""to_even_up"" - resize input to nearest bigger even height and width (if original height is odd then result height = original height + 1);""to_odd_down"" - resize input to nearest odd height and width (if original height is odd then result height = original height - 1);""to_odd_up"" - resize input to nearest odd height and width (if original height is odd then result height = original height + 1);",QSTR output PARAM equals parameter PARAM if PARAM parameter is not defined or input PARAM multiplied by PARAM otherwise,,,,,,,QSTR
787,1063,mxnet.ndarray.Activation,act_type,"DD: {'relu', 'sigmoid', 'softrelu', 'softsign', 'tanh'}, required",QSTR required,,,,,,,QSTR
788,1064,mxnet.ndarray.UpSampling,sample_type,"DD: {'bilinear', 'nearest'}, required",QSTR required,,,,,,,QSTR
789,295,mxnet.gluon.nn.MaxPool1D,layout,"Dimension ordering of data and out ('NCW' or 'NWC'). 'N', 'C', 'W' stands for batch, channel, and width (time) dimensions respectively. Pooling is applied on the W dimension.",QSTR stands for batch channel and width BSTR dimensions respectively,,,,,,,
790,292,mxnet.gluon.nn.Conv2D,layout,"Dimension ordering of data and weight. Only supports 'NCHW' and 'NHWC' layout for now. 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the 'H' and 'W' dimensions.",QSTR stands for batch channel height and width dimensions respectively,,,,,,,
791,298,mxnet.gluon.nn.MaxPool2D,layout,"Dimension ordering of data and out ('NCHW' or 'NHWC'). 'N', 'C', 'H', 'W' stands for batch, channel, height, and width dimensions respectively. padding is applied on 'H' and 'W' dimension.",QSTR stands for batch channel height and width dimensions respectively,,,,,,,
792,301,mxnet.gluon.nn.MaxPool3D,layout,"Dimension ordering of data and out ('NCDHW' or 'NDHWC'). 'N', 'C', 'H', 'W', 'D' stands for batch, channel, height, width and depth dimensions respectively. padding is applied on 'D', 'H' and 'W' dimension.",QSTR stands for batch channel height width and depth dimensions respectively,,,,,,,
793,491,mxnet.ndarray.mp_lamb_update_phase2,r1,r1,ONE_WORD r1,,,,,,,
794,492,mxnet.ndarray.op.mp_lamb_update_phase2,r2,r2,ONE_WORD r2,,,,,,,
795,548,mxnet.io.ImageRecordIter,seed_aug,Random seed for augmentations.,Random PARAM for augmentations,,,,,,,
796,565,mxnet.ndarray.ROIPooling,spatial_scale,Ratio of input feature map height (or w) to raw image height (or w). Equals the reciprocal of total stride in convolutional layers,Ratio of input feature map height BSTR,numeric,,,,,,
797,228,mxnet.gluon.contrib.rnn.Conv1DGRUCell,h2h_dilate,Recurrent convolution dilate.,Recurrent convolution dilate,,,,,,,
798,230,mxnet.gluon.contrib.rnn.Conv2DLSTMCell,h2h_kernel,Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.,Recurrent convolution kernel sizes,int,,,,,"[0,inf)",
799,498,mxnet.ndarray.ftml_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
800,500,mxnet.ndarray.op.rmsprop_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
801,501,mxnet.ndarray.op.signsgd_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
802,502,mxnet.ndarray.signsgd_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
803,503,mxnet.ndarray.sparse.adam_update,rescale_grad,Rescale gradient to grad = rescale_grad*grad.,Rescale gradient to PARAM rescale_grad PARAM,,,,,,,
804,318,mxnet.contrib.ndarray.BilinearResize2D,like,Resize data to it's shape,Resize PARAM to it shape,,,,,,,
805,350,mxnet.ndarray.contrib.BilinearResize2D,mode,"resizing mode. ""simple"" - output height equals parameter ""height"" if ""scale_height"" parameter is not defined or input height multiplied by ""scale_height"" otherwise. Same for width;""odd_scale"" - if original height or width is odd, then result height is calculated like result_h = (original_h - 1) * scale + 1; for scale > 1 the result shape would be like if we did deconvolution with kernel = (1, 1) and stride = (height_scale, width_scale); and for scale < 1 shape would be like we did convolution with kernel = (1, 1) and stride = (int(1 / height_scale), int( 1/ width_scale);""like"" - resize first input to the height and width of second input; ""to_even_down"" - resize input to nearest lower even height and width (if original height is odd then result height = original height - 1);""to_even_up"" - resize input to nearest bigger even height and width (if original height is odd then result height = original height + 1);""to_odd_down"" - resize input to nearest odd height and width (if original height is odd then result height = original height - 1);""to_odd_up"" - resize input to nearest odd height and width (if original height is odd then result height = original height + 1);",resizing mode,,,,,,,
806,518,mxnet.image.copyMakeBorder,right,Right margin.,right margin,,,,,,,
807,1066,mxnet.gluon.contrib.rnn.Conv3DLSTMCell,params,"DD: RNNParams, default None",RNNParams default None,,,,,,,
808,1067,mxnet.gluon.contrib.rnn.Conv3DRNNCell,params,"DD: RNNParams, default None",RNNParams default None,,,,,,,
809,1068,mxnet.gluon.contrib.rnn.Conv3DGRUCell,params,"DD: RNNParams, default None",RNNParams default None,,,,,,,
810,472,mxnet.contrib.ndarray.ROIAlign,pooled_size,"ROI Align output roi feature map height and width: (h, w)",ROI Align output roi feature map height and width BSTR,,,,BSTR,,,
811,474,mxnet.ndarray.op.ROIPooling,pooled_size,"ROI pooling output shape (h,w)",ROI pooling output shape BSTR,,,,BSTR,,,
812,473,mxnet.contrib.ndarray.RROIAlign,pooled_size,"RROI align output shape (h,w)",RROI align output shape BSTR,,,,BSTR,,,
813,366,mxnet.ndarray.BatchNorm,moving_mean,running mean of input,running mean of input,numeric,,,,,,
814,351,mxnet.ndarray.contrib.BilinearResize2D,mode,"resizing mode. ""simple"" - output height equals parameter ""height"" if ""scale_height"" parameter is not defined or input height multiplied by ""scale_height"" otherwise. Same for width;""odd_scale"" - if original height or width is odd, then result height is calculated like result_h = (original_h - 1) * scale + 1; for scale > 1 the result shape would be like if we did deconvolution with kernel = (1, 1) and stride = (height_scale, width_scale); and for scale < 1 shape would be like we did convolution with kernel = (1, 1) and stride = (int(1 / height_scale), int( 1/ width_scale);""like"" - resize first input to the height and width of second input; ""to_even_down"" - resize input to nearest lower even height and width (if original height is odd then result height = original height - 1);""to_even_up"" - resize input to nearest bigger even height and width (if original height is odd then result height = original height + 1);""to_odd_down"" - resize input to nearest odd height and width (if original height is odd then result height = original height - 1);""to_odd_up"" - resize input to nearest odd height and width (if original height is odd then result height = original height + 1);",Same for PARAM QSTR if original PARAM or PARAM is odd then result PARAM is calculated PARAM result_h BSTR scale CONSTANT_NUM for scale REXPR the result shape would be PARAM if we did deconvolution with kernel BSTR and stride BSTR and for scale REXPR shape would be PARAM we did convolution with kernel BSTR and stride BSTR PARAM resize first input to the PARAM and PARAM of second input QSTR resize input to nearest lower even PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM QSTR resize input to nearest bigger even PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM QSTR resize input to nearest odd PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM QSTR resize input to nearest odd PARAM and PARAM if original PARAM is odd then result PARAM original PARAM CONSTANT_NUM,,,,,,,QSTR
815,531,mxnet.ndarray.op.random_pdf_uniform,sample,Samples from the distributions.,Samples from the distributions,,,,,,,
816,532,mxnet.ndarray.random_pdf_dirichlet,sample,Samples from the distributions.,Samples from the distributions,,,,,,,
817,533,mxnet.ndarray.random_pdf_exponential,sample,Samples from the distributions.,Samples from the distributions,,,,,,,
818,547,mxnet.contrib.ndarray.BilinearResize2D,scale_width,"sampling scale of the width (optional, used in modes ""scale"" and ""odd_scale"")",sampling scale of the PARAM optional used in modes QSTR,,,,,,,
819,538,mxnet.contrib.ndarray.backward_gradientmultiplier,scalar,scalar input,scalar input,,,,,0,,
820,1070,mxnet.ndarray.subtract,lhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
821,1071,mxnet.ndarray.minimum,lhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
822,1072,mxnet.ndarray.minimum,rhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
823,1073,mxnet.ndarray.equal,rhs,DD: scalar or mxnet.ndarray.array,scalar or mxnet D_STRUCTURE D_STRUCTURE,,,D_STRUCTURE,,0,,
824,1074,mxnet.ndarray.sparse.subtract,rhs,DD: scalar or mxnet.ndarray.sparse.array,scalar or mxnet D_STRUCTURE sparse D_STRUCTURE,,,D_STRUCTURE,,0,,
825,1075,mxnet.ndarray.sparse.add,lhs,DD: scalar or mxnet.ndarray.sparse.array,scalar or mxnet D_STRUCTURE sparse D_STRUCTURE,,,D_STRUCTURE,,0,,
826,510,mxnet.ndarray.equal,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",Second D_STRUCTURE to be compared,,,D_STRUCTURE,,,,
827,512,mxnet.ndarray.minimum,rhs,"Second array to be compared. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.",Second D_STRUCTURE to be compared,,,D_STRUCTURE,,,,
828,517,mxnet.ndarray.sparse.subtract,rhs,"Second array to be subtracted. If `lhs.shape != rhs.shape`, they must be broadcastable to a common shape.__spec__",Second D_STRUCTURE to be subtracted,,,D_STRUCTURE,,,,
829,508,mxnet.ndarray.elemwise_add,rhs,second input,second input,,,,,,,
830,514,mxnet.ndarray.op.elemwise_mul,rhs,second input,second input,,,,,,,
831,515,mxnet.ndarray.sparse.elemwise_sub,rhs,second input,second input,,,,,,,
832,506,mxnet.ndarray.broadcast_logical_or,rhs,Second input to the function,Second input to the function,,,,,,,
833,507,mxnet.ndarray.broadcast_sub,rhs,Second input to the function,Second input to the function,,,,,,,
834,513,mxnet.ndarray.op.broadcast_equal,rhs,Second input to the function,Second input to the function,,,,,,,
835,12,mxnet.gluon.nn.Dense,activation,"Activation function to use. See help on Activation layer. If you don't specify anything, no activation is applied (ie. ""linear"" activation: a(x) = x).",See help on activation layer,,,,,,,
836,231,mxnet.contrib.ndarray.interleaved_matmul_encdec_qk,heads,Set number of heads,Set number of heads,,,,,,,
837,74,mxnet.ndarray.ctc_loss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",Set the PARAM that is reserved for blank PARAM If QSTR CONSTANT_NUM th PARAM is reserved and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
838,76,mxnet.ndarray.CTCLoss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",Set the PARAM that is reserved for blank PARAM If QSTR CONSTANT_NUM th PARAM is reserved and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
839,78,mxnet.ndarray.op.ctc_loss,blank_label,"Set the label that is reserved for blank label.If ""first"", 0-th label is reserved, and label values for tokens in the vocabulary are between `1` and `alphabet_size-1`, and the padding mask is `-1`. If ""last"", last label value `alphabet_size-1` is reserved for blank label instead, and label values for tokens in the vocabulary are between `0` and `alphabet_size-2`, and the padding mask is `0`.",Set the PARAM that is reserved for blank PARAM If QSTR CONSTANT_NUM th PARAM is reserved and PARAM values for tokens in the vocabulary are between CONSTANT_NUM and QSTR and the padding mask is CONSTANT_NUM,,,,,,,QSTR
840,1076,mxnet.ndarray.Pooling,kernel,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
841,1077,mxnet.ndarray.transpose,axes,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
842,1078,mxnet.ndarray.op.sample_exponential,shape,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
843,1079,mxnet.ndarray.op.reshape,shape,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
844,1080,mxnet.ndarray.op.Deconvolution,target_shape,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
845,1081,mxnet.ndarray.op.sample_gamma,shape,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
846,1082,mxnet.ndarray.sample_uniform,shape,"DD: Shape(tuple), optional, default=[]",Shape BSTR optional default,int,,tuple,,1,"[0,inf)",
847,1083,mxnet.ndarray.op.random_uniform,shape,"DD: Shape(tuple), optional, default=None",Shape BSTR optional default None,int,,tuple,,1,"[0,inf)",
848,1084,mxnet.contrib.ndarray.ROIAlign,pooled_size,"DD: Shape(tuple), required",Shape BSTR required,int,,tuple,,1,"[0,inf)",
849,1085,mxnet.contrib.ndarray.RROIAlign,pooled_size,"DD: Shape(tuple), required",Shape BSTR required,int,,tuple,,1,"[0,inf)",
850,1086,mxnet.ndarray.op.ROIPooling,pooled_size,"DD: Shape(tuple), required",Shape BSTR required,int,,tuple,,1,"[0,inf)",
851,66,mxnet.ndarray.contrib.hawkesll,beta,"Shape (K,) The decay parameter for each process",Shape BSTR The decay parameter for each process,,,,BSTR,,,
852,571,mxnet.contrib.ndarray.hawkesll,state,"Shape (N, K) the Hawkes state for each process",Shape BSTR the Hawkes state for each process,,,,BSTR,,,
853,164,mxnet.image.CreateAugmenter,data_shape,Shape for output data,Shape for output data,int,,,,1,"[0,inf)",
854,551,mxnet.ndarray.op.random_uniform,shape,Shape of the output.,shape of the output,int,,,,1,"[0,inf)",
855,579,mxnet.ndarray.op.Deconvolution,target_shape,"Shape of the output tensor: (w,), (h, w) or (d, h, w).",Shape of the output D_STRUCTURE BSTR,int,,,,1,"[0,inf)",
856,1087,mxnet.ndarray.op.nanprod,axis,"DD: Shape or None, optional, default=None",Shape or None optional default None,int,,,,1,"[0,inf)",
857,1088,mxnet.ndarray.op.max,axis,"DD: Shape or None, optional, default=None",Shape or None optional default None,int,,,,1,"[0,inf)",
858,553,mxnet.ndarray.op.sample_exponential,shape,Shape to be sampled from each random distribution.,shape to be sampled from each random distribution,int,,,,1,"[0,inf)",
859,554,mxnet.ndarray.op.sample_gamma,shape,Shape to be sampled from each random distribution.,shape to be sampled from each random distribution,int,,,,1,"[0,inf)",
860,558,mxnet.ndarray.sample_uniform,shape,Shape to be sampled from each random distribution.,shape to be sampled from each random distribution,int,,,,1,"[0,inf)",
861,22,mxnet.ndarray.random.gamma,alpha,The shape of the gamma distribution. Should be greater than zero.,Should be greater than zero,,,,,,"[0,inf)",
862,471,mxnet.gluon.nn.AvgPool1D,pool_size,Size of the average pooling windows.,Size of the average pooling windows,int,,,,,"[0,inf)",
863,19,mxnet.gluon.nn.LeakyReLU,alpha,slope coefficient for the negative half axis. Must be >= 0.,slope coefficient for the negative half axis,numeric,,,,,,
864,195,mxnet.gluon.nn.LayerNorm,epsilon,Small float added to variance to avoid dividing by zero.,Small D_TYPE added to variance to avoid dividing by zero,D_TYPE,,,,,,
865,356,mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",So if all indices mentioned are too large they are replaced by the PARAM that addresses the last element along an PARAM,,,,,,,
866,362,mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",So if all PARAM mentioned are too large they are replaced by the index that addresses the last element along an PARAM,,,,,,,
867,121,mxnet.ndarray.contrib.backward_gradientmultiplier,data,source input,source input,,,,,,,
868,144,mxnet.ndarray.op.transpose,data,Source input,Source input,,,,,,,
869,161,mxnet.ndarray.transpose,data,Source input,Source input,,,,,,,
870,574,mxnet.ndarray.contrib.arange_like,step,Spacing between values.,Spacing between values,,,,,,,
871,169,mxnet.gluon.nn.Conv3D,dilation,Specifies the dilation rate to use for dilated convolution.,Specifies the dilation rate to use for dilated convolution,numeric,,,,,,
872,279,mxnet.gluon.nn.Conv1DTranspose,kernel_size,Specifies the dimensions of the convolution window.,Specifies the dimensions of the convolution window,int,,,,1,,
873,357,mxnet.ndarray.pick,mode,"Specify how out-of-bound indices behave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis.  ""wrap"" means to wrap around.",Specify how PARAM of bound indices behave,,,,,,,
874,363,mxnet.ndarray.take,mode,"Specify how out-of-bound indices bahave. Default is ""clip"". ""clip"" means clip to the range. So, if all indices mentioned are too large, they are replaced by the index that addresses the last element along an axis. ""wrap"" means to wrap around. ""raise"" means to raise an error when index out of range.",Specify how PARAM of bound PARAM bahave,,,,,,,
875,575,mxnet.gluon.nn.Conv3DTranspose,strides,Specify the strides of the convolution.,Specify the strides of the convolution,int,,,,,"[0,inf)",
876,546,mxnet.ndarray.random.randn,scale,Standard deviation (spread or width) of the distribution.,Standard deviation BSTR of the distribution,numeric,,,,,,
877,545,mxnet.ndarray.op.random_normal,scale,Standard deviation of the distribution.,Standard deviation of the distribution,numeric,,,,,,
878,570,mxnet.ndarray.arange,start,Start of interval. The default start value is 0.,start of interval,,,,,,,
879,441,mxnet.ndarray.random.normal,out,Store output to an existing NDArray.,Store output to an existing D_STRUCTURE,,,,,,,
880,1092,mxnet.gluon.nn.SymbolBlock,inputs,DD: Symbol or list of Symbol,Symbol or D_STRUCTURE of Symbol,,,D_STRUCTURE,,,,
881,302,mxnet.gluon.rnn.RNN,layout,"The format of input and output tensors. T, N and C stand for sequence length, batch size, and feature dimensions respectively.",T N and C stand for D_STRUCTURE length batch size and feature dimensions respectively,,,,,,,
882,38,mxnet.ndarray.transpose,axes,Target axis order. By default the axes will be inverted.,Target axis order,int,,,,,"[0,inf)",
883,14,mxnet.gluon.rnn.RNN,activation,The activation function to use.,The activation function to use,,,,,,,
884,36,mxnet.gluon.nn.Dropout,axes,"The axes on which dropout mask is shared. If empty, regular dropout is applied.",The axes on which dropout mask is shared,int,,,,,,
885,46,mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The axis or axes along which to perform the reduction,int,,,,,"[0,inf)",
886,52,mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The axis or axes along which to perform the reduction,int,,,,,"[0,inf)",
887,61,mxnet.gluon.contrib.rnn.VariationalDropoutCell,base_cell,The cell on which to perform variational dropout.,The cell on which to perform variational dropout,,,,,,,
888,90,mxnet.gluon.model_zoo.vision.densenet121,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
889,91,mxnet.gluon.model_zoo.vision.densenet161,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
890,92,mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
891,93,mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
892,94,mxnet.gluon.model_zoo.vision.resnet152_v1,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
893,95,mxnet.gluon.model_zoo.vision.vgg16_bn,ctx,The context in which to load the pretrained weights.,The context in which to load the PARAM weights,,,,,,,
894,54,mxnet.ndarray.SequenceLast,axis,The sequence axis. Only values of 0 and 1 are currently supported.,The D_STRUCTURE axis,int,,,,,"[0,inf)",
895,175,mxnet.ndarray.arange,dtype,The data type of the NDArray. The default datatype is np.float32.,The data type of the D_STRUCTURE,dtype,,,,,,
896,364,mxnet.ndarray.multi_sgd_mom_update,momentum,The decay rate of momentum estimates at each epoch.,The decay rate of momentum estimates at each epoch,numeric,,,,0,,
897,365,mxnet.ndarray.op.multi_mp_sgd_mom_update,momentum,The decay rate of momentum estimates at each epoch.,The decay rate of momentum estimates at each epoch,numeric,,,,0,,
898,45,mxnet.ndarray.op.max,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The default axis BSTR,,,,,,,
899,51,mxnet.ndarray.op.nanprod,axis,"The axis or axes along which to perform the reduction.  The default, axis=(), will compute over all elements into a scalar array with shape (1,). If axis is int, a reduction is performed on a particular axis. If axis is a tuple of ints, a reduction is performed on all the axes specified in the tuple. If exclude is true, reduction will be performed on the axes that are NOT in axis instead. Negative values means indexing from right to left.  ",The default axis BSTR,,,,,,,
900,39,mxnet.ndarray.op.cumsum,axis,Axis along which the cumulative sum is computed. The default (None) is to compute the cumsum over the flattened array.,The default BSTR is to compute the cumsum over the flattened D_STRUCTURE,,,,,,,
901,176,mxnet.ndarray.arange,dtype,The data type of the NDArray. The default datatype is np.float32.,The default datatype is D_TYPE,,,,,,,
902,569,mxnet.ndarray.arange,start,Start of interval. The default start value is 0.,The default start value is CONSTANT_NUM,,,,,,,
903,235,mxnet.ndarray.random.uniform,high,Upper boundary of the output interval. All values generated will be less than high. The default value is 1.0.,The default value is CONSTANT_NUM,,,,,,,
904,324,mxnet.ndarray.random.uniform,low,Lower boundary of the output interval. All values generated will be greater than or equal to low. The default value is 0.,The default value is CONSTANT_NUM,,,,,,,
905,211,mxnet.ndarray.op.dot,forward_stype,"The desired storage type of the forward output given by user, if thecombination of input storage types and this hint does not matchany implemented ones, the dot operator will perform fallback operationand still produce an output of the desired storage type.",The desired storage type of the forward output given by user if thecombination of input storage types and this hint does not matchany implemented ones the dot operator will perform fallback operationand still produce an output of the desired storage type,,,,,,,QSTR
906,577,mxnet.test_utils.verify_generator,success_rate,The desired success rate,The desired success rate,numeric,,,,0,,
907,166,mxnet.context.cpu,device_id,The device id of the device. device_id is not needed for CPU. This is included to make interface compatible with GPU.,The device id of the device,int,,,,0,"[0,inf)",
908,606,mxnet.ndarray.Embedding,weight,The embedding weight matrix.,The embedding weight matrix,numeric,,,,,,
909,204,mxnet.test_utils.check_symbolic_forward,expected,The expected output value   if type is list of np.ndarrayContains arrays corresponding to exe.outputs.,The expected output value if type is D_STRUCTURE of np ndarrayContains D_STRUCTURE corresponding to exe outputs,,,D_STRUCTURE,,,,
910,210,mxnet.ndarray.utils.save,fname,The filename.,The filename,string,,,,0,,
911,307,mxnet.ndarray.batch_dot,lhs,The first input,The first input,,,,,,,
912,198,mxnet.test_utils.assert_almost_equal,equal_nan,The flag determining how to treat NAN values in comparison,The flag determining how to treat NAN values in comparison,,,,,,,
913,303,mxnet.gluon.rnn.RNN,layout,"The format of input and output tensors. T, N and C stand for sequence length, batch size, and feature dimensions respectively.",The format of input and output D_STRUCTURE,,,,,,,
914,249,mxnet.ndarray.pick,index,The index array,The index D_STRUCTURE,,,D_STRUCTURE,,,,
915,27,mxnet.contrib.autograd.grad,argnum,The index of argument to calculate gradient for.,The index of argument to calculate gradient for,int,,,,0,,
916,115,mxnet.contrib.ndarray.bipartite_matching,data,The input,The input,,,,,,,
917,118,mxnet.ndarray.argmin,data,The input,The input,,,,,,,
918,119,mxnet.ndarray.broadcast_to,data,The input,The input,,,,,,,
919,125,mxnet.ndarray.image.random_lighting,data,The input.,The input,,,,,,,
920,127,mxnet.ndarray.nanprod,data,The input,The input,,,,,,,
921,129,mxnet.ndarray.op.amp_cast,data,The input.,The input,,,,,,,
922,159,mxnet.ndarray.sum,data,The input,The input,,,,,,,
923,120,mxnet.ndarray.choose_element_0index,data,The input array,The input D_STRUCTURE,,,D_STRUCTURE,,,,
924,124,mxnet.ndarray.expm1,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
925,130,mxnet.ndarray.op.arccos,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
926,133,mxnet.ndarray.op.exp,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
927,135,mxnet.ndarray.op.log,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
928,136,mxnet.ndarray.op.rcbrt,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
929,142,mxnet.ndarray.op.square,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
930,146,mxnet.ndarray.radians,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
931,150,mxnet.ndarray.sign,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
932,151,mxnet.ndarray.sin,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
933,153,mxnet.ndarray.sparse.arcsinh,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
934,154,mxnet.ndarray.sparse.cosh,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
935,155,mxnet.ndarray.sparse.log,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
936,156,mxnet.ndarray.sparse.log2,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
937,158,mxnet.ndarray.sqrt,data,The input array.,The input D_STRUCTURE,,,D_STRUCTURE,,,,
938,157,mxnet.ndarray.sparse.retain,data,The input array for sparse_retain operator.,The input D_STRUCTURE for sparse_retain operator,,,D_STRUCTURE,,,,
939,137,mxnet.ndarray.op.ROIPooling,data,"The input array to the pooling operator,  a 4D Feature maps",The input D_STRUCTURE to the pooling operator a CONSTANT_NUM D Feature maps,,,D_STRUCTURE,,CONSTANT_NUM,,
940,244,mxnet.ndarray.op.SoftmaxOutput,ignore_label,"The instances whose labels == ignore_label will be ignored during backward, if use_ignore is set to `true`).",The instances whose labels ignore_label will be ignored during backward if PARAM is set to CONSTANT_BOOL,,,,,,,
941,345,mxnet.contrib.ndarray.hawkesll,max_time,the length of the interval where the processes were sampled,the length of the interval where the processes were sampled,numeric,,,,,"[0,inf)",
942,339,mxnet.ndarray.BatchNorm,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to by quantized batch norm op to calculate primitive scale.Note: this calib_range is to calib bn output.",The maximum scalar value in the form of D_TYPE obtained through calibration,D_TYPE,,,,0,,
943,341,mxnet.ndarray.contrib.requantize,max_calib_range,"The maximum scalar value in the form of float32 obtained through calibration. If present, it will be used to requantize the int32 data into int8.",The maximum scalar value in the form of D_TYPE obtained through calibration,D_TYPE,,,,0,,
944,344,mxnet.ndarray.contrib.quantize,max_range,The maximum scalar value possibly produced for the input,The maximum scalar value possibly produced for the input,,,,,0,,
945,347,mxnet.io.ImageRecordIter,mean_g,The mean value to be subtracted on the G channel,The mean value to be subtracted on the G channel,numeric,,,,,,
946,348,mxnet.ndarray.contrib.quantize,min_range,The minimum scalar value possibly produced for the input,The minimum scalar value possibly produced for the input,,,,,0,,
947,470,mxnet.callback.log_train_metric,period,The number of batch to log the training evaluation metric.,The number of batch to log the training evaluation metric,int,,,,0,"[0,inf)",
948,255,mxnet.gluon.rnn.RNN,input_size,"The number of expected features in the input x. If not specified, it will be inferred from input.",The number of expected features in the input x,int,,,,0,"[0,inf)",
949,233,mxnet.gluon.rnn.LSTM,hidden_size,The number of features in the hidden state h.,The number of features in the hidden state h,int,,,,0,"[0,inf)",
950,248,mxnet.gluon.nn.Conv2DTranspose,in_channels,"The number of input channels to this layer. If not specified, initialization will be deferred to the first time forward is called and in_channels will be inferred from the shape of input data.",The number of input PARAM to this layer,int,,,,0,"[0,inf)",
951,380,mxnet.contrib.ndarray.calibrate_entropy,num_quantized_bins,The number of quantized bins.,The number of quantized bins,int,,,,0,"[0,inf)",
952,497,mxnet.ndarray.op.repeat,repeats,The number of repetitions for each element.,The number of repetitions for each element,int,,,,0,"[0,inf)",
953,557,mxnet.ndarray.random.gamma,shape,"The number of samples to draw. If shape is, e.g., (m, n) and alpha and beta are scalars, output shape will be (m, n). If alpha and beta are NDArrays with shape, e.g., (x, y), then output will have shape (x, y, m, n), where m*n samples are drawn for each [alpha, beta) pair.",The number of samples to draw,int,,,,0,"[0,inf)",
954,371,mxnet.test_utils.verify_generator,nsamples,The number of samples to generate for the testing,The number of samples to generate for the testing,int,,,,0,"[0,inf)",
955,596,mxnet.contrib.ndarray.hawkesll,valid_length,The number of valid points in the process,The number of valid points in the process,int,,,,0,"[0,inf)",
956,418,mxnet.ndarray.ones,out,The output NDArray (default is None).,The output D_STRUCTURE BSTR,,,D_STRUCTURE,,,,
957,385,mxnet.contrib.ndarray.AdaptiveAvgPooling2D,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
958,386,mxnet.contrib.ndarray.allclose,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
959,387,mxnet.contrib.ndarray.fft,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
960,388,mxnet.contrib.ndarray.getnnz,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
961,389,mxnet.contrib.ndarray.MultiBoxDetection,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
962,390,mxnet.contrib.ndarray.ROIAlign,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
963,391,mxnet.contrib.ndarray.SparseEmbedding,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
964,392,mxnet.image.imresize,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
965,393,mxnet.ndarray.Activation,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
966,394,mxnet.ndarray.arccos,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
967,395,mxnet.ndarray.arctan,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
968,396,mxnet.ndarray.arctanh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
969,397,mxnet.ndarray.broadcast_axes,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
970,398,mxnet.ndarray.broadcast_greater,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
971,399,mxnet.ndarray.broadcast_logical_and,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
972,400,mxnet.ndarray.broadcast_mul,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
973,401,mxnet.ndarray.broadcast_plus,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
974,402,mxnet.ndarray.cast_storage,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
975,403,mxnet.ndarray.contrib.backward_hawkesll,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
976,404,mxnet.ndarray.contrib.CTCLoss,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
977,405,mxnet.ndarray.contrib.quantized_batch_norm,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
978,406,mxnet.ndarray.contrib.quantized_conv,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
979,407,mxnet.ndarray.contrib.quantized_fully_connected,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
980,408,mxnet.ndarray.contrib.round_ste,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
981,409,mxnet.ndarray.Dropout,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
982,410,mxnet.ndarray.ElementWiseSum,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
983,411,mxnet.ndarray.erfinv,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
984,412,mxnet.ndarray.LayerNorm,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
985,413,mxnet.ndarray.linalg_gelqf,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
986,414,mxnet.ndarray.linalg_trsm,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
987,415,mxnet.ndarray.MAERegressionOutput,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
988,416,mxnet.ndarray.MakeLoss,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
989,417,mxnet.ndarray.multi_mp_sgd_mom_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
990,419,mxnet.ndarray.ones_like,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
991,420,mxnet.ndarray.op.Activation,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
992,421,mxnet.ndarray.op.arccosh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
993,422,mxnet.ndarray.op.broadcast_greater_equal,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
994,423,mxnet.ndarray.op.broadcast_to,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
995,424,mxnet.ndarray.op.cast_storage,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
996,425,mxnet.ndarray.op.ceil,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
997,426,mxnet.ndarray.op.concat,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
998,427,mxnet.ndarray.op.diag,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
999,428,mxnet.ndarray.op.exp,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1000,429,mxnet.ndarray.op.fix,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1001,430,mxnet.ndarray.op.ftml_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1002,431,mxnet.ndarray.op.linalg_gelqf,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1003,432,mxnet.ndarray.op.log1p,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1004,433,mxnet.ndarray.op.mp_lamb_update_phase1,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1005,434,mxnet.ndarray.op.nag_mom_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1006,435,mxnet.ndarray.op.nansum,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1007,436,mxnet.ndarray.op.pad,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1008,437,mxnet.ndarray.op.random_poisson,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1009,438,mxnet.ndarray.op.sample_poisson,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1010,439,mxnet.ndarray.op.slice_axis,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1011,440,mxnet.ndarray.preloaded_multi_mp_sgd_update,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1012,442,mxnet.ndarray.random.normal_like,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1013,443,mxnet.ndarray.sample_exponential,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1014,444,mxnet.ndarray.SequenceReverse,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1015,445,mxnet.ndarray.shuffle,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1016,446,mxnet.ndarray.sinh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1017,447,mxnet.ndarray.space_to_depth,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1018,448,mxnet.ndarray.sparse.cosh,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1019,449,mxnet.ndarray.sparse.elemwise_add,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1020,450,mxnet.ndarray.sparse.floor,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1021,451,mxnet.ndarray.sparse.log,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1022,452,mxnet.ndarray.sqrt,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1023,453,mxnet.ndarray.take,out,The output NDArray to hold the result.,The output D_STRUCTURE to hold the result,,,D_STRUCTURE,,,,
1024,23,mxnet.ndarray.random.gamma,alpha,The shape of the gamma distribution. Should be greater than zero.,The PARAM of the gamma distribution,int,,,,1,"[0,inf)",
1025,600,mxnet.ndarray.mp_nag_mom_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,The penalty scales with the square of the magnitude of each PARAM,,,,,,,
1026,602,mxnet.ndarray.op.ftrl_update,wd,Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.,The penalty scales with the square of the magnitude of each PARAM,,,,,,,
1027,83,mxnet.contrib.quantization.quantize_model,calib_mode,"If calib_mode='none', no calibration will be used and the thresholds for requantization after the corresponding layers will be calculated at runtime by calling min and max operators. The quantized models generated in this mode are normally 10-20% slower than those with calibrations during inference. If calib_mode='naive', the min and max values of the layer outputs from a calibration dataset will be directly taken as the thresholds for quantization. If calib_mode='entropy' (default mode), the thresholds for quantization will be derived such that the KL divergence between the distributions of FP32 layer outputs and quantized layer outputs is minimized based upon the calibration dataset.",The quantized models generated in this mode are normally CONSTANT_NUM slower than those with calibrations during inference,,,,,,,
1028,56,mxnet.ndarray.diag,axis2,The second axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,The second axis of the sub D_STRUCTURE of interest,int,,,,,"[0,inf)",
1029,58,mxnet.ndarray.op.diag,axis2,The second axis of the sub-arrays of interest. Ignored when the input is a 1-D array.,The second axis of the sub D_STRUCTURE of interest,int,,,,,"[0,inf)",
1030,170,mxnet.ndarray.SwapAxis,dim2,the second axis to be swapped.,the second axis to be swapped,int,,,,,"[0,inf)",
1031,205,mxnet.contrib.ndarray.MultiProposal,feature_stride,"The size of the receptive field each unit in the convolution layer of the rpn,for example the product of all stride's prior to this layer.",The size of the receptive field each unit in the convolution layer of the rpn for example the product of all stride prior to this layer,numeric,,,,,"[0,inf)",
1032,576,mxnet.ndarray.zeros,stype,"The storage type of the empty array, such as 'row_sparse', 'csr', etc.",The storage type of the empty D_STRUCTURE such as QSTR etc,,,,,,,QSTR
1033,552,mxnet.ndarray.op.reshape,shape,The target shape,The target shape,int,,,,1,"[0,inf)",
1034,597,mxnet.ndarray.op.SequenceMask,value,The value to be used as a mask.,The value to be used as a mask,,,,,,,
1035,256,mxnet.gluon.nn.SymbolBlock,inputs,The Variables in output's argument that should be used as inputs.,The Variables in output argument that should be used as inputs,,,,,,,
1036,167,mxnet.context.cpu,device_id,The device id of the device. device_id is not needed for CPU. This is included to make interface compatible with GPU.,This is included to make interface compatible with GPU,,,,,,,
1037,16,mxnet.metric.np,allow_extra_outputs,"Whether prediction output is allowed to have extra outputs. This is useful in cases like RNN where states are also part of output which can then be fed back to the RNN in the next step. By default, extra outputs are not allowed.",This is useful in cases like RNN where states are also part of output which can then be fed back to the RNN in the next step,,,,,,,
1038,217,mxnet.ndarray.sample_multinomial,get_prob,"Whether to also return the log probability of sampled result. This is usually used for differentiating through stochastic variables, e.g. in reinforcement learning.",This is usually used for differentiating through stochastic variables e g,,,,,,,
1039,587,mxnet.contrib.ndarray.quantized_batch_norm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,This will force change batch norm into a scale shift operator,,,,,,,
1040,589,mxnet.contrib.ndarray.SyncBatchNorm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,This will force change batch norm into a scale shift operator,,,,,,,
1041,591,mxnet.ndarray.BatchNorm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,This will force change batch norm into a scale shift operator,,,,,,,
1042,376,mxnet.ndarray.op.GroupNorm,num_groups,Total number of groups.,Total number of groups,int,,,,0,"[0,inf)",
1043,113,mxnet.ndarray.op.Convolution,cudnn_off,Turn off cudnn for this layer.,Turn off cudnn for this layer,,,,,,,
1044,236,mxnet.ndarray.random.uniform,high,Upper boundary of the output interval. All values generated will be less than high. The default value is 1.0.,Upper boundary of the output interval,,,,,,,
1045,536,mxnet.ndarray.UpSampling,sample_type,upsampling method,upsampling method,,,,,,,
1046,583,mxnet.ndarray.op.linalg_trmm,transpose,Use transposed of the triangular matrix,Use transposed of the triangular matrix,,,,,,,
1047,34,mxnet.test_utils.numeric_grad,aux_states,Auxiliary states values used as location to compute gradient Maps the name of aux_states to the corresponding numpy.ndarray. Value of all the auxiliary arguments must be provided.,Value of all the auxiliary arguments must be provided,,,,,,,
1048,573,mxnet.ndarray.contrib.box_decode,std2,value to be divided from the 3rd encoded values,value to be divided from the 3rd encoded values,numeric,,,,,,
1049,250,mxnet.contrib.ndarray.SparseEmbedding,input_dim,Vocabulary size of the input indices.,Vocabulary size of the input indices,int,,,,,"[0,inf)",
1050,604,mxnet.contrib.ndarray.quantized_conv,weight,weight.,ONE_WORD weight,numeric,,,,,,
1051,605,mxnet.contrib.ndarray.quantized_fully_connected,weight,weight.,ONE_WORD weight,numeric,,,,,,
1052,608,mxnet.ndarray.op.ftml_update,weight,Weight,ONE_WORD weight,numeric,,,,,,
1053,609,mxnet.ndarray.op.mp_sgd_mom_update,weight,Weight,ONE_WORD weight,numeric,,,,,,
1054,610,mxnet.ndarray.op.sgd_mom_update,weight,Weight,ONE_WORD weight,numeric,,,,,,
1055,611,mxnet.ndarray.op.signum_update,weight,Weight,ONE_WORD weight,numeric,,,,,,
1056,612,mxnet.ndarray.rmsprop_update,weight,Weight,ONE_WORD weight,numeric,,,,,,
1057,603,mxnet.contrib.ndarray.DeformableConvolution,weight,Weight matrix.,weight matrix,numeric,,,,,,
1058,607,mxnet.ndarray.op.Convolution,weight,Weight matrix.,weight matrix,numeric,,,,,,
1059,614,mxnet.ndarray.mp_lamb_update_phase1,weight32,Weight32,ONE_WORD weight32,numeric,,,,,,
1060,615,mxnet.ndarray.mp_nag_mom_update,weight32,Weight32,ONE_WORD weight32,numeric,,,,,,
1061,616,mxnet.ndarray.mp_sgd_update,weight32,Weight32,ONE_WORD weight32,numeric,,,,,,
1062,88,mxnet.gluon.nn.AvgPool1D,count_include_pad,"When 'False', will exclude padding elements when computing the average value.",When QSTR will exclude PARAM elements when computing the average value,,,,,,,
1063,543,mxnet.gluon.nn.BatchNorm,scale,"If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.",When the next layer is linear also e g,,,,,,,
1064,560,mxnet.util.set_np,shape,"A boolean value indicating whether the NumPy-shape semantics should be turned on or off. When this flag is set to True, zero-size and zero-dim shapes are all valid shapes in shape inference process, instead of treated as unknown shapes in legacy mode.",When this flag is set to CONSTANT_BOOL zero size and zero dim shapes are all valid shapes in shape inference process instead of treated as unknown shapes in legacy mode,bool,,,,0,,
1065,17,mxnet.metric.np,allow_extra_outputs,"Whether prediction output is allowed to have extra outputs. This is useful in cases like RNN where states are also part of output which can then be fed back to the RNN in the next step. By default, extra outputs are not allowed.",Whether prediction output is allowed to have extra outputs,bool,,,,0,,
1066,586,mxnet.gluon.nn.Conv2DTranspose,use_bias,Whether the layer uses a bias vector.,Whether the layer uses a bias vector,bool,,,,0,,
1067,218,mxnet.ndarray.sample_multinomial,get_prob,"Whether to also return the log probability of sampled result. This is usually used for differentiating through stochastic variables, e.g. in reinforcement learning.",Whether to also return the log probability of sampled result,bool,,,,0,,
1068,493,mxnet.image.CreateAugmenter,rand_mirror,Whether to apply horizontal flip to image with probability 0.5,Whether to apply horizontal flip to image with probability CONSTANT_NUM,bool,,,,0,,
1069,209,mxnet.contrib.ndarray.quantized_fully_connected,flatten,Whether to collapse all but the first axis of the input data tensor.,Whether to collapse all but the first axis of the input PARAM D_STRUCTURE,bool,,,,0,,
1070,370,mxnet.contrib.ndarray.quantized_fully_connected,no_bias,Whether to disable bias parameter.,Whether to disable PARAM parameter,bool,,,,0,,
1071,200,mxnet.gluon.utils.split_data,even_split,"Whether to force all slices to have the same number of elements. If True, an error will be raised when num_slice does not evenly divide data.shape[batch_axis].",Whether to force all slices to have the same number of elements,bool,,,,0,,
1072,572,mxnet.ndarray.RNN,state_outputs,Whether to have the states as symbol outputs.,Whether to have the states as symbol outputs,bool,,,,0,,
1073,483,mxnet.gluon.model_zoo.vision.alexnet,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
1074,484,mxnet.gluon.model_zoo.vision.densenet121,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
1075,485,mxnet.gluon.model_zoo.vision.get_model,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
1076,486,mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
1077,487,mxnet.gluon.model_zoo.vision.resnet50_v2,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
1078,488,mxnet.gluon.model_zoo.vision.vgg11_bn,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
1079,489,mxnet.gluon.model_zoo.vision.vgg13,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
1080,490,mxnet.gluon.model_zoo.vision.vgg19,pretrained,Whether to load the pretrained weights for model.,Whether to load the pretrained weights for model,bool,,,,0,,
1081,352,mxnet.ndarray.Dropout,mode,Whether to only turn on dropout during training or to also turn on for inference.,Whether to only turn on dropout during training or to also turn on for inference,bool,,,,0,,
1082,201,mxnet.ndarray.op.nansum,exclude,Whether to perform reduction on axis that are NOT in axis instead.,Whether to perform reduction on PARAM that are NOT in PARAM instead,bool,,,,0,,
1083,202,mxnet.ndarray.op.sum_axis,exclude,Whether to perform reduction on axis that are NOT in axis instead.,Whether to perform reduction on PARAM that are NOT in PARAM instead,bool,,,,0,,
1084,203,mxnet.ndarray.sparse.mean,exclude,Whether to perform reduction on axis that are NOT in axis instead.,Whether to perform reduction on PARAM that are NOT in PARAM instead,bool,,,,0,,
1085,87,mxnet.profiler.set_config,continuous_dump,whether to periodically dump profiling data to file,whether to periodically dump profiling data to file,bool,,,,0,,
1086,114,mxnet.ndarray.Deconvolution,cudnn_tune,Whether to pick convolution algorithm by running performance test.,Whether to pick convolution algorithm by running performance test,bool,,,,0,,
1087,334,mxnet.ndarray.RNN,lstm_state_clip_nan,"Whether to stop NaN from propagating in state by clipping it to min/max. If clipping range is not specified, this option is ignored.",Whether to stop NaN from propagating in PARAM by clipping it to min max,bool,,,,0,,
1088,593,mxnet.ndarray.op.softmin,use_length,Whether to use the length input as a mask over the data input.,Whether to use the length input as a mask over the PARAM input,bool,,,,0,,
1089,588,mxnet.contrib.ndarray.quantized_batch_norm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,Whether use global moving statistics instead of local batch norm,bool,,,,0,,
1090,590,mxnet.contrib.ndarray.SyncBatchNorm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,Whether use global moving statistics instead of local batch norm,bool,,,,0,,
1091,592,mxnet.ndarray.BatchNorm,use_global_stats,Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.,Whether use global moving statistics instead of local batch norm,bool,,,,0,,
1092,550,mxnet.gluon.utils.download,sha1_hash,Expected sha1 hash in hexadecimal digits. Will ignore existing file when hash is specified but doesn't match.,Will ignore existing file when hash is specified but doesn t match,,,,,,,
