constraints:
  dim:
    default: None
    descp: A dimension along which Softmax will be computed (so every slice along
      dim will sum to 1).
    doc_dtype: int
    normalized_default: DEFAULT None
    normalized_descp:
    - A dimension along which Softmax will be computed BSTR
    normalized_docdtype: ONE_WORD D_TYPE
inputs:
  optional:
  - dim
  required: []
link: https://pytorch.org/docs/stable/nn.html#torch.nn.Softmax
package: torch
target: Softmax
title: torch.nn.Softmax
version: 1.5.0
