constraints:
  activation:
    default: tanh
    descp: Type of activation function. If argument type is string, it's equivalent
      to nn.Activation(act_type=str). See `Activation()` for available choices. Alternatively,
      other activation blocks such as nn.LeakyReLU can be used.
    doc_dtype:
    - str
    - gluon.Block
    - default 'tanh'
    dtype:
    - string
  conv_layout:
    default: NCHW
    descp: Layout for all convolution inputs, outputs and weights. Options are 'NCHW'
      and 'NHWC'.
    doc_dtype:
    - str
    - default 'NCHW'
    dtype:
    - string
  h2h_bias_initializer:
    default: zeros
    descp: Initializer for the recurrent convolution bias vectors.
    doc_dtype:
    - str
    - Initializer
    - default zeros
    dtype:
    - string
  h2h_dilate:
    default: (1,1)
    descp: Recurrent convolution dilate.
    doc_dtype:
    - int
    - tuple of int
    - default (1, 1)
    dtype:
    - int
    ndim:
    - '1'
    shape:
    - '[2]'
    structure:
    - tuple
    - tuple(int)
  h2h_kernel:
    descp: Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.
    doc_dtype:
    - int
    - tuple of int
    dtype:
    - int
    ndim:
    - '1'
    structure:
    - tuple(int)
  h2h_weight_initializer:
    default: None
    descp: Initializer for the recurrent weights matrix, used for the input convolutions.
    doc_dtype:
    - str
    - Initializer
    dtype:
    - string
  hidden_channels:
    descp: Number of output channels.
    doc_dtype:
    - int
    dtype:
    - int
    ndim:
    - '0'
    range:
    - '[0,inf)'
  i2h_bias_initializer:
    default: zeros
    descp: Initializer for the input convolution bias vectors.
    doc_dtype:
    - str
    - Initializer
    - default zeros
    dtype:
    - string
  i2h_dilate:
    default: (1,1)
    descp: Input convolution dilate.
    doc_dtype:
    - int
    - tuple of int
    - default (1, 1)
    dtype:
    - int
    ndim:
    - '1'
    shape:
    - '[2]'
    structure:
    - tuple
    - tuple(int)
  i2h_kernel:
    descp: Input convolution kernel sizes.
    doc_dtype:
    - int
    - tuple of int
    dtype:
    - int
    ndim:
    - '1'
    structure:
    - tuple(int)
  i2h_pad:
    default: (0,0)
    descp: Pad for input convolution.
    doc_dtype:
    - int
    - tuple of int
    - default (0, 0)
    dtype:
    - int
    ndim:
    - '1'
    shape:
    - '[2]'
    structure:
    - tuple
    - tuple(int)
  i2h_weight_initializer:
    default: None
    descp: Initializer for the input weights matrix, used for the input convolutions.
    doc_dtype:
    - str
    - Initializer
    dtype:
    - string
  input_shape:
    descp: Input tensor shape at each time step for each sample, excluding dimension
      of the batch size and sequence length. Must be consistent with conv_layout.
      For example, for layout 'NCHW' the shape should be (C, H, W).
    doc_dtype:
    - tuple of int
    dtype:
    - int
    ndim:
    - '1'
    range:
    - '[0,inf)'
    structure:
    - tuple(int)
    tensor_t:
    - tensor
  params:
    default: None
    descp: Container for weight sharing between cells. Created if None.
    doc_dtype:
    - RNNParams
    - default None
  prefix:
    default: None
    descp: Prefix for name of layers (and name of weight if params is None).
    doc_dtype:
    - str
    - default `'conv_rnn_`â€™
    dtype:
    - string
inputs:
  optional:
  - i2h_pad
  - i2h_dilate
  - h2h_dilate
  - i2h_weight_initializer
  - h2h_weight_initializer
  - i2h_bias_initializer
  - h2h_bias_initializer
  - conv_layout
  - activation
  - prefix
  - params
  required:
  - input_shape
  - hidden_channels
  - i2h_kernel
  - h2h_kernel
link: https://mxnet.apache.org/versions/1.6.0/api/python/docs/api/gluon/contrib/index.html#mxnet.gluon.contrib.rnn.Conv2DRNNCell
package: mxnet
target: Conv2DRNNCell
title: mxnet.gluon.contrib.rnn.Conv2DRNNCell
version: 1.6.0
layer_constructor: true
check_nan: true
