constraints:
  accept_large_sparse: {default: 'True', descp: 'bool (default=True) If a CSR, CSC,
      COO or BSR sparse matrix is supplied and accepted by accept_sparse, accept_large_sparse=False
      will cause it to be accepted only if its indices are stored with a 32-bit dtype.'}
  accept_sparse: {default: 'False', descp: 'string, boolean or list/tuple of strings
      (default=False) String[s] representing allowed sparse matrix formats, such as
      ''csc'', ''csr'', etc. If the input is sparse but not in the allowed format,
      it will be converted to the first listed format. True allows the input to be
      any format. False means that a sparse matrix input will raise an error.'}
  allow_nd: {default: 'False', descp: boolean (default=False) Whether to allow array.ndim
      > 2.}
  array: {descp: object Input object to check / convert.}
  copy: {default: 'False', descp: 'boolean (default=False) Whether a forced copy will
      be triggered. If copy=False, a copy might be triggered by a conversion.'}
  dtype: {default: numeric, descp: 'string, type, list of types or None (default="numeric")
      Data type of result. If None, the dtype of the input is preserved. If "numeric",
      dtype is preserved unless array.dtype is object. If dtype is a list of types,
      conversion on the first type is only performed if the dtype of the input is
      not in the list.'}
  ensure_2d: {default: 'True', descp: boolean (default=True) Whether to raise a value
      error if array is not 2D.}
  ensure_min_features: {default: '1', descp: int (default=1) Make sure that the 2D
      array has some minimum number of features (columns). The default value of 1
      rejects empty datasets. This check is only enforced when the input data has
      effectively 2 dimensions or is originally 1D and ``ensure_2d`` is True. Setting
      to 0 disables this check.}
  ensure_min_samples: {default: '1', descp: int (default=1) Make sure that the array
      has a minimum number of samples in its first axis (rows for a 2D array). Setting
      to 0 disables this check.}
  estimator: {default: None, descp: 'str or estimator instance (default=None) If passed,
      include the name of the estimator in warning messages.'}
  force_all_finite: {default: 'True', descp: 'boolean or ''allow-nan'', (default=True)
      Whether to raise an error on np.inf and np.nan in array. The possibilities are:
      - True: Force all values of array to be finite. - False: accept both np.inf
      and np.nan in array. - ''allow-nan'': accept only np.nan values in array. Values
      cannot be infinite. For object dtyped data, only np.nan is checked and not np.inf.'}
  order: {default: None, descp: '''F'', ''C'' or None (default=None) Whether an array
      will be forced to be fortran or c-style. When order is None (default), then
      if copy=False, nothing is ensured about the memory layout of the output array;
      otherwise (copy=True) the memory layout of the returned array is kept as close
      as possible to the original array.'}
  warn_on_dtype: {default: None, descp: 'boolean or None, optional (default=None)
      Raise DataConversionWarning if the dtype of the input data structure does not
      match the requested dtype, causing a memory copy.'}
inputs:
  optional: [accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite,
    ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator]
  required: [array]
link: ''
package: sklearn
target: check_array
title: sklearn.utils.check_array
version: 0.24.2
