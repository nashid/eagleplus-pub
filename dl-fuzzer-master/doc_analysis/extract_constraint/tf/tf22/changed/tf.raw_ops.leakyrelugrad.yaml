constraints:
  alpha:
    default: '0.2'
    descp: An optional float. Defaults to 0.2.
    dtype:
    - float
    ndim:
    - '0'
  features:
    descp: A Tensor. Must have the same type as gradients. The features passed as
      input to the corresponding LeakyRelu operation, OR the outputs of that operation
      (both work equivalently).
    dtype:
    - dtype:&gradients
    tensor_t:
    - tf.tensor
  gradients:
    descp: 'A Tensor. Must be one of the following types: half, bfloat16, float32,
      float64. The backpropagated gradients to the corresponding LeakyRelu operation.'
    tensor_t:
    - tf.tensor
  name:
    default: None
    descp: A name for the operation (optional).
    dtype:
    - tf.string
    ndim:
    - '0'
inputs:
  optional:
  - alpha
  - name
  required:
  - gradients
  - features
link: https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/raw_ops/LeakyReluGrad
outputs:
- A Tensor. Has the same type as gradients.
package: tensorflow
target: LeakyReluGrad
title: tf.raw_ops.LeakyReluGrad
version: 2.2.0
